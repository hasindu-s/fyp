{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454d0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1405f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7adadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f39b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/16M_7_day_lag_with_price_changes.csv', \n",
    "                 usecols=['date', 'compound', 'negative', 'positive', 'daily_count', 'price_direction', 'price_change', 'lagged_close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88be8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['date'] >= '2018-08-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3327502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>daily_count</th>\n",
       "      <th>lagged_close</th>\n",
       "      <th>price_change</th>\n",
       "      <th>price_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.062261</td>\n",
       "      <td>750</td>\n",
       "      <td>7361.660156</td>\n",
       "      <td>265.380371</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>736</td>\n",
       "      <td>6792.830078</td>\n",
       "      <td>254.330078</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>746</td>\n",
       "      <td>6529.169922</td>\n",
       "      <td>449.060059</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.055598</td>\n",
       "      <td>682</td>\n",
       "      <td>6467.069824</td>\n",
       "      <td>570.510254</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.049348</td>\n",
       "      <td>642</td>\n",
       "      <td>6225.979980</td>\n",
       "      <td>967.270020</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.165424</td>\n",
       "      <td>43287</td>\n",
       "      <td>7218.371094</td>\n",
       "      <td>987.774414</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.181522</td>\n",
       "      <td>42112</td>\n",
       "      <td>7531.663574</td>\n",
       "      <td>495.604492</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>0.096216</td>\n",
       "      <td>0.155917</td>\n",
       "      <td>47978</td>\n",
       "      <td>7463.105957</td>\n",
       "      <td>179.644043</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.129012</td>\n",
       "      <td>51043</td>\n",
       "      <td>7761.243652</td>\n",
       "      <td>464.666016</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>0.042292</td>\n",
       "      <td>0.100280</td>\n",
       "      <td>0.165002</td>\n",
       "      <td>24254</td>\n",
       "      <td>7569.629883</td>\n",
       "      <td>171.833008</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  negative  positive  compound  daily_count  lagged_close  \\\n",
       "278  2018-08-28  0.007695  0.028635  0.062261          750   7361.660156   \n",
       "279  2018-08-29  0.006276  0.028844  0.072007          736   6792.830078   \n",
       "280  2018-08-30  0.009227  0.029736  0.064531          746   6529.169922   \n",
       "281  2018-08-31  0.008908  0.027812  0.055598          682   6467.069824   \n",
       "282  2018-09-01  0.008893  0.025307  0.049348          642   6225.979980   \n",
       "..          ...       ...       ...       ...          ...           ...   \n",
       "726  2019-11-19  0.038151  0.093721  0.165424        43287   7218.371094   \n",
       "727  2019-11-20  0.036158  0.099087  0.181522        42112   7531.663574   \n",
       "728  2019-11-21  0.042986  0.096216  0.155917        47978   7463.105957   \n",
       "729  2019-11-22  0.048450  0.090741  0.129012        51043   7761.243652   \n",
       "730  2019-11-23  0.042292  0.100280  0.165002        24254   7569.629883   \n",
       "\n",
       "     price_change price_direction  \n",
       "278    265.380371        positive  \n",
       "279    254.330078        negative  \n",
       "280    449.060059        negative  \n",
       "281    570.510254        negative  \n",
       "282    967.270020        negative  \n",
       "..            ...             ...  \n",
       "726    987.774414        negative  \n",
       "727    495.604492        negative  \n",
       "728    179.644043        negative  \n",
       "729    464.666016        positive  \n",
       "730    171.833008        positive  \n",
       "\n",
       "[453 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a83337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_change'] = df.apply(lambda row: -1 * row['price_change'] if row['price_direction'] == 'negative' else row['price_change'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fc3d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>daily_count</th>\n",
       "      <th>lagged_close</th>\n",
       "      <th>price_change</th>\n",
       "      <th>price_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.062261</td>\n",
       "      <td>750</td>\n",
       "      <td>7361.660156</td>\n",
       "      <td>265.380371</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>736</td>\n",
       "      <td>6792.830078</td>\n",
       "      <td>-254.330078</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>746</td>\n",
       "      <td>6529.169922</td>\n",
       "      <td>-449.060059</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.055598</td>\n",
       "      <td>682</td>\n",
       "      <td>6467.069824</td>\n",
       "      <td>-570.510254</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.049348</td>\n",
       "      <td>642</td>\n",
       "      <td>6225.979980</td>\n",
       "      <td>-967.270020</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.165424</td>\n",
       "      <td>43287</td>\n",
       "      <td>7218.371094</td>\n",
       "      <td>-987.774414</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.181522</td>\n",
       "      <td>42112</td>\n",
       "      <td>7531.663574</td>\n",
       "      <td>-495.604492</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>0.096216</td>\n",
       "      <td>0.155917</td>\n",
       "      <td>47978</td>\n",
       "      <td>7463.105957</td>\n",
       "      <td>-179.644043</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.129012</td>\n",
       "      <td>51043</td>\n",
       "      <td>7761.243652</td>\n",
       "      <td>464.666016</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>0.042292</td>\n",
       "      <td>0.100280</td>\n",
       "      <td>0.165002</td>\n",
       "      <td>24254</td>\n",
       "      <td>7569.629883</td>\n",
       "      <td>171.833008</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  negative  positive  compound  daily_count  lagged_close  \\\n",
       "278  2018-08-28  0.007695  0.028635  0.062261          750   7361.660156   \n",
       "279  2018-08-29  0.006276  0.028844  0.072007          736   6792.830078   \n",
       "280  2018-08-30  0.009227  0.029736  0.064531          746   6529.169922   \n",
       "281  2018-08-31  0.008908  0.027812  0.055598          682   6467.069824   \n",
       "282  2018-09-01  0.008893  0.025307  0.049348          642   6225.979980   \n",
       "..          ...       ...       ...       ...          ...           ...   \n",
       "726  2019-11-19  0.038151  0.093721  0.165424        43287   7218.371094   \n",
       "727  2019-11-20  0.036158  0.099087  0.181522        42112   7531.663574   \n",
       "728  2019-11-21  0.042986  0.096216  0.155917        47978   7463.105957   \n",
       "729  2019-11-22  0.048450  0.090741  0.129012        51043   7761.243652   \n",
       "730  2019-11-23  0.042292  0.100280  0.165002        24254   7569.629883   \n",
       "\n",
       "     price_change price_direction  \n",
       "278    265.380371        positive  \n",
       "279   -254.330078        negative  \n",
       "280   -449.060059        negative  \n",
       "281   -570.510254        negative  \n",
       "282   -967.270020        negative  \n",
       "..            ...             ...  \n",
       "726   -987.774414        negative  \n",
       "727   -495.604492        negative  \n",
       "728   -179.644043        negative  \n",
       "729    464.666016        positive  \n",
       "730    171.833008        positive  \n",
       "\n",
       "[453 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44ca3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -3096.1708984375\n",
      "Max: 3742.7099609375\n"
     ]
    }
   ],
   "source": [
    "min_change = df['price_change'].min()\n",
    "max_change = df['price_change'].max()\n",
    "\n",
    "print(f'Min: {min_change}')\n",
    "print(f'Max: {max_change}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5f797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['price_change'], bins=25, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Price Change')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Price Change')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70051cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['price_change'] > 330])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d4a4bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['price_change'] < 330) & (df['price_change'] > 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e58a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['price_change'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2bfaeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['price_change'] > -330) & (df['price_change'] < 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da0d8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['price_change'] < -330])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3bd210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>daily_count</th>\n",
       "      <th>lagged_close</th>\n",
       "      <th>price_change</th>\n",
       "      <th>price_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.062261</td>\n",
       "      <td>750</td>\n",
       "      <td>7361.660156</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>736</td>\n",
       "      <td>6792.830078</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>746</td>\n",
       "      <td>6529.169922</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.055598</td>\n",
       "      <td>682</td>\n",
       "      <td>6467.069824</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.049348</td>\n",
       "      <td>642</td>\n",
       "      <td>6225.979980</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.165424</td>\n",
       "      <td>43287</td>\n",
       "      <td>7218.371094</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.181522</td>\n",
       "      <td>42112</td>\n",
       "      <td>7531.663574</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>2019-11-21</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>0.096216</td>\n",
       "      <td>0.155917</td>\n",
       "      <td>47978</td>\n",
       "      <td>7463.105957</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.129012</td>\n",
       "      <td>51043</td>\n",
       "      <td>7761.243652</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2019-11-23</td>\n",
       "      <td>0.042292</td>\n",
       "      <td>0.100280</td>\n",
       "      <td>0.165002</td>\n",
       "      <td>24254</td>\n",
       "      <td>7569.629883</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  negative  positive  compound  daily_count  lagged_close  \\\n",
       "278  2018-08-28  0.007695  0.028635  0.062261          750   7361.660156   \n",
       "279  2018-08-29  0.006276  0.028844  0.072007          736   6792.830078   \n",
       "280  2018-08-30  0.009227  0.029736  0.064531          746   6529.169922   \n",
       "281  2018-08-31  0.008908  0.027812  0.055598          682   6467.069824   \n",
       "282  2018-09-01  0.008893  0.025307  0.049348          642   6225.979980   \n",
       "..          ...       ...       ...       ...          ...           ...   \n",
       "726  2019-11-19  0.038151  0.093721  0.165424        43287   7218.371094   \n",
       "727  2019-11-20  0.036158  0.099087  0.181522        42112   7531.663574   \n",
       "728  2019-11-21  0.042986  0.096216  0.155917        47978   7463.105957   \n",
       "729  2019-11-22  0.048450  0.090741  0.129012        51043   7761.243652   \n",
       "730  2019-11-23  0.042292  0.100280  0.165002        24254   7569.629883   \n",
       "\n",
       "    price_change price_direction  \n",
       "278            2        positive  \n",
       "279            1        negative  \n",
       "280            0        negative  \n",
       "281            0        negative  \n",
       "282            0        negative  \n",
       "..           ...             ...  \n",
       "726            0        negative  \n",
       "727            0        negative  \n",
       "728            1        negative  \n",
       "729            3        positive  \n",
       "730            2        positive  \n",
       "\n",
       "[453 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bins\n",
    "bins = [float(\"-inf\"), -330, 0., 330, float(\"inf\")]\n",
    "labels = [0, 1, 2, 3]\n",
    "\n",
    "# Put records into bins\n",
    "df['price_change'] = pd.cut(x=df['price_change'], bins=bins, labels=labels, include_lowest=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0da4f950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    124\n",
       "2    123\n",
       "0    111\n",
       "3     95\n",
       "Name: price_change, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['price_change'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6934ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying df for further manipulations\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "274454ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['price_change', 'lagged_close', 'positive', 'negative', 'daily_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "757b8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53016d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of previous records to consider for every example (Window size)\n",
    "n_lag = 3\n",
    "\n",
    "# Number of features\n",
    "n_features = len(features)\n",
    "\n",
    "# Calculate total_features\n",
    "total_features = n_lag * n_features\n",
    "\n",
    "if(total_features == 0):\n",
    "    total_features = n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce29d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(data, n_lagged_features=1, to_remove=1):\n",
    "    variables = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    columns, names = list(), list()\n",
    "    \n",
    "    for i in range(n_lagged_features, 0, -1):\n",
    "        columns.append(df.shift(i))\n",
    "        names += [f'feature{j+1}(t-{i})' for j in range(variables)]\n",
    "\n",
    "    for i in range(0, to_remove):\n",
    "        columns.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [f'feature{j+1}(t)' for j in range(variables)]\n",
    "        else:\n",
    "            names += [f'feature{j+1}(t+{i})' for j in range(variables)]\n",
    "            \n",
    "    prepped_df = pd.concat(columns, axis=1)\n",
    "    prepped_df.columns = names\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    prepped_df.dropna(inplace=True)\n",
    "        \n",
    "    return prepped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "166841ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged data (previous data window) columns\n",
    "lagged_data = create_lagged_features(df_copy, n_lag, 1)\n",
    "lagged_data = lagged_data.reset_index()\n",
    "lagged_data = lagged_data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84493550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1(t-3)</th>\n",
       "      <th>feature2(t-3)</th>\n",
       "      <th>feature3(t-3)</th>\n",
       "      <th>feature4(t-3)</th>\n",
       "      <th>feature5(t-3)</th>\n",
       "      <th>feature1(t-2)</th>\n",
       "      <th>feature2(t-2)</th>\n",
       "      <th>feature3(t-2)</th>\n",
       "      <th>feature4(t-2)</th>\n",
       "      <th>feature5(t-2)</th>\n",
       "      <th>feature1(t-1)</th>\n",
       "      <th>feature2(t-1)</th>\n",
       "      <th>feature3(t-1)</th>\n",
       "      <th>feature4(t-1)</th>\n",
       "      <th>feature5(t-1)</th>\n",
       "      <th>feature1(t)</th>\n",
       "      <th>feature2(t)</th>\n",
       "      <th>feature3(t)</th>\n",
       "      <th>feature4(t)</th>\n",
       "      <th>feature5(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>7361.660156</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6792.830078</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6529.169922</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6467.069824</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6792.830078</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6529.169922</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6467.069824</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6225.979980</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6529.169922</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6467.069824</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6225.979980</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6300.859863</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6467.069824</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>682.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6225.979980</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6300.859863</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>659.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6329.700195</td>\n",
       "      <td>0.024956</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6225.979980</td>\n",
       "      <td>0.025307</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6300.859863</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>659.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6329.700195</td>\n",
       "      <td>0.024956</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>707.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6321.200195</td>\n",
       "      <td>0.025445</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0</td>\n",
       "      <td>7397.796875</td>\n",
       "      <td>0.093754</td>\n",
       "      <td>0.039901</td>\n",
       "      <td>33199.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7047.916992</td>\n",
       "      <td>0.092225</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>33029.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7146.133789</td>\n",
       "      <td>0.090824</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7218.371094</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>43287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0</td>\n",
       "      <td>7047.916992</td>\n",
       "      <td>0.092225</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>33029.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7146.133789</td>\n",
       "      <td>0.090824</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7218.371094</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>43287.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7531.663574</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>42112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0</td>\n",
       "      <td>7146.133789</td>\n",
       "      <td>0.090824</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>41172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7218.371094</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>43287.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7531.663574</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>42112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7463.105957</td>\n",
       "      <td>0.096216</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>47978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>7218.371094</td>\n",
       "      <td>0.093721</td>\n",
       "      <td>0.038151</td>\n",
       "      <td>43287.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7531.663574</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>42112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7463.105957</td>\n",
       "      <td>0.096216</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>47978.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7761.243652</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>51043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>7531.663574</td>\n",
       "      <td>0.099087</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>42112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7463.105957</td>\n",
       "      <td>0.096216</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>47978.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7761.243652</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.048450</td>\n",
       "      <td>51043.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7569.629883</td>\n",
       "      <td>0.100280</td>\n",
       "      <td>0.042292</td>\n",
       "      <td>24254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature1(t-3)  feature2(t-3)  feature3(t-3)  feature4(t-3)  feature5(t-3)  \\\n",
       "0               2    7361.660156       0.028635       0.007695          750.0   \n",
       "1               1    6792.830078       0.028844       0.006276          736.0   \n",
       "2               0    6529.169922       0.029736       0.009227          746.0   \n",
       "3               0    6467.069824       0.027812       0.008908          682.0   \n",
       "4               0    6225.979980       0.025307       0.008893          642.0   \n",
       "..            ...            ...            ...            ...            ...   \n",
       "445             0    7397.796875       0.093754       0.039901        33199.0   \n",
       "446             0    7047.916992       0.092225       0.039410        33029.0   \n",
       "447             0    7146.133789       0.090824       0.037751        41172.0   \n",
       "448             0    7218.371094       0.093721       0.038151        43287.0   \n",
       "449             0    7531.663574       0.099087       0.036158        42112.0   \n",
       "\n",
       "    feature1(t-2)  feature2(t-2)  feature3(t-2)  feature4(t-2)  feature5(t-2)  \\\n",
       "0               1    6792.830078       0.028844       0.006276          736.0   \n",
       "1               0    6529.169922       0.029736       0.009227          746.0   \n",
       "2               0    6467.069824       0.027812       0.008908          682.0   \n",
       "3               0    6225.979980       0.025307       0.008893          642.0   \n",
       "4               0    6300.859863       0.028598       0.010656          659.0   \n",
       "..            ...            ...            ...            ...            ...   \n",
       "445             0    7047.916992       0.092225       0.039410        33029.0   \n",
       "446             0    7146.133789       0.090824       0.037751        41172.0   \n",
       "447             0    7218.371094       0.093721       0.038151        43287.0   \n",
       "448             0    7531.663574       0.099087       0.036158        42112.0   \n",
       "449             1    7463.105957       0.096216       0.042986        47978.0   \n",
       "\n",
       "    feature1(t-1)  feature2(t-1)  feature3(t-1)  feature4(t-1)  feature5(t-1)  \\\n",
       "0               0    6529.169922       0.029736       0.009227          746.0   \n",
       "1               0    6467.069824       0.027812       0.008908          682.0   \n",
       "2               0    6225.979980       0.025307       0.008893          642.0   \n",
       "3               0    6300.859863       0.028598       0.010656          659.0   \n",
       "4               0    6329.700195       0.024956       0.009593          707.0   \n",
       "..            ...            ...            ...            ...            ...   \n",
       "445             0    7146.133789       0.090824       0.037751        41172.0   \n",
       "446             0    7218.371094       0.093721       0.038151        43287.0   \n",
       "447             0    7531.663574       0.099087       0.036158        42112.0   \n",
       "448             1    7463.105957       0.096216       0.042986        47978.0   \n",
       "449             3    7761.243652       0.090741       0.048450        51043.0   \n",
       "\n",
       "    feature1(t)  feature2(t)  feature3(t)  feature4(t)  feature5(t)  \n",
       "0             0  6467.069824     0.027812     0.008908          682  \n",
       "1             0  6225.979980     0.025307     0.008893          642  \n",
       "2             0  6300.859863     0.028598     0.010656          659  \n",
       "3             0  6329.700195     0.024956     0.009593          707  \n",
       "4             0  6321.200195     0.025445     0.006964          719  \n",
       "..          ...          ...          ...          ...          ...  \n",
       "445           0  7218.371094     0.093721     0.038151        43287  \n",
       "446           0  7531.663574     0.099087     0.036158        42112  \n",
       "447           1  7463.105957     0.096216     0.042986        47978  \n",
       "448           3  7761.243652     0.090741     0.048450        51043  \n",
       "449           2  7569.629883     0.100280     0.042292        24254  \n",
       "\n",
       "[450 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca41e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lagged_data.iloc[:, :total_features].values\n",
    "y = lagged_data['feature1(t)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d152ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6226c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (382, 15) (382,)\n",
      "Testing set shape: (68, 15) (68,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5547e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise features\n",
    "xscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = xscaler.fit_transform(X_train)\n",
    "X_test = xscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ed34b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to match LSTM input [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], n_lag, n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_lag, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ed79897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 3, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63e6572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set two class values (1-hot method)\n",
    "y_train = keras.utils.to_categorical(y_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59967c",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "297692b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34349c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6f27e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = keras.utils.to_categorical(y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9f9eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize hyperparameters\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75434f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) \n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25d63c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    activation_funcs = ['relu', 'tanh', 'selu', 'swish', 'linear']\n",
    "\n",
    "    # Hyperparameters that will be changed\n",
    "    activation_func_1 = trial.suggest_categorical('activation_func_1', activation_funcs)\n",
    "    activation_func_2 = trial.suggest_categorical('activation_func_2', activation_funcs)\n",
    "    activation_func_3 = trial.suggest_categorical('activation_func_3', activation_funcs)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 50, 64, 80])\n",
    "    dropout_1 = trial.suggest_categorical('dropout_1', [0.25, 0.5])\n",
    "    dropout_2 = trial.suggest_categorical('dropout_2', [0.25, 0.5])\n",
    "    dropout_3 = trial.suggest_categorical('dropout_3', [0.25, 0.5])\n",
    "    neurons = trial.suggest_int('neurons', 128, 256, log=True)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, \n",
    "                   return_sequences=True, \n",
    "                   input_shape=(X_train.shape[1], \n",
    "                                X_train.shape[2]), \n",
    "                   activation=activation_func_1))\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(LSTM(neurons, \n",
    "                   return_sequences=True, \n",
    "                   activation=activation_func_2))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(LSTM(neurons, \n",
    "                   return_sequences=False,  \n",
    "                   activation=activation_func_3))\n",
    "    model.add(Dropout(dropout_3))\n",
    "    model.add(Dense(4, activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "      \n",
    "    model.fit(X_train, \n",
    "              y_train, \n",
    "              epochs=EPOCHS,\n",
    "              batch_size=batch_size, \n",
    "              verbose=2, \n",
    "              shuffle=True,\n",
    "              validation_split=0.2, \n",
    "              callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    validation_accuracy = model.evaluate(X_test, y_eval)[1]\n",
    "\n",
    "    return validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfa42875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "003443a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:26:19,915] A new study created in RDB with name: LSTM_magnitude_change_7_day_lag_3_day_window\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3834 - accuracy: 0.2754 - val_loss: 1.3786 - val_accuracy: 0.3377 - 4s/epoch - 419ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3641 - accuracy: 0.4656 - val_loss: 1.3450 - val_accuracy: 0.4286 - 149ms/epoch - 15ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3035 - accuracy: 0.4590 - val_loss: 1.2771 - val_accuracy: 0.4026 - 156ms/epoch - 16ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2581 - accuracy: 0.4820 - val_loss: 1.2455 - val_accuracy: 0.4286 - 172ms/epoch - 17ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2251 - accuracy: 0.5082 - val_loss: 1.2419 - val_accuracy: 0.4416 - 154ms/epoch - 15ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2200 - accuracy: 0.5049 - val_loss: 1.2219 - val_accuracy: 0.4156 - 158ms/epoch - 16ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1811 - accuracy: 0.5115 - val_loss: 1.2083 - val_accuracy: 0.4545 - 172ms/epoch - 17ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2266 - accuracy: 0.5049 - val_loss: 1.1898 - val_accuracy: 0.4286 - 161ms/epoch - 16ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1884 - accuracy: 0.5082 - val_loss: 1.1647 - val_accuracy: 0.3896 - 160ms/epoch - 16ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1325 - accuracy: 0.5049 - val_loss: 1.1468 - val_accuracy: 0.3896 - 162ms/epoch - 16ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1038 - accuracy: 0.5115 - val_loss: 1.1276 - val_accuracy: 0.4156 - 161ms/epoch - 16ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1204 - accuracy: 0.5180 - val_loss: 1.1110 - val_accuracy: 0.4286 - 156ms/epoch - 16ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1699 - accuracy: 0.5180 - val_loss: 1.1353 - val_accuracy: 0.5065 - 151ms/epoch - 15ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1347 - accuracy: 0.5443 - val_loss: 1.1202 - val_accuracy: 0.5065 - 164ms/epoch - 16ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0971 - accuracy: 0.5508 - val_loss: 1.0748 - val_accuracy: 0.4675 - 149ms/epoch - 15ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0479 - accuracy: 0.5508 - val_loss: 1.0804 - val_accuracy: 0.4935 - 159ms/epoch - 16ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0550 - accuracy: 0.5377 - val_loss: 1.0541 - val_accuracy: 0.4805 - 163ms/epoch - 16ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0380 - accuracy: 0.5705 - val_loss: 1.0638 - val_accuracy: 0.4805 - 152ms/epoch - 15ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0667 - accuracy: 0.5541 - val_loss: 1.0789 - val_accuracy: 0.5065 - 157ms/epoch - 16ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0391 - accuracy: 0.5639 - val_loss: 1.0439 - val_accuracy: 0.5325 - 163ms/epoch - 16ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 0.9983 - accuracy: 0.5836 - val_loss: 1.0291 - val_accuracy: 0.5195 - 155ms/epoch - 16ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 0.9977 - accuracy: 0.6098 - val_loss: 1.0403 - val_accuracy: 0.4935 - 150ms/epoch - 15ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0106 - accuracy: 0.5803 - val_loss: 1.0227 - val_accuracy: 0.4935 - 155ms/epoch - 15ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 0.9711 - accuracy: 0.5770 - val_loss: 0.9496 - val_accuracy: 0.6104 - 156ms/epoch - 16ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9381 - accuracy: 0.6131 - val_loss: 0.9755 - val_accuracy: 0.5455 - 156ms/epoch - 16ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9321 - accuracy: 0.6295 - val_loss: 0.9328 - val_accuracy: 0.6234 - 158ms/epoch - 16ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9503 - accuracy: 0.6393 - val_loss: 0.9652 - val_accuracy: 0.5584 - 154ms/epoch - 15ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.8582 - accuracy: 0.6525 - val_loss: 0.9331 - val_accuracy: 0.6104 - 157ms/epoch - 16ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.8687 - accuracy: 0.6262 - val_loss: 0.9187 - val_accuracy: 0.6234 - 165ms/epoch - 16ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.8932 - accuracy: 0.6426 - val_loss: 0.8863 - val_accuracy: 0.6364 - 164ms/epoch - 16ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.8591 - accuracy: 0.6230 - val_loss: 0.9321 - val_accuracy: 0.6623 - 153ms/epoch - 15ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.8634 - accuracy: 0.6328 - val_loss: 0.9292 - val_accuracy: 0.6364 - 150ms/epoch - 15ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.8891 - accuracy: 0.6295 - val_loss: 0.9317 - val_accuracy: 0.5844 - 153ms/epoch - 15ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.8683 - accuracy: 0.6492 - val_loss: 0.9338 - val_accuracy: 0.5974 - 151ms/epoch - 15ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.8773 - accuracy: 0.6721 - val_loss: 0.9046 - val_accuracy: 0.6234 - 159ms/epoch - 16ms/step\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9446 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:26:31,552] Trial 0 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'linear', 'activation_func_3': 'swish', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.25, 'neurons': 169}. Best is trial 0 with value: 0.6470588445663452.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 4s - loss: 1.3852 - accuracy: 0.3049 - val_loss: 1.3826 - val_accuracy: 0.3896 - 4s/epoch - 928ms/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3808 - accuracy: 0.4131 - val_loss: 1.3765 - val_accuracy: 0.3766 - 111ms/epoch - 28ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3726 - accuracy: 0.4459 - val_loss: 1.3652 - val_accuracy: 0.3636 - 108ms/epoch - 27ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.3541 - accuracy: 0.4623 - val_loss: 1.3453 - val_accuracy: 0.3636 - 113ms/epoch - 28ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.3247 - accuracy: 0.4557 - val_loss: 1.3142 - val_accuracy: 0.3636 - 115ms/epoch - 29ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.2816 - accuracy: 0.4590 - val_loss: 1.2811 - val_accuracy: 0.3636 - 111ms/epoch - 28ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.2406 - accuracy: 0.4590 - val_loss: 1.2626 - val_accuracy: 0.3766 - 111ms/epoch - 28ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.1945 - accuracy: 0.4557 - val_loss: 1.2243 - val_accuracy: 0.3636 - 118ms/epoch - 29ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.1751 - accuracy: 0.4557 - val_loss: 1.1886 - val_accuracy: 0.4026 - 112ms/epoch - 28ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.1682 - accuracy: 0.4984 - val_loss: 1.1716 - val_accuracy: 0.4156 - 112ms/epoch - 28ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.1741 - accuracy: 0.4852 - val_loss: 1.1616 - val_accuracy: 0.4286 - 136ms/epoch - 34ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.1471 - accuracy: 0.5213 - val_loss: 1.1582 - val_accuracy: 0.4156 - 112ms/epoch - 28ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.1340 - accuracy: 0.5246 - val_loss: 1.1696 - val_accuracy: 0.4026 - 114ms/epoch - 29ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.1332 - accuracy: 0.5049 - val_loss: 1.1654 - val_accuracy: 0.4156 - 119ms/epoch - 30ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.1329 - accuracy: 0.5016 - val_loss: 1.1594 - val_accuracy: 0.4156 - 114ms/epoch - 29ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.1203 - accuracy: 0.5213 - val_loss: 1.1488 - val_accuracy: 0.4545 - 123ms/epoch - 31ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.1170 - accuracy: 0.5377 - val_loss: 1.1314 - val_accuracy: 0.4545 - 119ms/epoch - 30ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.1108 - accuracy: 0.5344 - val_loss: 1.1218 - val_accuracy: 0.4545 - 111ms/epoch - 28ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.1053 - accuracy: 0.5311 - val_loss: 1.1226 - val_accuracy: 0.4545 - 109ms/epoch - 27ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.0813 - accuracy: 0.5541 - val_loss: 1.1090 - val_accuracy: 0.4675 - 120ms/epoch - 30ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.0897 - accuracy: 0.5377 - val_loss: 1.1036 - val_accuracy: 0.4675 - 114ms/epoch - 28ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.0970 - accuracy: 0.5443 - val_loss: 1.1020 - val_accuracy: 0.4545 - 118ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.0795 - accuracy: 0.5508 - val_loss: 1.1179 - val_accuracy: 0.4675 - 124ms/epoch - 31ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.0900 - accuracy: 0.5377 - val_loss: 1.1059 - val_accuracy: 0.4545 - 143ms/epoch - 36ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.1030 - accuracy: 0.5279 - val_loss: 1.0921 - val_accuracy: 0.4545 - 148ms/epoch - 37ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 1.0555 - accuracy: 0.5475 - val_loss: 1.0913 - val_accuracy: 0.4805 - 183ms/epoch - 46ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.0776 - accuracy: 0.5279 - val_loss: 1.0673 - val_accuracy: 0.4935 - 163ms/epoch - 41ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 1.0603 - accuracy: 0.5770 - val_loss: 1.0708 - val_accuracy: 0.4675 - 193ms/epoch - 48ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 1.0567 - accuracy: 0.5475 - val_loss: 1.0581 - val_accuracy: 0.4805 - 144ms/epoch - 36ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 1.0553 - accuracy: 0.5410 - val_loss: 1.0654 - val_accuracy: 0.4545 - 148ms/epoch - 37ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 1.0464 - accuracy: 0.5541 - val_loss: 1.0453 - val_accuracy: 0.4935 - 140ms/epoch - 35ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 1.0304 - accuracy: 0.5869 - val_loss: 1.0417 - val_accuracy: 0.4675 - 126ms/epoch - 31ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 1.0217 - accuracy: 0.6066 - val_loss: 1.0374 - val_accuracy: 0.5195 - 126ms/epoch - 31ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 1.0301 - accuracy: 0.5738 - val_loss: 1.0309 - val_accuracy: 0.5065 - 149ms/epoch - 37ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 1.0154 - accuracy: 0.5574 - val_loss: 1.0075 - val_accuracy: 0.5325 - 164ms/epoch - 41ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 1.0011 - accuracy: 0.5770 - val_loss: 0.9846 - val_accuracy: 0.5714 - 150ms/epoch - 37ms/step\n",
      "Epoch 37/10000\n",
      "4/4 - 0s - loss: 0.9961 - accuracy: 0.5836 - val_loss: 0.9826 - val_accuracy: 0.5455 - 134ms/epoch - 33ms/step\n",
      "Epoch 38/10000\n",
      "4/4 - 0s - loss: 1.0057 - accuracy: 0.5967 - val_loss: 0.9844 - val_accuracy: 0.5325 - 180ms/epoch - 45ms/step\n",
      "Epoch 39/10000\n",
      "4/4 - 0s - loss: 0.9846 - accuracy: 0.6066 - val_loss: 0.9659 - val_accuracy: 0.5195 - 127ms/epoch - 32ms/step\n",
      "Epoch 40/10000\n",
      "4/4 - 0s - loss: 0.9833 - accuracy: 0.6197 - val_loss: 0.9564 - val_accuracy: 0.6104 - 146ms/epoch - 36ms/step\n",
      "Epoch 41/10000\n",
      "4/4 - 0s - loss: 0.9976 - accuracy: 0.6033 - val_loss: 0.9260 - val_accuracy: 0.6364 - 163ms/epoch - 41ms/step\n",
      "Epoch 42/10000\n",
      "4/4 - 0s - loss: 0.9573 - accuracy: 0.5934 - val_loss: 0.9507 - val_accuracy: 0.5195 - 113ms/epoch - 28ms/step\n",
      "Epoch 43/10000\n",
      "4/4 - 0s - loss: 0.9408 - accuracy: 0.6066 - val_loss: 0.9393 - val_accuracy: 0.6234 - 123ms/epoch - 31ms/step\n",
      "Epoch 44/10000\n",
      "4/4 - 0s - loss: 0.9562 - accuracy: 0.6197 - val_loss: 0.9212 - val_accuracy: 0.5455 - 111ms/epoch - 28ms/step\n",
      "Epoch 45/10000\n",
      "4/4 - 0s - loss: 0.9560 - accuracy: 0.6098 - val_loss: 0.9110 - val_accuracy: 0.5714 - 128ms/epoch - 32ms/step\n",
      "Epoch 46/10000\n",
      "4/4 - 0s - loss: 0.9459 - accuracy: 0.6230 - val_loss: 0.9193 - val_accuracy: 0.6104 - 117ms/epoch - 29ms/step\n",
      "Epoch 47/10000\n",
      "4/4 - 0s - loss: 0.9223 - accuracy: 0.6164 - val_loss: 0.9182 - val_accuracy: 0.5455 - 119ms/epoch - 30ms/step\n",
      "Epoch 48/10000\n",
      "4/4 - 0s - loss: 0.9210 - accuracy: 0.6098 - val_loss: 0.8931 - val_accuracy: 0.6104 - 108ms/epoch - 27ms/step\n",
      "Epoch 49/10000\n",
      "4/4 - 0s - loss: 0.9131 - accuracy: 0.6131 - val_loss: 0.8960 - val_accuracy: 0.5714 - 112ms/epoch - 28ms/step\n",
      "Epoch 50/10000\n",
      "4/4 - 0s - loss: 0.9436 - accuracy: 0.6197 - val_loss: 0.8959 - val_accuracy: 0.5455 - 168ms/epoch - 42ms/step\n",
      "Epoch 51/10000\n",
      "4/4 - 0s - loss: 0.8991 - accuracy: 0.6459 - val_loss: 0.8835 - val_accuracy: 0.6494 - 140ms/epoch - 35ms/step\n",
      "Epoch 52/10000\n",
      "4/4 - 0s - loss: 0.9451 - accuracy: 0.6230 - val_loss: 0.8761 - val_accuracy: 0.5974 - 136ms/epoch - 34ms/step\n",
      "Epoch 53/10000\n",
      "4/4 - 0s - loss: 0.9024 - accuracy: 0.6197 - val_loss: 0.9147 - val_accuracy: 0.6364 - 128ms/epoch - 32ms/step\n",
      "Epoch 54/10000\n",
      "4/4 - 0s - loss: 0.9461 - accuracy: 0.6262 - val_loss: 0.9043 - val_accuracy: 0.6623 - 119ms/epoch - 30ms/step\n",
      "Epoch 55/10000\n",
      "4/4 - 0s - loss: 0.9062 - accuracy: 0.6197 - val_loss: 0.9084 - val_accuracy: 0.5455 - 113ms/epoch - 28ms/step\n",
      "Epoch 56/10000\n",
      "4/4 - 0s - loss: 0.9103 - accuracy: 0.6426 - val_loss: 0.8881 - val_accuracy: 0.6104 - 117ms/epoch - 29ms/step\n",
      "Epoch 57/10000\n",
      "4/4 - 0s - loss: 0.9035 - accuracy: 0.6361 - val_loss: 0.8948 - val_accuracy: 0.6234 - 110ms/epoch - 27ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8856 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:26:44,078] Trial 1 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'selu', 'activation_func_3': 'linear', 'batch_size': 80, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 183}. Best is trial 1 with value: 0.6764705777168274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 5s - loss: 1.3860 - accuracy: 0.2918 - val_loss: 1.3849 - val_accuracy: 0.3247 - 5s/epoch - 946ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3843 - accuracy: 0.3672 - val_loss: 1.3817 - val_accuracy: 0.3506 - 164ms/epoch - 33ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3809 - accuracy: 0.3738 - val_loss: 1.3766 - val_accuracy: 0.3377 - 151ms/epoch - 30ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3751 - accuracy: 0.3934 - val_loss: 1.3687 - val_accuracy: 0.3117 - 160ms/epoch - 32ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3634 - accuracy: 0.3869 - val_loss: 1.3539 - val_accuracy: 0.2987 - 151ms/epoch - 30ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3435 - accuracy: 0.3869 - val_loss: 1.3291 - val_accuracy: 0.2987 - 151ms/epoch - 30ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3146 - accuracy: 0.3836 - val_loss: 1.2961 - val_accuracy: 0.3247 - 149ms/epoch - 30ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2717 - accuracy: 0.4426 - val_loss: 1.2743 - val_accuracy: 0.3506 - 152ms/epoch - 30ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2714 - accuracy: 0.4459 - val_loss: 1.2614 - val_accuracy: 0.3636 - 147ms/epoch - 29ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2284 - accuracy: 0.4590 - val_loss: 1.2418 - val_accuracy: 0.3636 - 148ms/epoch - 30ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.2070 - accuracy: 0.4623 - val_loss: 1.2142 - val_accuracy: 0.3636 - 147ms/epoch - 29ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1835 - accuracy: 0.4787 - val_loss: 1.1851 - val_accuracy: 0.3896 - 156ms/epoch - 31ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1538 - accuracy: 0.4951 - val_loss: 1.1851 - val_accuracy: 0.4026 - 168ms/epoch - 34ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1543 - accuracy: 0.5180 - val_loss: 1.1731 - val_accuracy: 0.3896 - 146ms/epoch - 29ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1519 - accuracy: 0.5115 - val_loss: 1.1704 - val_accuracy: 0.4026 - 146ms/epoch - 29ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1531 - accuracy: 0.5049 - val_loss: 1.1677 - val_accuracy: 0.4026 - 151ms/epoch - 30ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1391 - accuracy: 0.5246 - val_loss: 1.1628 - val_accuracy: 0.4026 - 149ms/epoch - 30ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1383 - accuracy: 0.5213 - val_loss: 1.1541 - val_accuracy: 0.4026 - 147ms/epoch - 29ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1292 - accuracy: 0.5016 - val_loss: 1.1562 - val_accuracy: 0.4026 - 143ms/epoch - 29ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1274 - accuracy: 0.4984 - val_loss: 1.1480 - val_accuracy: 0.4026 - 170ms/epoch - 34ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1347 - accuracy: 0.5213 - val_loss: 1.1413 - val_accuracy: 0.4026 - 142ms/epoch - 28ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1260 - accuracy: 0.5213 - val_loss: 1.1356 - val_accuracy: 0.4156 - 149ms/epoch - 30ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1086 - accuracy: 0.5115 - val_loss: 1.1288 - val_accuracy: 0.4286 - 159ms/epoch - 32ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.1116 - accuracy: 0.5148 - val_loss: 1.1253 - val_accuracy: 0.4286 - 154ms/epoch - 31ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1097 - accuracy: 0.5508 - val_loss: 1.1307 - val_accuracy: 0.4416 - 149ms/epoch - 30ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0953 - accuracy: 0.5508 - val_loss: 1.1192 - val_accuracy: 0.4545 - 152ms/epoch - 30ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.1108 - accuracy: 0.5213 - val_loss: 1.1141 - val_accuracy: 0.4935 - 147ms/epoch - 29ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.1009 - accuracy: 0.5344 - val_loss: 1.1066 - val_accuracy: 0.4416 - 156ms/epoch - 31ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0960 - accuracy: 0.5508 - val_loss: 1.1078 - val_accuracy: 0.4416 - 150ms/epoch - 30ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0777 - accuracy: 0.5475 - val_loss: 1.1025 - val_accuracy: 0.4545 - 143ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0684 - accuracy: 0.5410 - val_loss: 1.1047 - val_accuracy: 0.4675 - 153ms/epoch - 31ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0853 - accuracy: 0.5508 - val_loss: 1.0979 - val_accuracy: 0.4545 - 165ms/epoch - 33ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0889 - accuracy: 0.5639 - val_loss: 1.1163 - val_accuracy: 0.4416 - 158ms/epoch - 32ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0626 - accuracy: 0.5443 - val_loss: 1.0943 - val_accuracy: 0.4545 - 149ms/epoch - 30ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0621 - accuracy: 0.5508 - val_loss: 1.0906 - val_accuracy: 0.4545 - 153ms/epoch - 31ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0559 - accuracy: 0.5738 - val_loss: 1.0725 - val_accuracy: 0.4416 - 150ms/epoch - 30ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0566 - accuracy: 0.5443 - val_loss: 1.0591 - val_accuracy: 0.4675 - 154ms/epoch - 31ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0380 - accuracy: 0.5508 - val_loss: 1.0574 - val_accuracy: 0.4675 - 156ms/epoch - 31ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0410 - accuracy: 0.5672 - val_loss: 1.0609 - val_accuracy: 0.4675 - 152ms/epoch - 30ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0532 - accuracy: 0.5475 - val_loss: 1.0528 - val_accuracy: 0.4675 - 153ms/epoch - 31ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 1.0327 - accuracy: 0.5639 - val_loss: 1.0330 - val_accuracy: 0.5714 - 146ms/epoch - 29ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 1.0517 - accuracy: 0.5770 - val_loss: 1.0244 - val_accuracy: 0.5195 - 144ms/epoch - 29ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 1.0261 - accuracy: 0.5902 - val_loss: 1.0223 - val_accuracy: 0.4935 - 145ms/epoch - 29ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 1.0060 - accuracy: 0.5672 - val_loss: 1.0121 - val_accuracy: 0.5195 - 145ms/epoch - 29ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 1.0136 - accuracy: 0.5967 - val_loss: 1.0112 - val_accuracy: 0.5195 - 142ms/epoch - 28ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9993 - accuracy: 0.5967 - val_loss: 1.0053 - val_accuracy: 0.5325 - 135ms/epoch - 27ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 1.0050 - accuracy: 0.5803 - val_loss: 0.9988 - val_accuracy: 0.5325 - 139ms/epoch - 28ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 1.0108 - accuracy: 0.5869 - val_loss: 0.9856 - val_accuracy: 0.5974 - 144ms/epoch - 29ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9952 - accuracy: 0.5934 - val_loss: 0.9728 - val_accuracy: 0.5844 - 140ms/epoch - 28ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.9991 - accuracy: 0.6033 - val_loss: 0.9736 - val_accuracy: 0.5584 - 143ms/epoch - 29ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.9639 - accuracy: 0.6098 - val_loss: 0.9649 - val_accuracy: 0.5455 - 141ms/epoch - 28ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.9600 - accuracy: 0.6131 - val_loss: 0.9446 - val_accuracy: 0.5455 - 139ms/epoch - 28ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.9721 - accuracy: 0.5902 - val_loss: 0.9489 - val_accuracy: 0.5844 - 144ms/epoch - 29ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9664 - accuracy: 0.6361 - val_loss: 0.9242 - val_accuracy: 0.5974 - 142ms/epoch - 28ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9530 - accuracy: 0.6197 - val_loss: 0.9155 - val_accuracy: 0.5584 - 143ms/epoch - 29ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9719 - accuracy: 0.5967 - val_loss: 0.9072 - val_accuracy: 0.5844 - 143ms/epoch - 29ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9356 - accuracy: 0.6393 - val_loss: 0.9156 - val_accuracy: 0.6104 - 144ms/epoch - 29ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.9230 - accuracy: 0.6197 - val_loss: 0.9058 - val_accuracy: 0.6104 - 144ms/epoch - 29ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.9498 - accuracy: 0.6361 - val_loss: 0.8923 - val_accuracy: 0.6104 - 143ms/epoch - 29ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.9549 - accuracy: 0.6197 - val_loss: 0.9108 - val_accuracy: 0.5714 - 144ms/epoch - 29ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.9359 - accuracy: 0.6295 - val_loss: 0.8980 - val_accuracy: 0.6104 - 143ms/epoch - 29ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.9164 - accuracy: 0.6459 - val_loss: 0.9080 - val_accuracy: 0.5974 - 149ms/epoch - 30ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.9317 - accuracy: 0.6262 - val_loss: 0.9177 - val_accuracy: 0.5844 - 143ms/epoch - 29ms/step\n",
      "Epoch 64/10000\n",
      "5/5 - 0s - loss: 0.9315 - accuracy: 0.6295 - val_loss: 0.8974 - val_accuracy: 0.6234 - 143ms/epoch - 29ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8668 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:26:59,684] Trial 2 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'linear', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 185}. Best is trial 1 with value: 0.6764705777168274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 8s - loss: 1.3854 - accuracy: 0.2984 - val_loss: 1.3844 - val_accuracy: 0.4156 - 8s/epoch - 2s/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3819 - accuracy: 0.4459 - val_loss: 1.3801 - val_accuracy: 0.4026 - 198ms/epoch - 40ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3741 - accuracy: 0.4918 - val_loss: 1.3702 - val_accuracy: 0.4545 - 202ms/epoch - 40ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3558 - accuracy: 0.4787 - val_loss: 1.3479 - val_accuracy: 0.4416 - 205ms/epoch - 41ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3168 - accuracy: 0.5049 - val_loss: 1.3133 - val_accuracy: 0.4416 - 204ms/epoch - 41ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.2641 - accuracy: 0.4918 - val_loss: 1.2846 - val_accuracy: 0.3636 - 197ms/epoch - 39ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.2782 - accuracy: 0.4525 - val_loss: 1.2647 - val_accuracy: 0.3636 - 230ms/epoch - 46ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2481 - accuracy: 0.4525 - val_loss: 1.2513 - val_accuracy: 0.3506 - 197ms/epoch - 39ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2406 - accuracy: 0.4393 - val_loss: 1.2440 - val_accuracy: 0.3506 - 215ms/epoch - 43ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2292 - accuracy: 0.4721 - val_loss: 1.2303 - val_accuracy: 0.3896 - 210ms/epoch - 42ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1936 - accuracy: 0.4787 - val_loss: 1.2200 - val_accuracy: 0.3766 - 202ms/epoch - 40ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1776 - accuracy: 0.4754 - val_loss: 1.2046 - val_accuracy: 0.3766 - 211ms/epoch - 42ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1795 - accuracy: 0.4721 - val_loss: 1.1946 - val_accuracy: 0.3766 - 216ms/epoch - 43ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1506 - accuracy: 0.4951 - val_loss: 1.1770 - val_accuracy: 0.3766 - 220ms/epoch - 44ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1300 - accuracy: 0.4852 - val_loss: 1.1595 - val_accuracy: 0.3896 - 225ms/epoch - 45ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1317 - accuracy: 0.4754 - val_loss: 1.1577 - val_accuracy: 0.3766 - 207ms/epoch - 41ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1227 - accuracy: 0.4918 - val_loss: 1.1398 - val_accuracy: 0.4026 - 220ms/epoch - 44ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1237 - accuracy: 0.4918 - val_loss: 1.1380 - val_accuracy: 0.4026 - 214ms/epoch - 43ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1388 - accuracy: 0.5016 - val_loss: 1.1594 - val_accuracy: 0.4286 - 194ms/epoch - 39ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1128 - accuracy: 0.5180 - val_loss: 1.1320 - val_accuracy: 0.4156 - 211ms/epoch - 42ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1052 - accuracy: 0.5279 - val_loss: 1.1355 - val_accuracy: 0.4416 - 208ms/epoch - 42ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1073 - accuracy: 0.5311 - val_loss: 1.1180 - val_accuracy: 0.4286 - 200ms/epoch - 40ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.0910 - accuracy: 0.5279 - val_loss: 1.1268 - val_accuracy: 0.4545 - 200ms/epoch - 40ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0857 - accuracy: 0.5213 - val_loss: 1.1242 - val_accuracy: 0.4286 - 196ms/epoch - 39ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.0618 - accuracy: 0.5377 - val_loss: 1.1032 - val_accuracy: 0.4805 - 196ms/epoch - 39ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0626 - accuracy: 0.5443 - val_loss: 1.0883 - val_accuracy: 0.4416 - 191ms/epoch - 38ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0764 - accuracy: 0.5607 - val_loss: 1.0850 - val_accuracy: 0.4545 - 193ms/epoch - 39ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0577 - accuracy: 0.5639 - val_loss: 1.0764 - val_accuracy: 0.4675 - 206ms/epoch - 41ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0492 - accuracy: 0.5541 - val_loss: 1.0798 - val_accuracy: 0.4805 - 188ms/epoch - 38ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0518 - accuracy: 0.5508 - val_loss: 1.0770 - val_accuracy: 0.4805 - 197ms/epoch - 39ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0365 - accuracy: 0.5443 - val_loss: 1.0789 - val_accuracy: 0.4675 - 194ms/epoch - 39ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0399 - accuracy: 0.5410 - val_loss: 1.0631 - val_accuracy: 0.4545 - 199ms/epoch - 40ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0324 - accuracy: 0.5803 - val_loss: 1.0706 - val_accuracy: 0.4416 - 195ms/epoch - 39ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0207 - accuracy: 0.5803 - val_loss: 1.0752 - val_accuracy: 0.4935 - 182ms/epoch - 36ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0326 - accuracy: 0.5672 - val_loss: 1.0556 - val_accuracy: 0.4805 - 226ms/epoch - 45ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0134 - accuracy: 0.5705 - val_loss: 1.0477 - val_accuracy: 0.5065 - 193ms/epoch - 39ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0039 - accuracy: 0.5705 - val_loss: 1.0356 - val_accuracy: 0.4935 - 196ms/epoch - 39ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.9974 - accuracy: 0.5836 - val_loss: 1.0342 - val_accuracy: 0.4935 - 190ms/epoch - 38ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0119 - accuracy: 0.5869 - val_loss: 1.0409 - val_accuracy: 0.4935 - 206ms/epoch - 41ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0016 - accuracy: 0.6066 - val_loss: 1.0244 - val_accuracy: 0.5065 - 189ms/epoch - 38ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.9884 - accuracy: 0.6033 - val_loss: 1.0003 - val_accuracy: 0.5844 - 195ms/epoch - 39ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.9872 - accuracy: 0.5967 - val_loss: 0.9794 - val_accuracy: 0.5844 - 195ms/epoch - 39ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.9936 - accuracy: 0.6000 - val_loss: 0.9948 - val_accuracy: 0.5455 - 196ms/epoch - 39ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.9812 - accuracy: 0.6033 - val_loss: 0.9761 - val_accuracy: 0.5065 - 188ms/epoch - 38ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.9366 - accuracy: 0.6361 - val_loss: 0.9810 - val_accuracy: 0.5844 - 196ms/epoch - 39ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9278 - accuracy: 0.6197 - val_loss: 0.9802 - val_accuracy: 0.5325 - 198ms/epoch - 40ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9554 - accuracy: 0.6033 - val_loss: 0.9610 - val_accuracy: 0.6104 - 190ms/epoch - 38ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 0.9797 - accuracy: 0.6492 - val_loss: 0.9387 - val_accuracy: 0.6104 - 190ms/epoch - 38ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9205 - accuracy: 0.6393 - val_loss: 0.9627 - val_accuracy: 0.5584 - 201ms/epoch - 40ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.8919 - accuracy: 0.6393 - val_loss: 0.9326 - val_accuracy: 0.6104 - 188ms/epoch - 38ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.8925 - accuracy: 0.6557 - val_loss: 0.9268 - val_accuracy: 0.6104 - 199ms/epoch - 40ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.8815 - accuracy: 0.6623 - val_loss: 0.9145 - val_accuracy: 0.6104 - 191ms/epoch - 38ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.8740 - accuracy: 0.6262 - val_loss: 0.9195 - val_accuracy: 0.6104 - 210ms/epoch - 42ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.8947 - accuracy: 0.6525 - val_loss: 0.9003 - val_accuracy: 0.6104 - 195ms/epoch - 39ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.8664 - accuracy: 0.6656 - val_loss: 0.9146 - val_accuracy: 0.6364 - 200ms/epoch - 40ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9144 - accuracy: 0.6754 - val_loss: 0.9258 - val_accuracy: 0.6234 - 206ms/epoch - 41ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.8884 - accuracy: 0.6656 - val_loss: 0.9309 - val_accuracy: 0.6234 - 198ms/epoch - 40ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.8694 - accuracy: 0.6525 - val_loss: 0.8874 - val_accuracy: 0.6623 - 188ms/epoch - 38ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.8845 - accuracy: 0.6525 - val_loss: 0.9329 - val_accuracy: 0.6234 - 191ms/epoch - 38ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.8643 - accuracy: 0.6590 - val_loss: 0.9238 - val_accuracy: 0.6234 - 187ms/epoch - 37ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.8948 - accuracy: 0.6393 - val_loss: 0.8969 - val_accuracy: 0.6364 - 222ms/epoch - 44ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.8365 - accuracy: 0.6557 - val_loss: 0.9443 - val_accuracy: 0.5974 - 211ms/epoch - 42ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.8544 - accuracy: 0.6492 - val_loss: 0.9070 - val_accuracy: 0.6364 - 193ms/epoch - 39ms/step\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8347 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:27:21,975] Trial 3 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'tanh', 'activation_func_3': 'swish', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 250}. Best is trial 1 with value: 0.6764705777168274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3854 - accuracy: 0.3148 - val_loss: 1.3830 - val_accuracy: 0.3636 - 4s/epoch - 447ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 1s - loss: 1.3799 - accuracy: 0.3902 - val_loss: 1.3740 - val_accuracy: 0.3636 - 528ms/epoch - 53ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 1s - loss: 1.3631 - accuracy: 0.4361 - val_loss: 1.3485 - val_accuracy: 0.3766 - 545ms/epoch - 54ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 1s - loss: 1.3144 - accuracy: 0.4426 - val_loss: 1.2922 - val_accuracy: 0.3636 - 536ms/epoch - 54ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 1s - loss: 1.2284 - accuracy: 0.4525 - val_loss: 1.2527 - val_accuracy: 0.3636 - 591ms/epoch - 59ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 1s - loss: 1.1895 - accuracy: 0.4656 - val_loss: 1.1787 - val_accuracy: 0.3766 - 786ms/epoch - 79ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 1s - loss: 1.1535 - accuracy: 0.4885 - val_loss: 1.1830 - val_accuracy: 0.3896 - 847ms/epoch - 85ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 1s - loss: 1.1784 - accuracy: 0.4885 - val_loss: 1.1732 - val_accuracy: 0.4156 - 778ms/epoch - 78ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 1s - loss: 1.1619 - accuracy: 0.5148 - val_loss: 1.1548 - val_accuracy: 0.4156 - 776ms/epoch - 78ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 1s - loss: 1.1152 - accuracy: 0.5148 - val_loss: 1.1314 - val_accuracy: 0.4416 - 901ms/epoch - 90ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 1s - loss: 1.1045 - accuracy: 0.5311 - val_loss: 1.1420 - val_accuracy: 0.4286 - 868ms/epoch - 87ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 1s - loss: 1.0846 - accuracy: 0.5311 - val_loss: 1.1184 - val_accuracy: 0.4675 - 860ms/epoch - 86ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 1s - loss: 1.0756 - accuracy: 0.5475 - val_loss: 1.1053 - val_accuracy: 0.4545 - 765ms/epoch - 76ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 1s - loss: 1.0594 - accuracy: 0.5443 - val_loss: 1.0889 - val_accuracy: 0.4545 - 830ms/epoch - 83ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 1s - loss: 1.0655 - accuracy: 0.5508 - val_loss: 1.0975 - val_accuracy: 0.4675 - 760ms/epoch - 76ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 1s - loss: 1.0525 - accuracy: 0.5475 - val_loss: 1.0753 - val_accuracy: 0.4545 - 784ms/epoch - 78ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 1s - loss: 1.0726 - accuracy: 0.5443 - val_loss: 1.0762 - val_accuracy: 0.4416 - 779ms/epoch - 78ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 1s - loss: 1.0562 - accuracy: 0.5410 - val_loss: 1.0990 - val_accuracy: 0.4935 - 761ms/epoch - 76ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 1s - loss: 1.0738 - accuracy: 0.5410 - val_loss: 1.0811 - val_accuracy: 0.4805 - 753ms/epoch - 75ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 1s - loss: 1.0518 - accuracy: 0.5475 - val_loss: 1.0394 - val_accuracy: 0.6104 - 762ms/epoch - 76ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 1s - loss: 1.0393 - accuracy: 0.5770 - val_loss: 1.0499 - val_accuracy: 0.4805 - 794ms/epoch - 79ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 1s - loss: 1.0299 - accuracy: 0.5508 - val_loss: 1.0358 - val_accuracy: 0.4935 - 835ms/epoch - 83ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 1s - loss: 1.0216 - accuracy: 0.5672 - val_loss: 1.0370 - val_accuracy: 0.4935 - 827ms/epoch - 83ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 1s - loss: 1.0117 - accuracy: 0.5836 - val_loss: 1.0238 - val_accuracy: 0.5455 - 900ms/epoch - 90ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 1s - loss: 1.0018 - accuracy: 0.5803 - val_loss: 1.0119 - val_accuracy: 0.4805 - 854ms/epoch - 85ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 1s - loss: 0.9901 - accuracy: 0.5770 - val_loss: 0.9618 - val_accuracy: 0.5844 - 944ms/epoch - 94ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 1s - loss: 0.9701 - accuracy: 0.6164 - val_loss: 0.9846 - val_accuracy: 0.5195 - 766ms/epoch - 77ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 1s - loss: 0.9536 - accuracy: 0.6000 - val_loss: 0.9710 - val_accuracy: 0.5714 - 785ms/epoch - 79ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 1s - loss: 0.9319 - accuracy: 0.6098 - val_loss: 0.9450 - val_accuracy: 0.5455 - 766ms/epoch - 77ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 1s - loss: 0.9341 - accuracy: 0.6262 - val_loss: 0.8896 - val_accuracy: 0.6234 - 791ms/epoch - 79ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 1s - loss: 0.9322 - accuracy: 0.6164 - val_loss: 0.9138 - val_accuracy: 0.6234 - 771ms/epoch - 77ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 1s - loss: 0.9232 - accuracy: 0.6557 - val_loss: 0.9188 - val_accuracy: 0.5714 - 755ms/epoch - 76ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 1s - loss: 0.9442 - accuracy: 0.5934 - val_loss: 0.9422 - val_accuracy: 0.5584 - 762ms/epoch - 76ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 1s - loss: 0.9175 - accuracy: 0.6393 - val_loss: 0.8899 - val_accuracy: 0.6234 - 766ms/epoch - 77ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 1s - loss: 0.8877 - accuracy: 0.6590 - val_loss: 0.9075 - val_accuracy: 0.5844 - 796ms/epoch - 80ms/step\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9270 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:27:54,625] Trial 4 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.25, 'neurons': 243}. Best is trial 1 with value: 0.6764705777168274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3855 - accuracy: 0.3279 - val_loss: 1.3838 - val_accuracy: 0.3896 - 4s/epoch - 856ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3822 - accuracy: 0.3836 - val_loss: 1.3796 - val_accuracy: 0.3117 - 312ms/epoch - 62ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3757 - accuracy: 0.4230 - val_loss: 1.3728 - val_accuracy: 0.3636 - 331ms/epoch - 66ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3651 - accuracy: 0.4590 - val_loss: 1.3593 - val_accuracy: 0.3636 - 326ms/epoch - 65ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3409 - accuracy: 0.4590 - val_loss: 1.3361 - val_accuracy: 0.3636 - 335ms/epoch - 67ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3051 - accuracy: 0.4656 - val_loss: 1.3030 - val_accuracy: 0.3636 - 356ms/epoch - 71ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.2691 - accuracy: 0.4623 - val_loss: 1.2694 - val_accuracy: 0.3636 - 355ms/epoch - 71ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2149 - accuracy: 0.4623 - val_loss: 1.2315 - val_accuracy: 0.3636 - 337ms/epoch - 67ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.1844 - accuracy: 0.4623 - val_loss: 1.2046 - val_accuracy: 0.4026 - 330ms/epoch - 66ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.1728 - accuracy: 0.4918 - val_loss: 1.1832 - val_accuracy: 0.3636 - 330ms/epoch - 66ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1651 - accuracy: 0.5082 - val_loss: 1.1748 - val_accuracy: 0.3766 - 329ms/epoch - 66ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1536 - accuracy: 0.5049 - val_loss: 1.1618 - val_accuracy: 0.4026 - 338ms/epoch - 68ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1344 - accuracy: 0.4885 - val_loss: 1.1649 - val_accuracy: 0.4156 - 325ms/epoch - 65ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1247 - accuracy: 0.5115 - val_loss: 1.1466 - val_accuracy: 0.4545 - 330ms/epoch - 66ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1387 - accuracy: 0.5082 - val_loss: 1.1415 - val_accuracy: 0.4156 - 342ms/epoch - 68ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1199 - accuracy: 0.5279 - val_loss: 1.1328 - val_accuracy: 0.4805 - 336ms/epoch - 67ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1018 - accuracy: 0.5311 - val_loss: 1.1212 - val_accuracy: 0.4545 - 330ms/epoch - 66ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.0928 - accuracy: 0.5410 - val_loss: 1.1085 - val_accuracy: 0.4416 - 331ms/epoch - 66ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.0951 - accuracy: 0.5344 - val_loss: 1.1132 - val_accuracy: 0.4545 - 330ms/epoch - 66ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.0697 - accuracy: 0.5607 - val_loss: 1.0930 - val_accuracy: 0.4675 - 335ms/epoch - 67ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.0425 - accuracy: 0.5902 - val_loss: 1.0966 - val_accuracy: 0.4675 - 323ms/epoch - 65ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.0937 - accuracy: 0.5475 - val_loss: 1.0903 - val_accuracy: 0.4545 - 338ms/epoch - 68ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.0814 - accuracy: 0.5541 - val_loss: 1.0894 - val_accuracy: 0.4545 - 356ms/epoch - 71ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0681 - accuracy: 0.5410 - val_loss: 1.0714 - val_accuracy: 0.4545 - 328ms/epoch - 66ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.0444 - accuracy: 0.5574 - val_loss: 1.0716 - val_accuracy: 0.4675 - 339ms/epoch - 68ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0384 - accuracy: 0.5672 - val_loss: 1.0525 - val_accuracy: 0.5325 - 334ms/epoch - 67ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0605 - accuracy: 0.5541 - val_loss: 1.0404 - val_accuracy: 0.4805 - 328ms/epoch - 66ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0456 - accuracy: 0.5475 - val_loss: 1.0515 - val_accuracy: 0.4805 - 343ms/epoch - 69ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0401 - accuracy: 0.5574 - val_loss: 1.0312 - val_accuracy: 0.4805 - 334ms/epoch - 67ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0277 - accuracy: 0.5770 - val_loss: 1.0204 - val_accuracy: 0.4935 - 330ms/epoch - 66ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0188 - accuracy: 0.5574 - val_loss: 1.0257 - val_accuracy: 0.4805 - 357ms/epoch - 71ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0114 - accuracy: 0.5607 - val_loss: 1.0175 - val_accuracy: 0.5065 - 331ms/epoch - 66ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0115 - accuracy: 0.5770 - val_loss: 1.0254 - val_accuracy: 0.5065 - 334ms/epoch - 67ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0093 - accuracy: 0.5705 - val_loss: 1.0050 - val_accuracy: 0.4935 - 330ms/epoch - 66ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0030 - accuracy: 0.5803 - val_loss: 0.9818 - val_accuracy: 0.5714 - 339ms/epoch - 68ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0076 - accuracy: 0.5705 - val_loss: 0.9628 - val_accuracy: 0.5714 - 326ms/epoch - 65ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.9716 - accuracy: 0.5803 - val_loss: 0.9641 - val_accuracy: 0.5974 - 328ms/epoch - 66ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.9607 - accuracy: 0.6033 - val_loss: 0.9756 - val_accuracy: 0.5195 - 319ms/epoch - 64ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.9796 - accuracy: 0.6066 - val_loss: 0.9465 - val_accuracy: 0.5455 - 333ms/epoch - 67ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.9707 - accuracy: 0.6295 - val_loss: 0.9353 - val_accuracy: 0.5714 - 337ms/epoch - 67ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.9550 - accuracy: 0.6328 - val_loss: 0.9238 - val_accuracy: 0.6234 - 327ms/epoch - 65ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.9308 - accuracy: 0.6262 - val_loss: 0.9423 - val_accuracy: 0.5325 - 333ms/epoch - 67ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.9417 - accuracy: 0.6000 - val_loss: 0.9321 - val_accuracy: 0.6234 - 335ms/epoch - 67ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.9598 - accuracy: 0.6525 - val_loss: 0.9660 - val_accuracy: 0.5584 - 332ms/epoch - 66ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.9084 - accuracy: 0.6295 - val_loss: 0.9075 - val_accuracy: 0.5974 - 358ms/epoch - 72ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9518 - accuracy: 0.6197 - val_loss: 0.9052 - val_accuracy: 0.5974 - 349ms/epoch - 70ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9355 - accuracy: 0.6000 - val_loss: 0.9441 - val_accuracy: 0.5584 - 358ms/epoch - 72ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 0.9176 - accuracy: 0.6328 - val_loss: 0.9064 - val_accuracy: 0.6364 - 349ms/epoch - 70ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9139 - accuracy: 0.6197 - val_loss: 0.9209 - val_accuracy: 0.5455 - 337ms/epoch - 67ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.8862 - accuracy: 0.6361 - val_loss: 0.8888 - val_accuracy: 0.6364 - 332ms/epoch - 66ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.9047 - accuracy: 0.6623 - val_loss: 0.8946 - val_accuracy: 0.6104 - 335ms/epoch - 67ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.8833 - accuracy: 0.6590 - val_loss: 0.8827 - val_accuracy: 0.5974 - 333ms/epoch - 67ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.8848 - accuracy: 0.6557 - val_loss: 0.8902 - val_accuracy: 0.6104 - 334ms/epoch - 67ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9021 - accuracy: 0.6164 - val_loss: 0.8758 - val_accuracy: 0.6104 - 334ms/epoch - 67ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9040 - accuracy: 0.6328 - val_loss: 0.8703 - val_accuracy: 0.6104 - 330ms/epoch - 66ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.8868 - accuracy: 0.6525 - val_loss: 0.8835 - val_accuracy: 0.6234 - 348ms/epoch - 70ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.8551 - accuracy: 0.6426 - val_loss: 0.8792 - val_accuracy: 0.6234 - 326ms/epoch - 65ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.9023 - accuracy: 0.6295 - val_loss: 0.8894 - val_accuracy: 0.6234 - 339ms/epoch - 68ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.9125 - accuracy: 0.6557 - val_loss: 0.8641 - val_accuracy: 0.6364 - 324ms/epoch - 65ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.8684 - accuracy: 0.6721 - val_loss: 0.8739 - val_accuracy: 0.6234 - 332ms/epoch - 66ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.8962 - accuracy: 0.6525 - val_loss: 0.8714 - val_accuracy: 0.6364 - 335ms/epoch - 67ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.8969 - accuracy: 0.6492 - val_loss: 0.8991 - val_accuracy: 0.5974 - 333ms/epoch - 67ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.8590 - accuracy: 0.6459 - val_loss: 0.9116 - val_accuracy: 0.6104 - 333ms/epoch - 67ms/step\n",
      "Epoch 64/10000\n",
      "5/5 - 0s - loss: 0.8596 - accuracy: 0.6590 - val_loss: 0.8819 - val_accuracy: 0.6494 - 332ms/epoch - 66ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8906 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:28:21,634] Trial 5 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'selu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 174}. Best is trial 1 with value: 0.6764705777168274.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3848 - accuracy: 0.2820 - val_loss: 1.3803 - val_accuracy: 0.3247 - 4s/epoch - 403ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3807 - accuracy: 0.3213 - val_loss: 1.3708 - val_accuracy: 0.3247 - 201ms/epoch - 20ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3675 - accuracy: 0.3770 - val_loss: 1.3534 - val_accuracy: 0.4026 - 212ms/epoch - 21ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3347 - accuracy: 0.4557 - val_loss: 1.3139 - val_accuracy: 0.3636 - 215ms/epoch - 21ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2794 - accuracy: 0.4426 - val_loss: 1.2567 - val_accuracy: 0.3506 - 204ms/epoch - 20ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2067 - accuracy: 0.4525 - val_loss: 1.2177 - val_accuracy: 0.3636 - 199ms/epoch - 20ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1900 - accuracy: 0.4754 - val_loss: 1.1962 - val_accuracy: 0.3766 - 199ms/epoch - 20ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2107 - accuracy: 0.4557 - val_loss: 1.1866 - val_accuracy: 0.4156 - 187ms/epoch - 19ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1805 - accuracy: 0.4754 - val_loss: 1.1691 - val_accuracy: 0.3896 - 175ms/epoch - 18ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1429 - accuracy: 0.4656 - val_loss: 1.1711 - val_accuracy: 0.4026 - 187ms/epoch - 19ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1372 - accuracy: 0.4918 - val_loss: 1.1616 - val_accuracy: 0.3896 - 173ms/epoch - 17ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1279 - accuracy: 0.5082 - val_loss: 1.1502 - val_accuracy: 0.4286 - 178ms/epoch - 18ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1277 - accuracy: 0.5246 - val_loss: 1.1469 - val_accuracy: 0.4156 - 176ms/epoch - 18ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1169 - accuracy: 0.5311 - val_loss: 1.1421 - val_accuracy: 0.4156 - 181ms/epoch - 18ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1246 - accuracy: 0.5148 - val_loss: 1.1302 - val_accuracy: 0.4545 - 181ms/epoch - 18ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0925 - accuracy: 0.5344 - val_loss: 1.1238 - val_accuracy: 0.4545 - 177ms/epoch - 18ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1218 - accuracy: 0.5377 - val_loss: 1.1248 - val_accuracy: 0.4805 - 179ms/epoch - 18ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1022 - accuracy: 0.5443 - val_loss: 1.1116 - val_accuracy: 0.4416 - 188ms/epoch - 19ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1318 - accuracy: 0.5377 - val_loss: 1.1132 - val_accuracy: 0.4545 - 177ms/epoch - 18ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0921 - accuracy: 0.5213 - val_loss: 1.0912 - val_accuracy: 0.5455 - 175ms/epoch - 18ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0905 - accuracy: 0.5377 - val_loss: 1.0857 - val_accuracy: 0.4545 - 181ms/epoch - 18ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0755 - accuracy: 0.5246 - val_loss: 1.0785 - val_accuracy: 0.4675 - 183ms/epoch - 18ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0712 - accuracy: 0.5508 - val_loss: 1.0840 - val_accuracy: 0.4416 - 185ms/epoch - 19ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0858 - accuracy: 0.5574 - val_loss: 1.0754 - val_accuracy: 0.4675 - 184ms/epoch - 18ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0579 - accuracy: 0.5639 - val_loss: 1.0642 - val_accuracy: 0.4675 - 188ms/epoch - 19ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0769 - accuracy: 0.5508 - val_loss: 1.0354 - val_accuracy: 0.5584 - 178ms/epoch - 18ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0690 - accuracy: 0.5934 - val_loss: 1.0354 - val_accuracy: 0.4545 - 175ms/epoch - 17ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0406 - accuracy: 0.5672 - val_loss: 1.0271 - val_accuracy: 0.5065 - 175ms/epoch - 17ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0375 - accuracy: 0.5803 - val_loss: 1.0274 - val_accuracy: 0.4935 - 167ms/epoch - 17ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0265 - accuracy: 0.5705 - val_loss: 1.0093 - val_accuracy: 0.5325 - 171ms/epoch - 17ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0028 - accuracy: 0.5934 - val_loss: 0.9976 - val_accuracy: 0.5455 - 176ms/epoch - 18ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0262 - accuracy: 0.5803 - val_loss: 0.9911 - val_accuracy: 0.4935 - 174ms/epoch - 17ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0565 - accuracy: 0.5344 - val_loss: 0.9840 - val_accuracy: 0.5065 - 182ms/epoch - 18ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0198 - accuracy: 0.5902 - val_loss: 0.9864 - val_accuracy: 0.5325 - 174ms/epoch - 17ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9527 - accuracy: 0.6230 - val_loss: 0.9522 - val_accuracy: 0.5325 - 175ms/epoch - 18ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9867 - accuracy: 0.6197 - val_loss: 0.9239 - val_accuracy: 0.5974 - 177ms/epoch - 18ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9795 - accuracy: 0.6098 - val_loss: 0.9523 - val_accuracy: 0.5714 - 173ms/epoch - 17ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9972 - accuracy: 0.6098 - val_loss: 0.9571 - val_accuracy: 0.5065 - 178ms/epoch - 18ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9638 - accuracy: 0.6164 - val_loss: 0.9230 - val_accuracy: 0.5584 - 160ms/epoch - 16ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9666 - accuracy: 0.6197 - val_loss: 0.9049 - val_accuracy: 0.5844 - 171ms/epoch - 17ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0021 - accuracy: 0.5770 - val_loss: 0.9114 - val_accuracy: 0.5974 - 162ms/epoch - 16ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9865 - accuracy: 0.6164 - val_loss: 0.9300 - val_accuracy: 0.5195 - 164ms/epoch - 16ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9737 - accuracy: 0.6262 - val_loss: 0.9242 - val_accuracy: 0.5844 - 170ms/epoch - 17ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9702 - accuracy: 0.6164 - val_loss: 0.9067 - val_accuracy: 0.5844 - 175ms/epoch - 17ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9615 - accuracy: 0.6131 - val_loss: 0.9148 - val_accuracy: 0.5974 - 163ms/epoch - 16ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8945 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:28:35,406] Trial 6 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'selu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 140}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 5s - loss: 1.3833 - accuracy: 0.3246 - val_loss: 1.3777 - val_accuracy: 0.4156 - 5s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3691 - accuracy: 0.4787 - val_loss: 1.3620 - val_accuracy: 0.4156 - 231ms/epoch - 58ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3455 - accuracy: 0.5148 - val_loss: 1.3277 - val_accuracy: 0.3896 - 232ms/epoch - 58ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.2995 - accuracy: 0.5115 - val_loss: 1.2737 - val_accuracy: 0.4026 - 233ms/epoch - 58ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.2466 - accuracy: 0.4918 - val_loss: 1.2287 - val_accuracy: 0.3636 - 245ms/epoch - 61ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.2065 - accuracy: 0.4885 - val_loss: 1.2099 - val_accuracy: 0.3766 - 242ms/epoch - 60ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.2017 - accuracy: 0.4852 - val_loss: 1.1685 - val_accuracy: 0.4026 - 236ms/epoch - 59ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.1745 - accuracy: 0.5180 - val_loss: 1.1561 - val_accuracy: 0.5065 - 245ms/epoch - 61ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.1402 - accuracy: 0.5148 - val_loss: 1.1637 - val_accuracy: 0.4416 - 243ms/epoch - 61ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.1472 - accuracy: 0.5115 - val_loss: 1.1406 - val_accuracy: 0.3896 - 247ms/epoch - 62ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.1188 - accuracy: 0.5443 - val_loss: 1.1356 - val_accuracy: 0.4156 - 252ms/epoch - 63ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.1052 - accuracy: 0.5541 - val_loss: 1.1313 - val_accuracy: 0.4286 - 229ms/epoch - 57ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.1000 - accuracy: 0.5541 - val_loss: 1.1149 - val_accuracy: 0.4286 - 239ms/epoch - 60ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.0796 - accuracy: 0.5410 - val_loss: 1.0857 - val_accuracy: 0.4675 - 243ms/epoch - 61ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.0649 - accuracy: 0.5574 - val_loss: 1.0672 - val_accuracy: 0.4935 - 233ms/epoch - 58ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.0712 - accuracy: 0.5639 - val_loss: 1.0441 - val_accuracy: 0.4545 - 246ms/epoch - 61ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.0489 - accuracy: 0.5672 - val_loss: 1.0304 - val_accuracy: 0.4805 - 243ms/epoch - 61ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.0432 - accuracy: 0.5475 - val_loss: 1.0368 - val_accuracy: 0.4675 - 239ms/epoch - 60ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.0332 - accuracy: 0.5705 - val_loss: 1.0263 - val_accuracy: 0.4805 - 253ms/epoch - 63ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 0.9830 - accuracy: 0.5770 - val_loss: 0.9903 - val_accuracy: 0.5325 - 243ms/epoch - 61ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 0.9934 - accuracy: 0.5803 - val_loss: 0.9736 - val_accuracy: 0.5455 - 240ms/epoch - 60ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 0.9929 - accuracy: 0.6066 - val_loss: 0.9607 - val_accuracy: 0.5584 - 245ms/epoch - 61ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 0.9846 - accuracy: 0.5705 - val_loss: 1.0113 - val_accuracy: 0.5584 - 239ms/epoch - 60ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 0.9680 - accuracy: 0.6000 - val_loss: 0.9634 - val_accuracy: 0.5195 - 255ms/epoch - 64ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 0.9522 - accuracy: 0.6000 - val_loss: 0.9358 - val_accuracy: 0.5714 - 252ms/epoch - 63ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 0.9084 - accuracy: 0.6361 - val_loss: 0.9340 - val_accuracy: 0.6494 - 249ms/epoch - 62ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 0.9116 - accuracy: 0.6197 - val_loss: 0.8996 - val_accuracy: 0.6234 - 261ms/epoch - 65ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 0.8942 - accuracy: 0.6459 - val_loss: 0.9297 - val_accuracy: 0.6364 - 249ms/epoch - 62ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 0.8827 - accuracy: 0.6426 - val_loss: 0.9717 - val_accuracy: 0.5455 - 246ms/epoch - 61ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 0.9066 - accuracy: 0.6131 - val_loss: 0.9049 - val_accuracy: 0.6234 - 257ms/epoch - 64ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 0.8745 - accuracy: 0.6262 - val_loss: 0.8953 - val_accuracy: 0.6494 - 244ms/epoch - 61ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 0.8507 - accuracy: 0.6525 - val_loss: 0.9047 - val_accuracy: 0.6234 - 250ms/epoch - 63ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 0.8448 - accuracy: 0.6590 - val_loss: 0.9120 - val_accuracy: 0.6364 - 243ms/epoch - 61ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 0.8392 - accuracy: 0.6459 - val_loss: 0.9223 - val_accuracy: 0.6623 - 237ms/epoch - 59ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 0.8380 - accuracy: 0.6525 - val_loss: 0.9070 - val_accuracy: 0.6623 - 242ms/epoch - 60ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 0.8386 - accuracy: 0.6656 - val_loss: 0.9049 - val_accuracy: 0.6623 - 236ms/epoch - 59ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9124 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:28:50,240] Trial 7 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'selu', 'activation_func_3': 'linear', 'batch_size': 80, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 208}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3861 - accuracy: 0.2787 - val_loss: 1.3857 - val_accuracy: 0.2597 - 4s/epoch - 824ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3857 - accuracy: 0.2721 - val_loss: 1.3847 - val_accuracy: 0.2597 - 178ms/epoch - 36ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3848 - accuracy: 0.2721 - val_loss: 1.3834 - val_accuracy: 0.2727 - 188ms/epoch - 38ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3837 - accuracy: 0.3148 - val_loss: 1.3819 - val_accuracy: 0.3506 - 191ms/epoch - 38ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3817 - accuracy: 0.3738 - val_loss: 1.3793 - val_accuracy: 0.3247 - 184ms/epoch - 37ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3784 - accuracy: 0.3902 - val_loss: 1.3751 - val_accuracy: 0.3117 - 191ms/epoch - 38ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3729 - accuracy: 0.3803 - val_loss: 1.3684 - val_accuracy: 0.3117 - 189ms/epoch - 38ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.3611 - accuracy: 0.3836 - val_loss: 1.3573 - val_accuracy: 0.3117 - 194ms/epoch - 39ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.3415 - accuracy: 0.3803 - val_loss: 1.3408 - val_accuracy: 0.3117 - 189ms/epoch - 38ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.3147 - accuracy: 0.3803 - val_loss: 1.3258 - val_accuracy: 0.3117 - 186ms/epoch - 37ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.2937 - accuracy: 0.4131 - val_loss: 1.3044 - val_accuracy: 0.3636 - 188ms/epoch - 38ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.2714 - accuracy: 0.4557 - val_loss: 1.2897 - val_accuracy: 0.3506 - 182ms/epoch - 36ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.2529 - accuracy: 0.4393 - val_loss: 1.2819 - val_accuracy: 0.3636 - 185ms/epoch - 37ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.2439 - accuracy: 0.4361 - val_loss: 1.2669 - val_accuracy: 0.3636 - 192ms/epoch - 38ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.2188 - accuracy: 0.4426 - val_loss: 1.2360 - val_accuracy: 0.3636 - 188ms/epoch - 38ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1976 - accuracy: 0.4557 - val_loss: 1.2183 - val_accuracy: 0.3636 - 185ms/epoch - 37ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1815 - accuracy: 0.4918 - val_loss: 1.2061 - val_accuracy: 0.3766 - 189ms/epoch - 38ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1620 - accuracy: 0.4754 - val_loss: 1.1872 - val_accuracy: 0.3766 - 190ms/epoch - 38ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1766 - accuracy: 0.4754 - val_loss: 1.1774 - val_accuracy: 0.3766 - 188ms/epoch - 38ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1690 - accuracy: 0.4787 - val_loss: 1.1687 - val_accuracy: 0.3766 - 196ms/epoch - 39ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1342 - accuracy: 0.4754 - val_loss: 1.1570 - val_accuracy: 0.3896 - 190ms/epoch - 38ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1243 - accuracy: 0.4885 - val_loss: 1.1491 - val_accuracy: 0.3766 - 192ms/epoch - 38ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1333 - accuracy: 0.4787 - val_loss: 1.1418 - val_accuracy: 0.3766 - 183ms/epoch - 37ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0965 - accuracy: 0.4852 - val_loss: 1.1412 - val_accuracy: 0.3766 - 197ms/epoch - 39ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1438 - accuracy: 0.4623 - val_loss: 1.1445 - val_accuracy: 0.3896 - 197ms/epoch - 39ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.1133 - accuracy: 0.5279 - val_loss: 1.1293 - val_accuracy: 0.4286 - 192ms/epoch - 38ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.1168 - accuracy: 0.5148 - val_loss: 1.1249 - val_accuracy: 0.4286 - 198ms/epoch - 40ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.1038 - accuracy: 0.5082 - val_loss: 1.1217 - val_accuracy: 0.4286 - 183ms/epoch - 37ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0826 - accuracy: 0.5246 - val_loss: 1.1319 - val_accuracy: 0.4416 - 195ms/epoch - 39ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.1172 - accuracy: 0.4885 - val_loss: 1.1249 - val_accuracy: 0.4545 - 185ms/epoch - 37ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0739 - accuracy: 0.5148 - val_loss: 1.1273 - val_accuracy: 0.4416 - 189ms/epoch - 38ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.1116 - accuracy: 0.5279 - val_loss: 1.1263 - val_accuracy: 0.4286 - 194ms/epoch - 39ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0895 - accuracy: 0.5115 - val_loss: 1.1391 - val_accuracy: 0.4286 - 196ms/epoch - 39ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0670 - accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:29:01,836] Trial 8 finished with value: 0.5882353186607361 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'swish', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 148}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 4s - loss: 1.3862 - accuracy: 0.2590 - val_loss: 1.3857 - val_accuracy: 0.2597 - 4s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3860 - accuracy: 0.2656 - val_loss: 1.3850 - val_accuracy: 0.2597 - 172ms/epoch - 43ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3852 - accuracy: 0.2656 - val_loss: 1.3840 - val_accuracy: 0.2597 - 180ms/epoch - 45ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.3846 - accuracy: 0.2852 - val_loss: 1.3829 - val_accuracy: 0.3377 - 172ms/epoch - 43ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.3836 - accuracy: 0.3410 - val_loss: 1.3811 - val_accuracy: 0.3506 - 178ms/epoch - 44ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.3818 - accuracy: 0.3803 - val_loss: 1.3788 - val_accuracy: 0.3117 - 172ms/epoch - 43ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.3792 - accuracy: 0.3934 - val_loss: 1.3753 - val_accuracy: 0.3117 - 199ms/epoch - 50ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.3746 - accuracy: 0.3934 - val_loss: 1.3699 - val_accuracy: 0.3506 - 184ms/epoch - 46ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.3674 - accuracy: 0.4164 - val_loss: 1.3605 - val_accuracy: 0.3377 - 184ms/epoch - 46ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.3536 - accuracy: 0.4721 - val_loss: 1.3467 - val_accuracy: 0.4156 - 183ms/epoch - 46ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.3326 - accuracy: 0.4852 - val_loss: 1.3263 - val_accuracy: 0.4545 - 173ms/epoch - 43ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.3097 - accuracy: 0.5049 - val_loss: 1.2978 - val_accuracy: 0.4156 - 172ms/epoch - 43ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.2768 - accuracy: 0.4852 - val_loss: 1.2703 - val_accuracy: 0.3766 - 182ms/epoch - 46ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.2487 - accuracy: 0.4623 - val_loss: 1.2509 - val_accuracy: 0.3766 - 173ms/epoch - 43ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.2284 - accuracy: 0.4656 - val_loss: 1.2251 - val_accuracy: 0.3506 - 182ms/epoch - 45ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.2203 - accuracy: 0.4689 - val_loss: 1.2056 - val_accuracy: 0.3766 - 181ms/epoch - 45ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.1990 - accuracy: 0.4721 - val_loss: 1.1958 - val_accuracy: 0.3636 - 176ms/epoch - 44ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.1770 - accuracy: 0.4852 - val_loss: 1.1916 - val_accuracy: 0.3636 - 174ms/epoch - 43ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.1683 - accuracy: 0.5016 - val_loss: 1.1820 - val_accuracy: 0.3506 - 174ms/epoch - 43ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.1698 - accuracy: 0.5049 - val_loss: 1.1714 - val_accuracy: 0.3506 - 176ms/epoch - 44ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.1600 - accuracy: 0.5148 - val_loss: 1.1585 - val_accuracy: 0.3896 - 180ms/epoch - 45ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.1271 - accuracy: 0.4852 - val_loss: 1.1492 - val_accuracy: 0.4026 - 175ms/epoch - 44ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.1285 - accuracy: 0.5082 - val_loss: 1.1451 - val_accuracy: 0.4026 - 173ms/epoch - 43ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.1466 - accuracy: 0.5213 - val_loss: 1.1306 - val_accuracy: 0.3896 - 174ms/epoch - 43ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.1093 - accuracy: 0.5049 - val_loss: 1.1234 - val_accuracy: 0.4026 - 173ms/epoch - 43ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 1.1015 - accuracy: 0.5082 - val_loss: 1.1307 - val_accuracy: 0.4156 - 176ms/epoch - 44ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.1018 - accuracy: 0.5082 - val_loss: 1.1134 - val_accuracy: 0.3896 - 170ms/epoch - 42ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 1.1083 - accuracy: 0.5180 - val_loss: 1.1056 - val_accuracy: 0.4156 - 204ms/epoch - 51ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 1.1055 - accuracy: 0.5180 - val_loss: 1.1001 - val_accuracy: 0.4545 - 206ms/epoch - 52ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 1.0818 - accuracy: 0.5082 - val_loss: 1.0942 - val_accuracy: 0.4416 - 216ms/epoch - 54ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 1.0921 - accuracy: 0.5344 - val_loss: 1.0947 - val_accuracy: 0.4286 - 218ms/epoch - 54ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 1.1004 - accuracy: 0.5311 - val_loss: 1.0891 - val_accuracy: 0.4416 - 194ms/epoch - 48ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 1.0812 - accuracy: 0.5443 - val_loss: 1.0863 - val_accuracy: 0.4805 - 192ms/epoch - 48ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 1.0985 - accuracy: 0.5443 - val_loss: 1.0804 - val_accuracy: 0.4675 - 187ms/epoch - 47ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 1.0717 - accuracy: 0.5311 - val_loss: 1.0764 - val_accuracy: 0.4805 - 212ms/epoch - 53ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 1.0655 - accuracy: 0.5279 - val_loss: 1.0722 - val_accuracy: 0.4675 - 220ms/epoch - 55ms/step\n",
      "Epoch 37/10000\n",
      "4/4 - 0s - loss: 1.0327 - accuracy: 0.5607 - val_loss: 1.0655 - val_accuracy: 0.4545 - 249ms/epoch - 62ms/step\n",
      "Epoch 38/10000\n",
      "4/4 - 0s - loss: 1.0402 - accuracy: 0.5574 - val_loss: 1.0608 - val_accuracy: 0.4675 - 222ms/epoch - 55ms/step\n",
      "Epoch 39/10000\n",
      "4/4 - 0s - loss: 1.0260 - accuracy: 0.5672 - val_loss: 1.0592 - val_accuracy: 0.4805 - 196ms/epoch - 49ms/step\n",
      "Epoch 40/10000\n",
      "4/4 - 0s - loss: 1.0464 - accuracy: 0.5508 - val_loss: 1.0467 - val_accuracy: 0.4805 - 190ms/epoch - 48ms/step\n",
      "Epoch 41/10000\n",
      "4/4 - 0s - loss: 1.0331 - accuracy: 0.5639 - val_loss: 1.0371 - val_accuracy: 0.5455 - 177ms/epoch - 44ms/step\n",
      "Epoch 42/10000\n",
      "4/4 - 0s - loss: 1.0480 - accuracy: 0.5672 - val_loss: 1.0394 - val_accuracy: 0.5195 - 193ms/epoch - 48ms/step\n",
      "Epoch 43/10000\n",
      "4/4 - 0s - loss: 1.0210 - accuracy: 0.5967 - val_loss: 1.0294 - val_accuracy: 0.4935 - 189ms/epoch - 47ms/step\n",
      "Epoch 44/10000\n",
      "4/4 - 0s - loss: 1.0157 - accuracy: 0.5934 - val_loss: 1.0246 - val_accuracy: 0.4805 - 186ms/epoch - 46ms/step\n",
      "Epoch 45/10000\n",
      "4/4 - 0s - loss: 1.0099 - accuracy: 0.5869 - val_loss: 1.0165 - val_accuracy: 0.5195 - 180ms/epoch - 45ms/step\n",
      "Epoch 46/10000\n",
      "4/4 - 0s - loss: 0.9869 - accuracy: 0.6000 - val_loss: 1.0091 - val_accuracy: 0.5065 - 187ms/epoch - 47ms/step\n",
      "Epoch 47/10000\n",
      "4/4 - 0s - loss: 1.0003 - accuracy: 0.5738 - val_loss: 0.9961 - val_accuracy: 0.5195 - 183ms/epoch - 46ms/step\n",
      "Epoch 48/10000\n",
      "4/4 - 0s - loss: 1.0000 - accuracy: 0.5967 - val_loss: 0.9915 - val_accuracy: 0.5584 - 192ms/epoch - 48ms/step\n",
      "Epoch 49/10000\n",
      "4/4 - 0s - loss: 0.9808 - accuracy: 0.6033 - val_loss: 1.0113 - val_accuracy: 0.5584 - 193ms/epoch - 48ms/step\n",
      "Epoch 50/10000\n",
      "4/4 - 0s - loss: 0.9859 - accuracy: 0.5967 - val_loss: 0.9801 - val_accuracy: 0.5195 - 212ms/epoch - 53ms/step\n",
      "Epoch 51/10000\n",
      "4/4 - 0s - loss: 1.0337 - accuracy: 0.5902 - val_loss: 0.9725 - val_accuracy: 0.5325 - 215ms/epoch - 54ms/step\n",
      "Epoch 52/10000\n",
      "4/4 - 0s - loss: 0.9862 - accuracy: 0.5934 - val_loss: 0.9680 - val_accuracy: 0.5455 - 196ms/epoch - 49ms/step\n",
      "Epoch 53/10000\n",
      "4/4 - 0s - loss: 0.9765 - accuracy: 0.5967 - val_loss: 0.9536 - val_accuracy: 0.5455 - 193ms/epoch - 48ms/step\n",
      "Epoch 54/10000\n",
      "4/4 - 0s - loss: 0.9905 - accuracy: 0.5902 - val_loss: 0.9495 - val_accuracy: 0.6104 - 181ms/epoch - 45ms/step\n",
      "Epoch 55/10000\n",
      "4/4 - 0s - loss: 0.9703 - accuracy: 0.6066 - val_loss: 0.9397 - val_accuracy: 0.5844 - 187ms/epoch - 47ms/step\n",
      "Epoch 56/10000\n",
      "4/4 - 0s - loss: 0.9559 - accuracy: 0.6131 - val_loss: 0.9305 - val_accuracy: 0.5714 - 188ms/epoch - 47ms/step\n",
      "Epoch 57/10000\n",
      "4/4 - 0s - loss: 0.9692 - accuracy: 0.6164 - val_loss: 0.9322 - val_accuracy: 0.5714 - 190ms/epoch - 48ms/step\n",
      "Epoch 58/10000\n",
      "4/4 - 0s - loss: 0.9355 - accuracy: 0.6098 - val_loss: 0.9237 - val_accuracy: 0.5714 - 179ms/epoch - 45ms/step\n",
      "Epoch 59/10000\n",
      "4/4 - 0s - loss: 0.9306 - accuracy: 0.6262 - val_loss: 0.9029 - val_accuracy: 0.5974 - 183ms/epoch - 46ms/step\n",
      "Epoch 60/10000\n",
      "4/4 - 0s - loss: 0.9258 - accuracy: 0.6361 - val_loss: 0.8931 - val_accuracy: 0.5974 - 180ms/epoch - 45ms/step\n",
      "Epoch 61/10000\n",
      "4/4 - 0s - loss: 0.9109 - accuracy: 0.6393 - val_loss: 0.8861 - val_accuracy: 0.6494 - 186ms/epoch - 46ms/step\n",
      "Epoch 62/10000\n",
      "4/4 - 0s - loss: 0.9312 - accuracy: 0.6066 - val_loss: 0.9078 - val_accuracy: 0.5714 - 174ms/epoch - 43ms/step\n",
      "Epoch 63/10000\n",
      "4/4 - 0s - loss: 0.9235 - accuracy: 0.5967 - val_loss: 0.9135 - val_accuracy: 0.6104 - 199ms/epoch - 50ms/step\n",
      "Epoch 64/10000\n",
      "4/4 - 0s - loss: 0.9322 - accuracy: 0.6590 - val_loss: 0.9028 - val_accuracy: 0.6234 - 192ms/epoch - 48ms/step\n",
      "Epoch 65/10000\n",
      "4/4 - 0s - loss: 0.9184 - accuracy: 0.6590 - val_loss: 0.9118 - val_accuracy: 0.5844 - 195ms/epoch - 49ms/step\n",
      "Epoch 66/10000\n",
      "4/4 - 0s - loss: 0.9295 - accuracy: 0.6426 - val_loss: 0.8941 - val_accuracy: 0.6104 - 179ms/epoch - 45ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8818 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:29:19,930] Trial 9 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'swish', 'batch_size': 80, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 227}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3852 - accuracy: 0.2623 - val_loss: 1.3803 - val_accuracy: 0.3247 - 5s/epoch - 647ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3797 - accuracy: 0.3279 - val_loss: 1.3730 - val_accuracy: 0.3506 - 197ms/epoch - 28ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3726 - accuracy: 0.3377 - val_loss: 1.3626 - val_accuracy: 0.3506 - 343ms/epoch - 49ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3584 - accuracy: 0.3639 - val_loss: 1.3435 - val_accuracy: 0.3896 - 260ms/epoch - 37ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3330 - accuracy: 0.3902 - val_loss: 1.3244 - val_accuracy: 0.3117 - 219ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3033 - accuracy: 0.4361 - val_loss: 1.2931 - val_accuracy: 0.3766 - 237ms/epoch - 34ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2802 - accuracy: 0.4459 - val_loss: 1.2692 - val_accuracy: 0.3506 - 221ms/epoch - 32ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2407 - accuracy: 0.4689 - val_loss: 1.2529 - val_accuracy: 0.3636 - 228ms/epoch - 33ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2302 - accuracy: 0.4623 - val_loss: 1.2249 - val_accuracy: 0.4156 - 234ms/epoch - 33ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2060 - accuracy: 0.4754 - val_loss: 1.1981 - val_accuracy: 0.4026 - 246ms/epoch - 35ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1793 - accuracy: 0.4787 - val_loss: 1.1915 - val_accuracy: 0.3896 - 243ms/epoch - 35ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1700 - accuracy: 0.4984 - val_loss: 1.1880 - val_accuracy: 0.4026 - 228ms/epoch - 33ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1777 - accuracy: 0.4787 - val_loss: 1.1692 - val_accuracy: 0.4026 - 200ms/epoch - 29ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1518 - accuracy: 0.4885 - val_loss: 1.1759 - val_accuracy: 0.4026 - 211ms/epoch - 30ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1783 - accuracy: 0.4918 - val_loss: 1.1537 - val_accuracy: 0.3636 - 207ms/epoch - 30ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1502 - accuracy: 0.5049 - val_loss: 1.1695 - val_accuracy: 0.3766 - 202ms/epoch - 29ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1554 - accuracy: 0.4951 - val_loss: 1.1577 - val_accuracy: 0.3896 - 205ms/epoch - 29ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1479 - accuracy: 0.4984 - val_loss: 1.1469 - val_accuracy: 0.3896 - 202ms/epoch - 29ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1554 - accuracy: 0.5016 - val_loss: 1.1456 - val_accuracy: 0.4026 - 217ms/epoch - 31ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1471 - accuracy: 0.4885 - val_loss: 1.1577 - val_accuracy: 0.4545 - 199ms/epoch - 28ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1629 - accuracy: 0.4984 - val_loss: 1.1369 - val_accuracy: 0.4156 - 203ms/epoch - 29ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1231 - accuracy: 0.5148 - val_loss: 1.1286 - val_accuracy: 0.4286 - 213ms/epoch - 30ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1482 - accuracy: 0.5082 - val_loss: 1.1286 - val_accuracy: 0.4026 - 208ms/epoch - 30ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1194 - accuracy: 0.5148 - val_loss: 1.1219 - val_accuracy: 0.4026 - 213ms/epoch - 30ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1170 - accuracy: 0.5279 - val_loss: 1.1206 - val_accuracy: 0.4286 - 219ms/epoch - 31ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0966 - accuracy: 0.5377 - val_loss: 1.1098 - val_accuracy: 0.4675 - 207ms/epoch - 30ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1095 - accuracy: 0.5082 - val_loss: 1.1090 - val_accuracy: 0.4286 - 216ms/epoch - 31ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1071 - accuracy: 0.5344 - val_loss: 1.0981 - val_accuracy: 0.4545 - 209ms/epoch - 30ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1071 - accuracy: 0.5508 - val_loss: 1.0947 - val_accuracy: 0.4805 - 206ms/epoch - 29ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1095 - accuracy: 0.5148 - val_loss: 1.1123 - val_accuracy: 0.4675 - 203ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0827 - accuracy: 0.5410 - val_loss: 1.0914 - val_accuracy: 0.4156 - 211ms/epoch - 30ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.1048 - accuracy: 0.5082 - val_loss: 1.1057 - val_accuracy: 0.4286 - 211ms/epoch - 30ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0895 - accuracy: 0.5148 - val_loss: 1.1113 - val_accuracy: 0.4286 - 207ms/epoch - 30ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0841 - accuracy: 0.5344 - val_loss: 1.1056 - val_accuracy: 0.4156 - 212ms/epoch - 30ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.1011 - accuracy: 0.5607 - val_loss: 1.0975 - val_accuracy: 0.4805 - 197ms/epoch - 28ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0796 - accuracy: 0.5541 - val_loss: 1.0851 - val_accuracy: 0.5844 - 219ms/epoch - 31ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0777 - accuracy: 0.5541 - val_loss: 1.0905 - val_accuracy: 0.5714 - 216ms/epoch - 31ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.1101 - accuracy: 0.5377 - val_loss: 1.0752 - val_accuracy: 0.4805 - 199ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0804 - accuracy: 0.5574 - val_loss: 1.0859 - val_accuracy: 0.4675 - 204ms/epoch - 29ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0942 - accuracy: 0.5443 - val_loss: 1.0703 - val_accuracy: 0.4805 - 207ms/epoch - 30ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0872 - accuracy: 0.5279 - val_loss: 1.0339 - val_accuracy: 0.5974 - 209ms/epoch - 30ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0989 - accuracy: 0.5607 - val_loss: 1.0446 - val_accuracy: 0.5974 - 217ms/epoch - 31ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 1.0720 - accuracy: 0.5246 - val_loss: 1.0225 - val_accuracy: 0.6104 - 217ms/epoch - 31ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0635 - accuracy: 0.5410 - val_loss: 1.0220 - val_accuracy: 0.5714 - 224ms/epoch - 32ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 1.0625 - accuracy: 0.5377 - val_loss: 1.0217 - val_accuracy: 0.5325 - 217ms/epoch - 31ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 1.0721 - accuracy: 0.5607 - val_loss: 1.0409 - val_accuracy: 0.4935 - 220ms/epoch - 31ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 1.0479 - accuracy: 0.5836 - val_loss: 1.0448 - val_accuracy: 0.4935 - 215ms/epoch - 31ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 1.0465 - accuracy: 0.5738 - val_loss: 1.0560 - val_accuracy: 0.4416 - 220ms/epoch - 31ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 1.0639 - accuracy: 0.5508 - val_loss: 1.0429 - val_accuracy: 0.5195 - 214ms/epoch - 31ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 1.0433 - accuracy: 0.5902 - val_loss: 1.0132 - val_accuracy: 0.5455 - 210ms/epoch - 30ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 1.0464 - accuracy: 0.5967 - val_loss: 1.0125 - val_accuracy: 0.6104 - 210ms/epoch - 30ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 1.0364 - accuracy: 0.5344 - val_loss: 0.9957 - val_accuracy: 0.5844 - 206ms/epoch - 29ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 1.0320 - accuracy: 0.6000 - val_loss: 1.0066 - val_accuracy: 0.5195 - 205ms/epoch - 29ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 1.0220 - accuracy: 0.5738 - val_loss: 1.0148 - val_accuracy: 0.4935 - 210ms/epoch - 30ms/step\n",
      "Epoch 55/10000\n",
      "7/7 - 0s - loss: 1.0235 - accuracy: 0.5869 - val_loss: 1.0016 - val_accuracy: 0.5325 - 204ms/epoch - 29ms/step\n",
      "Epoch 56/10000\n",
      "7/7 - 0s - loss: 1.0310 - accuracy: 0.5869 - val_loss: 0.9905 - val_accuracy: 0.4935 - 205ms/epoch - 29ms/step\n",
      "Epoch 57/10000\n",
      "7/7 - 0s - loss: 1.0316 - accuracy: 0.6033 - val_loss: 0.9618 - val_accuracy: 0.5584 - 208ms/epoch - 30ms/step\n",
      "Epoch 58/10000\n",
      "7/7 - 0s - loss: 1.0277 - accuracy: 0.5836 - val_loss: 0.9592 - val_accuracy: 0.5065 - 205ms/epoch - 29ms/step\n",
      "Epoch 59/10000\n",
      "7/7 - 0s - loss: 1.0221 - accuracy: 0.5639 - val_loss: 0.9678 - val_accuracy: 0.5325 - 213ms/epoch - 30ms/step\n",
      "Epoch 60/10000\n",
      "7/7 - 0s - loss: 0.9945 - accuracy: 0.5902 - val_loss: 0.9559 - val_accuracy: 0.5195 - 200ms/epoch - 29ms/step\n",
      "Epoch 61/10000\n",
      "7/7 - 0s - loss: 1.0353 - accuracy: 0.6131 - val_loss: 0.9512 - val_accuracy: 0.5455 - 203ms/epoch - 29ms/step\n",
      "Epoch 62/10000\n",
      "7/7 - 0s - loss: 0.9968 - accuracy: 0.5902 - val_loss: 0.9606 - val_accuracy: 0.5195 - 206ms/epoch - 29ms/step\n",
      "Epoch 63/10000\n",
      "7/7 - 0s - loss: 1.0352 - accuracy: 0.5836 - val_loss: 0.9530 - val_accuracy: 0.5714 - 212ms/epoch - 30ms/step\n",
      "Epoch 64/10000\n",
      "7/7 - 0s - loss: 1.0114 - accuracy: 0.5902 - val_loss: 0.9546 - val_accuracy: 0.5714 - 204ms/epoch - 29ms/step\n",
      "Epoch 65/10000\n",
      "7/7 - 0s - loss: 0.9911 - accuracy: 0.5934 - val_loss: 0.9692 - val_accuracy: 0.5195 - 205ms/epoch - 29ms/step\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.9971 - accuracy: 0.5967 - val_loss: 0.9514 - val_accuracy: 0.4935 - 210ms/epoch - 30ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9204 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:29:40,216] Trial 10 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'selu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 132}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 5s - loss: 1.3774 - accuracy: 0.3902 - val_loss: 1.3667 - val_accuracy: 0.4156 - 5s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3549 - accuracy: 0.4852 - val_loss: 1.3407 - val_accuracy: 0.4286 - 208ms/epoch - 52ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3159 - accuracy: 0.5115 - val_loss: 1.3038 - val_accuracy: 0.3766 - 221ms/epoch - 55ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.2625 - accuracy: 0.4951 - val_loss: 1.2643 - val_accuracy: 0.3636 - 243ms/epoch - 61ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.2247 - accuracy: 0.4689 - val_loss: 1.2398 - val_accuracy: 0.3636 - 229ms/epoch - 57ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.1965 - accuracy: 0.4918 - val_loss: 1.2138 - val_accuracy: 0.3896 - 222ms/epoch - 55ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.1956 - accuracy: 0.5279 - val_loss: 1.1799 - val_accuracy: 0.4026 - 234ms/epoch - 59ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.1649 - accuracy: 0.5213 - val_loss: 1.1585 - val_accuracy: 0.4675 - 227ms/epoch - 57ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.1652 - accuracy: 0.5180 - val_loss: 1.1573 - val_accuracy: 0.4156 - 228ms/epoch - 57ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.1448 - accuracy: 0.5148 - val_loss: 1.1611 - val_accuracy: 0.4286 - 227ms/epoch - 57ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.1346 - accuracy: 0.5148 - val_loss: 1.1567 - val_accuracy: 0.4416 - 231ms/epoch - 58ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.1098 - accuracy: 0.5410 - val_loss: 1.1438 - val_accuracy: 0.4675 - 224ms/epoch - 56ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.0846 - accuracy: 0.5672 - val_loss: 1.1358 - val_accuracy: 0.4545 - 223ms/epoch - 56ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.0944 - accuracy: 0.5770 - val_loss: 1.1166 - val_accuracy: 0.4545 - 225ms/epoch - 56ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.0818 - accuracy: 0.5508 - val_loss: 1.0863 - val_accuracy: 0.4805 - 223ms/epoch - 56ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.0629 - accuracy: 0.5770 - val_loss: 1.0775 - val_accuracy: 0.4805 - 244ms/epoch - 61ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.0743 - accuracy: 0.5410 - val_loss: 1.0604 - val_accuracy: 0.4805 - 240ms/epoch - 60ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.0772 - accuracy: 0.5541 - val_loss: 1.0642 - val_accuracy: 0.4545 - 228ms/epoch - 57ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.0667 - accuracy: 0.5705 - val_loss: 1.0723 - val_accuracy: 0.4675 - 238ms/epoch - 59ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.0404 - accuracy: 0.5541 - val_loss: 1.0373 - val_accuracy: 0.5065 - 240ms/epoch - 60ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.0353 - accuracy: 0.5639 - val_loss: 1.0291 - val_accuracy: 0.5455 - 240ms/epoch - 60ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.0447 - accuracy: 0.5902 - val_loss: 1.0218 - val_accuracy: 0.4935 - 248ms/epoch - 62ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.0154 - accuracy: 0.5705 - val_loss: 1.0419 - val_accuracy: 0.4935 - 258ms/epoch - 64ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.0074 - accuracy: 0.5869 - val_loss: 0.9993 - val_accuracy: 0.5455 - 241ms/epoch - 60ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.0180 - accuracy: 0.5738 - val_loss: 0.9809 - val_accuracy: 0.5714 - 244ms/epoch - 61ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 0.9899 - accuracy: 0.5902 - val_loss: 0.9805 - val_accuracy: 0.5455 - 230ms/epoch - 57ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.0073 - accuracy: 0.5967 - val_loss: 0.9621 - val_accuracy: 0.5584 - 241ms/epoch - 60ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 0.9866 - accuracy: 0.5967 - val_loss: 0.9700 - val_accuracy: 0.5195 - 230ms/epoch - 57ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 0.9517 - accuracy: 0.6131 - val_loss: 0.9443 - val_accuracy: 0.5714 - 222ms/epoch - 55ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 0.9612 - accuracy: 0.5902 - val_loss: 0.9366 - val_accuracy: 0.5714 - 230ms/epoch - 57ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 0.9559 - accuracy: 0.6033 - val_loss: 0.9480 - val_accuracy: 0.5455 - 234ms/epoch - 58ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 0.9328 - accuracy: 0.6098 - val_loss: 0.9278 - val_accuracy: 0.5974 - 222ms/epoch - 56ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 0.9404 - accuracy: 0.6262 - val_loss: 0.9187 - val_accuracy: 0.5844 - 231ms/epoch - 58ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 0.9412 - accuracy: 0.6197 - val_loss: 0.9254 - val_accuracy: 0.5714 - 237ms/epoch - 59ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 0.9205 - accuracy: 0.6459 - val_loss: 0.9013 - val_accuracy: 0.5974 - 227ms/epoch - 57ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 0.9033 - accuracy: 0.6393 - val_loss: 0.8928 - val_accuracy: 0.5974 - 221ms/epoch - 55ms/step\n",
      "Epoch 37/10000\n",
      "4/4 - 0s - loss: 0.8882 - accuracy: 0.6098 - val_loss: 0.9013 - val_accuracy: 0.6104 - 224ms/epoch - 56ms/step\n",
      "Epoch 38/10000\n",
      "4/4 - 0s - loss: 0.9147 - accuracy: 0.6098 - val_loss: 0.8946 - val_accuracy: 0.6494 - 226ms/epoch - 57ms/step\n",
      "Epoch 39/10000\n",
      "4/4 - 0s - loss: 0.8938 - accuracy: 0.6295 - val_loss: 0.8909 - val_accuracy: 0.5714 - 228ms/epoch - 57ms/step\n",
      "Epoch 40/10000\n",
      "4/4 - 0s - loss: 0.8867 - accuracy: 0.6262 - val_loss: 0.8840 - val_accuracy: 0.6234 - 224ms/epoch - 56ms/step\n",
      "Epoch 41/10000\n",
      "4/4 - 0s - loss: 0.9233 - accuracy: 0.6426 - val_loss: 0.8800 - val_accuracy: 0.6234 - 223ms/epoch - 56ms/step\n",
      "Epoch 42/10000\n",
      "4/4 - 0s - loss: 0.8868 - accuracy: 0.6295 - val_loss: 0.9112 - val_accuracy: 0.5584 - 226ms/epoch - 56ms/step\n",
      "Epoch 43/10000\n",
      "4/4 - 0s - loss: 0.8775 - accuracy: 0.6557 - val_loss: 0.8924 - val_accuracy: 0.6364 - 224ms/epoch - 56ms/step\n",
      "Epoch 44/10000\n",
      "4/4 - 0s - loss: 0.8845 - accuracy: 0.6426 - val_loss: 0.8774 - val_accuracy: 0.6364 - 223ms/epoch - 56ms/step\n",
      "Epoch 45/10000\n",
      "4/4 - 0s - loss: 0.8617 - accuracy: 0.6492 - val_loss: 0.9070 - val_accuracy: 0.6364 - 230ms/epoch - 58ms/step\n",
      "Epoch 46/10000\n",
      "4/4 - 0s - loss: 0.8872 - accuracy: 0.6557 - val_loss: 0.8957 - val_accuracy: 0.6623 - 228ms/epoch - 57ms/step\n",
      "Epoch 47/10000\n",
      "4/4 - 0s - loss: 0.8488 - accuracy: 0.6590 - val_loss: 0.8756 - val_accuracy: 0.6364 - 232ms/epoch - 58ms/step\n",
      "Epoch 48/10000\n",
      "4/4 - 0s - loss: 0.8435 - accuracy: 0.6951 - val_loss: 0.8869 - val_accuracy: 0.6364 - 230ms/epoch - 57ms/step\n",
      "Epoch 49/10000\n",
      "4/4 - 0s - loss: 0.8583 - accuracy: 0.6754 - val_loss: 0.8803 - val_accuracy: 0.6364 - 228ms/epoch - 57ms/step\n",
      "Epoch 50/10000\n",
      "4/4 - 0s - loss: 0.8399 - accuracy: 0.6656 - val_loss: 0.8917 - val_accuracy: 0.6494 - 224ms/epoch - 56ms/step\n",
      "Epoch 51/10000\n",
      "4/4 - 0s - loss: 0.8483 - accuracy: 0.6656 - val_loss: 0.8977 - val_accuracy: 0.6364 - 225ms/epoch - 56ms/step\n",
      "Epoch 52/10000\n",
      "4/4 - 0s - loss: 0.8492 - accuracy: 0.6623 - val_loss: 0.8615 - val_accuracy: 0.6623 - 246ms/epoch - 61ms/step\n",
      "Epoch 53/10000\n",
      "4/4 - 0s - loss: 0.8315 - accuracy: 0.6557 - val_loss: 0.9087 - val_accuracy: 0.6364 - 231ms/epoch - 58ms/step\n",
      "Epoch 54/10000\n",
      "4/4 - 0s - loss: 0.8555 - accuracy: 0.6525 - val_loss: 0.8869 - val_accuracy: 0.6623 - 222ms/epoch - 56ms/step\n",
      "Epoch 55/10000\n",
      "4/4 - 0s - loss: 0.8683 - accuracy: 0.6459 - val_loss: 0.9128 - val_accuracy: 0.6364 - 233ms/epoch - 58ms/step\n",
      "Epoch 56/10000\n",
      "4/4 - 0s - loss: 0.8487 - accuracy: 0.6590 - val_loss: 0.9235 - val_accuracy: 0.6364 - 231ms/epoch - 58ms/step\n",
      "Epoch 57/10000\n",
      "4/4 - 0s - loss: 0.8325 - accuracy: 0.6721 - val_loss: 0.8947 - val_accuracy: 0.6364 - 228ms/epoch - 57ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:30:00,113] Trial 11 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'selu', 'activation_func_3': 'selu', 'batch_size': 80, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 152}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3834 - accuracy: 0.2656 - val_loss: 1.3787 - val_accuracy: 0.3896 - 5s/epoch - 526ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3693 - accuracy: 0.4656 - val_loss: 1.3608 - val_accuracy: 0.4286 - 174ms/epoch - 17ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3395 - accuracy: 0.5049 - val_loss: 1.3185 - val_accuracy: 0.4156 - 174ms/epoch - 17ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2794 - accuracy: 0.5016 - val_loss: 1.2613 - val_accuracy: 0.3506 - 178ms/epoch - 18ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2510 - accuracy: 0.4623 - val_loss: 1.2344 - val_accuracy: 0.3766 - 195ms/epoch - 19ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2137 - accuracy: 0.4885 - val_loss: 1.2107 - val_accuracy: 0.3636 - 189ms/epoch - 19ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1886 - accuracy: 0.4721 - val_loss: 1.1828 - val_accuracy: 0.3636 - 188ms/epoch - 19ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1936 - accuracy: 0.4721 - val_loss: 1.1699 - val_accuracy: 0.4026 - 192ms/epoch - 19ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1788 - accuracy: 0.4918 - val_loss: 1.1574 - val_accuracy: 0.3896 - 172ms/epoch - 17ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1430 - accuracy: 0.5115 - val_loss: 1.1511 - val_accuracy: 0.4026 - 178ms/epoch - 18ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1521 - accuracy: 0.4984 - val_loss: 1.1453 - val_accuracy: 0.3766 - 169ms/epoch - 17ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1159 - accuracy: 0.5049 - val_loss: 1.1513 - val_accuracy: 0.4156 - 172ms/epoch - 17ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1242 - accuracy: 0.5148 - val_loss: 1.1321 - val_accuracy: 0.3896 - 187ms/epoch - 19ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1034 - accuracy: 0.5180 - val_loss: 1.1191 - val_accuracy: 0.4286 - 180ms/epoch - 18ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1255 - accuracy: 0.5311 - val_loss: 1.1048 - val_accuracy: 0.4286 - 198ms/epoch - 20ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0984 - accuracy: 0.5311 - val_loss: 1.0971 - val_accuracy: 0.4026 - 171ms/epoch - 17ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0863 - accuracy: 0.5541 - val_loss: 1.0872 - val_accuracy: 0.4286 - 170ms/epoch - 17ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0986 - accuracy: 0.5311 - val_loss: 1.0788 - val_accuracy: 0.4675 - 176ms/epoch - 18ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0864 - accuracy: 0.5705 - val_loss: 1.0832 - val_accuracy: 0.4545 - 177ms/epoch - 18ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0826 - accuracy: 0.5410 - val_loss: 1.0703 - val_accuracy: 0.4805 - 178ms/epoch - 18ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0605 - accuracy: 0.5311 - val_loss: 1.0593 - val_accuracy: 0.4545 - 180ms/epoch - 18ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0591 - accuracy: 0.5770 - val_loss: 1.0472 - val_accuracy: 0.4675 - 180ms/epoch - 18ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0339 - accuracy: 0.5574 - val_loss: 1.0415 - val_accuracy: 0.4805 - 181ms/epoch - 18ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0303 - accuracy: 0.5738 - val_loss: 1.0246 - val_accuracy: 0.5065 - 176ms/epoch - 18ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0080 - accuracy: 0.6066 - val_loss: 1.0040 - val_accuracy: 0.5065 - 174ms/epoch - 17ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0314 - accuracy: 0.6000 - val_loss: 0.9766 - val_accuracy: 0.6234 - 171ms/epoch - 17ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0027 - accuracy: 0.5967 - val_loss: 0.9718 - val_accuracy: 0.5325 - 178ms/epoch - 18ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9891 - accuracy: 0.5934 - val_loss: 0.9671 - val_accuracy: 0.5584 - 180ms/epoch - 18ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0066 - accuracy: 0.6066 - val_loss: 0.9801 - val_accuracy: 0.5325 - 184ms/epoch - 18ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9828 - accuracy: 0.6164 - val_loss: 0.9380 - val_accuracy: 0.5844 - 180ms/epoch - 18ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9383 - accuracy: 0.6131 - val_loss: 0.9449 - val_accuracy: 0.5584 - 183ms/epoch - 18ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9623 - accuracy: 0.6361 - val_loss: 0.9155 - val_accuracy: 0.6104 - 179ms/epoch - 18ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9601 - accuracy: 0.6262 - val_loss: 0.9146 - val_accuracy: 0.5844 - 177ms/epoch - 18ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9540 - accuracy: 0.6131 - val_loss: 0.9146 - val_accuracy: 0.6234 - 174ms/epoch - 17ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9311 - accuracy: 0.6230 - val_loss: 0.8877 - val_accuracy: 0.5974 - 176ms/epoch - 18ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9166 - accuracy: 0.6328 - val_loss: 0.8638 - val_accuracy: 0.6364 - 182ms/epoch - 18ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.8977 - accuracy: 0.6557 - val_loss: 0.8656 - val_accuracy: 0.6364 - 176ms/epoch - 18ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.8970 - accuracy: 0.6262 - val_loss: 0.8863 - val_accuracy: 0.6234 - 176ms/epoch - 18ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.8896 - accuracy: 0.6557 - val_loss: 0.8668 - val_accuracy: 0.6364 - 175ms/epoch - 17ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9376 - accuracy: 0.6492 - val_loss: 0.8497 - val_accuracy: 0.6364 - 180ms/epoch - 18ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9483 - accuracy: 0.6459 - val_loss: 0.8857 - val_accuracy: 0.6364 - 183ms/epoch - 18ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.8990 - accuracy: 0.6459 - val_loss: 0.8776 - val_accuracy: 0.5974 - 171ms/epoch - 17ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.8618 - accuracy: 0.6525 - val_loss: 0.8692 - val_accuracy: 0.6364 - 180ms/epoch - 18ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9045 - accuracy: 0.6393 - val_loss: 0.8713 - val_accuracy: 0.6234 - 185ms/epoch - 19ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9211 - accuracy: 0.6361 - val_loss: 0.8713 - val_accuracy: 0.6234 - 195ms/epoch - 20ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8552 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:30:15,303] Trial 12 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'tanh', 'activation_func_3': 'tanh', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 130}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3845 - accuracy: 0.3049 - val_loss: 1.3786 - val_accuracy: 0.3247 - 5s/epoch - 683ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3753 - accuracy: 0.3869 - val_loss: 1.3633 - val_accuracy: 0.3377 - 358ms/epoch - 51ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3543 - accuracy: 0.3902 - val_loss: 1.3361 - val_accuracy: 0.3636 - 370ms/epoch - 53ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3083 - accuracy: 0.4393 - val_loss: 1.2953 - val_accuracy: 0.3636 - 376ms/epoch - 54ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2521 - accuracy: 0.4754 - val_loss: 1.2516 - val_accuracy: 0.3636 - 388ms/epoch - 55ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.1982 - accuracy: 0.4492 - val_loss: 1.2096 - val_accuracy: 0.3896 - 409ms/epoch - 58ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.1591 - accuracy: 0.4951 - val_loss: 1.1841 - val_accuracy: 0.4286 - 392ms/epoch - 56ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.1672 - accuracy: 0.5410 - val_loss: 1.1725 - val_accuracy: 0.4156 - 390ms/epoch - 56ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.1951 - accuracy: 0.4426 - val_loss: 1.1691 - val_accuracy: 0.3896 - 385ms/epoch - 55ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.1572 - accuracy: 0.4656 - val_loss: 1.1540 - val_accuracy: 0.4416 - 377ms/epoch - 54ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1314 - accuracy: 0.5311 - val_loss: 1.1751 - val_accuracy: 0.4156 - 383ms/epoch - 55ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1354 - accuracy: 0.5377 - val_loss: 1.1695 - val_accuracy: 0.4675 - 378ms/epoch - 54ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1389 - accuracy: 0.5148 - val_loss: 1.1453 - val_accuracy: 0.3896 - 365ms/epoch - 52ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1207 - accuracy: 0.4951 - val_loss: 1.1148 - val_accuracy: 0.4675 - 379ms/epoch - 54ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1059 - accuracy: 0.5443 - val_loss: 1.1221 - val_accuracy: 0.4286 - 372ms/epoch - 53ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1287 - accuracy: 0.5377 - val_loss: 1.1006 - val_accuracy: 0.4545 - 375ms/epoch - 54ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1076 - accuracy: 0.5410 - val_loss: 1.0935 - val_accuracy: 0.4805 - 380ms/epoch - 54ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1073 - accuracy: 0.5475 - val_loss: 1.1084 - val_accuracy: 0.5065 - 385ms/epoch - 55ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.0953 - accuracy: 0.5541 - val_loss: 1.0885 - val_accuracy: 0.4675 - 386ms/epoch - 55ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1225 - accuracy: 0.5082 - val_loss: 1.0506 - val_accuracy: 0.6104 - 368ms/epoch - 53ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.0868 - accuracy: 0.5803 - val_loss: 1.0535 - val_accuracy: 0.4805 - 369ms/epoch - 53ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.0576 - accuracy: 0.5574 - val_loss: 1.0435 - val_accuracy: 0.4935 - 374ms/epoch - 53ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.0535 - accuracy: 0.5541 - val_loss: 1.0466 - val_accuracy: 0.5065 - 356ms/epoch - 51ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.0485 - accuracy: 0.5410 - val_loss: 1.0512 - val_accuracy: 0.4935 - 353ms/epoch - 50ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0418 - accuracy: 0.5574 - val_loss: 1.0209 - val_accuracy: 0.5065 - 349ms/epoch - 50ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0405 - accuracy: 0.5738 - val_loss: 0.9784 - val_accuracy: 0.6234 - 357ms/epoch - 51ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0152 - accuracy: 0.5738 - val_loss: 0.9838 - val_accuracy: 0.5065 - 366ms/epoch - 52ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 0.9961 - accuracy: 0.5902 - val_loss: 0.9510 - val_accuracy: 0.5844 - 354ms/epoch - 51ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0221 - accuracy: 0.5705 - val_loss: 0.9848 - val_accuracy: 0.6234 - 403ms/epoch - 58ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0345 - accuracy: 0.5770 - val_loss: 0.9679 - val_accuracy: 0.5325 - 374ms/epoch - 53ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0060 - accuracy: 0.5803 - val_loss: 0.9499 - val_accuracy: 0.5195 - 354ms/epoch - 51ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 0.9772 - accuracy: 0.5705 - val_loss: 0.9417 - val_accuracy: 0.5455 - 358ms/epoch - 51ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 0.9585 - accuracy: 0.6098 - val_loss: 0.9174 - val_accuracy: 0.5455 - 363ms/epoch - 52ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 0.9584 - accuracy: 0.6328 - val_loss: 0.9036 - val_accuracy: 0.5974 - 370ms/epoch - 53ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 0.9623 - accuracy: 0.6164 - val_loss: 0.9099 - val_accuracy: 0.5714 - 372ms/epoch - 53ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 0.9354 - accuracy: 0.6197 - val_loss: 0.8998 - val_accuracy: 0.6364 - 350ms/epoch - 50ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 0.9557 - accuracy: 0.6426 - val_loss: 0.9048 - val_accuracy: 0.6364 - 357ms/epoch - 51ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 0.9481 - accuracy: 0.6361 - val_loss: 0.9203 - val_accuracy: 0.5455 - 362ms/epoch - 52ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 0.9127 - accuracy: 0.6525 - val_loss: 0.9033 - val_accuracy: 0.5584 - 353ms/epoch - 50ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 0.9156 - accuracy: 0.6197 - val_loss: 0.8898 - val_accuracy: 0.6364 - 352ms/epoch - 50ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 0.9400 - accuracy: 0.6393 - val_loss: 0.8623 - val_accuracy: 0.6494 - 357ms/epoch - 51ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 0.9689 - accuracy: 0.6295 - val_loss: 0.8620 - val_accuracy: 0.6494 - 349ms/epoch - 50ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9017 - accuracy: 0.6459 - val_loss: 0.8673 - val_accuracy: 0.6364 - 360ms/epoch - 51ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 0.9113 - accuracy: 0.6656 - val_loss: 0.8617 - val_accuracy: 0.6494 - 349ms/epoch - 50ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9274 - accuracy: 0.6361 - val_loss: 0.8919 - val_accuracy: 0.5714 - 355ms/epoch - 51ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9035 - accuracy: 0.6230 - val_loss: 0.8834 - val_accuracy: 0.5844 - 358ms/epoch - 51ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.8692 - accuracy: 0.6623 - val_loss: 0.8745 - val_accuracy: 0.6623 - 368ms/epoch - 53ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 0.8814 - accuracy: 0.6426 - val_loss: 0.8835 - val_accuracy: 0.6494 - 370ms/epoch - 53ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 0.8919 - accuracy: 0.6393 - val_loss: 0.8470 - val_accuracy: 0.6364 - 387ms/epoch - 55ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 0.9049 - accuracy: 0.6590 - val_loss: 0.8553 - val_accuracy: 0.6364 - 374ms/epoch - 53ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 0.8990 - accuracy: 0.6689 - val_loss: 0.8567 - val_accuracy: 0.6364 - 386ms/epoch - 55ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 0.8621 - accuracy: 0.6787 - val_loss: 0.8521 - val_accuracy: 0.6364 - 397ms/epoch - 57ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 0.8682 - accuracy: 0.6295 - val_loss: 0.9194 - val_accuracy: 0.5844 - 369ms/epoch - 53ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 0.9446 - accuracy: 0.6230 - val_loss: 0.8736 - val_accuracy: 0.6364 - 370ms/epoch - 53ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9226 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:30:41,263] Trial 13 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'relu', 'activation_func_3': 'selu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 192}. Best is trial 6 with value: 0.6911764740943909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3839 - accuracy: 0.3639 - val_loss: 1.3816 - val_accuracy: 0.3766 - 4s/epoch - 411ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3718 - accuracy: 0.4295 - val_loss: 1.3648 - val_accuracy: 0.3896 - 275ms/epoch - 27ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3322 - accuracy: 0.4721 - val_loss: 1.3213 - val_accuracy: 0.3766 - 293ms/epoch - 29ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2579 - accuracy: 0.4525 - val_loss: 1.2600 - val_accuracy: 0.3636 - 305ms/epoch - 31ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2125 - accuracy: 0.4557 - val_loss: 1.2272 - val_accuracy: 0.3636 - 307ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2060 - accuracy: 0.4557 - val_loss: 1.2065 - val_accuracy: 0.3636 - 313ms/epoch - 31ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1804 - accuracy: 0.4754 - val_loss: 1.2128 - val_accuracy: 0.3896 - 310ms/epoch - 31ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2453 - accuracy: 0.3967 - val_loss: 1.2050 - val_accuracy: 0.3896 - 296ms/epoch - 30ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1770 - accuracy: 0.4787 - val_loss: 1.1749 - val_accuracy: 0.4156 - 298ms/epoch - 30ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1427 - accuracy: 0.5049 - val_loss: 1.1554 - val_accuracy: 0.3766 - 306ms/epoch - 31ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1466 - accuracy: 0.4787 - val_loss: 1.1546 - val_accuracy: 0.4026 - 286ms/epoch - 29ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1594 - accuracy: 0.4852 - val_loss: 1.1396 - val_accuracy: 0.4156 - 302ms/epoch - 30ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1287 - accuracy: 0.4885 - val_loss: 1.1643 - val_accuracy: 0.3896 - 295ms/epoch - 29ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1163 - accuracy: 0.5246 - val_loss: 1.1278 - val_accuracy: 0.4286 - 299ms/epoch - 30ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1323 - accuracy: 0.5180 - val_loss: 1.1130 - val_accuracy: 0.4416 - 305ms/epoch - 31ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1063 - accuracy: 0.5180 - val_loss: 1.1062 - val_accuracy: 0.4026 - 287ms/epoch - 29ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1056 - accuracy: 0.5246 - val_loss: 1.0937 - val_accuracy: 0.4545 - 302ms/epoch - 30ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1005 - accuracy: 0.5344 - val_loss: 1.0960 - val_accuracy: 0.4935 - 290ms/epoch - 29ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0990 - accuracy: 0.5541 - val_loss: 1.1345 - val_accuracy: 0.4286 - 302ms/epoch - 30ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0878 - accuracy: 0.5541 - val_loss: 1.0781 - val_accuracy: 0.4935 - 287ms/epoch - 29ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0794 - accuracy: 0.5770 - val_loss: 1.0635 - val_accuracy: 0.4545 - 286ms/epoch - 29ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0681 - accuracy: 0.5443 - val_loss: 1.0612 - val_accuracy: 0.5065 - 285ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0561 - accuracy: 0.5770 - val_loss: 1.0568 - val_accuracy: 0.4935 - 291ms/epoch - 29ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0538 - accuracy: 0.5410 - val_loss: 1.0501 - val_accuracy: 0.4805 - 292ms/epoch - 29ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0666 - accuracy: 0.5311 - val_loss: 1.0458 - val_accuracy: 0.4805 - 285ms/epoch - 28ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0453 - accuracy: 0.5639 - val_loss: 1.0065 - val_accuracy: 0.5455 - 285ms/epoch - 28ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0036 - accuracy: 0.5770 - val_loss: 0.9972 - val_accuracy: 0.5065 - 281ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0180 - accuracy: 0.5770 - val_loss: 0.9937 - val_accuracy: 0.5065 - 286ms/epoch - 29ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0083 - accuracy: 0.5574 - val_loss: 1.0024 - val_accuracy: 0.5195 - 295ms/epoch - 29ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9996 - accuracy: 0.5770 - val_loss: 0.9754 - val_accuracy: 0.5195 - 295ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9940 - accuracy: 0.5869 - val_loss: 0.9671 - val_accuracy: 0.5065 - 299ms/epoch - 30ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9798 - accuracy: 0.5934 - val_loss: 0.9457 - val_accuracy: 0.5714 - 295ms/epoch - 29ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9629 - accuracy: 0.6098 - val_loss: 0.9914 - val_accuracy: 0.5455 - 306ms/epoch - 31ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9765 - accuracy: 0.5902 - val_loss: 0.9267 - val_accuracy: 0.5455 - 296ms/epoch - 30ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9599 - accuracy: 0.6328 - val_loss: 0.9108 - val_accuracy: 0.5455 - 298ms/epoch - 30ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9209 - accuracy: 0.6361 - val_loss: 0.9009 - val_accuracy: 0.6623 - 299ms/epoch - 30ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9497 - accuracy: 0.6262 - val_loss: 0.9086 - val_accuracy: 0.5584 - 279ms/epoch - 28ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9814 - accuracy: 0.6000 - val_loss: 0.9223 - val_accuracy: 0.5584 - 289ms/epoch - 29ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9150 - accuracy: 0.6426 - val_loss: 0.8898 - val_accuracy: 0.6234 - 280ms/epoch - 28ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9417 - accuracy: 0.6197 - val_loss: 0.9030 - val_accuracy: 0.6364 - 281ms/epoch - 28ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9998 - accuracy: 0.5967 - val_loss: 0.9826 - val_accuracy: 0.5584 - 282ms/epoch - 28ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9813 - accuracy: 0.6033 - val_loss: 0.9120 - val_accuracy: 0.5714 - 287ms/epoch - 29ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9090 - accuracy: 0.6361 - val_loss: 0.9189 - val_accuracy: 0.5714 - 294ms/epoch - 29ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9211 - accuracy: 0.6262 - val_loss: 0.8929 - val_accuracy: 0.6364 - 278ms/epoch - 28ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9094 - accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:30:59,513] Trial 14 finished with value: 0.7058823704719543 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 160}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3845 - accuracy: 0.3443 - val_loss: 1.3821 - val_accuracy: 0.3247 - 5s/epoch - 531ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3765 - accuracy: 0.4230 - val_loss: 1.3691 - val_accuracy: 0.3506 - 289ms/epoch - 29ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3518 - accuracy: 0.4656 - val_loss: 1.3326 - val_accuracy: 0.3636 - 304ms/epoch - 30ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2942 - accuracy: 0.4721 - val_loss: 1.2689 - val_accuracy: 0.3636 - 286ms/epoch - 29ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2368 - accuracy: 0.4492 - val_loss: 1.2388 - val_accuracy: 0.3636 - 297ms/epoch - 30ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2048 - accuracy: 0.4590 - val_loss: 1.2061 - val_accuracy: 0.3636 - 297ms/epoch - 30ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1923 - accuracy: 0.4885 - val_loss: 1.1869 - val_accuracy: 0.3896 - 293ms/epoch - 29ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2225 - accuracy: 0.4525 - val_loss: 1.1691 - val_accuracy: 0.3766 - 298ms/epoch - 30ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1704 - accuracy: 0.5016 - val_loss: 1.1508 - val_accuracy: 0.4026 - 306ms/epoch - 31ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1657 - accuracy: 0.5082 - val_loss: 1.1454 - val_accuracy: 0.3766 - 299ms/epoch - 30ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1468 - accuracy: 0.5082 - val_loss: 1.1344 - val_accuracy: 0.4416 - 299ms/epoch - 30ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1579 - accuracy: 0.5082 - val_loss: 1.1148 - val_accuracy: 0.4286 - 299ms/epoch - 30ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1404 - accuracy: 0.5148 - val_loss: 1.1197 - val_accuracy: 0.4286 - 296ms/epoch - 30ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1307 - accuracy: 0.5115 - val_loss: 1.1073 - val_accuracy: 0.4805 - 305ms/epoch - 30ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1290 - accuracy: 0.5311 - val_loss: 1.1042 - val_accuracy: 0.4675 - 308ms/epoch - 31ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1010 - accuracy: 0.5311 - val_loss: 1.0906 - val_accuracy: 0.4286 - 321ms/epoch - 32ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1277 - accuracy: 0.5246 - val_loss: 1.0961 - val_accuracy: 0.4416 - 323ms/epoch - 32ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1171 - accuracy: 0.5311 - val_loss: 1.0853 - val_accuracy: 0.4935 - 314ms/epoch - 31ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1102 - accuracy: 0.5672 - val_loss: 1.0933 - val_accuracy: 0.4545 - 312ms/epoch - 31ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0937 - accuracy: 0.5148 - val_loss: 1.0677 - val_accuracy: 0.5065 - 306ms/epoch - 31ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0621 - accuracy: 0.5508 - val_loss: 1.0564 - val_accuracy: 0.4675 - 306ms/epoch - 31ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0743 - accuracy: 0.5443 - val_loss: 1.0504 - val_accuracy: 0.4935 - 295ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0602 - accuracy: 0.5803 - val_loss: 1.0392 - val_accuracy: 0.4805 - 287ms/epoch - 29ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0537 - accuracy: 0.5639 - val_loss: 1.0252 - val_accuracy: 0.5195 - 303ms/epoch - 30ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0456 - accuracy: 0.5508 - val_loss: 1.0077 - val_accuracy: 0.5195 - 307ms/epoch - 31ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0228 - accuracy: 0.5705 - val_loss: 0.9795 - val_accuracy: 0.5195 - 291ms/epoch - 29ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0368 - accuracy: 0.5705 - val_loss: 0.9795 - val_accuracy: 0.5195 - 296ms/epoch - 30ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0187 - accuracy: 0.5770 - val_loss: 0.9757 - val_accuracy: 0.5195 - 297ms/epoch - 30ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0110 - accuracy: 0.6000 - val_loss: 0.9794 - val_accuracy: 0.5195 - 296ms/epoch - 30ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0192 - accuracy: 0.5639 - val_loss: 0.9568 - val_accuracy: 0.5584 - 294ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0026 - accuracy: 0.5967 - val_loss: 0.9611 - val_accuracy: 0.5325 - 297ms/epoch - 30ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9830 - accuracy: 0.6033 - val_loss: 0.9270 - val_accuracy: 0.5714 - 293ms/epoch - 29ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9874 - accuracy: 0.5869 - val_loss: 0.9526 - val_accuracy: 0.5325 - 296ms/epoch - 30ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9757 - accuracy: 0.6131 - val_loss: 0.9351 - val_accuracy: 0.6104 - 295ms/epoch - 29ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9620 - accuracy: 0.6230 - val_loss: 0.9070 - val_accuracy: 0.5325 - 295ms/epoch - 30ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9258 - accuracy: 0.6262 - val_loss: 0.8935 - val_accuracy: 0.5974 - 295ms/epoch - 29ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9183 - accuracy: 0.6393 - val_loss: 0.8875 - val_accuracy: 0.6364 - 321ms/epoch - 32ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9440 - accuracy: 0.6328 - val_loss: 0.8748 - val_accuracy: 0.6234 - 301ms/epoch - 30ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9234 - accuracy: 0.6492 - val_loss: 0.8739 - val_accuracy: 0.6364 - 303ms/epoch - 30ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9446 - accuracy: 0.6459 - val_loss: 0.8758 - val_accuracy: 0.5974 - 306ms/epoch - 31ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9628 - accuracy: 0.6131 - val_loss: 0.8980 - val_accuracy: 0.5974 - 299ms/epoch - 30ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.8776 - accuracy: 0.6426 - val_loss: 0.8680 - val_accuracy: 0.6623 - 298ms/epoch - 30ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.8971 - accuracy: 0.6328 - val_loss: 0.8717 - val_accuracy: 0.6364 - 306ms/epoch - 31ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9120 - accuracy: 0.6295 - val_loss: 0.8597 - val_accuracy: 0.6364 - 303ms/epoch - 30ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9099 - accuracy: 0.6557 - val_loss: 0.8916 - val_accuracy: 0.6104 - 305ms/epoch - 30ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9323 - accuracy: 0.6197 - val_loss: 0.8729 - val_accuracy: 0.6234 - 294ms/epoch - 29ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8875 - accuracy: 0.6492 - val_loss: 0.8623 - val_accuracy: 0.6364 - 295ms/epoch - 29ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9240 - accuracy: 0.6492 - val_loss: 0.9387 - val_accuracy: 0.5455 - 296ms/epoch - 30ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9147 - accuracy: 0.6328 - val_loss: 0.8903 - val_accuracy: 0.6364 - 295ms/epoch - 30ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9070 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:31:21,309] Trial 15 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'swish', 'activation_func_3': 'tanh', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 155}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3818 - accuracy: 0.3049 - val_loss: 1.3807 - val_accuracy: 0.3247 - 4s/epoch - 408ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3668 - accuracy: 0.3672 - val_loss: 1.3629 - val_accuracy: 0.3636 - 214ms/epoch - 21ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3323 - accuracy: 0.4492 - val_loss: 1.3290 - val_accuracy: 0.3636 - 222ms/epoch - 22ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2938 - accuracy: 0.4459 - val_loss: 1.2617 - val_accuracy: 0.3766 - 227ms/epoch - 23ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2449 - accuracy: 0.4590 - val_loss: 1.2218 - val_accuracy: 0.3896 - 230ms/epoch - 23ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1992 - accuracy: 0.4852 - val_loss: 1.1924 - val_accuracy: 0.3766 - 218ms/epoch - 22ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1835 - accuracy: 0.4852 - val_loss: 1.1710 - val_accuracy: 0.3896 - 223ms/epoch - 22ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1663 - accuracy: 0.5049 - val_loss: 1.1709 - val_accuracy: 0.4156 - 216ms/epoch - 22ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1568 - accuracy: 0.5148 - val_loss: 1.1323 - val_accuracy: 0.4026 - 215ms/epoch - 22ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1273 - accuracy: 0.5016 - val_loss: 1.1384 - val_accuracy: 0.4805 - 212ms/epoch - 21ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1362 - accuracy: 0.5344 - val_loss: 1.1517 - val_accuracy: 0.4416 - 209ms/epoch - 21ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1089 - accuracy: 0.5574 - val_loss: 1.1356 - val_accuracy: 0.4416 - 216ms/epoch - 22ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1223 - accuracy: 0.5639 - val_loss: 1.1232 - val_accuracy: 0.4805 - 215ms/epoch - 21ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0944 - accuracy: 0.5279 - val_loss: 1.0882 - val_accuracy: 0.4545 - 217ms/epoch - 22ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0831 - accuracy: 0.5508 - val_loss: 1.0758 - val_accuracy: 0.4805 - 223ms/epoch - 22ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0844 - accuracy: 0.5344 - val_loss: 1.0557 - val_accuracy: 0.4675 - 229ms/epoch - 23ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0649 - accuracy: 0.5344 - val_loss: 1.0572 - val_accuracy: 0.5584 - 254ms/epoch - 25ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0869 - accuracy: 0.5475 - val_loss: 1.0373 - val_accuracy: 0.5065 - 261ms/epoch - 26ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0618 - accuracy: 0.5672 - val_loss: 1.0599 - val_accuracy: 0.5065 - 275ms/epoch - 27ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0811 - accuracy: 0.5508 - val_loss: 1.0231 - val_accuracy: 0.6104 - 237ms/epoch - 24ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0413 - accuracy: 0.5607 - val_loss: 1.0034 - val_accuracy: 0.4935 - 231ms/epoch - 23ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0451 - accuracy: 0.5410 - val_loss: 0.9884 - val_accuracy: 0.5195 - 219ms/epoch - 22ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0363 - accuracy: 0.5607 - val_loss: 0.9806 - val_accuracy: 0.5325 - 228ms/epoch - 23ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0073 - accuracy: 0.5967 - val_loss: 0.9823 - val_accuracy: 0.5065 - 230ms/epoch - 23ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9678 - accuracy: 0.5967 - val_loss: 0.9635 - val_accuracy: 0.5325 - 232ms/epoch - 23ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0020 - accuracy: 0.5902 - val_loss: 0.9003 - val_accuracy: 0.6364 - 211ms/epoch - 21ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9658 - accuracy: 0.6164 - val_loss: 0.9362 - val_accuracy: 0.5584 - 243ms/epoch - 24ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9766 - accuracy: 0.5836 - val_loss: 0.9607 - val_accuracy: 0.5974 - 223ms/epoch - 22ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9569 - accuracy: 0.6393 - val_loss: 0.9673 - val_accuracy: 0.5455 - 221ms/epoch - 22ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9668 - accuracy: 0.6000 - val_loss: 0.8907 - val_accuracy: 0.6234 - 243ms/epoch - 24ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9674 - accuracy: 0.6164 - val_loss: 0.8953 - val_accuracy: 0.5844 - 228ms/epoch - 23ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9182 - accuracy: 0.6361 - val_loss: 0.8909 - val_accuracy: 0.5844 - 224ms/epoch - 22ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9038 - accuracy: 0.6361 - val_loss: 0.8999 - val_accuracy: 0.5974 - 233ms/epoch - 23ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9105 - accuracy: 0.6361 - val_loss: 0.9071 - val_accuracy: 0.5844 - 217ms/epoch - 22ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9203 - accuracy: 0.6262 - val_loss: 0.8798 - val_accuracy: 0.5974 - 225ms/epoch - 22ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9310 - accuracy: 0.6525 - val_loss: 0.8589 - val_accuracy: 0.6234 - 219ms/epoch - 22ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9081 - accuracy: 0.6262 - val_loss: 0.8952 - val_accuracy: 0.6234 - 224ms/epoch - 22ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9116 - accuracy: 0.6164 - val_loss: 0.9131 - val_accuracy: 0.5584 - 238ms/epoch - 24ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.8704 - accuracy: 0.6557 - val_loss: 0.8619 - val_accuracy: 0.6623 - 230ms/epoch - 23ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.8768 - accuracy: 0.6787 - val_loss: 0.8731 - val_accuracy: 0.6234 - 231ms/epoch - 23ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9118 - accuracy: 0.6492 - val_loss: 0.9006 - val_accuracy: 0.5844 - 226ms/epoch - 23ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8913 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:31:35,988] Trial 16 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'swish', 'activation_func_3': 'selu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 141}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3833 - accuracy: 0.3574 - val_loss: 1.3796 - val_accuracy: 0.3766 - 4s/epoch - 433ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3714 - accuracy: 0.4459 - val_loss: 1.3579 - val_accuracy: 0.3766 - 246ms/epoch - 25ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3296 - accuracy: 0.4623 - val_loss: 1.2963 - val_accuracy: 0.3766 - 250ms/epoch - 25ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2671 - accuracy: 0.4721 - val_loss: 1.2574 - val_accuracy: 0.3766 - 256ms/epoch - 26ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2384 - accuracy: 0.4656 - val_loss: 1.2349 - val_accuracy: 0.3766 - 267ms/epoch - 27ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1931 - accuracy: 0.4951 - val_loss: 1.2072 - val_accuracy: 0.4026 - 261ms/epoch - 26ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1669 - accuracy: 0.4984 - val_loss: 1.2016 - val_accuracy: 0.3896 - 262ms/epoch - 26ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2184 - accuracy: 0.4689 - val_loss: 1.1696 - val_accuracy: 0.4156 - 266ms/epoch - 27ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2011 - accuracy: 0.5016 - val_loss: 1.1781 - val_accuracy: 0.3896 - 254ms/epoch - 25ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1644 - accuracy: 0.5148 - val_loss: 1.1754 - val_accuracy: 0.4286 - 271ms/epoch - 27ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1586 - accuracy: 0.5180 - val_loss: 1.1606 - val_accuracy: 0.4026 - 253ms/epoch - 25ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1326 - accuracy: 0.5311 - val_loss: 1.1300 - val_accuracy: 0.4416 - 261ms/epoch - 26ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1326 - accuracy: 0.5410 - val_loss: 1.1338 - val_accuracy: 0.4286 - 259ms/epoch - 26ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1296 - accuracy: 0.5311 - val_loss: 1.1052 - val_accuracy: 0.4416 - 246ms/epoch - 25ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1276 - accuracy: 0.5180 - val_loss: 1.1097 - val_accuracy: 0.4805 - 260ms/epoch - 26ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1077 - accuracy: 0.5410 - val_loss: 1.0911 - val_accuracy: 0.4545 - 262ms/epoch - 26ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1343 - accuracy: 0.5377 - val_loss: 1.1005 - val_accuracy: 0.4805 - 257ms/epoch - 26ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0873 - accuracy: 0.5475 - val_loss: 1.0813 - val_accuracy: 0.4545 - 261ms/epoch - 26ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1096 - accuracy: 0.5508 - val_loss: 1.0889 - val_accuracy: 0.4805 - 263ms/epoch - 26ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0612 - accuracy: 0.5639 - val_loss: 1.0610 - val_accuracy: 0.5325 - 261ms/epoch - 26ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0558 - accuracy: 0.5803 - val_loss: 1.0397 - val_accuracy: 0.4805 - 258ms/epoch - 26ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0452 - accuracy: 0.5639 - val_loss: 1.0314 - val_accuracy: 0.4935 - 259ms/epoch - 26ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0772 - accuracy: 0.5639 - val_loss: 1.0397 - val_accuracy: 0.4805 - 265ms/epoch - 26ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0492 - accuracy: 0.5672 - val_loss: 1.0557 - val_accuracy: 0.4935 - 264ms/epoch - 26ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9978 - accuracy: 0.5738 - val_loss: 1.0160 - val_accuracy: 0.5065 - 262ms/epoch - 26ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0544 - accuracy: 0.5705 - val_loss: 0.9777 - val_accuracy: 0.5974 - 258ms/epoch - 26ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9781 - accuracy: 0.6131 - val_loss: 0.9692 - val_accuracy: 0.5455 - 248ms/epoch - 25ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9750 - accuracy: 0.5836 - val_loss: 0.9407 - val_accuracy: 0.5974 - 258ms/epoch - 26ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9634 - accuracy: 0.5902 - val_loss: 0.9226 - val_accuracy: 0.5455 - 246ms/epoch - 25ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9462 - accuracy: 0.6098 - val_loss: 0.9468 - val_accuracy: 0.5325 - 255ms/epoch - 25ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9429 - accuracy: 0.6164 - val_loss: 0.9410 - val_accuracy: 0.6364 - 272ms/epoch - 27ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9694 - accuracy: 0.6197 - val_loss: 0.9150 - val_accuracy: 0.6234 - 254ms/epoch - 25ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9788 - accuracy: 0.5672 - val_loss: 0.9899 - val_accuracy: 0.5065 - 255ms/epoch - 25ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9592 - accuracy: 0.5967 - val_loss: 0.9336 - val_accuracy: 0.5844 - 252ms/epoch - 25ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9389 - accuracy: 0.6262 - val_loss: 0.9100 - val_accuracy: 0.5844 - 259ms/epoch - 26ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9067 - accuracy: 0.6197 - val_loss: 0.9085 - val_accuracy: 0.6364 - 261ms/epoch - 26ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.8975 - accuracy: 0.6557 - val_loss: 0.8958 - val_accuracy: 0.6234 - 250ms/epoch - 25ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.8868 - accuracy: 0.6197 - val_loss: 0.9109 - val_accuracy: 0.5584 - 253ms/epoch - 25ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9157 - accuracy: 0.6164 - val_loss: 0.8853 - val_accuracy: 0.6364 - 260ms/epoch - 26ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9888 - accuracy: 0.5934 - val_loss: 0.9061 - val_accuracy: 0.5714 - 254ms/epoch - 25ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0171 - accuracy: 0.5934 - val_loss: 0.9457 - val_accuracy: 0.6494 - 265ms/epoch - 27ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9284 - accuracy: 0.6492 - val_loss: 0.9486 - val_accuracy: 0.5974 - 254ms/epoch - 25ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9010 - accuracy: 0.6328 - val_loss: 0.9159 - val_accuracy: 0.5974 - 253ms/epoch - 25ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.8709 - accuracy: 0.6525 - val_loss: 0.8781 - val_accuracy: 0.6623 - 261ms/epoch - 26ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.8760 - accuracy: 0.6656 - val_loss: 0.9102 - val_accuracy: 0.6104 - 280ms/epoch - 28ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.8513 - accuracy: 0.6590 - val_loss: 0.8695 - val_accuracy: 0.6364 - 267ms/epoch - 27ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8554 - accuracy: 0.6787 - val_loss: 0.9041 - val_accuracy: 0.6234 - 272ms/epoch - 27ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.8776 - accuracy: 0.6295 - val_loss: 0.9244 - val_accuracy: 0.5844 - 277ms/epoch - 28ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.8676 - accuracy: 0.6557 - val_loss: 0.8994 - val_accuracy: 0.6494 - 269ms/epoch - 27ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.8366 - accuracy: 0.6525 - val_loss: 0.9353 - val_accuracy: 0.5584 - 271ms/epoch - 27ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.8441 - accuracy: 0.6492 - val_loss: 0.8937 - val_accuracy: 0.6364 - 284ms/epoch - 28ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9144 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:31:55,484] Trial 17 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 161}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3818 - accuracy: 0.3475 - val_loss: 1.3786 - val_accuracy: 0.3896 - 5s/epoch - 504ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3698 - accuracy: 0.4459 - val_loss: 1.3528 - val_accuracy: 0.3636 - 240ms/epoch - 24ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3229 - accuracy: 0.4689 - val_loss: 1.2848 - val_accuracy: 0.3896 - 249ms/epoch - 25ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2534 - accuracy: 0.5049 - val_loss: 1.2103 - val_accuracy: 0.3896 - 255ms/epoch - 26ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.1860 - accuracy: 0.4984 - val_loss: 1.1700 - val_accuracy: 0.3766 - 267ms/epoch - 27ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1749 - accuracy: 0.5016 - val_loss: 1.1457 - val_accuracy: 0.3896 - 248ms/epoch - 25ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1622 - accuracy: 0.4852 - val_loss: 1.1520 - val_accuracy: 0.3896 - 266ms/epoch - 27ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1443 - accuracy: 0.5148 - val_loss: 1.1411 - val_accuracy: 0.4156 - 265ms/epoch - 26ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1205 - accuracy: 0.5279 - val_loss: 1.1165 - val_accuracy: 0.4286 - 244ms/epoch - 24ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1038 - accuracy: 0.5410 - val_loss: 1.1199 - val_accuracy: 0.4805 - 262ms/epoch - 26ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1360 - accuracy: 0.5475 - val_loss: 1.1303 - val_accuracy: 0.4545 - 246ms/epoch - 25ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1019 - accuracy: 0.5344 - val_loss: 1.0964 - val_accuracy: 0.4675 - 249ms/epoch - 25ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.0996 - accuracy: 0.5607 - val_loss: 1.0929 - val_accuracy: 0.4545 - 258ms/epoch - 26ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0959 - accuracy: 0.5541 - val_loss: 1.0679 - val_accuracy: 0.4805 - 245ms/epoch - 24ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0769 - accuracy: 0.5574 - val_loss: 1.0537 - val_accuracy: 0.4935 - 249ms/epoch - 25ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0834 - accuracy: 0.5246 - val_loss: 1.0424 - val_accuracy: 0.4805 - 248ms/epoch - 25ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0694 - accuracy: 0.5443 - val_loss: 1.0582 - val_accuracy: 0.4675 - 252ms/epoch - 25ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0493 - accuracy: 0.5869 - val_loss: 1.0371 - val_accuracy: 0.4675 - 253ms/epoch - 25ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0772 - accuracy: 0.5869 - val_loss: 1.0534 - val_accuracy: 0.4935 - 250ms/epoch - 25ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0846 - accuracy: 0.5148 - val_loss: 1.0125 - val_accuracy: 0.5844 - 262ms/epoch - 26ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0084 - accuracy: 0.5836 - val_loss: 1.0043 - val_accuracy: 0.5195 - 253ms/epoch - 25ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0210 - accuracy: 0.5607 - val_loss: 0.9754 - val_accuracy: 0.5065 - 245ms/epoch - 24ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0402 - accuracy: 0.5934 - val_loss: 0.9598 - val_accuracy: 0.5844 - 253ms/epoch - 25ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 0.9808 - accuracy: 0.6066 - val_loss: 0.9561 - val_accuracy: 0.5195 - 255ms/epoch - 25ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9880 - accuracy: 0.6262 - val_loss: 0.9699 - val_accuracy: 0.5195 - 260ms/epoch - 26ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9884 - accuracy: 0.5869 - val_loss: 0.9006 - val_accuracy: 0.6234 - 250ms/epoch - 25ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9521 - accuracy: 0.6131 - val_loss: 0.9279 - val_accuracy: 0.5584 - 257ms/epoch - 26ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9689 - accuracy: 0.6164 - val_loss: 0.9377 - val_accuracy: 0.6104 - 262ms/epoch - 26ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.8956 - accuracy: 0.6492 - val_loss: 0.9306 - val_accuracy: 0.5714 - 257ms/epoch - 26ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9179 - accuracy: 0.6262 - val_loss: 0.8685 - val_accuracy: 0.6104 - 246ms/epoch - 25ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9985 - accuracy: 0.5836 - val_loss: 0.9322 - val_accuracy: 0.6234 - 254ms/epoch - 25ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9952 - accuracy: 0.5738 - val_loss: 0.9209 - val_accuracy: 0.5844 - 251ms/epoch - 25ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9400 - accuracy: 0.6066 - val_loss: 0.9029 - val_accuracy: 0.5974 - 255ms/epoch - 26ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9140 - accuracy: 0.6131 - val_loss: 0.9051 - val_accuracy: 0.6234 - 245ms/epoch - 24ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9057 - accuracy: 0.6066 - val_loss: 0.9008 - val_accuracy: 0.5844 - 259ms/epoch - 26ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:32:10,952] Trial 18 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'swish', 'activation_func_3': 'selu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 141}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3840 - accuracy: 0.3148 - val_loss: 1.3789 - val_accuracy: 0.4026 - 4s/epoch - 447ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3725 - accuracy: 0.4852 - val_loss: 1.3592 - val_accuracy: 0.4156 - 294ms/epoch - 29ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3402 - accuracy: 0.4721 - val_loss: 1.3025 - val_accuracy: 0.4156 - 308ms/epoch - 31ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2668 - accuracy: 0.4852 - val_loss: 1.2244 - val_accuracy: 0.4026 - 314ms/epoch - 31ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2054 - accuracy: 0.5049 - val_loss: 1.1952 - val_accuracy: 0.3896 - 349ms/epoch - 35ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1819 - accuracy: 0.5049 - val_loss: 1.1692 - val_accuracy: 0.3896 - 328ms/epoch - 33ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1569 - accuracy: 0.5049 - val_loss: 1.1611 - val_accuracy: 0.3896 - 322ms/epoch - 32ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1679 - accuracy: 0.5016 - val_loss: 1.1617 - val_accuracy: 0.4026 - 306ms/epoch - 31ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1532 - accuracy: 0.5180 - val_loss: 1.1275 - val_accuracy: 0.4026 - 323ms/epoch - 32ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1305 - accuracy: 0.5344 - val_loss: 1.1214 - val_accuracy: 0.4675 - 303ms/epoch - 30ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.0949 - accuracy: 0.5344 - val_loss: 1.1110 - val_accuracy: 0.4545 - 353ms/epoch - 35ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.0877 - accuracy: 0.5508 - val_loss: 1.1088 - val_accuracy: 0.4286 - 319ms/epoch - 32ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.0999 - accuracy: 0.5541 - val_loss: 1.0952 - val_accuracy: 0.4675 - 303ms/epoch - 30ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0623 - accuracy: 0.5574 - val_loss: 1.0704 - val_accuracy: 0.4675 - 314ms/epoch - 31ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0590 - accuracy: 0.5738 - val_loss: 1.0531 - val_accuracy: 0.4805 - 332ms/epoch - 33ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0413 - accuracy: 0.5607 - val_loss: 1.0186 - val_accuracy: 0.4675 - 319ms/epoch - 32ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0381 - accuracy: 0.5705 - val_loss: 1.0215 - val_accuracy: 0.5584 - 314ms/epoch - 31ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0277 - accuracy: 0.5836 - val_loss: 1.0067 - val_accuracy: 0.5325 - 343ms/epoch - 34ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0205 - accuracy: 0.5770 - val_loss: 1.0061 - val_accuracy: 0.4935 - 368ms/epoch - 37ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0249 - accuracy: 0.5508 - val_loss: 0.9776 - val_accuracy: 0.5714 - 330ms/epoch - 33ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 0.9809 - accuracy: 0.5869 - val_loss: 0.9991 - val_accuracy: 0.5065 - 355ms/epoch - 35ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 0.9646 - accuracy: 0.6164 - val_loss: 0.9483 - val_accuracy: 0.5714 - 352ms/epoch - 35ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 0.9713 - accuracy: 0.5934 - val_loss: 0.9339 - val_accuracy: 0.5714 - 332ms/epoch - 33ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 0.9736 - accuracy: 0.5836 - val_loss: 0.9407 - val_accuracy: 0.5584 - 369ms/epoch - 37ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9581 - accuracy: 0.6098 - val_loss: 0.9119 - val_accuracy: 0.6104 - 385ms/epoch - 38ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9224 - accuracy: 0.6098 - val_loss: 0.8877 - val_accuracy: 0.6104 - 335ms/epoch - 34ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9428 - accuracy: 0.5967 - val_loss: 0.9308 - val_accuracy: 0.5844 - 318ms/epoch - 32ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9238 - accuracy: 0.6164 - val_loss: 0.9262 - val_accuracy: 0.6494 - 303ms/epoch - 30ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9023 - accuracy: 0.6393 - val_loss: 0.9293 - val_accuracy: 0.5844 - 306ms/epoch - 31ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9324 - accuracy: 0.6262 - val_loss: 0.8791 - val_accuracy: 0.6623 - 311ms/epoch - 31ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9355 - accuracy: 0.6098 - val_loss: 0.8989 - val_accuracy: 0.6104 - 316ms/epoch - 32ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.8970 - accuracy: 0.6492 - val_loss: 0.8851 - val_accuracy: 0.6234 - 306ms/epoch - 31ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.8798 - accuracy: 0.6361 - val_loss: 0.8789 - val_accuracy: 0.6494 - 311ms/epoch - 31ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.8836 - accuracy: 0.6459 - val_loss: 0.8755 - val_accuracy: 0.6753 - 318ms/epoch - 32ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.8647 - accuracy: 0.6459 - val_loss: 0.8537 - val_accuracy: 0.6494 - 307ms/epoch - 31ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.8929 - accuracy: 0.6328 - val_loss: 0.8645 - val_accuracy: 0.6364 - 322ms/epoch - 32ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.8535 - accuracy: 0.6393 - val_loss: 0.8533 - val_accuracy: 0.6494 - 350ms/epoch - 35ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.8690 - accuracy: 0.6295 - val_loss: 0.8703 - val_accuracy: 0.6753 - 305ms/epoch - 31ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.8592 - accuracy: 0.6393 - val_loss: 0.8639 - val_accuracy: 0.6623 - 324ms/epoch - 32ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.8480 - accuracy: 0.6492 - val_loss: 0.8779 - val_accuracy: 0.6753 - 304ms/epoch - 30ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9031 - accuracy: 0.6393 - val_loss: 0.9146 - val_accuracy: 0.6234 - 306ms/epoch - 31ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9090 - accuracy: 0.6393 - val_loss: 0.8678 - val_accuracy: 0.6753 - 303ms/epoch - 30ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8652 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:32:30,532] Trial 19 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'linear', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 168}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3852 - accuracy: 0.2459 - val_loss: 1.3841 - val_accuracy: 0.4545 - 4s/epoch - 621ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3819 - accuracy: 0.3967 - val_loss: 1.3801 - val_accuracy: 0.2987 - 238ms/epoch - 34ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3760 - accuracy: 0.4393 - val_loss: 1.3745 - val_accuracy: 0.3636 - 264ms/epoch - 38ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3639 - accuracy: 0.4525 - val_loss: 1.3635 - val_accuracy: 0.3896 - 248ms/epoch - 35ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3333 - accuracy: 0.4393 - val_loss: 1.3574 - val_accuracy: 0.3766 - 246ms/epoch - 35ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3252 - accuracy: 0.4426 - val_loss: 1.3269 - val_accuracy: 0.3766 - 246ms/epoch - 35ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2866 - accuracy: 0.4492 - val_loss: 1.2977 - val_accuracy: 0.3506 - 250ms/epoch - 36ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2883 - accuracy: 0.4492 - val_loss: 1.3005 - val_accuracy: 0.3636 - 237ms/epoch - 34ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2799 - accuracy: 0.4393 - val_loss: 1.2788 - val_accuracy: 0.3636 - 242ms/epoch - 35ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2575 - accuracy: 0.4590 - val_loss: 1.2674 - val_accuracy: 0.3766 - 243ms/epoch - 35ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2400 - accuracy: 0.4426 - val_loss: 1.2655 - val_accuracy: 0.4026 - 238ms/epoch - 34ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2094 - accuracy: 0.5115 - val_loss: 1.2394 - val_accuracy: 0.3766 - 249ms/epoch - 36ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2034 - accuracy: 0.4656 - val_loss: 1.2186 - val_accuracy: 0.3636 - 245ms/epoch - 35ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1957 - accuracy: 0.4623 - val_loss: 1.2066 - val_accuracy: 0.3636 - 242ms/epoch - 35ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1939 - accuracy: 0.4721 - val_loss: 1.1995 - val_accuracy: 0.3896 - 240ms/epoch - 34ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1685 - accuracy: 0.4918 - val_loss: 1.2090 - val_accuracy: 0.3766 - 241ms/epoch - 34ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1727 - accuracy: 0.5082 - val_loss: 1.1923 - val_accuracy: 0.3766 - 249ms/epoch - 36ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1787 - accuracy: 0.4951 - val_loss: 1.1752 - val_accuracy: 0.3766 - 253ms/epoch - 36ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1413 - accuracy: 0.5246 - val_loss: 1.1642 - val_accuracy: 0.3896 - 243ms/epoch - 35ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1569 - accuracy: 0.4984 - val_loss: 1.1694 - val_accuracy: 0.4416 - 247ms/epoch - 35ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1720 - accuracy: 0.5049 - val_loss: 1.1384 - val_accuracy: 0.4156 - 245ms/epoch - 35ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1326 - accuracy: 0.5246 - val_loss: 1.1314 - val_accuracy: 0.4156 - 249ms/epoch - 36ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1389 - accuracy: 0.5213 - val_loss: 1.1151 - val_accuracy: 0.4026 - 243ms/epoch - 35ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1401 - accuracy: 0.5082 - val_loss: 1.1164 - val_accuracy: 0.4026 - 245ms/epoch - 35ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1225 - accuracy: 0.5213 - val_loss: 1.0994 - val_accuracy: 0.4545 - 245ms/epoch - 35ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1090 - accuracy: 0.5311 - val_loss: 1.0840 - val_accuracy: 0.4805 - 239ms/epoch - 34ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0882 - accuracy: 0.5115 - val_loss: 1.0874 - val_accuracy: 0.4675 - 245ms/epoch - 35ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0907 - accuracy: 0.5508 - val_loss: 1.0744 - val_accuracy: 0.4545 - 253ms/epoch - 36ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0918 - accuracy: 0.5410 - val_loss: 1.0643 - val_accuracy: 0.5325 - 245ms/epoch - 35ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1061 - accuracy: 0.5443 - val_loss: 1.0752 - val_accuracy: 0.4675 - 249ms/epoch - 36ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1130 - accuracy: 0.5475 - val_loss: 1.0678 - val_accuracy: 0.4675 - 242ms/epoch - 35ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0765 - accuracy: 0.5410 - val_loss: 1.0656 - val_accuracy: 0.4675 - 248ms/epoch - 35ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0587 - accuracy: 0.5770 - val_loss: 1.0578 - val_accuracy: 0.4675 - 249ms/epoch - 36ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0426 - accuracy: 0.5803 - val_loss: 1.0451 - val_accuracy: 0.4545 - 244ms/epoch - 35ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0692 - accuracy: 0.5705 - val_loss: 1.0354 - val_accuracy: 0.4675 - 240ms/epoch - 34ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0541 - accuracy: 0.5639 - val_loss: 1.0205 - val_accuracy: 0.5195 - 254ms/epoch - 36ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0647 - accuracy: 0.5344 - val_loss: 1.0165 - val_accuracy: 0.5714 - 254ms/epoch - 36ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0201 - accuracy: 0.6000 - val_loss: 1.0038 - val_accuracy: 0.5325 - 252ms/epoch - 36ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0601 - accuracy: 0.5344 - val_loss: 1.0313 - val_accuracy: 0.4935 - 246ms/epoch - 35ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0318 - accuracy: 0.5311 - val_loss: 1.0068 - val_accuracy: 0.5455 - 258ms/epoch - 37ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0136 - accuracy: 0.6000 - val_loss: 0.9785 - val_accuracy: 0.5974 - 243ms/epoch - 35ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0284 - accuracy: 0.5902 - val_loss: 0.9825 - val_accuracy: 0.5844 - 252ms/epoch - 36ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9846 - accuracy: 0.5869 - val_loss: 0.9621 - val_accuracy: 0.5844 - 245ms/epoch - 35ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0185 - accuracy: 0.5869 - val_loss: 0.9607 - val_accuracy: 0.5714 - 251ms/epoch - 36ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9946 - accuracy: 0.5967 - val_loss: 0.9716 - val_accuracy: 0.5455 - 265ms/epoch - 38ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9928 - accuracy: 0.5967 - val_loss: 0.9595 - val_accuracy: 0.5325 - 255ms/epoch - 36ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9691 - accuracy: 0.5967 - val_loss: 0.9497 - val_accuracy: 0.5195 - 258ms/epoch - 37ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 1.0116 - accuracy: 0.5639 - val_loss: 0.9404 - val_accuracy: 0.5844 - 263ms/epoch - 38ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 0.9730 - accuracy: 0.6033 - val_loss: 0.9210 - val_accuracy: 0.5974 - 261ms/epoch - 37ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 0.9920 - accuracy: 0.5967 - val_loss: 0.9187 - val_accuracy: 0.5844 - 257ms/epoch - 37ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 0.9949 - accuracy: 0.6230 - val_loss: 0.9151 - val_accuracy: 0.5844 - 247ms/epoch - 35ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 0.9788 - accuracy: 0.5902 - val_loss: 0.9125 - val_accuracy: 0.5584 - 250ms/epoch - 36ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 0.9768 - accuracy: 0.6098 - val_loss: 0.9280 - val_accuracy: 0.5584 - 241ms/epoch - 34ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 0.9662 - accuracy: 0.6197 - val_loss: 0.9315 - val_accuracy: 0.5844 - 245ms/epoch - 35ms/step\n",
      "Epoch 55/10000\n",
      "7/7 - 0s - loss: 1.0044 - accuracy: 0.6066 - val_loss: 0.9138 - val_accuracy: 0.5455 - 247ms/epoch - 35ms/step\n",
      "Epoch 56/10000\n",
      "7/7 - 0s - loss: 0.9578 - accuracy: 0.6197 - val_loss: 0.9193 - val_accuracy: 0.5455 - 243ms/epoch - 35ms/step\n",
      "Epoch 57/10000\n",
      "7/7 - 0s - loss: 0.9731 - accuracy: 0.6361 - val_loss: 0.9048 - val_accuracy: 0.5714 - 243ms/epoch - 35ms/step\n",
      "Epoch 58/10000\n",
      "7/7 - 0s - loss: 0.9555 - accuracy: 0.6361 - val_loss: 0.8969 - val_accuracy: 0.6234 - 252ms/epoch - 36ms/step\n",
      "Epoch 59/10000\n",
      "7/7 - 0s - loss: 0.8951 - accuracy: 0.6525 - val_loss: 0.8777 - val_accuracy: 0.5974 - 245ms/epoch - 35ms/step\n",
      "Epoch 60/10000\n",
      "7/7 - 0s - loss: 0.9548 - accuracy: 0.6197 - val_loss: 0.8724 - val_accuracy: 0.6104 - 244ms/epoch - 35ms/step\n",
      "Epoch 61/10000\n",
      "7/7 - 0s - loss: 0.9628 - accuracy: 0.5967 - val_loss: 0.8720 - val_accuracy: 0.6234 - 255ms/epoch - 36ms/step\n",
      "Epoch 62/10000\n",
      "7/7 - 0s - loss: 0.9306 - accuracy: 0.6361 - val_loss: 0.8860 - val_accuracy: 0.5584 - 246ms/epoch - 35ms/step\n",
      "Epoch 63/10000\n",
      "7/7 - 0s - loss: 0.9379 - accuracy: 0.6262 - val_loss: 0.8858 - val_accuracy: 0.5844 - 249ms/epoch - 36ms/step\n",
      "Epoch 64/10000\n",
      "7/7 - 0s - loss: 0.9498 - accuracy: 0.6361 - val_loss: 0.9072 - val_accuracy: 0.5714 - 244ms/epoch - 35ms/step\n",
      "Epoch 65/10000\n",
      "7/7 - 0s - loss: 0.9630 - accuracy: 0.6230 - val_loss: 0.8970 - val_accuracy: 0.5714 - 249ms/epoch - 36ms/step\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.9342 - accuracy: 0.6131 - val_loss: 0.8942 - val_accuracy: 0.6234 - 256ms/epoch - 37ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8895 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:32:52,922] Trial 20 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 160}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3858 - accuracy: 0.3115 - val_loss: 1.3837 - val_accuracy: 0.3117 - 4s/epoch - 571ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3826 - accuracy: 0.3902 - val_loss: 1.3798 - val_accuracy: 0.3117 - 232ms/epoch - 33ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3784 - accuracy: 0.3902 - val_loss: 1.3741 - val_accuracy: 0.3636 - 239ms/epoch - 34ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3675 - accuracy: 0.4262 - val_loss: 1.3617 - val_accuracy: 0.3377 - 242ms/epoch - 35ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3477 - accuracy: 0.4098 - val_loss: 1.3417 - val_accuracy: 0.3636 - 269ms/epoch - 38ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3136 - accuracy: 0.4754 - val_loss: 1.3054 - val_accuracy: 0.3896 - 254ms/epoch - 36ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2852 - accuracy: 0.4590 - val_loss: 1.2869 - val_accuracy: 0.3636 - 268ms/epoch - 38ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2694 - accuracy: 0.4754 - val_loss: 1.2792 - val_accuracy: 0.3896 - 247ms/epoch - 35ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2878 - accuracy: 0.4262 - val_loss: 1.2732 - val_accuracy: 0.3636 - 257ms/epoch - 37ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2634 - accuracy: 0.4393 - val_loss: 1.2633 - val_accuracy: 0.3896 - 246ms/epoch - 35ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2367 - accuracy: 0.4590 - val_loss: 1.2557 - val_accuracy: 0.4156 - 256ms/epoch - 37ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2436 - accuracy: 0.4984 - val_loss: 1.2434 - val_accuracy: 0.4156 - 258ms/epoch - 37ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2434 - accuracy: 0.4623 - val_loss: 1.2210 - val_accuracy: 0.3636 - 251ms/epoch - 36ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.2024 - accuracy: 0.4984 - val_loss: 1.2137 - val_accuracy: 0.3506 - 251ms/epoch - 36ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.2044 - accuracy: 0.4754 - val_loss: 1.2013 - val_accuracy: 0.4416 - 280ms/epoch - 40ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1882 - accuracy: 0.4918 - val_loss: 1.1974 - val_accuracy: 0.4286 - 272ms/epoch - 39ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1838 - accuracy: 0.5082 - val_loss: 1.1718 - val_accuracy: 0.4286 - 247ms/epoch - 35ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1733 - accuracy: 0.5082 - val_loss: 1.1691 - val_accuracy: 0.4026 - 254ms/epoch - 36ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1629 - accuracy: 0.5115 - val_loss: 1.1535 - val_accuracy: 0.3636 - 262ms/epoch - 37ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1896 - accuracy: 0.4787 - val_loss: 1.1732 - val_accuracy: 0.4545 - 262ms/epoch - 37ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1653 - accuracy: 0.4885 - val_loss: 1.1365 - val_accuracy: 0.4026 - 263ms/epoch - 38ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1562 - accuracy: 0.4951 - val_loss: 1.1291 - val_accuracy: 0.3896 - 264ms/epoch - 38ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1250 - accuracy: 0.5148 - val_loss: 1.1234 - val_accuracy: 0.3896 - 266ms/epoch - 38ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1315 - accuracy: 0.5213 - val_loss: 1.1191 - val_accuracy: 0.3896 - 250ms/epoch - 36ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1535 - accuracy: 0.4984 - val_loss: 1.1018 - val_accuracy: 0.4286 - 264ms/epoch - 38ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0966 - accuracy: 0.5016 - val_loss: 1.0821 - val_accuracy: 0.5195 - 259ms/epoch - 37ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1024 - accuracy: 0.5311 - val_loss: 1.0956 - val_accuracy: 0.4675 - 254ms/epoch - 36ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1007 - accuracy: 0.5443 - val_loss: 1.0832 - val_accuracy: 0.4156 - 237ms/epoch - 34ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1058 - accuracy: 0.5148 - val_loss: 1.0726 - val_accuracy: 0.4416 - 264ms/epoch - 38ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1167 - accuracy: 0.5180 - val_loss: 1.0867 - val_accuracy: 0.4805 - 237ms/epoch - 34ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0757 - accuracy: 0.5607 - val_loss: 1.0802 - val_accuracy: 0.4675 - 244ms/epoch - 35ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0789 - accuracy: 0.5410 - val_loss: 1.0827 - val_accuracy: 0.4675 - 249ms/epoch - 36ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0956 - accuracy: 0.5443 - val_loss: 1.0750 - val_accuracy: 0.4675 - 237ms/epoch - 34ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0873 - accuracy: 0.5443 - val_loss: 1.0679 - val_accuracy: 0.4675 - 251ms/epoch - 36ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0437 - accuracy: 0.5279 - val_loss: 1.0511 - val_accuracy: 0.4935 - 237ms/epoch - 34ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0687 - accuracy: 0.5672 - val_loss: 1.0495 - val_accuracy: 0.4675 - 246ms/epoch - 35ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0551 - accuracy: 0.5607 - val_loss: 1.0536 - val_accuracy: 0.5714 - 257ms/epoch - 37ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0565 - accuracy: 0.5508 - val_loss: 1.0368 - val_accuracy: 0.4805 - 251ms/epoch - 36ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0722 - accuracy: 0.5541 - val_loss: 1.0692 - val_accuracy: 0.4805 - 260ms/epoch - 37ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0411 - accuracy: 0.5443 - val_loss: 1.0488 - val_accuracy: 0.4935 - 239ms/epoch - 34ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0476 - accuracy: 0.5475 - val_loss: 1.0096 - val_accuracy: 0.5455 - 247ms/epoch - 35ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0346 - accuracy: 0.5705 - val_loss: 1.0186 - val_accuracy: 0.5584 - 246ms/epoch - 35ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9949 - accuracy: 0.5836 - val_loss: 0.9944 - val_accuracy: 0.5714 - 244ms/epoch - 35ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0565 - accuracy: 0.5639 - val_loss: 0.9886 - val_accuracy: 0.5325 - 240ms/epoch - 34ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 1.0309 - accuracy: 0.5639 - val_loss: 1.0036 - val_accuracy: 0.5065 - 252ms/epoch - 36ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9923 - accuracy: 0.5770 - val_loss: 0.9927 - val_accuracy: 0.5065 - 242ms/epoch - 35ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9989 - accuracy: 0.5770 - val_loss: 0.9899 - val_accuracy: 0.4935 - 255ms/epoch - 36ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 1.0234 - accuracy: 0.5672 - val_loss: 0.9908 - val_accuracy: 0.4935 - 261ms/epoch - 37ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 1.0314 - accuracy: 0.5836 - val_loss: 0.9693 - val_accuracy: 0.5584 - 262ms/epoch - 37ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 0.9779 - accuracy: 0.5967 - val_loss: 0.9473 - val_accuracy: 0.5584 - 242ms/epoch - 35ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 1.0207 - accuracy: 0.6164 - val_loss: 0.9365 - val_accuracy: 0.6364 - 250ms/epoch - 36ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 0.9697 - accuracy: 0.6164 - val_loss: 0.9308 - val_accuracy: 0.5584 - 257ms/epoch - 37ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 0.9659 - accuracy: 0.6098 - val_loss: 0.9268 - val_accuracy: 0.5455 - 244ms/epoch - 35ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 0.9717 - accuracy: 0.5770 - val_loss: 0.9462 - val_accuracy: 0.5584 - 244ms/epoch - 35ms/step\n",
      "Epoch 55/10000\n",
      "7/7 - 0s - loss: 0.9647 - accuracy: 0.5836 - val_loss: 0.9563 - val_accuracy: 0.5455 - 266ms/epoch - 38ms/step\n",
      "Epoch 56/10000\n",
      "7/7 - 0s - loss: 0.9845 - accuracy: 0.5836 - val_loss: 0.9464 - val_accuracy: 0.5455 - 236ms/epoch - 34ms/step\n",
      "Epoch 57/10000\n",
      "7/7 - 0s - loss: 1.0207 - accuracy: 0.6033 - val_loss: 0.9194 - val_accuracy: 0.5844 - 246ms/epoch - 35ms/step\n",
      "Epoch 58/10000\n",
      "7/7 - 0s - loss: 0.9794 - accuracy: 0.5836 - val_loss: 0.9182 - val_accuracy: 0.5714 - 243ms/epoch - 35ms/step\n",
      "Epoch 59/10000\n",
      "7/7 - 0s - loss: 0.9119 - accuracy: 0.6230 - val_loss: 0.9194 - val_accuracy: 0.5714 - 248ms/epoch - 35ms/step\n",
      "Epoch 60/10000\n",
      "7/7 - 0s - loss: 1.0019 - accuracy: 0.5967 - val_loss: 0.9253 - val_accuracy: 0.5455 - 240ms/epoch - 34ms/step\n",
      "Epoch 61/10000\n",
      "7/7 - 0s - loss: 0.9850 - accuracy: 0.6164 - val_loss: 0.9122 - val_accuracy: 0.5844 - 242ms/epoch - 35ms/step\n",
      "Epoch 62/10000\n",
      "7/7 - 0s - loss: 0.9966 - accuracy: 0.6295 - val_loss: 0.9176 - val_accuracy: 0.5584 - 251ms/epoch - 36ms/step\n",
      "Epoch 63/10000\n",
      "7/7 - 0s - loss: 0.9478 - accuracy: 0.6262 - val_loss: 0.9233 - val_accuracy: 0.5455 - 247ms/epoch - 35ms/step\n",
      "Epoch 64/10000\n",
      "7/7 - 0s - loss: 0.9315 - accuracy: 0.6393 - val_loss: 0.9414 - val_accuracy: 0.5455 - 251ms/epoch - 36ms/step\n",
      "Epoch 65/10000\n",
      "7/7 - 0s - loss: 0.9519 - accuracy: 0.6197 - val_loss: 0.9194 - val_accuracy: 0.5455 - 244ms/epoch - 35ms/step\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.9488 - accuracy: 0.6033 - val_loss: 0.8943 - val_accuracy: 0.6234 - 243ms/epoch - 35ms/step\n",
      "Epoch 67/10000\n",
      "7/7 - 0s - loss: 0.9657 - accuracy: 0.6000 - val_loss: 0.8906 - val_accuracy: 0.5844 - 239ms/epoch - 34ms/step\n",
      "Epoch 68/10000\n",
      "7/7 - 0s - loss: 0.9395 - accuracy: 0.6197 - val_loss: 0.8969 - val_accuracy: 0.5584 - 252ms/epoch - 36ms/step\n",
      "Epoch 69/10000\n",
      "7/7 - 0s - loss: 0.9014 - accuracy: 0.6459 - val_loss: 0.8924 - val_accuracy: 0.5584 - 251ms/epoch - 36ms/step\n",
      "Epoch 70/10000\n",
      "7/7 - 0s - loss: 0.9055 - accuracy: 0.6262 - val_loss: 0.8902 - val_accuracy: 0.6364 - 270ms/epoch - 39ms/step\n",
      "Epoch 71/10000\n",
      "7/7 - 0s - loss: 0.9349 - accuracy: 0.6623 - val_loss: 0.9075 - val_accuracy: 0.6104 - 260ms/epoch - 37ms/step\n",
      "Epoch 72/10000\n",
      "7/7 - 0s - loss: 0.9364 - accuracy: 0.6492 - val_loss: 0.8821 - val_accuracy: 0.6364 - 262ms/epoch - 37ms/step\n",
      "Epoch 73/10000\n",
      "7/7 - 0s - loss: 0.9378 - accuracy: 0.6459 - val_loss: 0.8956 - val_accuracy: 0.5584 - 240ms/epoch - 34ms/step\n",
      "Epoch 74/10000\n",
      "7/7 - 0s - loss: 0.9123 - accuracy: 0.6000 - val_loss: 0.8926 - val_accuracy: 0.5714 - 258ms/epoch - 37ms/step\n",
      "Epoch 75/10000\n",
      "7/7 - 0s - loss: 0.9412 - accuracy: 0.6197 - val_loss: 0.9039 - val_accuracy: 0.5844 - 250ms/epoch - 36ms/step\n",
      "Epoch 76/10000\n",
      "7/7 - 0s - loss: 0.8844 - accuracy: 0.6098 - val_loss: 0.9046 - val_accuracy: 0.5584 - 247ms/epoch - 35ms/step\n",
      "Epoch 77/10000\n",
      "7/7 - 0s - loss: 0.9217 - accuracy: 0.6328 - val_loss: 0.8752 - val_accuracy: 0.6364 - 237ms/epoch - 34ms/step\n",
      "Epoch 78/10000\n",
      "7/7 - 0s - loss: 0.9002 - accuracy: 0.6525 - val_loss: 0.8983 - val_accuracy: 0.6364 - 252ms/epoch - 36ms/step\n",
      "Epoch 79/10000\n",
      "7/7 - 0s - loss: 0.9332 - accuracy: 0.6361 - val_loss: 0.8790 - val_accuracy: 0.6364 - 253ms/epoch - 36ms/step\n",
      "Epoch 80/10000\n",
      "7/7 - 0s - loss: 0.9182 - accuracy: 0.6525 - val_loss: 0.8761 - val_accuracy: 0.6494 - 252ms/epoch - 36ms/step\n",
      "Epoch 81/10000\n",
      "7/7 - 0s - loss: 0.9051 - accuracy: 0.6426 - val_loss: 0.8672 - val_accuracy: 0.6234 - 248ms/epoch - 35ms/step\n",
      "Epoch 82/10000\n",
      "7/7 - 0s - loss: 0.9088 - accuracy: 0.6459 - val_loss: 0.8528 - val_accuracy: 0.6364 - 265ms/epoch - 38ms/step\n",
      "Epoch 83/10000\n",
      "7/7 - 0s - loss: 0.8678 - accuracy: 0.6820 - val_loss: 0.8412 - val_accuracy: 0.6623 - 262ms/epoch - 37ms/step\n",
      "Epoch 84/10000\n",
      "7/7 - 0s - loss: 0.9468 - accuracy: 0.6164 - val_loss: 0.9186 - val_accuracy: 0.6623 - 262ms/epoch - 37ms/step\n",
      "Epoch 85/10000\n",
      "7/7 - 0s - loss: 0.9670 - accuracy: 0.6164 - val_loss: 0.9178 - val_accuracy: 0.6494 - 256ms/epoch - 37ms/step\n",
      "Epoch 86/10000\n",
      "7/7 - 0s - loss: 0.9165 - accuracy: 0.6164 - val_loss: 0.8943 - val_accuracy: 0.6364 - 260ms/epoch - 37ms/step\n",
      "Epoch 87/10000\n",
      "7/7 - 0s - loss: 0.8994 - accuracy: 0.6262 - val_loss: 0.8842 - val_accuracy: 0.6104 - 256ms/epoch - 37ms/step\n",
      "Epoch 88/10000\n",
      "7/7 - 0s - loss: 0.9229 - accuracy: 0.6262 - val_loss: 0.8760 - val_accuracy: 0.6494 - 251ms/epoch - 36ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9046 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:33:20,760] Trial 21 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 160}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3853 - accuracy: 0.3082 - val_loss: 1.3825 - val_accuracy: 0.3896 - 5s/epoch - 645ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3816 - accuracy: 0.3902 - val_loss: 1.3776 - val_accuracy: 0.3377 - 295ms/epoch - 42ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3770 - accuracy: 0.3869 - val_loss: 1.3707 - val_accuracy: 0.3247 - 294ms/epoch - 42ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3672 - accuracy: 0.4131 - val_loss: 1.3581 - val_accuracy: 0.3636 - 282ms/epoch - 40ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3450 - accuracy: 0.4033 - val_loss: 1.3411 - val_accuracy: 0.3636 - 294ms/epoch - 42ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3259 - accuracy: 0.4525 - val_loss: 1.3107 - val_accuracy: 0.4156 - 285ms/epoch - 41ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2970 - accuracy: 0.4754 - val_loss: 1.2842 - val_accuracy: 0.4026 - 295ms/epoch - 42ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2802 - accuracy: 0.4820 - val_loss: 1.2683 - val_accuracy: 0.3896 - 285ms/epoch - 41ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2791 - accuracy: 0.4328 - val_loss: 1.2461 - val_accuracy: 0.3766 - 289ms/epoch - 41ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2540 - accuracy: 0.4492 - val_loss: 1.2364 - val_accuracy: 0.4026 - 285ms/epoch - 41ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2281 - accuracy: 0.4590 - val_loss: 1.2290 - val_accuracy: 0.4675 - 284ms/epoch - 41ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2140 - accuracy: 0.4984 - val_loss: 1.1960 - val_accuracy: 0.4156 - 291ms/epoch - 42ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2366 - accuracy: 0.4918 - val_loss: 1.1883 - val_accuracy: 0.3896 - 289ms/epoch - 41ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1954 - accuracy: 0.5082 - val_loss: 1.1898 - val_accuracy: 0.3766 - 297ms/epoch - 42ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.2005 - accuracy: 0.4918 - val_loss: 1.1806 - val_accuracy: 0.4156 - 288ms/epoch - 41ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1925 - accuracy: 0.4918 - val_loss: 1.1767 - val_accuracy: 0.4156 - 284ms/epoch - 41ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1787 - accuracy: 0.5246 - val_loss: 1.1551 - val_accuracy: 0.4026 - 304ms/epoch - 43ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1429 - accuracy: 0.5115 - val_loss: 1.1443 - val_accuracy: 0.4286 - 282ms/epoch - 40ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1531 - accuracy: 0.5213 - val_loss: 1.1334 - val_accuracy: 0.3896 - 306ms/epoch - 44ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1594 - accuracy: 0.5148 - val_loss: 1.1469 - val_accuracy: 0.4935 - 287ms/epoch - 41ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1683 - accuracy: 0.4984 - val_loss: 1.1171 - val_accuracy: 0.5065 - 301ms/epoch - 43ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1251 - accuracy: 0.5311 - val_loss: 1.1160 - val_accuracy: 0.4545 - 294ms/epoch - 42ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1358 - accuracy: 0.5115 - val_loss: 1.1006 - val_accuracy: 0.4286 - 295ms/epoch - 42ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1104 - accuracy: 0.5443 - val_loss: 1.0996 - val_accuracy: 0.4286 - 287ms/epoch - 41ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1438 - accuracy: 0.5082 - val_loss: 1.0838 - val_accuracy: 0.4675 - 296ms/epoch - 42ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1025 - accuracy: 0.5279 - val_loss: 1.0719 - val_accuracy: 0.5455 - 287ms/epoch - 41ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1087 - accuracy: 0.5508 - val_loss: 1.0717 - val_accuracy: 0.5325 - 289ms/epoch - 41ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0999 - accuracy: 0.5541 - val_loss: 1.0587 - val_accuracy: 0.5195 - 281ms/epoch - 40ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0977 - accuracy: 0.5246 - val_loss: 1.0577 - val_accuracy: 0.5325 - 300ms/epoch - 43ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0866 - accuracy: 0.5574 - val_loss: 1.1036 - val_accuracy: 0.4805 - 304ms/epoch - 43ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0772 - accuracy: 0.5377 - val_loss: 1.0586 - val_accuracy: 0.4805 - 322ms/epoch - 46ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0740 - accuracy: 0.5475 - val_loss: 1.0562 - val_accuracy: 0.4545 - 306ms/epoch - 44ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0804 - accuracy: 0.5377 - val_loss: 1.0535 - val_accuracy: 0.4805 - 313ms/epoch - 45ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0655 - accuracy: 0.5180 - val_loss: 1.0390 - val_accuracy: 0.4545 - 303ms/epoch - 43ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0488 - accuracy: 0.5574 - val_loss: 1.0191 - val_accuracy: 0.5195 - 307ms/epoch - 44ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0444 - accuracy: 0.5803 - val_loss: 1.0177 - val_accuracy: 0.5584 - 299ms/epoch - 43ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0589 - accuracy: 0.5508 - val_loss: 1.0314 - val_accuracy: 0.5844 - 284ms/epoch - 41ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0280 - accuracy: 0.5443 - val_loss: 1.0119 - val_accuracy: 0.5195 - 284ms/epoch - 41ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0799 - accuracy: 0.5279 - val_loss: 1.0327 - val_accuracy: 0.4935 - 295ms/epoch - 42ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0697 - accuracy: 0.5410 - val_loss: 1.0039 - val_accuracy: 0.5195 - 289ms/epoch - 41ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0182 - accuracy: 0.5967 - val_loss: 0.9775 - val_accuracy: 0.5844 - 295ms/epoch - 42ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0206 - accuracy: 0.6098 - val_loss: 0.9624 - val_accuracy: 0.5844 - 285ms/epoch - 41ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 1.0029 - accuracy: 0.5836 - val_loss: 0.9396 - val_accuracy: 0.5844 - 297ms/epoch - 42ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0383 - accuracy: 0.5770 - val_loss: 0.9387 - val_accuracy: 0.5974 - 297ms/epoch - 42ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9948 - accuracy: 0.5902 - val_loss: 0.9606 - val_accuracy: 0.5584 - 279ms/epoch - 40ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9677 - accuracy: 0.5934 - val_loss: 0.9593 - val_accuracy: 0.5065 - 298ms/epoch - 43ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9807 - accuracy: 0.5705 - val_loss: 0.9420 - val_accuracy: 0.5325 - 283ms/epoch - 40ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 0.9977 - accuracy: 0.5934 - val_loss: 0.9459 - val_accuracy: 0.5844 - 288ms/epoch - 41ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 1.0271 - accuracy: 0.6000 - val_loss: 0.9406 - val_accuracy: 0.5584 - 305ms/epoch - 44ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9518 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:33:41,173] Trial 22 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 145}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3857 - accuracy: 0.2721 - val_loss: 1.3840 - val_accuracy: 0.4935 - 4s/epoch - 588ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3830 - accuracy: 0.3738 - val_loss: 1.3802 - val_accuracy: 0.4026 - 310ms/epoch - 44ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3786 - accuracy: 0.4295 - val_loss: 1.3744 - val_accuracy: 0.3896 - 311ms/epoch - 44ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3705 - accuracy: 0.4131 - val_loss: 1.3615 - val_accuracy: 0.3766 - 328ms/epoch - 47ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3568 - accuracy: 0.4787 - val_loss: 1.3425 - val_accuracy: 0.4286 - 321ms/epoch - 46ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3153 - accuracy: 0.4918 - val_loss: 1.2983 - val_accuracy: 0.4156 - 307ms/epoch - 44ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2826 - accuracy: 0.4525 - val_loss: 1.2692 - val_accuracy: 0.4156 - 321ms/epoch - 46ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2823 - accuracy: 0.4492 - val_loss: 1.2632 - val_accuracy: 0.4416 - 313ms/epoch - 45ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2677 - accuracy: 0.4525 - val_loss: 1.2505 - val_accuracy: 0.4026 - 315ms/epoch - 45ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2652 - accuracy: 0.4557 - val_loss: 1.2473 - val_accuracy: 0.3506 - 323ms/epoch - 46ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2362 - accuracy: 0.4656 - val_loss: 1.2401 - val_accuracy: 0.4675 - 308ms/epoch - 44ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2329 - accuracy: 0.4820 - val_loss: 1.2134 - val_accuracy: 0.4416 - 314ms/epoch - 45ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2178 - accuracy: 0.4951 - val_loss: 1.1939 - val_accuracy: 0.4026 - 325ms/epoch - 46ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1676 - accuracy: 0.5180 - val_loss: 1.1807 - val_accuracy: 0.3896 - 322ms/epoch - 46ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1868 - accuracy: 0.4820 - val_loss: 1.1802 - val_accuracy: 0.4286 - 339ms/epoch - 48ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.2011 - accuracy: 0.5049 - val_loss: 1.1736 - val_accuracy: 0.4416 - 342ms/epoch - 49ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.2046 - accuracy: 0.5016 - val_loss: 1.2178 - val_accuracy: 0.3636 - 357ms/epoch - 51ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.2065 - accuracy: 0.5016 - val_loss: 1.1733 - val_accuracy: 0.4026 - 356ms/epoch - 51ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1531 - accuracy: 0.5311 - val_loss: 1.1830 - val_accuracy: 0.4156 - 345ms/epoch - 49ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1554 - accuracy: 0.4984 - val_loss: 1.1768 - val_accuracy: 0.4156 - 342ms/epoch - 49ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1749 - accuracy: 0.5049 - val_loss: 1.1680 - val_accuracy: 0.4156 - 328ms/epoch - 47ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1554 - accuracy: 0.5148 - val_loss: 1.1429 - val_accuracy: 0.4156 - 326ms/epoch - 47ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1298 - accuracy: 0.5148 - val_loss: 1.1480 - val_accuracy: 0.4156 - 326ms/epoch - 47ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1235 - accuracy: 0.5410 - val_loss: 1.1354 - val_accuracy: 0.4026 - 334ms/epoch - 48ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1325 - accuracy: 0.5148 - val_loss: 1.1244 - val_accuracy: 0.4286 - 341ms/epoch - 49ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0957 - accuracy: 0.5344 - val_loss: 1.1036 - val_accuracy: 0.4805 - 318ms/epoch - 45ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1205 - accuracy: 0.5311 - val_loss: 1.0968 - val_accuracy: 0.4805 - 320ms/epoch - 46ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0803 - accuracy: 0.5344 - val_loss: 1.0826 - val_accuracy: 0.4805 - 314ms/epoch - 45ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0891 - accuracy: 0.5115 - val_loss: 1.0776 - val_accuracy: 0.4935 - 333ms/epoch - 48ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1070 - accuracy: 0.5508 - val_loss: 1.0752 - val_accuracy: 0.4545 - 323ms/epoch - 46ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1043 - accuracy: 0.5148 - val_loss: 1.0695 - val_accuracy: 0.4935 - 324ms/epoch - 46ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0557 - accuracy: 0.5705 - val_loss: 1.0767 - val_accuracy: 0.4675 - 326ms/epoch - 47ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0770 - accuracy: 0.5410 - val_loss: 1.0707 - val_accuracy: 0.4675 - 344ms/epoch - 49ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0641 - accuracy: 0.5475 - val_loss: 1.0807 - val_accuracy: 0.4545 - 312ms/epoch - 45ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0845 - accuracy: 0.5508 - val_loss: 1.0630 - val_accuracy: 0.4805 - 318ms/epoch - 45ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0519 - accuracy: 0.5541 - val_loss: 1.0484 - val_accuracy: 0.5325 - 321ms/epoch - 46ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0353 - accuracy: 0.5672 - val_loss: 1.0386 - val_accuracy: 0.5325 - 312ms/epoch - 45ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0958 - accuracy: 0.5574 - val_loss: 1.0255 - val_accuracy: 0.4935 - 320ms/epoch - 46ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0585 - accuracy: 0.5344 - val_loss: 1.0477 - val_accuracy: 0.4935 - 312ms/epoch - 45ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0491 - accuracy: 0.5541 - val_loss: 1.0250 - val_accuracy: 0.5195 - 312ms/epoch - 45ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0451 - accuracy: 0.5475 - val_loss: 0.9948 - val_accuracy: 0.5844 - 313ms/epoch - 45ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0524 - accuracy: 0.5639 - val_loss: 1.0195 - val_accuracy: 0.5974 - 315ms/epoch - 45ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 1.0249 - accuracy: 0.5639 - val_loss: 0.9757 - val_accuracy: 0.5844 - 335ms/epoch - 48ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0377 - accuracy: 0.5607 - val_loss: 0.9719 - val_accuracy: 0.5584 - 317ms/epoch - 45ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 1.0183 - accuracy: 0.5967 - val_loss: 0.9850 - val_accuracy: 0.5325 - 319ms/epoch - 46ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9970 - accuracy: 0.6033 - val_loss: 0.9905 - val_accuracy: 0.5065 - 328ms/epoch - 47ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9634 - accuracy: 0.5902 - val_loss: 0.9841 - val_accuracy: 0.5195 - 312ms/epoch - 45ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 0.9884 - accuracy: 0.5934 - val_loss: 0.9778 - val_accuracy: 0.5325 - 334ms/epoch - 48ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 0.9916 - accuracy: 0.6000 - val_loss: 0.9614 - val_accuracy: 0.5455 - 312ms/epoch - 45ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 0.9813 - accuracy: 0.6197 - val_loss: 0.9418 - val_accuracy: 0.5714 - 321ms/epoch - 46ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 0.9690 - accuracy: 0.6164 - val_loss: 0.9539 - val_accuracy: 0.6234 - 313ms/epoch - 45ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 0.9819 - accuracy: 0.6131 - val_loss: 0.9304 - val_accuracy: 0.5714 - 318ms/epoch - 45ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 1.0069 - accuracy: 0.5639 - val_loss: 0.9290 - val_accuracy: 0.5455 - 311ms/epoch - 44ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 0.9719 - accuracy: 0.5934 - val_loss: 0.9488 - val_accuracy: 0.5325 - 317ms/epoch - 45ms/step\n",
      "Epoch 55/10000\n",
      "7/7 - 0s - loss: 0.9458 - accuracy: 0.6066 - val_loss: 0.9377 - val_accuracy: 0.5325 - 330ms/epoch - 47ms/step\n",
      "Epoch 56/10000\n",
      "7/7 - 0s - loss: 0.9981 - accuracy: 0.6000 - val_loss: 0.9240 - val_accuracy: 0.5455 - 319ms/epoch - 46ms/step\n",
      "Epoch 57/10000\n",
      "7/7 - 0s - loss: 0.9799 - accuracy: 0.5967 - val_loss: 0.9167 - val_accuracy: 0.5584 - 355ms/epoch - 51ms/step\n",
      "Epoch 58/10000\n",
      "7/7 - 0s - loss: 0.9715 - accuracy: 0.6000 - val_loss: 0.9037 - val_accuracy: 0.6234 - 355ms/epoch - 51ms/step\n",
      "Epoch 59/10000\n",
      "7/7 - 0s - loss: 0.9373 - accuracy: 0.6230 - val_loss: 0.9225 - val_accuracy: 0.5584 - 331ms/epoch - 47ms/step\n",
      "Epoch 60/10000\n",
      "7/7 - 0s - loss: 0.9441 - accuracy: 0.6525 - val_loss: 0.9254 - val_accuracy: 0.5584 - 335ms/epoch - 48ms/step\n",
      "Epoch 61/10000\n",
      "7/7 - 0s - loss: 0.9876 - accuracy: 0.5967 - val_loss: 0.9067 - val_accuracy: 0.5974 - 333ms/epoch - 48ms/step\n",
      "Epoch 62/10000\n",
      "7/7 - 0s - loss: 0.9710 - accuracy: 0.6361 - val_loss: 0.9041 - val_accuracy: 0.5714 - 353ms/epoch - 50ms/step\n",
      "Epoch 63/10000\n",
      "7/7 - 0s - loss: 0.9441 - accuracy: 0.6262 - val_loss: 0.9258 - val_accuracy: 0.5714 - 351ms/epoch - 50ms/step\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8871 - accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:34:07,362] Trial 23 finished with value: 0.7058823704719543 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 155}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 6s - loss: 1.3843 - accuracy: 0.2689 - val_loss: 1.3799 - val_accuracy: 0.3896 - 6s/epoch - 869ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3762 - accuracy: 0.4459 - val_loss: 1.3707 - val_accuracy: 0.3636 - 221ms/epoch - 32ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3638 - accuracy: 0.4590 - val_loss: 1.3530 - val_accuracy: 0.3506 - 230ms/epoch - 33ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3370 - accuracy: 0.4623 - val_loss: 1.3181 - val_accuracy: 0.3506 - 221ms/epoch - 32ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2930 - accuracy: 0.4557 - val_loss: 1.2883 - val_accuracy: 0.3766 - 231ms/epoch - 33ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2626 - accuracy: 0.4590 - val_loss: 1.2596 - val_accuracy: 0.3506 - 233ms/epoch - 33ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2473 - accuracy: 0.4459 - val_loss: 1.2494 - val_accuracy: 0.3636 - 233ms/epoch - 33ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2313 - accuracy: 0.4557 - val_loss: 1.2355 - val_accuracy: 0.3636 - 233ms/epoch - 33ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2217 - accuracy: 0.4590 - val_loss: 1.2156 - val_accuracy: 0.4026 - 224ms/epoch - 32ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2107 - accuracy: 0.4852 - val_loss: 1.2082 - val_accuracy: 0.4156 - 227ms/epoch - 32ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1682 - accuracy: 0.5049 - val_loss: 1.1828 - val_accuracy: 0.3766 - 222ms/epoch - 32ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1694 - accuracy: 0.4852 - val_loss: 1.1811 - val_accuracy: 0.3766 - 225ms/epoch - 32ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1657 - accuracy: 0.4787 - val_loss: 1.1771 - val_accuracy: 0.3766 - 224ms/epoch - 32ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1424 - accuracy: 0.5082 - val_loss: 1.1615 - val_accuracy: 0.3896 - 230ms/epoch - 33ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1593 - accuracy: 0.4787 - val_loss: 1.1476 - val_accuracy: 0.3766 - 226ms/epoch - 32ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1519 - accuracy: 0.5213 - val_loss: 1.1646 - val_accuracy: 0.3896 - 221ms/epoch - 32ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1353 - accuracy: 0.5016 - val_loss: 1.1577 - val_accuracy: 0.3896 - 223ms/epoch - 32ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1379 - accuracy: 0.5016 - val_loss: 1.1425 - val_accuracy: 0.3896 - 223ms/epoch - 32ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1253 - accuracy: 0.5311 - val_loss: 1.1472 - val_accuracy: 0.4156 - 224ms/epoch - 32ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1257 - accuracy: 0.5180 - val_loss: 1.1291 - val_accuracy: 0.4026 - 240ms/epoch - 34ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1245 - accuracy: 0.5246 - val_loss: 1.1123 - val_accuracy: 0.4286 - 230ms/epoch - 33ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1248 - accuracy: 0.5311 - val_loss: 1.1049 - val_accuracy: 0.4935 - 223ms/epoch - 32ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1138 - accuracy: 0.5311 - val_loss: 1.1085 - val_accuracy: 0.4416 - 236ms/epoch - 34ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1149 - accuracy: 0.5279 - val_loss: 1.0931 - val_accuracy: 0.4156 - 237ms/epoch - 34ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1043 - accuracy: 0.5279 - val_loss: 1.0925 - val_accuracy: 0.4156 - 234ms/epoch - 33ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1039 - accuracy: 0.5311 - val_loss: 1.0839 - val_accuracy: 0.4545 - 229ms/epoch - 33ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1046 - accuracy: 0.5246 - val_loss: 1.0931 - val_accuracy: 0.5195 - 223ms/epoch - 32ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0923 - accuracy: 0.5344 - val_loss: 1.0789 - val_accuracy: 0.5065 - 234ms/epoch - 33ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0845 - accuracy: 0.5508 - val_loss: 1.0742 - val_accuracy: 0.5195 - 231ms/epoch - 33ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0932 - accuracy: 0.5574 - val_loss: 1.0866 - val_accuracy: 0.4675 - 224ms/epoch - 32ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1037 - accuracy: 0.5443 - val_loss: 1.0761 - val_accuracy: 0.4675 - 225ms/epoch - 32ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0863 - accuracy: 0.5410 - val_loss: 1.0916 - val_accuracy: 0.4286 - 231ms/epoch - 33ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0970 - accuracy: 0.5246 - val_loss: 1.0976 - val_accuracy: 0.4545 - 229ms/epoch - 33ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0813 - accuracy: 0.5475 - val_loss: 1.0914 - val_accuracy: 0.4675 - 250ms/epoch - 36ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0370 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:34:23,064] Trial 24 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'tanh', 'activation_func_3': 'tanh', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 136}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3829 - accuracy: 0.3377 - val_loss: 1.3803 - val_accuracy: 0.3766 - 4s/epoch - 443ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3724 - accuracy: 0.4295 - val_loss: 1.3656 - val_accuracy: 0.3766 - 199ms/epoch - 20ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3428 - accuracy: 0.4590 - val_loss: 1.3334 - val_accuracy: 0.3636 - 217ms/epoch - 22ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2884 - accuracy: 0.4557 - val_loss: 1.2826 - val_accuracy: 0.3506 - 206ms/epoch - 21ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2374 - accuracy: 0.4459 - val_loss: 1.2476 - val_accuracy: 0.3766 - 212ms/epoch - 21ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2200 - accuracy: 0.4623 - val_loss: 1.2165 - val_accuracy: 0.3636 - 210ms/epoch - 21ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1958 - accuracy: 0.4754 - val_loss: 1.1898 - val_accuracy: 0.3896 - 207ms/epoch - 21ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1991 - accuracy: 0.4885 - val_loss: 1.1820 - val_accuracy: 0.4156 - 218ms/epoch - 22ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1683 - accuracy: 0.4984 - val_loss: 1.1644 - val_accuracy: 0.4026 - 212ms/epoch - 21ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1695 - accuracy: 0.4820 - val_loss: 1.1647 - val_accuracy: 0.4026 - 209ms/epoch - 21ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1369 - accuracy: 0.4852 - val_loss: 1.1610 - val_accuracy: 0.4026 - 214ms/epoch - 21ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1486 - accuracy: 0.4984 - val_loss: 1.1554 - val_accuracy: 0.4156 - 205ms/epoch - 21ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1289 - accuracy: 0.5246 - val_loss: 1.1479 - val_accuracy: 0.3896 - 206ms/epoch - 21ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1187 - accuracy: 0.5082 - val_loss: 1.1386 - val_accuracy: 0.4026 - 221ms/epoch - 22ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1239 - accuracy: 0.5115 - val_loss: 1.1288 - val_accuracy: 0.4286 - 204ms/epoch - 20ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1314 - accuracy: 0.5213 - val_loss: 1.1060 - val_accuracy: 0.3896 - 211ms/epoch - 21ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1030 - accuracy: 0.5180 - val_loss: 1.1078 - val_accuracy: 0.4156 - 219ms/epoch - 22ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0993 - accuracy: 0.5410 - val_loss: 1.1136 - val_accuracy: 0.4545 - 214ms/epoch - 21ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1214 - accuracy: 0.5344 - val_loss: 1.1207 - val_accuracy: 0.4416 - 211ms/epoch - 21ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0912 - accuracy: 0.5410 - val_loss: 1.1056 - val_accuracy: 0.4935 - 216ms/epoch - 22ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0910 - accuracy: 0.5541 - val_loss: 1.0923 - val_accuracy: 0.4286 - 207ms/epoch - 21ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0777 - accuracy: 0.5410 - val_loss: 1.0837 - val_accuracy: 0.4156 - 222ms/epoch - 22ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0822 - accuracy: 0.5410 - val_loss: 1.0846 - val_accuracy: 0.4805 - 232ms/epoch - 23ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0846 - accuracy: 0.5475 - val_loss: 1.0751 - val_accuracy: 0.4156 - 201ms/epoch - 20ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0654 - accuracy: 0.5377 - val_loss: 1.0838 - val_accuracy: 0.4675 - 205ms/epoch - 21ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0680 - accuracy: 0.5672 - val_loss: 1.0555 - val_accuracy: 0.5714 - 219ms/epoch - 22ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0658 - accuracy: 0.5508 - val_loss: 1.0454 - val_accuracy: 0.4935 - 219ms/epoch - 22ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0624 - accuracy: 0.5541 - val_loss: 1.0463 - val_accuracy: 0.4805 - 223ms/epoch - 22ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0825 - accuracy: 0.5738 - val_loss: 1.0457 - val_accuracy: 0.4805 - 217ms/epoch - 22ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0246 - accuracy: 0.5803 - val_loss: 1.0283 - val_accuracy: 0.5065 - 217ms/epoch - 22ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0121 - accuracy: 0.5836 - val_loss: 1.0157 - val_accuracy: 0.4935 - 214ms/epoch - 21ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0035 - accuracy: 0.5902 - val_loss: 1.0017 - val_accuracy: 0.5065 - 210ms/epoch - 21ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0236 - accuracy: 0.5836 - val_loss: 0.9889 - val_accuracy: 0.5455 - 221ms/epoch - 22ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9983 - accuracy: 0.6000 - val_loss: 0.9722 - val_accuracy: 0.5844 - 209ms/epoch - 21ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9672 - accuracy: 0.6230 - val_loss: 0.9568 - val_accuracy: 0.5974 - 206ms/epoch - 21ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9591 - accuracy: 0.6131 - val_loss: 0.9372 - val_accuracy: 0.5844 - 216ms/epoch - 22ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9800 - accuracy: 0.6000 - val_loss: 0.9292 - val_accuracy: 0.5844 - 211ms/epoch - 21ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9705 - accuracy: 0.6393 - val_loss: 0.9260 - val_accuracy: 0.5844 - 211ms/epoch - 21ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9894 - accuracy: 0.6033 - val_loss: 0.9232 - val_accuracy: 0.5844 - 206ms/epoch - 21ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9698 - accuracy: 0.6000 - val_loss: 0.9223 - val_accuracy: 0.5714 - 218ms/epoch - 22ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9474 - accuracy: 0.6459 - val_loss: 0.9129 - val_accuracy: 0.6234 - 209ms/epoch - 21ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9422 - accuracy: 0.6262 - val_loss: 0.9153 - val_accuracy: 0.5714 - 211ms/epoch - 21ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9379 - accuracy: 0.6230 - val_loss: 0.9176 - val_accuracy: 0.5714 - 208ms/epoch - 21ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9593 - accuracy: 0.6295 - val_loss: 0.8887 - val_accuracy: 0.6234 - 211ms/epoch - 21ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9243 - accuracy: 0.6230 - val_loss: 0.8989 - val_accuracy: 0.5714 - 208ms/epoch - 21ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9155 - accuracy: 0.6230 - val_loss: 0.8839 - val_accuracy: 0.5714 - 206ms/epoch - 21ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8792 - accuracy: 0.6689 - val_loss: 0.8662 - val_accuracy: 0.6104 - 208ms/epoch - 21ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9217 - accuracy: 0.6361 - val_loss: 0.8867 - val_accuracy: 0.6234 - 237ms/epoch - 24ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9205 - accuracy: 0.6459 - val_loss: 0.8838 - val_accuracy: 0.6364 - 219ms/epoch - 22ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.8954 - accuracy: 0.6328 - val_loss: 0.9070 - val_accuracy: 0.5844 - 230ms/epoch - 23ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9118 - accuracy: 0.6230 - val_loss: 0.8846 - val_accuracy: 0.6234 - 216ms/epoch - 22ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9029 - accuracy: 0.6459 - val_loss: 0.8864 - val_accuracy: 0.6234 - 227ms/epoch - 23ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8836 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:34:40,134] Trial 25 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'linear', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 128}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3829 - accuracy: 0.3213 - val_loss: 1.3796 - val_accuracy: 0.3636 - 4s/epoch - 414ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3672 - accuracy: 0.4557 - val_loss: 1.3593 - val_accuracy: 0.4156 - 304ms/epoch - 30ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3319 - accuracy: 0.4033 - val_loss: 1.3180 - val_accuracy: 0.3766 - 301ms/epoch - 30ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2747 - accuracy: 0.4492 - val_loss: 1.2683 - val_accuracy: 0.4026 - 311ms/epoch - 31ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2611 - accuracy: 0.5082 - val_loss: 1.2470 - val_accuracy: 0.4026 - 306ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2277 - accuracy: 0.4754 - val_loss: 1.2424 - val_accuracy: 0.4156 - 308ms/epoch - 31ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2203 - accuracy: 0.5148 - val_loss: 1.2260 - val_accuracy: 0.4286 - 304ms/epoch - 30ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2279 - accuracy: 0.5016 - val_loss: 1.2154 - val_accuracy: 0.4156 - 295ms/epoch - 29ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2308 - accuracy: 0.5246 - val_loss: 1.1926 - val_accuracy: 0.4156 - 302ms/epoch - 30ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1792 - accuracy: 0.5377 - val_loss: 1.1707 - val_accuracy: 0.4286 - 301ms/epoch - 30ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1528 - accuracy: 0.5377 - val_loss: 1.1468 - val_accuracy: 0.4416 - 297ms/epoch - 30ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1308 - accuracy: 0.5541 - val_loss: 1.1183 - val_accuracy: 0.4675 - 301ms/epoch - 30ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1036 - accuracy: 0.5639 - val_loss: 1.0795 - val_accuracy: 0.5455 - 302ms/epoch - 30ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1084 - accuracy: 0.5344 - val_loss: 1.0656 - val_accuracy: 0.4805 - 293ms/epoch - 29ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0765 - accuracy: 0.5410 - val_loss: 1.0443 - val_accuracy: 0.4675 - 313ms/epoch - 31ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0679 - accuracy: 0.5475 - val_loss: 1.0289 - val_accuracy: 0.5195 - 308ms/epoch - 31ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0827 - accuracy: 0.5443 - val_loss: 1.1167 - val_accuracy: 0.4935 - 298ms/epoch - 30ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0623 - accuracy: 0.5738 - val_loss: 1.0455 - val_accuracy: 0.4805 - 302ms/epoch - 30ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0489 - accuracy: 0.5574 - val_loss: 1.0207 - val_accuracy: 0.5195 - 302ms/epoch - 30ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0346 - accuracy: 0.5803 - val_loss: 0.9806 - val_accuracy: 0.5584 - 302ms/epoch - 30ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 0.9738 - accuracy: 0.5902 - val_loss: 0.9833 - val_accuracy: 0.4935 - 302ms/epoch - 30ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 0.9593 - accuracy: 0.6131 - val_loss: 0.9531 - val_accuracy: 0.6364 - 303ms/epoch - 30ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 0.9423 - accuracy: 0.6230 - val_loss: 1.0239 - val_accuracy: 0.5325 - 324ms/epoch - 32ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0085 - accuracy: 0.5934 - val_loss: 0.9476 - val_accuracy: 0.6234 - 330ms/epoch - 33ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9468 - accuracy: 0.6393 - val_loss: 0.8834 - val_accuracy: 0.6234 - 338ms/epoch - 34ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9678 - accuracy: 0.6197 - val_loss: 0.9025 - val_accuracy: 0.6104 - 312ms/epoch - 31ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9605 - accuracy: 0.6131 - val_loss: 0.9303 - val_accuracy: 0.5455 - 319ms/epoch - 32ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9560 - accuracy: 0.6033 - val_loss: 0.9448 - val_accuracy: 0.6104 - 334ms/epoch - 33ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.8981 - accuracy: 0.6295 - val_loss: 0.8971 - val_accuracy: 0.5974 - 319ms/epoch - 32ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9001 - accuracy: 0.6393 - val_loss: 0.8904 - val_accuracy: 0.6494 - 309ms/epoch - 31ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9178 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:34:54,722] Trial 26 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 150}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3854 - accuracy: 0.2918 - val_loss: 1.3809 - val_accuracy: 0.2987 - 4s/epoch - 636ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3800 - accuracy: 0.3541 - val_loss: 1.3741 - val_accuracy: 0.3506 - 212ms/epoch - 30ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3729 - accuracy: 0.3574 - val_loss: 1.3627 - val_accuracy: 0.3377 - 228ms/epoch - 33ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3575 - accuracy: 0.3639 - val_loss: 1.3417 - val_accuracy: 0.3117 - 229ms/epoch - 33ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3298 - accuracy: 0.3869 - val_loss: 1.3206 - val_accuracy: 0.3247 - 230ms/epoch - 33ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2908 - accuracy: 0.4426 - val_loss: 1.2869 - val_accuracy: 0.3636 - 230ms/epoch - 33ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2697 - accuracy: 0.4426 - val_loss: 1.2607 - val_accuracy: 0.3506 - 242ms/epoch - 35ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2406 - accuracy: 0.4590 - val_loss: 1.2445 - val_accuracy: 0.3896 - 221ms/epoch - 32ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2270 - accuracy: 0.4820 - val_loss: 1.2116 - val_accuracy: 0.4156 - 214ms/epoch - 31ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.1984 - accuracy: 0.4820 - val_loss: 1.1902 - val_accuracy: 0.4026 - 239ms/epoch - 34ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1938 - accuracy: 0.4852 - val_loss: 1.1757 - val_accuracy: 0.3896 - 230ms/epoch - 33ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1622 - accuracy: 0.4951 - val_loss: 1.2000 - val_accuracy: 0.3766 - 238ms/epoch - 34ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1729 - accuracy: 0.4787 - val_loss: 1.1707 - val_accuracy: 0.3896 - 226ms/epoch - 32ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1623 - accuracy: 0.4689 - val_loss: 1.1695 - val_accuracy: 0.3896 - 258ms/epoch - 37ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1443 - accuracy: 0.4885 - val_loss: 1.1497 - val_accuracy: 0.4156 - 245ms/epoch - 35ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1617 - accuracy: 0.5016 - val_loss: 1.1627 - val_accuracy: 0.4156 - 270ms/epoch - 39ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1525 - accuracy: 0.4918 - val_loss: 1.1442 - val_accuracy: 0.4026 - 252ms/epoch - 36ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1351 - accuracy: 0.4918 - val_loss: 1.1329 - val_accuracy: 0.3766 - 243ms/epoch - 35ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1277 - accuracy: 0.5082 - val_loss: 1.1291 - val_accuracy: 0.4026 - 230ms/epoch - 33ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1127 - accuracy: 0.5213 - val_loss: 1.1198 - val_accuracy: 0.4805 - 250ms/epoch - 36ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1417 - accuracy: 0.5016 - val_loss: 1.0999 - val_accuracy: 0.4675 - 222ms/epoch - 32ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1015 - accuracy: 0.5279 - val_loss: 1.0953 - val_accuracy: 0.5195 - 233ms/epoch - 33ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1277 - accuracy: 0.4984 - val_loss: 1.0988 - val_accuracy: 0.4416 - 232ms/epoch - 33ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.0908 - accuracy: 0.5475 - val_loss: 1.0998 - val_accuracy: 0.4026 - 236ms/epoch - 34ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1025 - accuracy: 0.5213 - val_loss: 1.1032 - val_accuracy: 0.4416 - 250ms/epoch - 36ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0963 - accuracy: 0.5443 - val_loss: 1.0840 - val_accuracy: 0.5325 - 232ms/epoch - 33ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0879 - accuracy: 0.5213 - val_loss: 1.0978 - val_accuracy: 0.5455 - 227ms/epoch - 32ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1068 - accuracy: 0.5410 - val_loss: 1.0748 - val_accuracy: 0.5065 - 233ms/epoch - 33ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0738 - accuracy: 0.5180 - val_loss: 1.0720 - val_accuracy: 0.5455 - 243ms/epoch - 35ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1243 - accuracy: 0.5279 - val_loss: 1.0837 - val_accuracy: 0.4545 - 234ms/epoch - 33ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0905 - accuracy: 0.5246 - val_loss: 1.0736 - val_accuracy: 0.4286 - 224ms/epoch - 32ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0803 - accuracy: 0.5475 - val_loss: 1.0862 - val_accuracy: 0.4286 - 221ms/epoch - 32ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0881 - accuracy: 0.5508 - val_loss: 1.0816 - val_accuracy: 0.4545 - 267ms/epoch - 38ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0915 - accuracy: 0.5508 - val_loss: 1.0723 - val_accuracy: 0.4545 - 236ms/epoch - 34ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0004 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:35:08,390] Trial 27 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'selu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 142}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 6s - loss: 1.3861 - accuracy: 0.2656 - val_loss: 1.3850 - val_accuracy: 0.2597 - 6s/epoch - 579ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3851 - accuracy: 0.2689 - val_loss: 1.3830 - val_accuracy: 0.2727 - 282ms/epoch - 28ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3829 - accuracy: 0.3311 - val_loss: 1.3807 - val_accuracy: 0.3766 - 297ms/epoch - 30ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3795 - accuracy: 0.3803 - val_loss: 1.3758 - val_accuracy: 0.3766 - 310ms/epoch - 31ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3706 - accuracy: 0.4426 - val_loss: 1.3658 - val_accuracy: 0.3506 - 277ms/epoch - 28ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3496 - accuracy: 0.4426 - val_loss: 1.3443 - val_accuracy: 0.3636 - 290ms/epoch - 29ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.3272 - accuracy: 0.4525 - val_loss: 1.3098 - val_accuracy: 0.3766 - 267ms/epoch - 27ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2736 - accuracy: 0.4426 - val_loss: 1.2740 - val_accuracy: 0.3636 - 258ms/epoch - 26ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2329 - accuracy: 0.4459 - val_loss: 1.2317 - val_accuracy: 0.3636 - 255ms/epoch - 25ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.2055 - accuracy: 0.4689 - val_loss: 1.2141 - val_accuracy: 0.4026 - 270ms/epoch - 27ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1897 - accuracy: 0.4721 - val_loss: 1.1804 - val_accuracy: 0.3896 - 246ms/epoch - 25ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1880 - accuracy: 0.4852 - val_loss: 1.1862 - val_accuracy: 0.3896 - 241ms/epoch - 24ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1643 - accuracy: 0.5049 - val_loss: 1.1629 - val_accuracy: 0.4026 - 246ms/epoch - 25ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1300 - accuracy: 0.5115 - val_loss: 1.1484 - val_accuracy: 0.4156 - 242ms/epoch - 24ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1410 - accuracy: 0.5148 - val_loss: 1.1386 - val_accuracy: 0.4026 - 260ms/epoch - 26ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1453 - accuracy: 0.5082 - val_loss: 1.1246 - val_accuracy: 0.4156 - 252ms/epoch - 25ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1337 - accuracy: 0.5049 - val_loss: 1.1161 - val_accuracy: 0.4026 - 241ms/epoch - 24ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1188 - accuracy: 0.5180 - val_loss: 1.1111 - val_accuracy: 0.4156 - 253ms/epoch - 25ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1173 - accuracy: 0.5148 - val_loss: 1.1183 - val_accuracy: 0.4286 - 267ms/epoch - 27ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1182 - accuracy: 0.5082 - val_loss: 1.1057 - val_accuracy: 0.5325 - 281ms/epoch - 28ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0769 - accuracy: 0.5246 - val_loss: 1.0930 - val_accuracy: 0.4286 - 261ms/epoch - 26ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1091 - accuracy: 0.5443 - val_loss: 1.0877 - val_accuracy: 0.4675 - 256ms/epoch - 26ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1186 - accuracy: 0.5377 - val_loss: 1.0880 - val_accuracy: 0.5065 - 261ms/epoch - 26ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0684 - accuracy: 0.5410 - val_loss: 1.0845 - val_accuracy: 0.4805 - 268ms/epoch - 27ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0780 - accuracy: 0.5508 - val_loss: 1.0813 - val_accuracy: 0.4805 - 276ms/epoch - 28ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0621 - accuracy: 0.5508 - val_loss: 1.0523 - val_accuracy: 0.5325 - 257ms/epoch - 26ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0846 - accuracy: 0.5508 - val_loss: 1.0492 - val_accuracy: 0.4935 - 258ms/epoch - 26ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0854 - accuracy: 0.5213 - val_loss: 1.0502 - val_accuracy: 0.4805 - 241ms/epoch - 24ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0682 - accuracy: 0.5607 - val_loss: 1.0478 - val_accuracy: 0.4935 - 250ms/epoch - 25ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0633 - accuracy: 0.5443 - val_loss: 1.0460 - val_accuracy: 0.4805 - 270ms/epoch - 27ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0331 - accuracy: 0.5344 - val_loss: 1.0422 - val_accuracy: 0.4935 - 244ms/epoch - 24ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0541 - accuracy: 0.5738 - val_loss: 1.0333 - val_accuracy: 0.5195 - 246ms/epoch - 25ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0505 - accuracy: 0.5508 - val_loss: 1.0288 - val_accuracy: 0.4935 - 243ms/epoch - 24ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0417 - accuracy: 0.5574 - val_loss: 1.0177 - val_accuracy: 0.5065 - 253ms/epoch - 25ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0275 - accuracy: 0.5672 - val_loss: 1.0046 - val_accuracy: 0.5195 - 243ms/epoch - 24ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0242 - accuracy: 0.5705 - val_loss: 0.9814 - val_accuracy: 0.5325 - 244ms/epoch - 24ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0319 - accuracy: 0.5574 - val_loss: 0.9800 - val_accuracy: 0.5584 - 246ms/epoch - 25ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0147 - accuracy: 0.5705 - val_loss: 0.9895 - val_accuracy: 0.5195 - 256ms/epoch - 26ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0187 - accuracy: 0.5607 - val_loss: 0.9802 - val_accuracy: 0.5195 - 253ms/epoch - 25ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9946 - accuracy: 0.5770 - val_loss: 0.9631 - val_accuracy: 0.5195 - 242ms/epoch - 24ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9755 - accuracy: 0.5639 - val_loss: 0.9532 - val_accuracy: 0.5974 - 247ms/epoch - 25ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0058 - accuracy: 0.5738 - val_loss: 0.9322 - val_accuracy: 0.5325 - 242ms/epoch - 24ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9822 - accuracy: 0.6230 - val_loss: 0.9323 - val_accuracy: 0.5714 - 243ms/epoch - 24ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9758 - accuracy: 0.5934 - val_loss: 0.9189 - val_accuracy: 0.5455 - 247ms/epoch - 25ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9850 - accuracy: 0.5934 - val_loss: 0.9103 - val_accuracy: 0.6364 - 274ms/epoch - 27ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9597 - accuracy: 0.6000 - val_loss: 0.9194 - val_accuracy: 0.5455 - 268ms/epoch - 27ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9985 - accuracy: 0.5705 - val_loss: 0.9166 - val_accuracy: 0.5714 - 258ms/epoch - 26ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9988 - accuracy: 0.6000 - val_loss: 0.9263 - val_accuracy: 0.5584 - 259ms/epoch - 26ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9380 - accuracy: 0.6361 - val_loss: 0.9158 - val_accuracy: 0.5455 - 264ms/epoch - 26ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9611 - accuracy: 0.6131 - val_loss: 0.9145 - val_accuracy: 0.5455 - 254ms/epoch - 25ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8967 - accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:35:28,678] Trial 28 finished with value: 0.7058823704719543 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 136}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3835 - accuracy: 0.3180 - val_loss: 1.3794 - val_accuracy: 0.4286 - 5s/epoch - 492ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3688 - accuracy: 0.4426 - val_loss: 1.3541 - val_accuracy: 0.4286 - 378ms/epoch - 38ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3215 - accuracy: 0.4918 - val_loss: 1.3020 - val_accuracy: 0.4156 - 377ms/epoch - 38ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2584 - accuracy: 0.4852 - val_loss: 1.2458 - val_accuracy: 0.4286 - 377ms/epoch - 38ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2531 - accuracy: 0.4852 - val_loss: 1.2226 - val_accuracy: 0.4286 - 376ms/epoch - 38ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2219 - accuracy: 0.5049 - val_loss: 1.2017 - val_accuracy: 0.4026 - 381ms/epoch - 38ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1977 - accuracy: 0.5311 - val_loss: 1.1966 - val_accuracy: 0.4286 - 377ms/epoch - 38ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2181 - accuracy: 0.4623 - val_loss: 1.1697 - val_accuracy: 0.4416 - 384ms/epoch - 38ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1976 - accuracy: 0.5311 - val_loss: 1.1481 - val_accuracy: 0.4545 - 378ms/epoch - 38ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1331 - accuracy: 0.5279 - val_loss: 1.1181 - val_accuracy: 0.4416 - 383ms/epoch - 38ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.0971 - accuracy: 0.5180 - val_loss: 1.0886 - val_accuracy: 0.4675 - 395ms/epoch - 39ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.0813 - accuracy: 0.5344 - val_loss: 1.0540 - val_accuracy: 0.4805 - 433ms/epoch - 43ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1132 - accuracy: 0.5639 - val_loss: 1.0332 - val_accuracy: 0.5065 - 399ms/epoch - 40ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0669 - accuracy: 0.5672 - val_loss: 1.0265 - val_accuracy: 0.4545 - 377ms/epoch - 38ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0436 - accuracy: 0.5607 - val_loss: 1.0074 - val_accuracy: 0.5065 - 373ms/epoch - 37ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0430 - accuracy: 0.5344 - val_loss: 0.9953 - val_accuracy: 0.5584 - 352ms/epoch - 35ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0081 - accuracy: 0.5869 - val_loss: 0.9928 - val_accuracy: 0.5325 - 348ms/epoch - 35ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0088 - accuracy: 0.5869 - val_loss: 0.9920 - val_accuracy: 0.5455 - 350ms/epoch - 35ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 0.9746 - accuracy: 0.5967 - val_loss: 0.9627 - val_accuracy: 0.5974 - 392ms/epoch - 39ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 0.9643 - accuracy: 0.6066 - val_loss: 0.9055 - val_accuracy: 0.5844 - 401ms/epoch - 40ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 0.9693 - accuracy: 0.6295 - val_loss: 0.9405 - val_accuracy: 0.5455 - 384ms/epoch - 38ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 0.9191 - accuracy: 0.6492 - val_loss: 0.9130 - val_accuracy: 0.5584 - 378ms/epoch - 38ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 0.9388 - accuracy: 0.6459 - val_loss: 0.9089 - val_accuracy: 0.5584 - 377ms/epoch - 38ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 0.9431 - accuracy: 0.6262 - val_loss: 0.9160 - val_accuracy: 0.6494 - 420ms/epoch - 42ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9171 - accuracy: 0.6459 - val_loss: 0.8867 - val_accuracy: 0.6234 - 440ms/epoch - 44ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9473 - accuracy: 0.6164 - val_loss: 0.8779 - val_accuracy: 0.6234 - 457ms/epoch - 46ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9582 - accuracy: 0.6066 - val_loss: 0.9097 - val_accuracy: 0.5714 - 436ms/epoch - 44ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9741 - accuracy: 0.6033 - val_loss: 0.9161 - val_accuracy: 0.6494 - 399ms/epoch - 40ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9234 - accuracy: 0.6393 - val_loss: 0.9366 - val_accuracy: 0.5974 - 409ms/epoch - 41ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.8730 - accuracy: 0.6754 - val_loss: 0.8832 - val_accuracy: 0.6364 - 401ms/epoch - 40ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9778 - accuracy: 0.5902 - val_loss: 0.9239 - val_accuracy: 0.6104 - 399ms/epoch - 40ms/step\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8749 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:35:46,908] Trial 29 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 167}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3849 - accuracy: 0.2295 - val_loss: 1.3819 - val_accuracy: 0.3377 - 4s/epoch - 575ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3800 - accuracy: 0.4098 - val_loss: 1.3757 - val_accuracy: 0.3766 - 201ms/epoch - 29ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3726 - accuracy: 0.4328 - val_loss: 1.3649 - val_accuracy: 0.3766 - 222ms/epoch - 32ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3587 - accuracy: 0.4295 - val_loss: 1.3419 - val_accuracy: 0.4156 - 225ms/epoch - 32ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3106 - accuracy: 0.4918 - val_loss: 1.3020 - val_accuracy: 0.3247 - 227ms/epoch - 32ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2745 - accuracy: 0.3934 - val_loss: 1.2628 - val_accuracy: 0.4286 - 219ms/epoch - 31ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2543 - accuracy: 0.4787 - val_loss: 1.2358 - val_accuracy: 0.4156 - 220ms/epoch - 31ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2655 - accuracy: 0.4820 - val_loss: 1.2567 - val_accuracy: 0.4545 - 221ms/epoch - 32ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2673 - accuracy: 0.5049 - val_loss: 1.2360 - val_accuracy: 0.4156 - 222ms/epoch - 32ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2364 - accuracy: 0.4590 - val_loss: 1.2383 - val_accuracy: 0.4026 - 220ms/epoch - 31ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2281 - accuracy: 0.4656 - val_loss: 1.2261 - val_accuracy: 0.4675 - 233ms/epoch - 33ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2091 - accuracy: 0.5279 - val_loss: 1.2112 - val_accuracy: 0.4675 - 230ms/epoch - 33ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2151 - accuracy: 0.5180 - val_loss: 1.1919 - val_accuracy: 0.4286 - 223ms/epoch - 32ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1879 - accuracy: 0.5213 - val_loss: 1.1865 - val_accuracy: 0.4416 - 222ms/epoch - 32ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1876 - accuracy: 0.5115 - val_loss: 1.1601 - val_accuracy: 0.4286 - 220ms/epoch - 31ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1929 - accuracy: 0.4951 - val_loss: 1.1451 - val_accuracy: 0.4545 - 227ms/epoch - 32ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1916 - accuracy: 0.5213 - val_loss: 1.1872 - val_accuracy: 0.4805 - 219ms/epoch - 31ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1861 - accuracy: 0.5082 - val_loss: 1.1532 - val_accuracy: 0.4545 - 250ms/epoch - 36ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1639 - accuracy: 0.5344 - val_loss: 1.1388 - val_accuracy: 0.4675 - 259ms/epoch - 37ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1360 - accuracy: 0.5443 - val_loss: 1.1135 - val_accuracy: 0.5195 - 239ms/epoch - 34ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1533 - accuracy: 0.5148 - val_loss: 1.1002 - val_accuracy: 0.5195 - 256ms/epoch - 37ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1162 - accuracy: 0.5508 - val_loss: 1.0732 - val_accuracy: 0.4805 - 247ms/epoch - 35ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1030 - accuracy: 0.5672 - val_loss: 1.0894 - val_accuracy: 0.4675 - 244ms/epoch - 35ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.0807 - accuracy: 0.5738 - val_loss: 1.0629 - val_accuracy: 0.4805 - 260ms/epoch - 37ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0675 - accuracy: 0.5607 - val_loss: 1.0327 - val_accuracy: 0.4805 - 255ms/epoch - 36ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0659 - accuracy: 0.5705 - val_loss: 1.0116 - val_accuracy: 0.5325 - 239ms/epoch - 34ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0265 - accuracy: 0.5738 - val_loss: 1.0172 - val_accuracy: 0.4805 - 243ms/epoch - 35ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0372 - accuracy: 0.5672 - val_loss: 1.0021 - val_accuracy: 0.4935 - 251ms/epoch - 36ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0352 - accuracy: 0.5475 - val_loss: 0.9974 - val_accuracy: 0.5065 - 286ms/epoch - 41ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0870 - accuracy: 0.5738 - val_loss: 0.9817 - val_accuracy: 0.5325 - 262ms/epoch - 37ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0317 - accuracy: 0.5574 - val_loss: 0.9726 - val_accuracy: 0.5325 - 263ms/epoch - 38ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0063 - accuracy: 0.5902 - val_loss: 0.9527 - val_accuracy: 0.5455 - 256ms/epoch - 37ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0379 - accuracy: 0.5803 - val_loss: 0.9719 - val_accuracy: 0.5584 - 254ms/epoch - 36ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 0.9944 - accuracy: 0.5574 - val_loss: 0.9542 - val_accuracy: 0.5714 - 261ms/epoch - 37ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 0.9780 - accuracy: 0.5934 - val_loss: 0.9547 - val_accuracy: 0.5455 - 265ms/epoch - 38ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 0.9830 - accuracy: 0.6098 - val_loss: 0.9368 - val_accuracy: 0.6234 - 246ms/epoch - 35ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 0.9979 - accuracy: 0.6098 - val_loss: 0.9681 - val_accuracy: 0.6494 - 231ms/epoch - 33ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0055 - accuracy: 0.5967 - val_loss: 0.9445 - val_accuracy: 0.6104 - 229ms/epoch - 33ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 0.9696 - accuracy: 0.6033 - val_loss: 0.9388 - val_accuracy: 0.5455 - 222ms/epoch - 32ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 0.9687 - accuracy: 0.6131 - val_loss: 0.9188 - val_accuracy: 0.5584 - 232ms/epoch - 33ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 0.9943 - accuracy: 0.6131 - val_loss: 0.9211 - val_accuracy: 0.6494 - 221ms/epoch - 32ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 0.9784 - accuracy: 0.6164 - val_loss: 0.9282 - val_accuracy: 0.6494 - 228ms/epoch - 33ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9390 - accuracy: 0.5967 - val_loss: 0.9278 - val_accuracy: 0.6364 - 221ms/epoch - 32ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 0.9544 - accuracy: 0.6295 - val_loss: 0.9243 - val_accuracy: 0.5584 - 222ms/epoch - 32ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9427 - accuracy: 0.6361 - val_loss: 0.9430 - val_accuracy: 0.5584 - 222ms/epoch - 32ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9039 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:36:02,904] Trial 30 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 135}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3857 - accuracy: 0.3049 - val_loss: 1.3847 - val_accuracy: 0.2727 - 4s/epoch - 443ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3842 - accuracy: 0.3311 - val_loss: 1.3816 - val_accuracy: 0.3506 - 222ms/epoch - 22ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3807 - accuracy: 0.3148 - val_loss: 1.3766 - val_accuracy: 0.3896 - 249ms/epoch - 25ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3729 - accuracy: 0.4131 - val_loss: 1.3662 - val_accuracy: 0.3766 - 230ms/epoch - 23ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3531 - accuracy: 0.4754 - val_loss: 1.3437 - val_accuracy: 0.3636 - 263ms/epoch - 26ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3117 - accuracy: 0.4623 - val_loss: 1.2982 - val_accuracy: 0.3766 - 238ms/epoch - 24ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2653 - accuracy: 0.4557 - val_loss: 1.2486 - val_accuracy: 0.3506 - 237ms/epoch - 24ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2373 - accuracy: 0.4557 - val_loss: 1.2152 - val_accuracy: 0.3896 - 248ms/epoch - 25ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1893 - accuracy: 0.4787 - val_loss: 1.1864 - val_accuracy: 0.3766 - 242ms/epoch - 24ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1845 - accuracy: 0.4984 - val_loss: 1.1868 - val_accuracy: 0.3766 - 233ms/epoch - 23ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1723 - accuracy: 0.4787 - val_loss: 1.1831 - val_accuracy: 0.3896 - 249ms/epoch - 25ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1548 - accuracy: 0.4918 - val_loss: 1.1736 - val_accuracy: 0.3766 - 236ms/epoch - 24ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1482 - accuracy: 0.4754 - val_loss: 1.1543 - val_accuracy: 0.3766 - 245ms/epoch - 25ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1374 - accuracy: 0.4885 - val_loss: 1.1440 - val_accuracy: 0.4156 - 238ms/epoch - 24ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1017 - accuracy: 0.5148 - val_loss: 1.1284 - val_accuracy: 0.4416 - 235ms/epoch - 24ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1082 - accuracy: 0.5148 - val_loss: 1.1191 - val_accuracy: 0.4026 - 240ms/epoch - 24ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1103 - accuracy: 0.5311 - val_loss: 1.1058 - val_accuracy: 0.4545 - 238ms/epoch - 24ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1128 - accuracy: 0.5115 - val_loss: 1.1095 - val_accuracy: 0.4545 - 255ms/epoch - 25ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1057 - accuracy: 0.5377 - val_loss: 1.1203 - val_accuracy: 0.4416 - 262ms/epoch - 26ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1016 - accuracy: 0.5049 - val_loss: 1.0910 - val_accuracy: 0.5325 - 239ms/epoch - 24ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1000 - accuracy: 0.4984 - val_loss: 1.0891 - val_accuracy: 0.4675 - 239ms/epoch - 24ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0968 - accuracy: 0.5049 - val_loss: 1.0845 - val_accuracy: 0.4675 - 239ms/epoch - 24ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0812 - accuracy: 0.5410 - val_loss: 1.0863 - val_accuracy: 0.4545 - 239ms/epoch - 24ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0749 - accuracy: 0.5213 - val_loss: 1.0769 - val_accuracy: 0.4805 - 237ms/epoch - 24ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0660 - accuracy: 0.5574 - val_loss: 1.0899 - val_accuracy: 0.4805 - 247ms/epoch - 25ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0663 - accuracy: 0.5180 - val_loss: 1.0676 - val_accuracy: 0.4935 - 249ms/epoch - 25ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0543 - accuracy: 0.5607 - val_loss: 1.0716 - val_accuracy: 0.4675 - 273ms/epoch - 27ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0384 - accuracy: 0.5574 - val_loss: 1.0631 - val_accuracy: 0.4935 - 257ms/epoch - 26ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0555 - accuracy: 0.5475 - val_loss: 1.0535 - val_accuracy: 0.5065 - 258ms/epoch - 26ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0454 - accuracy: 0.5475 - val_loss: 1.0470 - val_accuracy: 0.4805 - 249ms/epoch - 25ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0309 - accuracy: 0.5639 - val_loss: 1.0377 - val_accuracy: 0.4935 - 263ms/epoch - 26ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0708 - accuracy: 0.5672 - val_loss: 1.0287 - val_accuracy: 0.4935 - 250ms/epoch - 25ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0296 - accuracy: 0.5672 - val_loss: 1.0313 - val_accuracy: 0.5065 - 245ms/epoch - 24ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0288 - accuracy: 0.5639 - val_loss: 1.0223 - val_accuracy: 0.4935 - 251ms/epoch - 25ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0104 - accuracy: 0.6066 - val_loss: 1.0139 - val_accuracy: 0.4935 - 260ms/epoch - 26ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0201 - accuracy: 0.5541 - val_loss: 0.9959 - val_accuracy: 0.5195 - 256ms/epoch - 26ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0181 - accuracy: 0.5574 - val_loss: 1.0112 - val_accuracy: 0.5195 - 252ms/epoch - 25ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0078 - accuracy: 0.5902 - val_loss: 1.0010 - val_accuracy: 0.5195 - 244ms/epoch - 24ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0107 - accuracy: 0.6066 - val_loss: 0.9991 - val_accuracy: 0.5065 - 266ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9849 - accuracy: 0.5672 - val_loss: 0.9818 - val_accuracy: 0.5325 - 230ms/epoch - 23ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9664 - accuracy: 0.5738 - val_loss: 0.9477 - val_accuracy: 0.5844 - 255ms/epoch - 25ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9784 - accuracy: 0.6000 - val_loss: 0.9611 - val_accuracy: 0.5455 - 242ms/epoch - 24ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9428 - accuracy: 0.6197 - val_loss: 0.9545 - val_accuracy: 0.5455 - 258ms/epoch - 26ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9413 - accuracy: 0.6197 - val_loss: 0.9378 - val_accuracy: 0.5714 - 233ms/epoch - 23ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9675 - accuracy: 0.5934 - val_loss: 0.9404 - val_accuracy: 0.5195 - 261ms/epoch - 26ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9820 - accuracy: 0.6033 - val_loss: 0.9430 - val_accuracy: 0.5325 - 240ms/epoch - 24ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9768 - accuracy: 0.5967 - val_loss: 0.9353 - val_accuracy: 0.6104 - 266ms/epoch - 27ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9597 - accuracy: 0.6131 - val_loss: 0.9278 - val_accuracy: 0.5584 - 237ms/epoch - 24ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9497 - accuracy: 0.6131 - val_loss: 0.9170 - val_accuracy: 0.6364 - 265ms/epoch - 26ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9396 - accuracy: 0.6525 - val_loss: 0.9172 - val_accuracy: 0.5584 - 242ms/epoch - 24ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9274 - accuracy: 0.6525 - val_loss: 0.9047 - val_accuracy: 0.6104 - 266ms/epoch - 27ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9458 - accuracy: 0.6295 - val_loss: 0.8885 - val_accuracy: 0.6364 - 262ms/epoch - 26ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9363 - accuracy: 0.6098 - val_loss: 0.9186 - val_accuracy: 0.6234 - 239ms/epoch - 24ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9054 - accuracy: 0.6230 - val_loss: 0.9065 - val_accuracy: 0.5584 - 244ms/epoch - 24ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9491 - accuracy: 0.6426 - val_loss: 0.9056 - val_accuracy: 0.5584 - 245ms/epoch - 24ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9156 - accuracy: 0.6295 - val_loss: 0.8864 - val_accuracy: 0.6234 - 237ms/epoch - 24ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9419 - accuracy: 0.6164 - val_loss: 0.9092 - val_accuracy: 0.6234 - 239ms/epoch - 24ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9360 - accuracy: 0.6230 - val_loss: 0.9113 - val_accuracy: 0.6234 - 239ms/epoch - 24ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9055 - accuracy: 0.6361 - val_loss: 0.9106 - val_accuracy: 0.6234 - 238ms/epoch - 24ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9163 - accuracy: 0.6492 - val_loss: 0.8895 - val_accuracy: 0.6234 - 242ms/epoch - 24ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9031 - accuracy: 0.6721 - val_loss: 0.9009 - val_accuracy: 0.6234 - 242ms/epoch - 24ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8582 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:36:23,694] Trial 31 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 139}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3858 - accuracy: 0.2951 - val_loss: 1.3844 - val_accuracy: 0.3377 - 4s/epoch - 421ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3836 - accuracy: 0.3475 - val_loss: 1.3792 - val_accuracy: 0.3636 - 264ms/epoch - 26ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3783 - accuracy: 0.3475 - val_loss: 1.3710 - val_accuracy: 0.3766 - 272ms/epoch - 27ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3651 - accuracy: 0.3902 - val_loss: 1.3530 - val_accuracy: 0.3117 - 268ms/epoch - 27ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3344 - accuracy: 0.4230 - val_loss: 1.3147 - val_accuracy: 0.3247 - 269ms/epoch - 27ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2820 - accuracy: 0.4492 - val_loss: 1.2679 - val_accuracy: 0.3506 - 267ms/epoch - 27ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2656 - accuracy: 0.4459 - val_loss: 1.2416 - val_accuracy: 0.3506 - 277ms/epoch - 28ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2177 - accuracy: 0.4656 - val_loss: 1.2034 - val_accuracy: 0.3896 - 282ms/epoch - 28ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2055 - accuracy: 0.4918 - val_loss: 1.1751 - val_accuracy: 0.3896 - 280ms/epoch - 28ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1771 - accuracy: 0.4951 - val_loss: 1.1877 - val_accuracy: 0.3766 - 282ms/epoch - 28ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1730 - accuracy: 0.4820 - val_loss: 1.1733 - val_accuracy: 0.3896 - 283ms/epoch - 28ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1389 - accuracy: 0.5049 - val_loss: 1.1883 - val_accuracy: 0.4026 - 278ms/epoch - 28ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1525 - accuracy: 0.5082 - val_loss: 1.1584 - val_accuracy: 0.3636 - 276ms/epoch - 28ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1438 - accuracy: 0.4885 - val_loss: 1.1483 - val_accuracy: 0.3896 - 268ms/epoch - 27ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1204 - accuracy: 0.5049 - val_loss: 1.1407 - val_accuracy: 0.3766 - 293ms/epoch - 29ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1163 - accuracy: 0.5246 - val_loss: 1.1253 - val_accuracy: 0.4026 - 268ms/epoch - 27ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1173 - accuracy: 0.5246 - val_loss: 1.1212 - val_accuracy: 0.3766 - 272ms/epoch - 27ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1249 - accuracy: 0.5180 - val_loss: 1.1096 - val_accuracy: 0.4156 - 272ms/epoch - 27ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1311 - accuracy: 0.4951 - val_loss: 1.1143 - val_accuracy: 0.4286 - 278ms/epoch - 28ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0827 - accuracy: 0.5213 - val_loss: 1.1052 - val_accuracy: 0.4416 - 272ms/epoch - 27ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0789 - accuracy: 0.5344 - val_loss: 1.0891 - val_accuracy: 0.4416 - 279ms/epoch - 28ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0920 - accuracy: 0.5410 - val_loss: 1.0731 - val_accuracy: 0.4675 - 269ms/epoch - 27ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0743 - accuracy: 0.5443 - val_loss: 1.0761 - val_accuracy: 0.4805 - 273ms/epoch - 27ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0663 - accuracy: 0.5541 - val_loss: 1.0733 - val_accuracy: 0.4675 - 274ms/epoch - 27ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0388 - accuracy: 0.5770 - val_loss: 1.0744 - val_accuracy: 0.4805 - 277ms/epoch - 28ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0857 - accuracy: 0.5672 - val_loss: 1.0458 - val_accuracy: 0.5195 - 270ms/epoch - 27ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0510 - accuracy: 0.5672 - val_loss: 1.0361 - val_accuracy: 0.4805 - 272ms/epoch - 27ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0646 - accuracy: 0.5541 - val_loss: 1.0277 - val_accuracy: 0.5065 - 275ms/epoch - 28ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0374 - accuracy: 0.5738 - val_loss: 1.0195 - val_accuracy: 0.4935 - 275ms/epoch - 27ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0069 - accuracy: 0.5705 - val_loss: 1.0066 - val_accuracy: 0.5325 - 276ms/epoch - 28ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0252 - accuracy: 0.5672 - val_loss: 0.9862 - val_accuracy: 0.5065 - 276ms/epoch - 28ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0118 - accuracy: 0.5738 - val_loss: 0.9820 - val_accuracy: 0.5325 - 283ms/epoch - 28ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0093 - accuracy: 0.5770 - val_loss: 0.9774 - val_accuracy: 0.5195 - 278ms/epoch - 28ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0190 - accuracy: 0.5902 - val_loss: 0.9666 - val_accuracy: 0.5455 - 271ms/epoch - 27ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9836 - accuracy: 0.5967 - val_loss: 0.9558 - val_accuracy: 0.5325 - 271ms/epoch - 27ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9773 - accuracy: 0.6000 - val_loss: 0.9315 - val_accuracy: 0.5974 - 270ms/epoch - 27ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9668 - accuracy: 0.6098 - val_loss: 0.9334 - val_accuracy: 0.5844 - 282ms/epoch - 28ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9546 - accuracy: 0.6000 - val_loss: 0.9320 - val_accuracy: 0.5455 - 272ms/epoch - 27ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9425 - accuracy: 0.6295 - val_loss: 0.9037 - val_accuracy: 0.5714 - 270ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9679 - accuracy: 0.5902 - val_loss: 0.8963 - val_accuracy: 0.5974 - 274ms/epoch - 27ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0121 - accuracy: 0.6131 - val_loss: 0.9038 - val_accuracy: 0.6234 - 275ms/epoch - 28ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9620 - accuracy: 0.6164 - val_loss: 0.9029 - val_accuracy: 0.5714 - 275ms/epoch - 27ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9384 - accuracy: 0.6426 - val_loss: 0.8985 - val_accuracy: 0.6364 - 279ms/epoch - 28ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9672 - accuracy: 0.6197 - val_loss: 0.8972 - val_accuracy: 0.5714 - 280ms/epoch - 28ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.8999 - accuracy: 0.6361 - val_loss: 0.8922 - val_accuracy: 0.6234 - 271ms/epoch - 27ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9333 - accuracy: 0.6262 - val_loss: 0.8916 - val_accuracy: 0.5974 - 284ms/epoch - 28ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9071 - accuracy: 0.6295 - val_loss: 0.8747 - val_accuracy: 0.6234 - 270ms/epoch - 27ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9445 - accuracy: 0.6230 - val_loss: 0.8970 - val_accuracy: 0.6364 - 278ms/epoch - 28ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9167 - accuracy: 0.6426 - val_loss: 0.8819 - val_accuracy: 0.5974 - 276ms/epoch - 28ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9190 - accuracy: 0.6557 - val_loss: 0.8901 - val_accuracy: 0.5974 - 276ms/epoch - 28ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9243 - accuracy: 0.6197 - val_loss: 0.8764 - val_accuracy: 0.6364 - 276ms/epoch - 28ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9745 - accuracy: 0.6393 - val_loss: 0.8653 - val_accuracy: 0.6234 - 272ms/epoch - 27ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.8994 - accuracy: 0.6262 - val_loss: 0.9256 - val_accuracy: 0.6104 - 273ms/epoch - 27ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9011 - accuracy: 0.6623 - val_loss: 0.8888 - val_accuracy: 0.5844 - 276ms/epoch - 28ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9011 - accuracy: 0.6262 - val_loss: 0.8844 - val_accuracy: 0.6234 - 277ms/epoch - 28ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9064 - accuracy: 0.6721 - val_loss: 0.8794 - val_accuracy: 0.6364 - 272ms/epoch - 27ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.8851 - accuracy: 0.6492 - val_loss: 0.8774 - val_accuracy: 0.6234 - 286ms/epoch - 29ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8990 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:36:45,074] Trial 32 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 146}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3859 - accuracy: 0.3082 - val_loss: 1.3850 - val_accuracy: 0.3636 - 4s/epoch - 424ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3847 - accuracy: 0.3443 - val_loss: 1.3825 - val_accuracy: 0.3377 - 253ms/epoch - 25ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3819 - accuracy: 0.3475 - val_loss: 1.3789 - val_accuracy: 0.3506 - 282ms/epoch - 28ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3751 - accuracy: 0.4295 - val_loss: 1.3705 - val_accuracy: 0.3766 - 271ms/epoch - 27ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3623 - accuracy: 0.4820 - val_loss: 1.3515 - val_accuracy: 0.3766 - 277ms/epoch - 28ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3274 - accuracy: 0.4721 - val_loss: 1.3177 - val_accuracy: 0.3636 - 278ms/epoch - 28ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2959 - accuracy: 0.4361 - val_loss: 1.2653 - val_accuracy: 0.3636 - 279ms/epoch - 28ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2711 - accuracy: 0.4557 - val_loss: 1.2388 - val_accuracy: 0.3506 - 304ms/epoch - 30ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2435 - accuracy: 0.4459 - val_loss: 1.2242 - val_accuracy: 0.3636 - 265ms/epoch - 27ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.2124 - accuracy: 0.5049 - val_loss: 1.2069 - val_accuracy: 0.3766 - 275ms/epoch - 27ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1757 - accuracy: 0.5049 - val_loss: 1.1790 - val_accuracy: 0.3766 - 283ms/epoch - 28ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1642 - accuracy: 0.4852 - val_loss: 1.1698 - val_accuracy: 0.3766 - 279ms/epoch - 28ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1531 - accuracy: 0.4918 - val_loss: 1.1493 - val_accuracy: 0.4026 - 279ms/epoch - 28ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1534 - accuracy: 0.5148 - val_loss: 1.1377 - val_accuracy: 0.4026 - 285ms/epoch - 28ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1342 - accuracy: 0.5082 - val_loss: 1.1288 - val_accuracy: 0.4026 - 282ms/epoch - 28ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1224 - accuracy: 0.5180 - val_loss: 1.1190 - val_accuracy: 0.4286 - 266ms/epoch - 27ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0993 - accuracy: 0.5246 - val_loss: 1.1144 - val_accuracy: 0.4156 - 265ms/epoch - 26ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1214 - accuracy: 0.5049 - val_loss: 1.1018 - val_accuracy: 0.4286 - 279ms/epoch - 28ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1141 - accuracy: 0.5213 - val_loss: 1.1168 - val_accuracy: 0.4286 - 275ms/epoch - 28ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1111 - accuracy: 0.5246 - val_loss: 1.0981 - val_accuracy: 0.5195 - 281ms/epoch - 28ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0645 - accuracy: 0.5672 - val_loss: 1.0852 - val_accuracy: 0.4675 - 275ms/epoch - 27ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0708 - accuracy: 0.5541 - val_loss: 1.0635 - val_accuracy: 0.4805 - 276ms/epoch - 28ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1209 - accuracy: 0.5311 - val_loss: 1.0635 - val_accuracy: 0.4935 - 284ms/epoch - 28ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0741 - accuracy: 0.5311 - val_loss: 1.0628 - val_accuracy: 0.4675 - 271ms/epoch - 27ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0808 - accuracy: 0.5016 - val_loss: 1.0706 - val_accuracy: 0.4805 - 277ms/epoch - 28ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0697 - accuracy: 0.5475 - val_loss: 1.0435 - val_accuracy: 0.5325 - 278ms/epoch - 28ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0765 - accuracy: 0.5705 - val_loss: 1.0298 - val_accuracy: 0.4935 - 271ms/epoch - 27ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0816 - accuracy: 0.5607 - val_loss: 1.0303 - val_accuracy: 0.4935 - 273ms/epoch - 27ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0411 - accuracy: 0.5607 - val_loss: 1.0234 - val_accuracy: 0.5065 - 281ms/epoch - 28ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0112 - accuracy: 0.5475 - val_loss: 1.0184 - val_accuracy: 0.5195 - 278ms/epoch - 28ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0480 - accuracy: 0.5574 - val_loss: 1.0038 - val_accuracy: 0.5065 - 277ms/epoch - 28ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0540 - accuracy: 0.5770 - val_loss: 1.0058 - val_accuracy: 0.5325 - 287ms/epoch - 29ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0337 - accuracy: 0.5902 - val_loss: 0.9971 - val_accuracy: 0.5065 - 283ms/epoch - 28ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9805 - accuracy: 0.5836 - val_loss: 1.0012 - val_accuracy: 0.5455 - 271ms/epoch - 27ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0026 - accuracy: 0.5607 - val_loss: 0.9615 - val_accuracy: 0.5455 - 281ms/epoch - 28ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9925 - accuracy: 0.5803 - val_loss: 0.9454 - val_accuracy: 0.5584 - 283ms/epoch - 28ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9953 - accuracy: 0.5672 - val_loss: 0.9380 - val_accuracy: 0.5584 - 272ms/epoch - 27ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9884 - accuracy: 0.5934 - val_loss: 0.9257 - val_accuracy: 0.5584 - 278ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9417 - accuracy: 0.6197 - val_loss: 0.9108 - val_accuracy: 0.5584 - 270ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9713 - accuracy: 0.6000 - val_loss: 0.9014 - val_accuracy: 0.5584 - 276ms/epoch - 28ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9941 - accuracy: 0.6197 - val_loss: 0.9174 - val_accuracy: 0.5974 - 284ms/epoch - 28ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9812 - accuracy: 0.6197 - val_loss: 0.8943 - val_accuracy: 0.6104 - 282ms/epoch - 28ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9526 - accuracy: 0.6000 - val_loss: 0.8956 - val_accuracy: 0.6364 - 275ms/epoch - 28ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9748 - accuracy: 0.6262 - val_loss: 0.8869 - val_accuracy: 0.6234 - 286ms/epoch - 29ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9375 - accuracy: 0.6197 - val_loss: 0.8959 - val_accuracy: 0.6104 - 299ms/epoch - 30ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9297 - accuracy: 0.6197 - val_loss: 0.8949 - val_accuracy: 0.5584 - 280ms/epoch - 28ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9103 - accuracy: 0.6361 - val_loss: 0.8728 - val_accuracy: 0.6364 - 290ms/epoch - 29ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9941 - accuracy: 0.6033 - val_loss: 0.8879 - val_accuracy: 0.6104 - 289ms/epoch - 29ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9585 - accuracy: 0.5803 - val_loss: 0.8900 - val_accuracy: 0.5844 - 283ms/epoch - 28ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9314 - accuracy: 0.6361 - val_loss: 0.8853 - val_accuracy: 0.6364 - 282ms/epoch - 28ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9646 - accuracy: 0.6033 - val_loss: 0.8793 - val_accuracy: 0.6364 - 284ms/epoch - 28ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9483 - accuracy: 0.6295 - val_loss: 0.8650 - val_accuracy: 0.6234 - 273ms/epoch - 27ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9078 - accuracy: 0.6295 - val_loss: 0.8997 - val_accuracy: 0.6234 - 275ms/epoch - 28ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9143 - accuracy: 0.6230 - val_loss: 0.8707 - val_accuracy: 0.6234 - 280ms/epoch - 28ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9108 - accuracy: 0.6262 - val_loss: 0.8636 - val_accuracy: 0.6494 - 271ms/epoch - 27ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9201 - accuracy: 0.6459 - val_loss: 0.8908 - val_accuracy: 0.6234 - 276ms/epoch - 28ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9554 - accuracy: 0.6393 - val_loss: 0.8748 - val_accuracy: 0.6234 - 272ms/epoch - 27ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9363 - accuracy: 0.6623 - val_loss: 0.8743 - val_accuracy: 0.6234 - 277ms/epoch - 28ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9297 - accuracy: 0.6492 - val_loss: 0.8719 - val_accuracy: 0.6364 - 276ms/epoch - 28ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9169 - accuracy: 0.6426 - val_loss: 0.8618 - val_accuracy: 0.6364 - 283ms/epoch - 28ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.8945 - accuracy: 0.6557 - val_loss: 0.8547 - val_accuracy: 0.6494 - 284ms/epoch - 28ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9102 - accuracy: 0.6754 - val_loss: 0.8803 - val_accuracy: 0.6234 - 277ms/epoch - 28ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.8834 - accuracy: 0.6459 - val_loss: 0.8725 - val_accuracy: 0.6494 - 276ms/epoch - 28ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.8833 - accuracy: 0.6656 - val_loss: 0.8715 - val_accuracy: 0.6104 - 289ms/epoch - 29ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9491 - accuracy: 0.6328 - val_loss: 0.8615 - val_accuracy: 0.6364 - 286ms/epoch - 29ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.8618 - accuracy: 0.6918 - val_loss: 0.8761 - val_accuracy: 0.6234 - 280ms/epoch - 28ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8871 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:37:08,967] Trial 33 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 153}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3854 - accuracy: 0.2689 - val_loss: 1.3825 - val_accuracy: 0.2597 - 4s/epoch - 413ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3817 - accuracy: 0.3213 - val_loss: 1.3750 - val_accuracy: 0.3506 - 217ms/epoch - 22ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3717 - accuracy: 0.3869 - val_loss: 1.3607 - val_accuracy: 0.3766 - 234ms/epoch - 23ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3438 - accuracy: 0.4557 - val_loss: 1.3276 - val_accuracy: 0.3636 - 228ms/epoch - 23ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2800 - accuracy: 0.4689 - val_loss: 1.2705 - val_accuracy: 0.3636 - 218ms/epoch - 22ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1980 - accuracy: 0.4590 - val_loss: 1.2228 - val_accuracy: 0.3896 - 218ms/epoch - 22ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1899 - accuracy: 0.4820 - val_loss: 1.1924 - val_accuracy: 0.3636 - 220ms/epoch - 22ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1800 - accuracy: 0.4754 - val_loss: 1.1814 - val_accuracy: 0.4026 - 228ms/epoch - 23ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1686 - accuracy: 0.4885 - val_loss: 1.1619 - val_accuracy: 0.4026 - 227ms/epoch - 23ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1523 - accuracy: 0.5115 - val_loss: 1.1684 - val_accuracy: 0.3766 - 219ms/epoch - 22ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1459 - accuracy: 0.4885 - val_loss: 1.1680 - val_accuracy: 0.3766 - 220ms/epoch - 22ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1282 - accuracy: 0.4951 - val_loss: 1.1645 - val_accuracy: 0.4026 - 223ms/epoch - 22ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1481 - accuracy: 0.4984 - val_loss: 1.1556 - val_accuracy: 0.4026 - 222ms/epoch - 22ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1235 - accuracy: 0.5082 - val_loss: 1.1460 - val_accuracy: 0.4156 - 219ms/epoch - 22ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1207 - accuracy: 0.5344 - val_loss: 1.1360 - val_accuracy: 0.4545 - 224ms/epoch - 22ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1163 - accuracy: 0.5180 - val_loss: 1.1275 - val_accuracy: 0.4286 - 218ms/epoch - 22ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1130 - accuracy: 0.5311 - val_loss: 1.1265 - val_accuracy: 0.4545 - 228ms/epoch - 23ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1072 - accuracy: 0.5410 - val_loss: 1.1260 - val_accuracy: 0.4545 - 229ms/epoch - 23ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1110 - accuracy: 0.5279 - val_loss: 1.1337 - val_accuracy: 0.4545 - 226ms/epoch - 23ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0922 - accuracy: 0.5607 - val_loss: 1.1113 - val_accuracy: 0.4805 - 221ms/epoch - 22ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0747 - accuracy: 0.5541 - val_loss: 1.1032 - val_accuracy: 0.4545 - 238ms/epoch - 24ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0957 - accuracy: 0.5443 - val_loss: 1.0911 - val_accuracy: 0.4545 - 240ms/epoch - 24ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0761 - accuracy: 0.5508 - val_loss: 1.0962 - val_accuracy: 0.4416 - 236ms/epoch - 24ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0717 - accuracy: 0.5475 - val_loss: 1.0932 - val_accuracy: 0.4545 - 234ms/epoch - 23ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0586 - accuracy: 0.5639 - val_loss: 1.0902 - val_accuracy: 0.4805 - 237ms/epoch - 24ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0557 - accuracy: 0.5541 - val_loss: 1.0625 - val_accuracy: 0.5455 - 233ms/epoch - 23ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0615 - accuracy: 0.5672 - val_loss: 1.0764 - val_accuracy: 0.4416 - 243ms/epoch - 24ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0524 - accuracy: 0.5607 - val_loss: 1.0712 - val_accuracy: 0.4675 - 231ms/epoch - 23ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0468 - accuracy: 0.5639 - val_loss: 1.0666 - val_accuracy: 0.4675 - 219ms/epoch - 22ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0413 - accuracy: 0.5803 - val_loss: 1.0474 - val_accuracy: 0.4675 - 237ms/epoch - 24ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0251 - accuracy: 0.5672 - val_loss: 1.0393 - val_accuracy: 0.4545 - 221ms/epoch - 22ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0260 - accuracy: 0.5639 - val_loss: 1.0308 - val_accuracy: 0.4675 - 222ms/epoch - 22ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0097 - accuracy: 0.6033 - val_loss: 1.0389 - val_accuracy: 0.4805 - 223ms/epoch - 22ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0009 - accuracy: 0.5574 - val_loss: 1.0277 - val_accuracy: 0.5065 - 222ms/epoch - 22ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9912 - accuracy: 0.5902 - val_loss: 0.9971 - val_accuracy: 0.5325 - 227ms/epoch - 23ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9671 - accuracy: 0.5869 - val_loss: 0.9676 - val_accuracy: 0.5844 - 219ms/epoch - 22ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9904 - accuracy: 0.6393 - val_loss: 0.9784 - val_accuracy: 0.5714 - 238ms/epoch - 24ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9780 - accuracy: 0.6197 - val_loss: 0.9763 - val_accuracy: 0.5195 - 235ms/epoch - 23ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9269 - accuracy: 0.6426 - val_loss: 0.9475 - val_accuracy: 0.5714 - 237ms/epoch - 24ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9520 - accuracy: 0.6131 - val_loss: 0.9451 - val_accuracy: 0.5974 - 235ms/epoch - 24ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9581 - accuracy: 0.6131 - val_loss: 0.9295 - val_accuracy: 0.6234 - 223ms/epoch - 22ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9444 - accuracy: 0.6000 - val_loss: 0.9239 - val_accuracy: 0.5584 - 234ms/epoch - 23ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9036 - accuracy: 0.6426 - val_loss: 0.9281 - val_accuracy: 0.6104 - 232ms/epoch - 23ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9122 - accuracy: 0.6459 - val_loss: 0.8924 - val_accuracy: 0.5844 - 235ms/epoch - 23ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9427 - accuracy: 0.6328 - val_loss: 0.9032 - val_accuracy: 0.6364 - 231ms/epoch - 23ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9341 - accuracy: 0.6393 - val_loss: 0.9094 - val_accuracy: 0.5974 - 226ms/epoch - 23ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8804 - accuracy: 0.6328 - val_loss: 0.8955 - val_accuracy: 0.5844 - 228ms/epoch - 23ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9374 - accuracy: 0.6361 - val_loss: 0.9035 - val_accuracy: 0.6234 - 230ms/epoch - 23ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9287 - accuracy: 0.6590 - val_loss: 0.8862 - val_accuracy: 0.6234 - 224ms/epoch - 22ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.8800 - accuracy: 0.6689 - val_loss: 0.9213 - val_accuracy: 0.6104 - 239ms/epoch - 24ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.8993 - accuracy: 0.6492 - val_loss: 0.8685 - val_accuracy: 0.6364 - 221ms/epoch - 22ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9176 - accuracy: 0.6426 - val_loss: 0.8852 - val_accuracy: 0.6104 - 247ms/epoch - 25ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.8965 - accuracy: 0.6492 - val_loss: 0.9416 - val_accuracy: 0.6104 - 227ms/epoch - 23ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9077 - accuracy: 0.6393 - val_loss: 0.8825 - val_accuracy: 0.6234 - 229ms/epoch - 23ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.8924 - accuracy: 0.6656 - val_loss: 0.8858 - val_accuracy: 0.6234 - 236ms/epoch - 24ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.8967 - accuracy: 0.6557 - val_loss: 0.8948 - val_accuracy: 0.6104 - 238ms/epoch - 24ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8152 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:37:27,468] Trial 34 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 137}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 6s - loss: 1.3862 - accuracy: 0.2557 - val_loss: 1.3858 - val_accuracy: 0.2597 - 6s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3856 - accuracy: 0.3049 - val_loss: 1.3849 - val_accuracy: 0.2727 - 308ms/epoch - 62ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3848 - accuracy: 0.3213 - val_loss: 1.3837 - val_accuracy: 0.3506 - 340ms/epoch - 68ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3838 - accuracy: 0.3574 - val_loss: 1.3820 - val_accuracy: 0.3506 - 333ms/epoch - 67ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3819 - accuracy: 0.3803 - val_loss: 1.3795 - val_accuracy: 0.3117 - 359ms/epoch - 72ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3785 - accuracy: 0.3803 - val_loss: 1.3754 - val_accuracy: 0.3117 - 332ms/epoch - 66ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3728 - accuracy: 0.3803 - val_loss: 1.3689 - val_accuracy: 0.3117 - 317ms/epoch - 63ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.3608 - accuracy: 0.3869 - val_loss: 1.3588 - val_accuracy: 0.2987 - 321ms/epoch - 64ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.3432 - accuracy: 0.3803 - val_loss: 1.3441 - val_accuracy: 0.3117 - 317ms/epoch - 63ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.3154 - accuracy: 0.3836 - val_loss: 1.3310 - val_accuracy: 0.3117 - 313ms/epoch - 63ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.2988 - accuracy: 0.4033 - val_loss: 1.3120 - val_accuracy: 0.3766 - 322ms/epoch - 64ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.2756 - accuracy: 0.4525 - val_loss: 1.2945 - val_accuracy: 0.3506 - 316ms/epoch - 63ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.2596 - accuracy: 0.4492 - val_loss: 1.2860 - val_accuracy: 0.3506 - 324ms/epoch - 65ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.2354 - accuracy: 0.4525 - val_loss: 1.2764 - val_accuracy: 0.3636 - 321ms/epoch - 64ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.2210 - accuracy: 0.4459 - val_loss: 1.2532 - val_accuracy: 0.3766 - 316ms/epoch - 63ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.2028 - accuracy: 0.4852 - val_loss: 1.2294 - val_accuracy: 0.3896 - 328ms/epoch - 66ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1833 - accuracy: 0.4820 - val_loss: 1.2106 - val_accuracy: 0.3766 - 311ms/epoch - 62ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1838 - accuracy: 0.4820 - val_loss: 1.1947 - val_accuracy: 0.3766 - 324ms/epoch - 65ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1694 - accuracy: 0.4721 - val_loss: 1.1864 - val_accuracy: 0.3766 - 320ms/epoch - 64ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1451 - accuracy: 0.4951 - val_loss: 1.1799 - val_accuracy: 0.3896 - 313ms/epoch - 63ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1360 - accuracy: 0.4984 - val_loss: 1.1621 - val_accuracy: 0.3896 - 318ms/epoch - 64ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1347 - accuracy: 0.4787 - val_loss: 1.1514 - val_accuracy: 0.3766 - 317ms/epoch - 63ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1338 - accuracy: 0.4754 - val_loss: 1.1444 - val_accuracy: 0.3766 - 316ms/epoch - 63ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.1239 - accuracy: 0.4951 - val_loss: 1.1372 - val_accuracy: 0.3766 - 315ms/epoch - 63ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1260 - accuracy: 0.4918 - val_loss: 1.1432 - val_accuracy: 0.3766 - 315ms/epoch - 63ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.1096 - accuracy: 0.5082 - val_loss: 1.1342 - val_accuracy: 0.3896 - 314ms/epoch - 63ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.1167 - accuracy: 0.5082 - val_loss: 1.1310 - val_accuracy: 0.4026 - 323ms/epoch - 65ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.1052 - accuracy: 0.4984 - val_loss: 1.1293 - val_accuracy: 0.4026 - 318ms/epoch - 64ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.1006 - accuracy: 0.5049 - val_loss: 1.1349 - val_accuracy: 0.4286 - 323ms/epoch - 65ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.1106 - accuracy: 0.5082 - val_loss: 1.1345 - val_accuracy: 0.4545 - 316ms/epoch - 63ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0997 - accuracy: 0.5049 - val_loss: 1.1384 - val_accuracy: 0.4545 - 338ms/epoch - 68ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0979 - accuracy: 0.5279 - val_loss: 1.1334 - val_accuracy: 0.4416 - 322ms/epoch - 64ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.1024 - accuracy: 0.5180 - val_loss: 1.1412 - val_accuracy: 0.4286 - 317ms/epoch - 63ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0541 - accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:37:45,047] Trial 35 finished with value: 0.5882353186607361 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'tanh', 'activation_func_3': 'swish', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 147}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 5s - loss: 1.3848 - accuracy: 0.2852 - val_loss: 1.3815 - val_accuracy: 0.3377 - 5s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3806 - accuracy: 0.3377 - val_loss: 1.3758 - val_accuracy: 0.3636 - 207ms/epoch - 52ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3736 - accuracy: 0.3902 - val_loss: 1.3676 - val_accuracy: 0.3506 - 218ms/epoch - 54ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.3629 - accuracy: 0.3902 - val_loss: 1.3557 - val_accuracy: 0.3117 - 212ms/epoch - 53ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.3463 - accuracy: 0.3934 - val_loss: 1.3373 - val_accuracy: 0.3247 - 218ms/epoch - 55ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.3216 - accuracy: 0.4131 - val_loss: 1.3137 - val_accuracy: 0.3636 - 220ms/epoch - 55ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.2922 - accuracy: 0.4393 - val_loss: 1.2941 - val_accuracy: 0.3636 - 209ms/epoch - 52ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.2581 - accuracy: 0.4557 - val_loss: 1.2819 - val_accuracy: 0.3506 - 212ms/epoch - 53ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.2397 - accuracy: 0.4426 - val_loss: 1.2614 - val_accuracy: 0.3506 - 205ms/epoch - 51ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.1998 - accuracy: 0.4459 - val_loss: 1.2315 - val_accuracy: 0.3636 - 203ms/epoch - 51ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.1942 - accuracy: 0.4689 - val_loss: 1.2022 - val_accuracy: 0.3636 - 210ms/epoch - 52ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.1651 - accuracy: 0.4885 - val_loss: 1.1764 - val_accuracy: 0.3766 - 207ms/epoch - 52ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.1462 - accuracy: 0.5049 - val_loss: 1.1688 - val_accuracy: 0.4026 - 207ms/epoch - 52ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.1377 - accuracy: 0.5082 - val_loss: 1.1594 - val_accuracy: 0.3896 - 203ms/epoch - 51ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.1448 - accuracy: 0.5246 - val_loss: 1.1574 - val_accuracy: 0.3766 - 202ms/epoch - 51ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.1289 - accuracy: 0.5082 - val_loss: 1.1499 - val_accuracy: 0.3896 - 210ms/epoch - 53ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.1246 - accuracy: 0.5279 - val_loss: 1.1443 - val_accuracy: 0.3766 - 213ms/epoch - 53ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.1159 - accuracy: 0.4984 - val_loss: 1.1432 - val_accuracy: 0.4026 - 204ms/epoch - 51ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.1287 - accuracy: 0.5115 - val_loss: 1.1472 - val_accuracy: 0.3896 - 203ms/epoch - 51ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.1200 - accuracy: 0.5082 - val_loss: 1.1334 - val_accuracy: 0.4026 - 214ms/epoch - 54ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.1161 - accuracy: 0.5115 - val_loss: 1.1263 - val_accuracy: 0.4156 - 205ms/epoch - 51ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.1102 - accuracy: 0.5213 - val_loss: 1.1215 - val_accuracy: 0.3896 - 213ms/epoch - 53ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.0957 - accuracy: 0.5213 - val_loss: 1.1145 - val_accuracy: 0.4026 - 200ms/epoch - 50ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.0849 - accuracy: 0.5344 - val_loss: 1.1095 - val_accuracy: 0.3896 - 208ms/epoch - 52ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.0856 - accuracy: 0.5213 - val_loss: 1.1081 - val_accuracy: 0.4026 - 203ms/epoch - 51ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 1.0772 - accuracy: 0.5246 - val_loss: 1.0931 - val_accuracy: 0.4286 - 205ms/epoch - 51ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.0771 - accuracy: 0.5672 - val_loss: 1.0807 - val_accuracy: 0.5455 - 205ms/epoch - 51ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 1.0726 - accuracy: 0.5475 - val_loss: 1.0787 - val_accuracy: 0.4545 - 208ms/epoch - 52ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 1.0707 - accuracy: 0.5639 - val_loss: 1.0775 - val_accuracy: 0.4416 - 206ms/epoch - 52ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 1.0693 - accuracy: 0.5639 - val_loss: 1.0712 - val_accuracy: 0.4805 - 203ms/epoch - 51ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 1.0622 - accuracy: 0.5803 - val_loss: 1.0663 - val_accuracy: 0.4805 - 207ms/epoch - 52ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 1.0639 - accuracy: 0.5607 - val_loss: 1.0573 - val_accuracy: 0.4805 - 201ms/epoch - 50ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 1.0435 - accuracy: 0.5869 - val_loss: 1.0643 - val_accuracy: 0.4675 - 211ms/epoch - 53ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 1.0548 - accuracy: 0.5705 - val_loss: 1.0562 - val_accuracy: 0.4545 - 209ms/epoch - 52ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 1.0360 - accuracy: 0.5607 - val_loss: 1.0352 - val_accuracy: 0.4805 - 202ms/epoch - 51ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 1.0269 - accuracy: 0.5803 - val_loss: 1.0162 - val_accuracy: 0.4935 - 210ms/epoch - 53ms/step\n",
      "Epoch 37/10000\n",
      "4/4 - 0s - loss: 0.9997 - accuracy: 0.5967 - val_loss: 1.0073 - val_accuracy: 0.5065 - 201ms/epoch - 50ms/step\n",
      "Epoch 38/10000\n",
      "4/4 - 0s - loss: 1.0109 - accuracy: 0.5869 - val_loss: 1.0027 - val_accuracy: 0.5065 - 208ms/epoch - 52ms/step\n",
      "Epoch 39/10000\n",
      "4/4 - 0s - loss: 0.9994 - accuracy: 0.6066 - val_loss: 0.9950 - val_accuracy: 0.4805 - 209ms/epoch - 52ms/step\n",
      "Epoch 40/10000\n",
      "4/4 - 0s - loss: 1.0203 - accuracy: 0.5770 - val_loss: 0.9778 - val_accuracy: 0.5584 - 208ms/epoch - 52ms/step\n",
      "Epoch 41/10000\n",
      "4/4 - 0s - loss: 1.0182 - accuracy: 0.5967 - val_loss: 0.9703 - val_accuracy: 0.6104 - 208ms/epoch - 52ms/step\n",
      "Epoch 42/10000\n",
      "4/4 - 0s - loss: 0.9951 - accuracy: 0.5869 - val_loss: 0.9726 - val_accuracy: 0.5195 - 223ms/epoch - 56ms/step\n",
      "Epoch 43/10000\n",
      "4/4 - 0s - loss: 0.9835 - accuracy: 0.5934 - val_loss: 0.9842 - val_accuracy: 0.4935 - 236ms/epoch - 59ms/step\n",
      "Epoch 44/10000\n",
      "4/4 - 0s - loss: 1.0024 - accuracy: 0.6164 - val_loss: 0.9476 - val_accuracy: 0.5844 - 251ms/epoch - 63ms/step\n",
      "Epoch 45/10000\n",
      "4/4 - 0s - loss: 0.9829 - accuracy: 0.5869 - val_loss: 0.9291 - val_accuracy: 0.5974 - 244ms/epoch - 61ms/step\n",
      "Epoch 46/10000\n",
      "4/4 - 0s - loss: 0.9590 - accuracy: 0.6164 - val_loss: 0.9335 - val_accuracy: 0.5065 - 222ms/epoch - 55ms/step\n",
      "Epoch 47/10000\n",
      "4/4 - 0s - loss: 0.9925 - accuracy: 0.6098 - val_loss: 0.9485 - val_accuracy: 0.5325 - 211ms/epoch - 53ms/step\n",
      "Epoch 48/10000\n",
      "4/4 - 0s - loss: 0.9632 - accuracy: 0.6295 - val_loss: 0.9270 - val_accuracy: 0.6364 - 225ms/epoch - 56ms/step\n",
      "Epoch 49/10000\n",
      "4/4 - 0s - loss: 0.9552 - accuracy: 0.6459 - val_loss: 0.9040 - val_accuracy: 0.6104 - 226ms/epoch - 57ms/step\n",
      "Epoch 50/10000\n",
      "4/4 - 0s - loss: 0.9453 - accuracy: 0.6557 - val_loss: 0.9095 - val_accuracy: 0.5584 - 206ms/epoch - 52ms/step\n",
      "Epoch 51/10000\n",
      "4/4 - 0s - loss: 0.9348 - accuracy: 0.6426 - val_loss: 0.9046 - val_accuracy: 0.6104 - 224ms/epoch - 56ms/step\n",
      "Epoch 52/10000\n",
      "4/4 - 0s - loss: 0.9325 - accuracy: 0.6590 - val_loss: 0.8839 - val_accuracy: 0.5844 - 223ms/epoch - 56ms/step\n",
      "Epoch 53/10000\n",
      "4/4 - 0s - loss: 0.9885 - accuracy: 0.6131 - val_loss: 0.9055 - val_accuracy: 0.6104 - 218ms/epoch - 54ms/step\n",
      "Epoch 54/10000\n",
      "4/4 - 0s - loss: 0.9674 - accuracy: 0.6197 - val_loss: 0.9194 - val_accuracy: 0.6364 - 245ms/epoch - 61ms/step\n",
      "Epoch 55/10000\n",
      "4/4 - 0s - loss: 0.9149 - accuracy: 0.6426 - val_loss: 0.9137 - val_accuracy: 0.5584 - 223ms/epoch - 56ms/step\n",
      "Epoch 56/10000\n",
      "4/4 - 0s - loss: 0.9277 - accuracy: 0.6492 - val_loss: 0.9111 - val_accuracy: 0.5325 - 233ms/epoch - 58ms/step\n",
      "Epoch 57/10000\n",
      "4/4 - 0s - loss: 0.9198 - accuracy: 0.6557 - val_loss: 0.9015 - val_accuracy: 0.6234 - 214ms/epoch - 54ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9089 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:38:03,750] Trial 36 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'swish', 'activation_func_3': 'selu', 'batch_size': 80, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 128}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3857 - accuracy: 0.2787 - val_loss: 1.3839 - val_accuracy: 0.3117 - 5s/epoch - 479ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3834 - accuracy: 0.3705 - val_loss: 1.3799 - val_accuracy: 0.3377 - 383ms/epoch - 38ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3781 - accuracy: 0.3836 - val_loss: 1.3716 - val_accuracy: 0.3766 - 425ms/epoch - 43ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3648 - accuracy: 0.4361 - val_loss: 1.3536 - val_accuracy: 0.3636 - 401ms/epoch - 40ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3317 - accuracy: 0.4361 - val_loss: 1.3128 - val_accuracy: 0.3766 - 383ms/epoch - 38ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2777 - accuracy: 0.4623 - val_loss: 1.2560 - val_accuracy: 0.3506 - 379ms/epoch - 38ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2541 - accuracy: 0.4492 - val_loss: 1.2355 - val_accuracy: 0.3636 - 385ms/epoch - 39ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2279 - accuracy: 0.4525 - val_loss: 1.2037 - val_accuracy: 0.3896 - 386ms/epoch - 39ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2109 - accuracy: 0.4590 - val_loss: 1.1835 - val_accuracy: 0.4026 - 391ms/epoch - 39ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1724 - accuracy: 0.4918 - val_loss: 1.1736 - val_accuracy: 0.3636 - 391ms/epoch - 39ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1649 - accuracy: 0.4721 - val_loss: 1.1684 - val_accuracy: 0.3766 - 379ms/epoch - 38ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1358 - accuracy: 0.4984 - val_loss: 1.1527 - val_accuracy: 0.3896 - 352ms/epoch - 35ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1300 - accuracy: 0.4951 - val_loss: 1.1331 - val_accuracy: 0.4286 - 354ms/epoch - 35ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1175 - accuracy: 0.4984 - val_loss: 1.1205 - val_accuracy: 0.4416 - 347ms/epoch - 35ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1302 - accuracy: 0.5311 - val_loss: 1.1219 - val_accuracy: 0.4286 - 345ms/epoch - 34ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1218 - accuracy: 0.5180 - val_loss: 1.1051 - val_accuracy: 0.4675 - 346ms/epoch - 35ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1217 - accuracy: 0.5344 - val_loss: 1.0963 - val_accuracy: 0.4805 - 348ms/epoch - 35ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0878 - accuracy: 0.5148 - val_loss: 1.1035 - val_accuracy: 0.4545 - 347ms/epoch - 35ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1039 - accuracy: 0.5377 - val_loss: 1.1126 - val_accuracy: 0.4545 - 348ms/epoch - 35ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0799 - accuracy: 0.5443 - val_loss: 1.0883 - val_accuracy: 0.4935 - 349ms/epoch - 35ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0833 - accuracy: 0.5377 - val_loss: 1.0859 - val_accuracy: 0.4416 - 367ms/epoch - 37ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0824 - accuracy: 0.5344 - val_loss: 1.0756 - val_accuracy: 0.4805 - 347ms/epoch - 35ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0757 - accuracy: 0.5574 - val_loss: 1.0784 - val_accuracy: 0.4675 - 348ms/epoch - 35ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0355 - accuracy: 0.5607 - val_loss: 1.0747 - val_accuracy: 0.4675 - 350ms/epoch - 35ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0835 - accuracy: 0.5410 - val_loss: 1.0595 - val_accuracy: 0.4675 - 347ms/epoch - 35ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0475 - accuracy: 0.5607 - val_loss: 1.0400 - val_accuracy: 0.5325 - 352ms/epoch - 35ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0774 - accuracy: 0.5607 - val_loss: 1.0606 - val_accuracy: 0.4805 - 347ms/epoch - 35ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0555 - accuracy: 0.5475 - val_loss: 1.0347 - val_accuracy: 0.5195 - 355ms/epoch - 35ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0501 - accuracy: 0.5770 - val_loss: 1.0239 - val_accuracy: 0.4935 - 347ms/epoch - 35ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0478 - accuracy: 0.5639 - val_loss: 1.0183 - val_accuracy: 0.5065 - 352ms/epoch - 35ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0445 - accuracy: 0.5705 - val_loss: 1.0246 - val_accuracy: 0.4675 - 346ms/epoch - 35ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0178 - accuracy: 0.5869 - val_loss: 1.0228 - val_accuracy: 0.4935 - 348ms/epoch - 35ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0404 - accuracy: 0.5803 - val_loss: 1.0137 - val_accuracy: 0.5065 - 350ms/epoch - 35ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0124 - accuracy: 0.5738 - val_loss: 0.9966 - val_accuracy: 0.5325 - 351ms/epoch - 35ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0167 - accuracy: 0.6000 - val_loss: 0.9806 - val_accuracy: 0.5584 - 350ms/epoch - 35ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0146 - accuracy: 0.5672 - val_loss: 0.9573 - val_accuracy: 0.5455 - 351ms/epoch - 35ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0069 - accuracy: 0.5934 - val_loss: 0.9632 - val_accuracy: 0.5844 - 375ms/epoch - 37ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9808 - accuracy: 0.6000 - val_loss: 0.9533 - val_accuracy: 0.5195 - 371ms/epoch - 37ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0006 - accuracy: 0.6000 - val_loss: 0.9423 - val_accuracy: 0.5065 - 375ms/epoch - 38ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9879 - accuracy: 0.6164 - val_loss: 0.9319 - val_accuracy: 0.5714 - 367ms/epoch - 37ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9910 - accuracy: 0.5934 - val_loss: 0.9111 - val_accuracy: 0.5844 - 371ms/epoch - 37ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9691 - accuracy: 0.6000 - val_loss: 0.9134 - val_accuracy: 0.5974 - 356ms/epoch - 36ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9633 - accuracy: 0.5967 - val_loss: 0.9120 - val_accuracy: 0.5844 - 353ms/epoch - 35ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9683 - accuracy: 0.6295 - val_loss: 0.9023 - val_accuracy: 0.5974 - 348ms/epoch - 35ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9505 - accuracy: 0.6131 - val_loss: 0.9117 - val_accuracy: 0.5974 - 374ms/epoch - 37ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9490 - accuracy: 0.6361 - val_loss: 0.9156 - val_accuracy: 0.5455 - 355ms/epoch - 35ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9119 - accuracy: 0.6262 - val_loss: 0.8922 - val_accuracy: 0.5844 - 352ms/epoch - 35ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9647 - accuracy: 0.6295 - val_loss: 0.9150 - val_accuracy: 0.5974 - 351ms/epoch - 35ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.8903 - accuracy: 0.6557 - val_loss: 0.8732 - val_accuracy: 0.6234 - 349ms/epoch - 35ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9291 - accuracy: 0.6262 - val_loss: 0.9062 - val_accuracy: 0.5844 - 352ms/epoch - 35ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9423 - accuracy: 0.6197 - val_loss: 0.8871 - val_accuracy: 0.6234 - 349ms/epoch - 35ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9307 - accuracy: 0.6262 - val_loss: 0.8834 - val_accuracy: 0.5974 - 380ms/epoch - 38ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9028 - accuracy: 0.6459 - val_loss: 0.9303 - val_accuracy: 0.5584 - 369ms/epoch - 37ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9123 - accuracy: 0.6328 - val_loss: 0.9051 - val_accuracy: 0.6364 - 362ms/epoch - 36ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8900 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:38:29,516] Trial 37 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 178}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 5s - loss: 1.3833 - accuracy: 0.2623 - val_loss: 1.3811 - val_accuracy: 0.2987 - 5s/epoch - 921ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3741 - accuracy: 0.3705 - val_loss: 1.3714 - val_accuracy: 0.4545 - 200ms/epoch - 40ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3585 - accuracy: 0.4295 - val_loss: 1.3539 - val_accuracy: 0.3766 - 219ms/epoch - 44ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3292 - accuracy: 0.4787 - val_loss: 1.3222 - val_accuracy: 0.4156 - 218ms/epoch - 44ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.2858 - accuracy: 0.4852 - val_loss: 1.2744 - val_accuracy: 0.4416 - 222ms/epoch - 44ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.2303 - accuracy: 0.5148 - val_loss: 1.2425 - val_accuracy: 0.4026 - 228ms/epoch - 46ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.2342 - accuracy: 0.4754 - val_loss: 1.2114 - val_accuracy: 0.3766 - 225ms/epoch - 45ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.1893 - accuracy: 0.5049 - val_loss: 1.1950 - val_accuracy: 0.3506 - 224ms/epoch - 45ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.1799 - accuracy: 0.4820 - val_loss: 1.1830 - val_accuracy: 0.4156 - 220ms/epoch - 44ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.1708 - accuracy: 0.4951 - val_loss: 1.1705 - val_accuracy: 0.4156 - 219ms/epoch - 44ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1487 - accuracy: 0.5115 - val_loss: 1.1635 - val_accuracy: 0.3896 - 220ms/epoch - 44ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1380 - accuracy: 0.5213 - val_loss: 1.1611 - val_accuracy: 0.3896 - 219ms/epoch - 44ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1380 - accuracy: 0.5148 - val_loss: 1.1596 - val_accuracy: 0.4026 - 216ms/epoch - 43ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1061 - accuracy: 0.5148 - val_loss: 1.1357 - val_accuracy: 0.3896 - 219ms/epoch - 44ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1058 - accuracy: 0.5213 - val_loss: 1.1128 - val_accuracy: 0.4286 - 231ms/epoch - 46ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.0781 - accuracy: 0.5672 - val_loss: 1.0931 - val_accuracy: 0.4675 - 232ms/epoch - 46ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.0750 - accuracy: 0.5574 - val_loss: 1.0711 - val_accuracy: 0.4935 - 236ms/epoch - 47ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.0738 - accuracy: 0.5607 - val_loss: 1.0662 - val_accuracy: 0.4675 - 236ms/epoch - 47ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.0830 - accuracy: 0.5344 - val_loss: 1.0640 - val_accuracy: 0.4545 - 241ms/epoch - 48ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.0334 - accuracy: 0.5475 - val_loss: 1.0443 - val_accuracy: 0.4675 - 234ms/epoch - 47ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.0500 - accuracy: 0.5738 - val_loss: 1.0259 - val_accuracy: 0.5065 - 237ms/epoch - 47ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.0439 - accuracy: 0.5705 - val_loss: 1.0097 - val_accuracy: 0.5065 - 235ms/epoch - 47ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.0167 - accuracy: 0.5836 - val_loss: 1.0159 - val_accuracy: 0.4935 - 236ms/epoch - 47ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 0.9830 - accuracy: 0.5803 - val_loss: 0.9894 - val_accuracy: 0.5065 - 226ms/epoch - 45ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 0.9873 - accuracy: 0.5934 - val_loss: 0.9640 - val_accuracy: 0.5714 - 216ms/epoch - 43ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 0.9721 - accuracy: 0.6164 - val_loss: 0.9389 - val_accuracy: 0.6234 - 218ms/epoch - 44ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 0.9426 - accuracy: 0.6426 - val_loss: 0.9324 - val_accuracy: 0.5714 - 222ms/epoch - 44ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 0.9709 - accuracy: 0.6230 - val_loss: 0.9429 - val_accuracy: 0.5714 - 222ms/epoch - 44ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 0.9592 - accuracy: 0.6131 - val_loss: 0.9355 - val_accuracy: 0.5584 - 216ms/epoch - 43ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 0.9326 - accuracy: 0.6098 - val_loss: 0.8996 - val_accuracy: 0.5974 - 227ms/epoch - 45ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 0.8895 - accuracy: 0.6426 - val_loss: 0.8891 - val_accuracy: 0.6494 - 236ms/epoch - 47ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 0.9061 - accuracy: 0.6164 - val_loss: 0.9082 - val_accuracy: 0.5974 - 230ms/epoch - 46ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 0.9237 - accuracy: 0.6295 - val_loss: 0.8819 - val_accuracy: 0.6104 - 222ms/epoch - 44ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 0.8822 - accuracy: 0.6393 - val_loss: 0.9106 - val_accuracy: 0.6364 - 221ms/epoch - 44ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 0.8637 - accuracy: 0.6361 - val_loss: 0.8573 - val_accuracy: 0.6364 - 237ms/epoch - 47ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 0.8610 - accuracy: 0.6623 - val_loss: 0.8740 - val_accuracy: 0.6494 - 230ms/epoch - 46ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.8591 - accuracy: 0.6426 - val_loss: 0.9187 - val_accuracy: 0.6623 - 222ms/epoch - 44ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.8622 - accuracy: 0.6590 - val_loss: 0.8814 - val_accuracy: 0.6364 - 222ms/epoch - 44ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.8688 - accuracy: 0.6721 - val_loss: 0.8800 - val_accuracy: 0.6623 - 226ms/epoch - 45ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.8574 - accuracy: 0.6525 - val_loss: 0.9201 - val_accuracy: 0.6104 - 225ms/epoch - 45ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8470 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:38:44,726] Trial 38 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'selu', 'activation_func_3': 'linear', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 133}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3857 - accuracy: 0.2951 - val_loss: 1.3834 - val_accuracy: 0.3117 - 5s/epoch - 496ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3827 - accuracy: 0.3639 - val_loss: 1.3776 - val_accuracy: 0.3117 - 300ms/epoch - 30ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3742 - accuracy: 0.3836 - val_loss: 1.3667 - val_accuracy: 0.3766 - 320ms/epoch - 32ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3524 - accuracy: 0.4426 - val_loss: 1.3406 - val_accuracy: 0.3766 - 313ms/epoch - 31ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3024 - accuracy: 0.4492 - val_loss: 1.2953 - val_accuracy: 0.3506 - 315ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2489 - accuracy: 0.4492 - val_loss: 1.2574 - val_accuracy: 0.3506 - 318ms/epoch - 32ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2204 - accuracy: 0.4525 - val_loss: 1.2097 - val_accuracy: 0.3636 - 320ms/epoch - 32ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2097 - accuracy: 0.4689 - val_loss: 1.1880 - val_accuracy: 0.4026 - 316ms/epoch - 32ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1968 - accuracy: 0.4918 - val_loss: 1.1664 - val_accuracy: 0.4026 - 314ms/epoch - 31ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1584 - accuracy: 0.4984 - val_loss: 1.1675 - val_accuracy: 0.3896 - 320ms/epoch - 32ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1507 - accuracy: 0.4721 - val_loss: 1.1570 - val_accuracy: 0.3896 - 317ms/epoch - 32ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1300 - accuracy: 0.4885 - val_loss: 1.1630 - val_accuracy: 0.3896 - 320ms/epoch - 32ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1340 - accuracy: 0.4951 - val_loss: 1.1398 - val_accuracy: 0.3766 - 352ms/epoch - 35ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1142 - accuracy: 0.5082 - val_loss: 1.1265 - val_accuracy: 0.3896 - 369ms/epoch - 37ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1217 - accuracy: 0.5115 - val_loss: 1.1160 - val_accuracy: 0.4026 - 341ms/epoch - 34ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1057 - accuracy: 0.5049 - val_loss: 1.1057 - val_accuracy: 0.4156 - 351ms/epoch - 35ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1167 - accuracy: 0.5049 - val_loss: 1.1133 - val_accuracy: 0.4156 - 333ms/epoch - 33ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1181 - accuracy: 0.5180 - val_loss: 1.1037 - val_accuracy: 0.3896 - 328ms/epoch - 33ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1093 - accuracy: 0.5115 - val_loss: 1.1150 - val_accuracy: 0.4026 - 341ms/epoch - 34ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1064 - accuracy: 0.5148 - val_loss: 1.0957 - val_accuracy: 0.4545 - 315ms/epoch - 32ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0882 - accuracy: 0.5279 - val_loss: 1.0815 - val_accuracy: 0.4416 - 313ms/epoch - 31ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0886 - accuracy: 0.5475 - val_loss: 1.0690 - val_accuracy: 0.4805 - 309ms/epoch - 31ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0831 - accuracy: 0.5574 - val_loss: 1.0720 - val_accuracy: 0.4805 - 316ms/epoch - 32ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0825 - accuracy: 0.5475 - val_loss: 1.0614 - val_accuracy: 0.4675 - 339ms/epoch - 34ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0466 - accuracy: 0.5508 - val_loss: 1.0649 - val_accuracy: 0.4805 - 356ms/epoch - 36ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0448 - accuracy: 0.5607 - val_loss: 1.0312 - val_accuracy: 0.4935 - 327ms/epoch - 33ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0480 - accuracy: 0.5639 - val_loss: 1.0278 - val_accuracy: 0.4675 - 335ms/epoch - 33ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0536 - accuracy: 0.5541 - val_loss: 1.0170 - val_accuracy: 0.4935 - 336ms/epoch - 34ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0132 - accuracy: 0.5410 - val_loss: 1.0089 - val_accuracy: 0.4935 - 331ms/epoch - 33ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0081 - accuracy: 0.5770 - val_loss: 0.9988 - val_accuracy: 0.5195 - 317ms/epoch - 32ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0103 - accuracy: 0.5770 - val_loss: 0.9862 - val_accuracy: 0.5325 - 335ms/epoch - 33ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9868 - accuracy: 0.6164 - val_loss: 0.9735 - val_accuracy: 0.5325 - 333ms/epoch - 33ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9817 - accuracy: 0.6098 - val_loss: 0.9586 - val_accuracy: 0.5584 - 334ms/epoch - 33ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9862 - accuracy: 0.5967 - val_loss: 0.9291 - val_accuracy: 0.5455 - 324ms/epoch - 32ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9773 - accuracy: 0.6000 - val_loss: 0.9245 - val_accuracy: 0.5584 - 334ms/epoch - 33ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0011 - accuracy: 0.5738 - val_loss: 0.9108 - val_accuracy: 0.6104 - 316ms/epoch - 32ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9403 - accuracy: 0.6098 - val_loss: 0.9139 - val_accuracy: 0.6104 - 318ms/epoch - 32ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9639 - accuracy: 0.5902 - val_loss: 0.9120 - val_accuracy: 0.5584 - 319ms/epoch - 32ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9408 - accuracy: 0.6131 - val_loss: 0.9114 - val_accuracy: 0.5584 - 331ms/epoch - 33ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9608 - accuracy: 0.6328 - val_loss: 0.9024 - val_accuracy: 0.5714 - 328ms/epoch - 33ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9512 - accuracy: 0.5967 - val_loss: 0.8904 - val_accuracy: 0.5974 - 322ms/epoch - 32ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9103 - accuracy: 0.6393 - val_loss: 0.8815 - val_accuracy: 0.5584 - 322ms/epoch - 32ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9316 - accuracy: 0.6066 - val_loss: 0.8830 - val_accuracy: 0.6364 - 320ms/epoch - 32ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9313 - accuracy: 0.6328 - val_loss: 0.8962 - val_accuracy: 0.5714 - 325ms/epoch - 32ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9453 - accuracy: 0.6197 - val_loss: 0.8798 - val_accuracy: 0.6364 - 315ms/epoch - 32ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9425 - accuracy: 0.6459 - val_loss: 0.8954 - val_accuracy: 0.5455 - 334ms/epoch - 33ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8905 - accuracy: 0.6459 - val_loss: 0.8702 - val_accuracy: 0.5974 - 338ms/epoch - 34ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9377 - accuracy: 0.6393 - val_loss: 0.8885 - val_accuracy: 0.6234 - 333ms/epoch - 33ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9235 - accuracy: 0.6197 - val_loss: 0.8782 - val_accuracy: 0.6364 - 338ms/epoch - 34ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9347 - accuracy: 0.6328 - val_loss: 0.8938 - val_accuracy: 0.5714 - 348ms/epoch - 35ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.8961 - accuracy: 0.6590 - val_loss: 0.8745 - val_accuracy: 0.6364 - 331ms/epoch - 33ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9133 - accuracy: 0.6492 - val_loss: 0.8680 - val_accuracy: 0.6234 - 333ms/epoch - 33ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.8863 - accuracy: 0.6525 - val_loss: 0.9068 - val_accuracy: 0.6234 - 332ms/epoch - 33ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.8859 - accuracy: 0.6656 - val_loss: 0.8580 - val_accuracy: 0.6234 - 336ms/epoch - 34ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9033 - accuracy: 0.6393 - val_loss: 0.8793 - val_accuracy: 0.5844 - 352ms/epoch - 35ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9344 - accuracy: 0.6393 - val_loss: 0.8760 - val_accuracy: 0.6234 - 335ms/epoch - 34ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9333 - accuracy: 0.6230 - val_loss: 0.8741 - val_accuracy: 0.6234 - 339ms/epoch - 34ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.8845 - accuracy: 0.6459 - val_loss: 0.8711 - val_accuracy: 0.6364 - 332ms/epoch - 33ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.8879 - accuracy: 0.6492 - val_loss: 0.8782 - val_accuracy: 0.6364 - 348ms/epoch - 35ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8551 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:39:10,459] Trial 39 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'tanh', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 157}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 5s - loss: 1.3861 - accuracy: 0.2852 - val_loss: 1.3857 - val_accuracy: 0.2597 - 5s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3857 - accuracy: 0.2689 - val_loss: 1.3850 - val_accuracy: 0.2597 - 218ms/epoch - 54ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3850 - accuracy: 0.2721 - val_loss: 1.3840 - val_accuracy: 0.2597 - 234ms/epoch - 59ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.3842 - accuracy: 0.2918 - val_loss: 1.3828 - val_accuracy: 0.3636 - 238ms/epoch - 59ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.3831 - accuracy: 0.3377 - val_loss: 1.3811 - val_accuracy: 0.3377 - 230ms/epoch - 57ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.3810 - accuracy: 0.3934 - val_loss: 1.3788 - val_accuracy: 0.3117 - 231ms/epoch - 58ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.3778 - accuracy: 0.3836 - val_loss: 1.3756 - val_accuracy: 0.3117 - 237ms/epoch - 59ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.3724 - accuracy: 0.3803 - val_loss: 1.3707 - val_accuracy: 0.3117 - 238ms/epoch - 59ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.3628 - accuracy: 0.3902 - val_loss: 1.3629 - val_accuracy: 0.3117 - 228ms/epoch - 57ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.3481 - accuracy: 0.3869 - val_loss: 1.3536 - val_accuracy: 0.3117 - 237ms/epoch - 59ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.3293 - accuracy: 0.4164 - val_loss: 1.3462 - val_accuracy: 0.3247 - 256ms/epoch - 64ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.3086 - accuracy: 0.4361 - val_loss: 1.3351 - val_accuracy: 0.3896 - 229ms/epoch - 57ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.2877 - accuracy: 0.4426 - val_loss: 1.3121 - val_accuracy: 0.3506 - 229ms/epoch - 57ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.2608 - accuracy: 0.4557 - val_loss: 1.2922 - val_accuracy: 0.3506 - 238ms/epoch - 59ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.2455 - accuracy: 0.4426 - val_loss: 1.2752 - val_accuracy: 0.3636 - 228ms/epoch - 57ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.2259 - accuracy: 0.4557 - val_loss: 1.2633 - val_accuracy: 0.3896 - 231ms/epoch - 58ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.2147 - accuracy: 0.4590 - val_loss: 1.2598 - val_accuracy: 0.3636 - 230ms/epoch - 58ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.2011 - accuracy: 0.4590 - val_loss: 1.2322 - val_accuracy: 0.3896 - 238ms/epoch - 59ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.2002 - accuracy: 0.4754 - val_loss: 1.2145 - val_accuracy: 0.3896 - 258ms/epoch - 64ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.1865 - accuracy: 0.4885 - val_loss: 1.2042 - val_accuracy: 0.4026 - 234ms/epoch - 58ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.1635 - accuracy: 0.5049 - val_loss: 1.2010 - val_accuracy: 0.4026 - 232ms/epoch - 58ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.1664 - accuracy: 0.4984 - val_loss: 1.1774 - val_accuracy: 0.4026 - 229ms/epoch - 57ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.1564 - accuracy: 0.5016 - val_loss: 1.1671 - val_accuracy: 0.3896 - 240ms/epoch - 60ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.1341 - accuracy: 0.4984 - val_loss: 1.1641 - val_accuracy: 0.4026 - 233ms/epoch - 58ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.1383 - accuracy: 0.4951 - val_loss: 1.1524 - val_accuracy: 0.3766 - 235ms/epoch - 59ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 1.1209 - accuracy: 0.5049 - val_loss: 1.1433 - val_accuracy: 0.3896 - 241ms/epoch - 60ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.1241 - accuracy: 0.5016 - val_loss: 1.1364 - val_accuracy: 0.3896 - 234ms/epoch - 58ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 1.1111 - accuracy: 0.5049 - val_loss: 1.1292 - val_accuracy: 0.3896 - 239ms/epoch - 60ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 1.0994 - accuracy: 0.4984 - val_loss: 1.1283 - val_accuracy: 0.3896 - 229ms/epoch - 57ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 1.1092 - accuracy: 0.4787 - val_loss: 1.1301 - val_accuracy: 0.4286 - 240ms/epoch - 60ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 1.1086 - accuracy: 0.5082 - val_loss: 1.1322 - val_accuracy: 0.4416 - 230ms/epoch - 58ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 1.0865 - accuracy: 0.5246 - val_loss: 1.1323 - val_accuracy: 0.4416 - 243ms/epoch - 61ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 1.1120 - accuracy: 0.5049 - val_loss: 1.1383 - val_accuracy: 0.4286 - 244ms/epoch - 61ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 1.0770 - accuracy: 0.5148 - val_loss: 1.1453 - val_accuracy: 0.4286 - 234ms/epoch - 58ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0564 - accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:39:24,196] Trial 40 finished with value: 0.5882353186607361 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'swish', 'batch_size': 80, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 150}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3855 - accuracy: 0.2984 - val_loss: 1.3840 - val_accuracy: 0.3766 - 5s/epoch - 652ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3831 - accuracy: 0.3902 - val_loss: 1.3811 - val_accuracy: 0.3247 - 318ms/epoch - 45ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3793 - accuracy: 0.3738 - val_loss: 1.3756 - val_accuracy: 0.3766 - 336ms/epoch - 48ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3699 - accuracy: 0.4033 - val_loss: 1.3651 - val_accuracy: 0.3506 - 334ms/epoch - 48ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3547 - accuracy: 0.4656 - val_loss: 1.3484 - val_accuracy: 0.3896 - 347ms/epoch - 50ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3169 - accuracy: 0.4656 - val_loss: 1.3120 - val_accuracy: 0.3766 - 348ms/epoch - 50ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2696 - accuracy: 0.4689 - val_loss: 1.3045 - val_accuracy: 0.3896 - 343ms/epoch - 49ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2877 - accuracy: 0.4656 - val_loss: 1.2919 - val_accuracy: 0.4026 - 333ms/epoch - 48ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2730 - accuracy: 0.4557 - val_loss: 1.2636 - val_accuracy: 0.3766 - 346ms/epoch - 49ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2577 - accuracy: 0.4721 - val_loss: 1.2553 - val_accuracy: 0.4286 - 333ms/epoch - 48ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2386 - accuracy: 0.4689 - val_loss: 1.2476 - val_accuracy: 0.3896 - 337ms/epoch - 48ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2267 - accuracy: 0.4852 - val_loss: 1.2402 - val_accuracy: 0.4545 - 335ms/epoch - 48ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2069 - accuracy: 0.5016 - val_loss: 1.2123 - val_accuracy: 0.4026 - 353ms/epoch - 50ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1706 - accuracy: 0.4984 - val_loss: 1.1933 - val_accuracy: 0.3636 - 356ms/epoch - 51ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.2230 - accuracy: 0.4426 - val_loss: 1.2301 - val_accuracy: 0.3377 - 349ms/epoch - 50ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1957 - accuracy: 0.5016 - val_loss: 1.2056 - val_accuracy: 0.3896 - 353ms/epoch - 50ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1957 - accuracy: 0.4754 - val_loss: 1.1952 - val_accuracy: 0.3896 - 353ms/epoch - 50ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1666 - accuracy: 0.4984 - val_loss: 1.1717 - val_accuracy: 0.4026 - 348ms/epoch - 50ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1783 - accuracy: 0.4918 - val_loss: 1.1674 - val_accuracy: 0.3636 - 359ms/epoch - 51ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1835 - accuracy: 0.4918 - val_loss: 1.1801 - val_accuracy: 0.4805 - 349ms/epoch - 50ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1928 - accuracy: 0.4820 - val_loss: 1.1629 - val_accuracy: 0.4026 - 362ms/epoch - 52ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1564 - accuracy: 0.4951 - val_loss: 1.1495 - val_accuracy: 0.3766 - 361ms/epoch - 52ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1507 - accuracy: 0.5016 - val_loss: 1.1466 - val_accuracy: 0.4026 - 348ms/epoch - 50ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1111 - accuracy: 0.5049 - val_loss: 1.1300 - val_accuracy: 0.4026 - 358ms/epoch - 51ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1593 - accuracy: 0.5180 - val_loss: 1.1271 - val_accuracy: 0.3896 - 348ms/epoch - 50ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1458 - accuracy: 0.5082 - val_loss: 1.1097 - val_accuracy: 0.4286 - 356ms/epoch - 51ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1119 - accuracy: 0.5082 - val_loss: 1.1184 - val_accuracy: 0.4286 - 355ms/epoch - 51ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1211 - accuracy: 0.5475 - val_loss: 1.1030 - val_accuracy: 0.4675 - 344ms/epoch - 49ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1455 - accuracy: 0.5016 - val_loss: 1.0841 - val_accuracy: 0.4935 - 331ms/epoch - 47ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0997 - accuracy: 0.5082 - val_loss: 1.1194 - val_accuracy: 0.4675 - 358ms/epoch - 51ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1198 - accuracy: 0.5279 - val_loss: 1.0809 - val_accuracy: 0.4805 - 342ms/epoch - 49ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.1078 - accuracy: 0.5443 - val_loss: 1.0847 - val_accuracy: 0.4675 - 337ms/epoch - 48ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0873 - accuracy: 0.5344 - val_loss: 1.0795 - val_accuracy: 0.4675 - 333ms/epoch - 48ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0747 - accuracy: 0.5410 - val_loss: 1.0759 - val_accuracy: 0.4675 - 346ms/epoch - 49ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0815 - accuracy: 0.5574 - val_loss: 1.0587 - val_accuracy: 0.4675 - 366ms/epoch - 52ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0907 - accuracy: 0.5443 - val_loss: 1.0438 - val_accuracy: 0.5065 - 337ms/epoch - 48ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0515 - accuracy: 0.5311 - val_loss: 1.0587 - val_accuracy: 0.5584 - 353ms/epoch - 50ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.1028 - accuracy: 0.5443 - val_loss: 1.0429 - val_accuracy: 0.4675 - 364ms/epoch - 52ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0517 - accuracy: 0.5705 - val_loss: 1.0573 - val_accuracy: 0.4805 - 360ms/epoch - 51ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0599 - accuracy: 0.5639 - val_loss: 1.0417 - val_accuracy: 0.4805 - 363ms/epoch - 52ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0640 - accuracy: 0.5443 - val_loss: 1.0179 - val_accuracy: 0.5065 - 354ms/epoch - 51ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0482 - accuracy: 0.5344 - val_loss: 1.0450 - val_accuracy: 0.4935 - 376ms/epoch - 54ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 1.0689 - accuracy: 0.5672 - val_loss: 1.0085 - val_accuracy: 0.5714 - 346ms/epoch - 49ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0597 - accuracy: 0.5311 - val_loss: 1.0026 - val_accuracy: 0.5714 - 346ms/epoch - 49ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 1.0719 - accuracy: 0.5770 - val_loss: 1.0081 - val_accuracy: 0.5325 - 333ms/epoch - 48ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 1.0332 - accuracy: 0.5705 - val_loss: 1.0178 - val_accuracy: 0.5065 - 343ms/epoch - 49ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 1.0248 - accuracy: 0.5803 - val_loss: 1.0371 - val_accuracy: 0.4675 - 333ms/epoch - 48ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 1.0433 - accuracy: 0.5705 - val_loss: 1.0433 - val_accuracy: 0.4935 - 337ms/epoch - 48ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 1.0360 - accuracy: 0.5967 - val_loss: 1.0116 - val_accuracy: 0.4935 - 336ms/epoch - 48ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9998 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:39:47,175] Trial 41 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 165}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3855 - accuracy: 0.2590 - val_loss: 1.3844 - val_accuracy: 0.3247 - 4s/epoch - 581ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3825 - accuracy: 0.3803 - val_loss: 1.3811 - val_accuracy: 0.2987 - 293ms/epoch - 42ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3785 - accuracy: 0.4066 - val_loss: 1.3755 - val_accuracy: 0.3636 - 305ms/epoch - 44ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3685 - accuracy: 0.4623 - val_loss: 1.3642 - val_accuracy: 0.3896 - 302ms/epoch - 43ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3546 - accuracy: 0.4066 - val_loss: 1.3500 - val_accuracy: 0.3636 - 315ms/epoch - 45ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3276 - accuracy: 0.4623 - val_loss: 1.3231 - val_accuracy: 0.3636 - 317ms/epoch - 45ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.3018 - accuracy: 0.4557 - val_loss: 1.2945 - val_accuracy: 0.3506 - 311ms/epoch - 44ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2864 - accuracy: 0.4820 - val_loss: 1.2888 - val_accuracy: 0.3896 - 301ms/epoch - 43ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2614 - accuracy: 0.4557 - val_loss: 1.2613 - val_accuracy: 0.3636 - 306ms/epoch - 44ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2614 - accuracy: 0.4426 - val_loss: 1.2536 - val_accuracy: 0.4026 - 305ms/epoch - 44ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2233 - accuracy: 0.4689 - val_loss: 1.2534 - val_accuracy: 0.4156 - 305ms/epoch - 44ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2049 - accuracy: 0.5148 - val_loss: 1.2491 - val_accuracy: 0.4156 - 312ms/epoch - 45ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2302 - accuracy: 0.4754 - val_loss: 1.2058 - val_accuracy: 0.3766 - 303ms/epoch - 43ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.2172 - accuracy: 0.4557 - val_loss: 1.2148 - val_accuracy: 0.3766 - 304ms/epoch - 43ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.2006 - accuracy: 0.4885 - val_loss: 1.1980 - val_accuracy: 0.3766 - 321ms/epoch - 46ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1848 - accuracy: 0.5148 - val_loss: 1.2039 - val_accuracy: 0.4026 - 316ms/epoch - 45ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1843 - accuracy: 0.5246 - val_loss: 1.2038 - val_accuracy: 0.4286 - 309ms/epoch - 44ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1949 - accuracy: 0.5082 - val_loss: 1.1819 - val_accuracy: 0.3766 - 309ms/epoch - 44ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1526 - accuracy: 0.5148 - val_loss: 1.1800 - val_accuracy: 0.3896 - 305ms/epoch - 44ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1718 - accuracy: 0.4820 - val_loss: 1.1725 - val_accuracy: 0.4026 - 304ms/epoch - 43ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1784 - accuracy: 0.5049 - val_loss: 1.1516 - val_accuracy: 0.4286 - 313ms/epoch - 45ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1532 - accuracy: 0.5115 - val_loss: 1.1403 - val_accuracy: 0.4416 - 323ms/epoch - 46ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1726 - accuracy: 0.5574 - val_loss: 1.1438 - val_accuracy: 0.4026 - 322ms/epoch - 46ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1482 - accuracy: 0.5213 - val_loss: 1.1415 - val_accuracy: 0.3896 - 323ms/epoch - 46ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1383 - accuracy: 0.5049 - val_loss: 1.1195 - val_accuracy: 0.4416 - 335ms/epoch - 48ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0936 - accuracy: 0.5607 - val_loss: 1.1004 - val_accuracy: 0.5584 - 318ms/epoch - 45ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1266 - accuracy: 0.4918 - val_loss: 1.0915 - val_accuracy: 0.5325 - 313ms/epoch - 45ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1129 - accuracy: 0.5410 - val_loss: 1.0779 - val_accuracy: 0.5325 - 308ms/epoch - 44ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1174 - accuracy: 0.4951 - val_loss: 1.0732 - val_accuracy: 0.5195 - 308ms/epoch - 44ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1107 - accuracy: 0.5541 - val_loss: 1.1129 - val_accuracy: 0.4805 - 305ms/epoch - 44ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1424 - accuracy: 0.5246 - val_loss: 1.0806 - val_accuracy: 0.4935 - 304ms/epoch - 43ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0961 - accuracy: 0.5607 - val_loss: 1.0788 - val_accuracy: 0.4675 - 302ms/epoch - 43ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0789 - accuracy: 0.5344 - val_loss: 1.0779 - val_accuracy: 0.4805 - 309ms/epoch - 44ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0754 - accuracy: 0.5377 - val_loss: 1.0748 - val_accuracy: 0.4805 - 304ms/epoch - 43ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0453 - accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:40:03,240] Trial 42 finished with value: 0.5882353186607361 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 159}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3855 - accuracy: 0.2164 - val_loss: 1.3838 - val_accuracy: 0.2987 - 4s/epoch - 578ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3814 - accuracy: 0.3574 - val_loss: 1.3804 - val_accuracy: 0.2857 - 279ms/epoch - 40ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3784 - accuracy: 0.3705 - val_loss: 1.3741 - val_accuracy: 0.2727 - 310ms/epoch - 44ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3686 - accuracy: 0.3902 - val_loss: 1.3622 - val_accuracy: 0.3766 - 297ms/epoch - 42ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3423 - accuracy: 0.4492 - val_loss: 1.3426 - val_accuracy: 0.3896 - 301ms/epoch - 43ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3084 - accuracy: 0.3672 - val_loss: 1.3158 - val_accuracy: 0.3766 - 307ms/epoch - 44ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2638 - accuracy: 0.4623 - val_loss: 1.2789 - val_accuracy: 0.3636 - 292ms/epoch - 42ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2492 - accuracy: 0.4689 - val_loss: 1.2598 - val_accuracy: 0.4026 - 298ms/epoch - 43ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2524 - accuracy: 0.4557 - val_loss: 1.2347 - val_accuracy: 0.4156 - 298ms/epoch - 43ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2520 - accuracy: 0.4590 - val_loss: 1.2297 - val_accuracy: 0.3896 - 301ms/epoch - 43ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1854 - accuracy: 0.4820 - val_loss: 1.2234 - val_accuracy: 0.4156 - 305ms/epoch - 44ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2072 - accuracy: 0.5016 - val_loss: 1.2130 - val_accuracy: 0.3896 - 300ms/epoch - 43ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1688 - accuracy: 0.5049 - val_loss: 1.1906 - val_accuracy: 0.3636 - 300ms/epoch - 43ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.2000 - accuracy: 0.4852 - val_loss: 1.1824 - val_accuracy: 0.3766 - 300ms/epoch - 43ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1897 - accuracy: 0.4721 - val_loss: 1.1723 - val_accuracy: 0.4156 - 301ms/epoch - 43ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1900 - accuracy: 0.4721 - val_loss: 1.1711 - val_accuracy: 0.4286 - 308ms/epoch - 44ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.2129 - accuracy: 0.4754 - val_loss: 1.2000 - val_accuracy: 0.4026 - 307ms/epoch - 44ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1752 - accuracy: 0.5082 - val_loss: 1.1666 - val_accuracy: 0.4026 - 314ms/epoch - 45ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1467 - accuracy: 0.5016 - val_loss: 1.1791 - val_accuracy: 0.3636 - 296ms/epoch - 42ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1578 - accuracy: 0.4984 - val_loss: 1.1630 - val_accuracy: 0.4026 - 306ms/epoch - 44ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1588 - accuracy: 0.4918 - val_loss: 1.1457 - val_accuracy: 0.4156 - 303ms/epoch - 43ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1424 - accuracy: 0.5508 - val_loss: 1.1223 - val_accuracy: 0.4156 - 317ms/epoch - 45ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1484 - accuracy: 0.5049 - val_loss: 1.1110 - val_accuracy: 0.4545 - 322ms/epoch - 46ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1206 - accuracy: 0.5344 - val_loss: 1.1126 - val_accuracy: 0.4286 - 325ms/epoch - 46ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1352 - accuracy: 0.5148 - val_loss: 1.1031 - val_accuracy: 0.4675 - 311ms/epoch - 44ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0885 - accuracy: 0.5311 - val_loss: 1.0847 - val_accuracy: 0.4545 - 319ms/epoch - 46ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1096 - accuracy: 0.5377 - val_loss: 1.1085 - val_accuracy: 0.4545 - 312ms/epoch - 45ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0788 - accuracy: 0.5377 - val_loss: 1.0860 - val_accuracy: 0.4675 - 305ms/epoch - 44ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0719 - accuracy: 0.5410 - val_loss: 1.0875 - val_accuracy: 0.4675 - 303ms/epoch - 43ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1350 - accuracy: 0.5541 - val_loss: 1.0673 - val_accuracy: 0.4935 - 298ms/epoch - 43ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0889 - accuracy: 0.5508 - val_loss: 1.0658 - val_accuracy: 0.4935 - 297ms/epoch - 42ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0747 - accuracy: 0.5508 - val_loss: 1.0658 - val_accuracy: 0.4675 - 302ms/epoch - 43ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.1112 - accuracy: 0.5377 - val_loss: 1.0666 - val_accuracy: 0.4935 - 300ms/epoch - 43ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0764 - accuracy: 0.5377 - val_loss: 1.0677 - val_accuracy: 0.4675 - 296ms/epoch - 42ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0759 - accuracy: 0.5443 - val_loss: 1.0719 - val_accuracy: 0.4805 - 308ms/epoch - 44ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0688 - accuracy: 0.5738 - val_loss: 1.0283 - val_accuracy: 0.4935 - 305ms/epoch - 44ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0740 - accuracy: 0.5803 - val_loss: 1.0483 - val_accuracy: 0.5325 - 300ms/epoch - 43ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0744 - accuracy: 0.5836 - val_loss: 1.0388 - val_accuracy: 0.4935 - 308ms/epoch - 44ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0474 - accuracy: 0.5344 - val_loss: 1.0609 - val_accuracy: 0.4675 - 310ms/epoch - 44ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0436 - accuracy: 0.5607 - val_loss: 1.0301 - val_accuracy: 0.5195 - 305ms/epoch - 44ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0175 - accuracy: 0.5574 - val_loss: 0.9885 - val_accuracy: 0.5714 - 306ms/epoch - 44ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0459 - accuracy: 0.5508 - val_loss: 0.9848 - val_accuracy: 0.5974 - 312ms/epoch - 45ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 1.0441 - accuracy: 0.5672 - val_loss: 0.9763 - val_accuracy: 0.5455 - 322ms/epoch - 46ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0176 - accuracy: 0.5836 - val_loss: 0.9708 - val_accuracy: 0.5714 - 311ms/epoch - 44ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 1.0633 - accuracy: 0.5672 - val_loss: 1.0114 - val_accuracy: 0.5455 - 315ms/epoch - 45ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 1.0158 - accuracy: 0.5770 - val_loss: 1.0044 - val_accuracy: 0.5325 - 298ms/epoch - 43ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 1.0048 - accuracy: 0.5475 - val_loss: 0.9998 - val_accuracy: 0.4935 - 303ms/epoch - 43ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 1.0131 - accuracy: 0.5607 - val_loss: 1.0269 - val_accuracy: 0.4805 - 310ms/epoch - 44ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 1.0894 - accuracy: 0.5574 - val_loss: 0.9940 - val_accuracy: 0.5325 - 308ms/epoch - 44ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0169 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:40:23,728] Trial 43 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 170}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3832 - accuracy: 0.2557 - val_loss: 1.3784 - val_accuracy: 0.3636 - 4s/epoch - 576ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3743 - accuracy: 0.3738 - val_loss: 1.3650 - val_accuracy: 0.4286 - 225ms/epoch - 32ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3561 - accuracy: 0.4689 - val_loss: 1.3423 - val_accuracy: 0.3506 - 241ms/epoch - 34ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3205 - accuracy: 0.4787 - val_loss: 1.3034 - val_accuracy: 0.4286 - 240ms/epoch - 34ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2834 - accuracy: 0.4721 - val_loss: 1.2691 - val_accuracy: 0.4026 - 251ms/epoch - 36ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2637 - accuracy: 0.4852 - val_loss: 1.2539 - val_accuracy: 0.4026 - 258ms/epoch - 37ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2457 - accuracy: 0.4787 - val_loss: 1.2475 - val_accuracy: 0.4156 - 243ms/epoch - 35ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2524 - accuracy: 0.4721 - val_loss: 1.2405 - val_accuracy: 0.4545 - 252ms/epoch - 36ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2330 - accuracy: 0.4951 - val_loss: 1.2189 - val_accuracy: 0.4156 - 257ms/epoch - 37ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2040 - accuracy: 0.4984 - val_loss: 1.2059 - val_accuracy: 0.3896 - 257ms/epoch - 37ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1859 - accuracy: 0.5049 - val_loss: 1.1919 - val_accuracy: 0.4545 - 255ms/epoch - 36ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1806 - accuracy: 0.5148 - val_loss: 1.1805 - val_accuracy: 0.4026 - 254ms/epoch - 36ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1676 - accuracy: 0.5180 - val_loss: 1.1639 - val_accuracy: 0.3896 - 268ms/epoch - 38ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1501 - accuracy: 0.5344 - val_loss: 1.1619 - val_accuracy: 0.4286 - 248ms/epoch - 35ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1765 - accuracy: 0.5148 - val_loss: 1.1294 - val_accuracy: 0.4416 - 251ms/epoch - 36ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1472 - accuracy: 0.5180 - val_loss: 1.1221 - val_accuracy: 0.4286 - 245ms/epoch - 35ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1604 - accuracy: 0.5016 - val_loss: 1.1196 - val_accuracy: 0.4416 - 261ms/epoch - 37ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1269 - accuracy: 0.5213 - val_loss: 1.1272 - val_accuracy: 0.4545 - 242ms/epoch - 35ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1058 - accuracy: 0.5475 - val_loss: 1.1033 - val_accuracy: 0.4545 - 249ms/epoch - 36ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1114 - accuracy: 0.5377 - val_loss: 1.0889 - val_accuracy: 0.5325 - 244ms/epoch - 35ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.0996 - accuracy: 0.5738 - val_loss: 1.0754 - val_accuracy: 0.4545 - 248ms/epoch - 35ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.0875 - accuracy: 0.5377 - val_loss: 1.0730 - val_accuracy: 0.4805 - 243ms/epoch - 35ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.0993 - accuracy: 0.5475 - val_loss: 1.0686 - val_accuracy: 0.4805 - 240ms/epoch - 34ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.0813 - accuracy: 0.5443 - val_loss: 1.0741 - val_accuracy: 0.4675 - 242ms/epoch - 35ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0933 - accuracy: 0.5672 - val_loss: 1.0602 - val_accuracy: 0.4675 - 247ms/epoch - 35ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0587 - accuracy: 0.5738 - val_loss: 1.0342 - val_accuracy: 0.5325 - 243ms/epoch - 35ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0564 - accuracy: 0.5344 - val_loss: 1.0410 - val_accuracy: 0.4805 - 243ms/epoch - 35ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0693 - accuracy: 0.5574 - val_loss: 1.0276 - val_accuracy: 0.4675 - 245ms/epoch - 35ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0627 - accuracy: 0.5803 - val_loss: 1.0252 - val_accuracy: 0.5065 - 242ms/epoch - 35ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0498 - accuracy: 0.5705 - val_loss: 1.0692 - val_accuracy: 0.4805 - 246ms/epoch - 35ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0432 - accuracy: 0.5607 - val_loss: 1.0274 - val_accuracy: 0.4805 - 247ms/epoch - 35ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0240 - accuracy: 0.5803 - val_loss: 1.0169 - val_accuracy: 0.5065 - 242ms/epoch - 35ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0278 - accuracy: 0.5770 - val_loss: 1.0023 - val_accuracy: 0.5455 - 245ms/epoch - 35ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0301 - accuracy: 0.5836 - val_loss: 0.9840 - val_accuracy: 0.5325 - 247ms/epoch - 35ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0206 - accuracy: 0.6131 - val_loss: 0.9776 - val_accuracy: 0.5325 - 246ms/epoch - 35ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0182 - accuracy: 0.5836 - val_loss: 0.9631 - val_accuracy: 0.5844 - 240ms/epoch - 34ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 0.9824 - accuracy: 0.6000 - val_loss: 0.9646 - val_accuracy: 0.6104 - 246ms/epoch - 35ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0013 - accuracy: 0.5934 - val_loss: 0.9576 - val_accuracy: 0.5065 - 253ms/epoch - 36ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 0.9902 - accuracy: 0.5836 - val_loss: 0.9786 - val_accuracy: 0.5195 - 261ms/epoch - 37ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 0.9738 - accuracy: 0.6000 - val_loss: 0.9490 - val_accuracy: 0.5974 - 248ms/epoch - 35ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0241 - accuracy: 0.5607 - val_loss: 0.9451 - val_accuracy: 0.6364 - 245ms/epoch - 35ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 0.9705 - accuracy: 0.6295 - val_loss: 0.9077 - val_accuracy: 0.5974 - 253ms/epoch - 36ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9766 - accuracy: 0.6393 - val_loss: 0.9260 - val_accuracy: 0.5844 - 250ms/epoch - 36ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 0.9807 - accuracy: 0.6262 - val_loss: 0.9197 - val_accuracy: 0.5844 - 251ms/epoch - 36ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9633 - accuracy: 0.6131 - val_loss: 0.9432 - val_accuracy: 0.5714 - 243ms/epoch - 35ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9836 - accuracy: 0.6131 - val_loss: 0.9261 - val_accuracy: 0.5455 - 254ms/epoch - 36ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9559 - accuracy: 0.6000 - val_loss: 0.9239 - val_accuracy: 0.5974 - 271ms/epoch - 39ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9219 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:40:40,979] Trial 44 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'selu', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 144}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 5s - loss: 1.3857 - accuracy: 0.3082 - val_loss: 1.3847 - val_accuracy: 0.3636 - 5s/epoch - 963ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3838 - accuracy: 0.3607 - val_loss: 1.3822 - val_accuracy: 0.3766 - 332ms/epoch - 66ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3797 - accuracy: 0.4689 - val_loss: 1.3779 - val_accuracy: 0.3506 - 347ms/epoch - 69ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3742 - accuracy: 0.4525 - val_loss: 1.3709 - val_accuracy: 0.3766 - 340ms/epoch - 68ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3621 - accuracy: 0.4623 - val_loss: 1.3587 - val_accuracy: 0.4026 - 326ms/epoch - 65ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3391 - accuracy: 0.4852 - val_loss: 1.3396 - val_accuracy: 0.4416 - 323ms/epoch - 65ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3218 - accuracy: 0.4262 - val_loss: 1.3143 - val_accuracy: 0.4156 - 326ms/epoch - 65ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2720 - accuracy: 0.4656 - val_loss: 1.2830 - val_accuracy: 0.4286 - 327ms/epoch - 65ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2512 - accuracy: 0.4623 - val_loss: 1.2427 - val_accuracy: 0.3636 - 331ms/epoch - 66ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2397 - accuracy: 0.4590 - val_loss: 1.2314 - val_accuracy: 0.3636 - 321ms/epoch - 64ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1989 - accuracy: 0.5344 - val_loss: 1.2266 - val_accuracy: 0.3896 - 323ms/epoch - 65ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.2376 - accuracy: 0.5016 - val_loss: 1.2111 - val_accuracy: 0.3766 - 330ms/epoch - 66ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1959 - accuracy: 0.4918 - val_loss: 1.1963 - val_accuracy: 0.3766 - 321ms/epoch - 64ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1813 - accuracy: 0.5049 - val_loss: 1.1900 - val_accuracy: 0.3766 - 326ms/epoch - 65ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1947 - accuracy: 0.4951 - val_loss: 1.1813 - val_accuracy: 0.3896 - 324ms/epoch - 65ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1643 - accuracy: 0.5049 - val_loss: 1.1746 - val_accuracy: 0.3766 - 323ms/epoch - 65ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1786 - accuracy: 0.5148 - val_loss: 1.1585 - val_accuracy: 0.3896 - 321ms/epoch - 64ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1361 - accuracy: 0.4984 - val_loss: 1.1476 - val_accuracy: 0.4286 - 325ms/epoch - 65ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1643 - accuracy: 0.5016 - val_loss: 1.1478 - val_accuracy: 0.4156 - 335ms/epoch - 67ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1248 - accuracy: 0.5246 - val_loss: 1.1258 - val_accuracy: 0.4026 - 333ms/epoch - 67ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1087 - accuracy: 0.5180 - val_loss: 1.1309 - val_accuracy: 0.4416 - 325ms/epoch - 65ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1305 - accuracy: 0.5115 - val_loss: 1.1113 - val_accuracy: 0.4545 - 328ms/epoch - 66ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1347 - accuracy: 0.5377 - val_loss: 1.1091 - val_accuracy: 0.4935 - 324ms/epoch - 65ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.1168 - accuracy: 0.5344 - val_loss: 1.1038 - val_accuracy: 0.4935 - 321ms/epoch - 64ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.0983 - accuracy: 0.5311 - val_loss: 1.1051 - val_accuracy: 0.4805 - 344ms/epoch - 69ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.1109 - accuracy: 0.5246 - val_loss: 1.0799 - val_accuracy: 0.4805 - 327ms/epoch - 65ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0631 - accuracy: 0.5377 - val_loss: 1.0727 - val_accuracy: 0.5065 - 327ms/epoch - 65ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.1535 - accuracy: 0.5180 - val_loss: 1.0660 - val_accuracy: 0.4935 - 330ms/epoch - 66ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0915 - accuracy: 0.5443 - val_loss: 1.0642 - val_accuracy: 0.4805 - 320ms/epoch - 64ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0640 - accuracy: 0.5475 - val_loss: 1.0603 - val_accuracy: 0.4935 - 328ms/epoch - 66ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0717 - accuracy: 0.5180 - val_loss: 1.0475 - val_accuracy: 0.4935 - 326ms/epoch - 65ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0811 - accuracy: 0.5279 - val_loss: 1.0379 - val_accuracy: 0.4935 - 337ms/epoch - 67ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0817 - accuracy: 0.5410 - val_loss: 1.0317 - val_accuracy: 0.4805 - 326ms/epoch - 65ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0503 - accuracy: 0.5607 - val_loss: 1.0262 - val_accuracy: 0.5195 - 326ms/epoch - 65ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0596 - accuracy: 0.5475 - val_loss: 1.0185 - val_accuracy: 0.5195 - 325ms/epoch - 65ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0660 - accuracy: 0.5311 - val_loss: 1.0141 - val_accuracy: 0.5195 - 323ms/epoch - 65ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0222 - accuracy: 0.5836 - val_loss: 1.0109 - val_accuracy: 0.5195 - 326ms/epoch - 65ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0524 - accuracy: 0.5607 - val_loss: 0.9986 - val_accuracy: 0.5195 - 328ms/epoch - 66ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0236 - accuracy: 0.5639 - val_loss: 0.9947 - val_accuracy: 0.5195 - 333ms/epoch - 67ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0501 - accuracy: 0.5672 - val_loss: 0.9857 - val_accuracy: 0.5325 - 319ms/epoch - 64ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.9911 - accuracy: 0.5902 - val_loss: 0.9712 - val_accuracy: 0.5974 - 327ms/epoch - 65ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.9995 - accuracy: 0.6164 - val_loss: 0.9632 - val_accuracy: 0.5195 - 332ms/epoch - 66ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.9971 - accuracy: 0.5836 - val_loss: 0.9478 - val_accuracy: 0.5455 - 324ms/epoch - 65ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 1.0203 - accuracy: 0.5967 - val_loss: 0.9375 - val_accuracy: 0.5584 - 331ms/epoch - 66ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 1.0010 - accuracy: 0.6066 - val_loss: 0.9281 - val_accuracy: 0.5584 - 324ms/epoch - 65ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9997 - accuracy: 0.5967 - val_loss: 0.9271 - val_accuracy: 0.5584 - 325ms/epoch - 65ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9900 - accuracy: 0.6164 - val_loss: 0.9361 - val_accuracy: 0.5584 - 323ms/epoch - 65ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 1.0026 - accuracy: 0.5869 - val_loss: 0.9259 - val_accuracy: 0.5584 - 326ms/epoch - 65ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9920 - accuracy: 0.6131 - val_loss: 0.9296 - val_accuracy: 0.5455 - 344ms/epoch - 69ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.9700 - accuracy: 0.5770 - val_loss: 0.9221 - val_accuracy: 0.5455 - 371ms/epoch - 74ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.9437 - accuracy: 0.5902 - val_loss: 0.9080 - val_accuracy: 0.5584 - 351ms/epoch - 70ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.9799 - accuracy: 0.6197 - val_loss: 0.8994 - val_accuracy: 0.5455 - 346ms/epoch - 69ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 1.0012 - accuracy: 0.6197 - val_loss: 0.9104 - val_accuracy: 0.5455 - 341ms/epoch - 68ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9571 - accuracy: 0.6262 - val_loss: 0.8925 - val_accuracy: 0.6364 - 326ms/epoch - 65ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9758 - accuracy: 0.6295 - val_loss: 0.8865 - val_accuracy: 0.6104 - 330ms/epoch - 66ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9445 - accuracy: 0.6033 - val_loss: 0.8928 - val_accuracy: 0.5714 - 334ms/epoch - 67ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9298 - accuracy: 0.6328 - val_loss: 0.9020 - val_accuracy: 0.5455 - 320ms/epoch - 64ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.9644 - accuracy: 0.6230 - val_loss: 0.9009 - val_accuracy: 0.5714 - 330ms/epoch - 66ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.9140 - accuracy: 0.6525 - val_loss: 0.8801 - val_accuracy: 0.5584 - 326ms/epoch - 65ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.9724 - accuracy: 0.6262 - val_loss: 0.8943 - val_accuracy: 0.5584 - 328ms/epoch - 66ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.9305 - accuracy: 0.6131 - val_loss: 0.8680 - val_accuracy: 0.6494 - 325ms/epoch - 65ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.9287 - accuracy: 0.6393 - val_loss: 0.8776 - val_accuracy: 0.5455 - 334ms/epoch - 67ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.9575 - accuracy: 0.6197 - val_loss: 0.8992 - val_accuracy: 0.5714 - 332ms/epoch - 66ms/step\n",
      "Epoch 64/10000\n",
      "5/5 - 0s - loss: 0.9298 - accuracy: 0.6557 - val_loss: 0.8846 - val_accuracy: 0.6494 - 335ms/epoch - 67ms/step\n",
      "Epoch 65/10000\n",
      "5/5 - 0s - loss: 0.9340 - accuracy: 0.6230 - val_loss: 0.8857 - val_accuracy: 0.5844 - 335ms/epoch - 67ms/step\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 0.9326 - accuracy: 0.6393 - val_loss: 0.8889 - val_accuracy: 0.5844 - 334ms/epoch - 67ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8860 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:41:09,086] Trial 45 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 153}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 6s - loss: 1.3805 - accuracy: 0.2525 - val_loss: 1.3699 - val_accuracy: 0.4416 - 6s/epoch - 802ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3588 - accuracy: 0.4557 - val_loss: 1.3422 - val_accuracy: 0.3506 - 317ms/epoch - 45ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3263 - accuracy: 0.4459 - val_loss: 1.3022 - val_accuracy: 0.3506 - 338ms/epoch - 48ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.2668 - accuracy: 0.4689 - val_loss: 1.2561 - val_accuracy: 0.3636 - 334ms/epoch - 48ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2335 - accuracy: 0.4721 - val_loss: 1.2331 - val_accuracy: 0.3896 - 336ms/epoch - 48ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2060 - accuracy: 0.4820 - val_loss: 1.2065 - val_accuracy: 0.3766 - 342ms/epoch - 49ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.1661 - accuracy: 0.4852 - val_loss: 1.1831 - val_accuracy: 0.3766 - 336ms/epoch - 48ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.1989 - accuracy: 0.4984 - val_loss: 1.1720 - val_accuracy: 0.3636 - 340ms/epoch - 49ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.1761 - accuracy: 0.4918 - val_loss: 1.1825 - val_accuracy: 0.4026 - 356ms/epoch - 51ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.1668 - accuracy: 0.4918 - val_loss: 1.1552 - val_accuracy: 0.4026 - 358ms/epoch - 51ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1430 - accuracy: 0.5049 - val_loss: 1.1629 - val_accuracy: 0.4026 - 364ms/epoch - 52ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1280 - accuracy: 0.5180 - val_loss: 1.1715 - val_accuracy: 0.4156 - 368ms/epoch - 53ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1290 - accuracy: 0.5082 - val_loss: 1.1494 - val_accuracy: 0.4286 - 351ms/epoch - 50ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1130 - accuracy: 0.5279 - val_loss: 1.1354 - val_accuracy: 0.4156 - 351ms/epoch - 50ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1328 - accuracy: 0.5082 - val_loss: 1.1161 - val_accuracy: 0.4545 - 341ms/epoch - 49ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1447 - accuracy: 0.4885 - val_loss: 1.1253 - val_accuracy: 0.4545 - 339ms/epoch - 48ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1319 - accuracy: 0.5344 - val_loss: 1.1284 - val_accuracy: 0.4675 - 336ms/epoch - 48ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1205 - accuracy: 0.5410 - val_loss: 1.1253 - val_accuracy: 0.4286 - 341ms/epoch - 49ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1148 - accuracy: 0.5607 - val_loss: 1.1170 - val_accuracy: 0.4156 - 341ms/epoch - 49ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1068 - accuracy: 0.5344 - val_loss: 1.0933 - val_accuracy: 0.5195 - 352ms/epoch - 50ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1011 - accuracy: 0.5279 - val_loss: 1.0677 - val_accuracy: 0.4805 - 341ms/epoch - 49ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.0751 - accuracy: 0.5541 - val_loss: 1.0791 - val_accuracy: 0.4805 - 333ms/epoch - 48ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.0754 - accuracy: 0.5574 - val_loss: 1.0666 - val_accuracy: 0.4675 - 344ms/epoch - 49ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.0729 - accuracy: 0.5607 - val_loss: 1.0610 - val_accuracy: 0.4805 - 337ms/epoch - 48ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0660 - accuracy: 0.5639 - val_loss: 1.0492 - val_accuracy: 0.4675 - 338ms/epoch - 48ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0780 - accuracy: 0.5213 - val_loss: 1.0317 - val_accuracy: 0.5584 - 335ms/epoch - 48ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0812 - accuracy: 0.5443 - val_loss: 1.0700 - val_accuracy: 0.5065 - 347ms/epoch - 50ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0584 - accuracy: 0.5770 - val_loss: 1.0393 - val_accuracy: 0.4935 - 334ms/epoch - 48ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0437 - accuracy: 0.5607 - val_loss: 1.0285 - val_accuracy: 0.4805 - 336ms/epoch - 48ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0410 - accuracy: 0.5705 - val_loss: 1.0320 - val_accuracy: 0.4935 - 338ms/epoch - 48ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0257 - accuracy: 0.5574 - val_loss: 1.0067 - val_accuracy: 0.4935 - 341ms/epoch - 49ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0379 - accuracy: 0.5738 - val_loss: 1.0102 - val_accuracy: 0.5455 - 337ms/epoch - 48ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 0.9939 - accuracy: 0.5934 - val_loss: 0.9952 - val_accuracy: 0.5455 - 353ms/epoch - 50ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 0.9897 - accuracy: 0.6262 - val_loss: 0.9758 - val_accuracy: 0.5325 - 335ms/epoch - 48ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 0.9957 - accuracy: 0.5967 - val_loss: 0.9525 - val_accuracy: 0.5584 - 343ms/epoch - 49ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 0.9624 - accuracy: 0.6262 - val_loss: 0.9279 - val_accuracy: 0.5974 - 360ms/epoch - 51ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 0.9748 - accuracy: 0.6098 - val_loss: 0.9649 - val_accuracy: 0.5844 - 341ms/epoch - 49ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 0.9991 - accuracy: 0.5967 - val_loss: 0.9581 - val_accuracy: 0.5325 - 339ms/epoch - 48ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0066 - accuracy: 0.6131 - val_loss: 0.9447 - val_accuracy: 0.5065 - 344ms/epoch - 49ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 0.9760 - accuracy: 0.6164 - val_loss: 0.9321 - val_accuracy: 0.5714 - 336ms/epoch - 48ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 0.9472 - accuracy: 0.6328 - val_loss: 0.9091 - val_accuracy: 0.6234 - 342ms/epoch - 49ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 0.9923 - accuracy: 0.6197 - val_loss: 0.8952 - val_accuracy: 0.6234 - 333ms/epoch - 48ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9489 - accuracy: 0.6033 - val_loss: 0.9006 - val_accuracy: 0.5714 - 342ms/epoch - 49ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 0.9627 - accuracy: 0.6295 - val_loss: 0.8966 - val_accuracy: 0.6104 - 345ms/epoch - 49ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9943 - accuracy: 0.6033 - val_loss: 0.9145 - val_accuracy: 0.6234 - 335ms/epoch - 48ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9579 - accuracy: 0.6098 - val_loss: 0.9518 - val_accuracy: 0.5325 - 341ms/epoch - 49ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9596 - accuracy: 0.5967 - val_loss: 0.9350 - val_accuracy: 0.5195 - 335ms/epoch - 48ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9110 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:41:32,234] Trial 46 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'tanh', 'activation_func_3': 'selu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 162}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3861 - accuracy: 0.2623 - val_loss: 1.3846 - val_accuracy: 0.2597 - 4s/epoch - 447ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3849 - accuracy: 0.2984 - val_loss: 1.3812 - val_accuracy: 0.3377 - 292ms/epoch - 29ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3816 - accuracy: 0.2951 - val_loss: 1.3758 - val_accuracy: 0.3377 - 303ms/epoch - 30ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3749 - accuracy: 0.3803 - val_loss: 1.3656 - val_accuracy: 0.3117 - 311ms/epoch - 31ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3551 - accuracy: 0.3836 - val_loss: 1.3424 - val_accuracy: 0.2987 - 347ms/epoch - 35ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3145 - accuracy: 0.3934 - val_loss: 1.3031 - val_accuracy: 0.3117 - 319ms/epoch - 32ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2841 - accuracy: 0.4361 - val_loss: 1.2797 - val_accuracy: 0.3896 - 305ms/epoch - 31ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2374 - accuracy: 0.4557 - val_loss: 1.2448 - val_accuracy: 0.3636 - 312ms/epoch - 31ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2050 - accuracy: 0.4557 - val_loss: 1.2033 - val_accuracy: 0.3896 - 301ms/epoch - 30ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1733 - accuracy: 0.4852 - val_loss: 1.1883 - val_accuracy: 0.4026 - 307ms/epoch - 31ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1505 - accuracy: 0.4951 - val_loss: 1.1766 - val_accuracy: 0.3896 - 307ms/epoch - 31ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1588 - accuracy: 0.4984 - val_loss: 1.1800 - val_accuracy: 0.4026 - 305ms/epoch - 30ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1654 - accuracy: 0.4984 - val_loss: 1.1624 - val_accuracy: 0.3896 - 308ms/epoch - 31ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1546 - accuracy: 0.5016 - val_loss: 1.1622 - val_accuracy: 0.3896 - 310ms/epoch - 31ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1464 - accuracy: 0.4951 - val_loss: 1.1559 - val_accuracy: 0.3766 - 310ms/epoch - 31ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1352 - accuracy: 0.5082 - val_loss: 1.1431 - val_accuracy: 0.4026 - 313ms/epoch - 31ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1433 - accuracy: 0.5082 - val_loss: 1.1353 - val_accuracy: 0.3896 - 310ms/epoch - 31ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1346 - accuracy: 0.5213 - val_loss: 1.1309 - val_accuracy: 0.3766 - 314ms/epoch - 31ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1155 - accuracy: 0.4918 - val_loss: 1.1304 - val_accuracy: 0.4026 - 308ms/epoch - 31ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1158 - accuracy: 0.5180 - val_loss: 1.1239 - val_accuracy: 0.4026 - 315ms/epoch - 31ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1061 - accuracy: 0.5148 - val_loss: 1.1180 - val_accuracy: 0.3896 - 308ms/epoch - 31ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1104 - accuracy: 0.5148 - val_loss: 1.1141 - val_accuracy: 0.3896 - 326ms/epoch - 33ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1016 - accuracy: 0.5311 - val_loss: 1.1185 - val_accuracy: 0.4156 - 318ms/epoch - 32ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.1055 - accuracy: 0.5180 - val_loss: 1.1155 - val_accuracy: 0.4026 - 316ms/epoch - 32ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0949 - accuracy: 0.5279 - val_loss: 1.1105 - val_accuracy: 0.4156 - 307ms/epoch - 31ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0908 - accuracy: 0.5443 - val_loss: 1.0904 - val_accuracy: 0.5325 - 306ms/epoch - 31ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0953 - accuracy: 0.5475 - val_loss: 1.0939 - val_accuracy: 0.4805 - 354ms/epoch - 35ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0902 - accuracy: 0.5705 - val_loss: 1.0930 - val_accuracy: 0.4545 - 322ms/epoch - 32ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0851 - accuracy: 0.5344 - val_loss: 1.0971 - val_accuracy: 0.4805 - 328ms/epoch - 33ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0761 - accuracy: 0.5344 - val_loss: 1.0867 - val_accuracy: 0.4545 - 318ms/epoch - 32ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0796 - accuracy: 0.5443 - val_loss: 1.0879 - val_accuracy: 0.4416 - 312ms/epoch - 31ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0510 - accuracy: 0.5705 - val_loss: 1.0765 - val_accuracy: 0.4545 - 316ms/epoch - 32ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0726 - accuracy: 0.5508 - val_loss: 1.0890 - val_accuracy: 0.4675 - 319ms/epoch - 32ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0621 - accuracy: 0.5541 - val_loss: 1.0728 - val_accuracy: 0.4545 - 307ms/epoch - 31ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0557 - accuracy: 0.5574 - val_loss: 1.0682 - val_accuracy: 0.4805 - 322ms/epoch - 32ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0694 - accuracy: 0.5869 - val_loss: 1.0418 - val_accuracy: 0.5195 - 312ms/epoch - 31ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0341 - accuracy: 0.5902 - val_loss: 1.0516 - val_accuracy: 0.5065 - 325ms/epoch - 33ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0523 - accuracy: 0.5705 - val_loss: 1.0397 - val_accuracy: 0.5065 - 321ms/epoch - 32ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0261 - accuracy: 0.5672 - val_loss: 1.0344 - val_accuracy: 0.4675 - 311ms/epoch - 31ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0293 - accuracy: 0.5705 - val_loss: 1.0141 - val_accuracy: 0.5325 - 355ms/epoch - 36ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0536 - accuracy: 0.5475 - val_loss: 1.0105 - val_accuracy: 0.5844 - 316ms/epoch - 32ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9997 - accuracy: 0.6000 - val_loss: 1.0034 - val_accuracy: 0.5325 - 327ms/epoch - 33ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0247 - accuracy: 0.5967 - val_loss: 1.0116 - val_accuracy: 0.5195 - 321ms/epoch - 32ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0404 - accuracy: 0.5803 - val_loss: 0.9888 - val_accuracy: 0.5325 - 329ms/epoch - 33ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0129 - accuracy: 0.6033 - val_loss: 0.9843 - val_accuracy: 0.5455 - 317ms/epoch - 32ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 1.0282 - accuracy: 0.5836 - val_loss: 0.9855 - val_accuracy: 0.5065 - 361ms/epoch - 36ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 1.0030 - accuracy: 0.5869 - val_loss: 0.9843 - val_accuracy: 0.5195 - 367ms/epoch - 37ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9896 - accuracy: 0.6098 - val_loss: 0.9756 - val_accuracy: 0.5325 - 354ms/epoch - 35ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9840 - accuracy: 0.6262 - val_loss: 0.9579 - val_accuracy: 0.5974 - 323ms/epoch - 32ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9548 - accuracy: 0.6066 - val_loss: 0.9604 - val_accuracy: 0.5065 - 340ms/epoch - 34ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9934 - accuracy: 0.6230 - val_loss: 0.9342 - val_accuracy: 0.5584 - 339ms/epoch - 34ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9941 - accuracy: 0.5836 - val_loss: 0.9367 - val_accuracy: 0.5714 - 342ms/epoch - 34ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 1.0029 - accuracy: 0.6197 - val_loss: 0.9680 - val_accuracy: 0.5195 - 331ms/epoch - 33ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9960 - accuracy: 0.6033 - val_loss: 0.9520 - val_accuracy: 0.5844 - 321ms/epoch - 32ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9636 - accuracy: 0.6328 - val_loss: 0.9407 - val_accuracy: 0.5325 - 318ms/epoch - 32ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9491 - accuracy: 0.6295 - val_loss: 0.9240 - val_accuracy: 0.5974 - 314ms/epoch - 31ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9488 - accuracy: 0.6426 - val_loss: 0.9224 - val_accuracy: 0.5974 - 339ms/epoch - 34ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9493 - accuracy: 0.6262 - val_loss: 0.9260 - val_accuracy: 0.5714 - 320ms/epoch - 32ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9676 - accuracy: 0.6361 - val_loss: 0.9126 - val_accuracy: 0.6234 - 306ms/epoch - 31ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9582 - accuracy: 0.6131 - val_loss: 0.9160 - val_accuracy: 0.5714 - 307ms/epoch - 31ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9186 - accuracy: 0.6295 - val_loss: 0.8943 - val_accuracy: 0.6104 - 316ms/epoch - 32ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9515 - accuracy: 0.6426 - val_loss: 0.9045 - val_accuracy: 0.5844 - 330ms/epoch - 33ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9389 - accuracy: 0.6295 - val_loss: 0.8849 - val_accuracy: 0.6364 - 326ms/epoch - 33ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9337 - accuracy: 0.6426 - val_loss: 0.8945 - val_accuracy: 0.5844 - 318ms/epoch - 32ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9521 - accuracy: 0.6328 - val_loss: 0.8988 - val_accuracy: 0.5974 - 316ms/epoch - 32ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.8966 - accuracy: 0.6492 - val_loss: 0.8855 - val_accuracy: 0.6104 - 314ms/epoch - 31ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.9160 - accuracy: 0.6393 - val_loss: 0.8752 - val_accuracy: 0.6364 - 320ms/epoch - 32ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.9038 - accuracy: 0.6787 - val_loss: 0.8941 - val_accuracy: 0.5974 - 331ms/epoch - 33ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.9387 - accuracy: 0.6361 - val_loss: 0.8798 - val_accuracy: 0.6234 - 326ms/epoch - 33ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.9087 - accuracy: 0.6656 - val_loss: 0.8622 - val_accuracy: 0.6234 - 319ms/epoch - 32ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9194 - accuracy: 0.6590 - val_loss: 0.8719 - val_accuracy: 0.6234 - 317ms/epoch - 32ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.9186 - accuracy: 0.6230 - val_loss: 0.8947 - val_accuracy: 0.5974 - 306ms/epoch - 31ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.8889 - accuracy: 0.6492 - val_loss: 0.8848 - val_accuracy: 0.6234 - 308ms/epoch - 31ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.9417 - accuracy: 0.6656 - val_loss: 0.8796 - val_accuracy: 0.6234 - 333ms/epoch - 33ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.9127 - accuracy: 0.6525 - val_loss: 0.8919 - val_accuracy: 0.5974 - 317ms/epoch - 32ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8532 - accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:42:02,285] Trial 47 finished with value: 0.7058823704719543 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 155}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 6s - loss: 1.3860 - accuracy: 0.2590 - val_loss: 1.3839 - val_accuracy: 0.2597 - 6s/epoch - 578ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3850 - accuracy: 0.2689 - val_loss: 1.3810 - val_accuracy: 0.2597 - 336ms/epoch - 34ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3816 - accuracy: 0.2721 - val_loss: 1.3761 - val_accuracy: 0.3117 - 343ms/epoch - 34ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3769 - accuracy: 0.3639 - val_loss: 1.3686 - val_accuracy: 0.3377 - 294ms/epoch - 29ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3634 - accuracy: 0.4098 - val_loss: 1.3534 - val_accuracy: 0.3117 - 279ms/epoch - 28ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3286 - accuracy: 0.4262 - val_loss: 1.3256 - val_accuracy: 0.3766 - 276ms/epoch - 28ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2890 - accuracy: 0.4459 - val_loss: 1.2823 - val_accuracy: 0.3636 - 283ms/epoch - 28ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2310 - accuracy: 0.4525 - val_loss: 1.2408 - val_accuracy: 0.3896 - 287ms/epoch - 29ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1919 - accuracy: 0.4426 - val_loss: 1.2104 - val_accuracy: 0.3896 - 271ms/epoch - 27ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1786 - accuracy: 0.4918 - val_loss: 1.1922 - val_accuracy: 0.4026 - 277ms/epoch - 28ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1684 - accuracy: 0.4885 - val_loss: 1.1778 - val_accuracy: 0.3896 - 276ms/epoch - 28ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1393 - accuracy: 0.4918 - val_loss: 1.1881 - val_accuracy: 0.4026 - 281ms/epoch - 28ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1615 - accuracy: 0.4951 - val_loss: 1.1682 - val_accuracy: 0.3896 - 274ms/epoch - 27ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1444 - accuracy: 0.4787 - val_loss: 1.1601 - val_accuracy: 0.3896 - 275ms/epoch - 28ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1379 - accuracy: 0.4820 - val_loss: 1.1528 - val_accuracy: 0.3896 - 275ms/epoch - 27ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1329 - accuracy: 0.5180 - val_loss: 1.1422 - val_accuracy: 0.4026 - 279ms/epoch - 28ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1321 - accuracy: 0.5148 - val_loss: 1.1371 - val_accuracy: 0.4026 - 279ms/epoch - 28ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1123 - accuracy: 0.5115 - val_loss: 1.1313 - val_accuracy: 0.4026 - 283ms/epoch - 28ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1114 - accuracy: 0.5180 - val_loss: 1.1315 - val_accuracy: 0.4026 - 273ms/epoch - 27ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1015 - accuracy: 0.5279 - val_loss: 1.1220 - val_accuracy: 0.4026 - 274ms/epoch - 27ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1064 - accuracy: 0.5180 - val_loss: 1.1128 - val_accuracy: 0.3896 - 280ms/epoch - 28ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1127 - accuracy: 0.5377 - val_loss: 1.1114 - val_accuracy: 0.3896 - 282ms/epoch - 28ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0975 - accuracy: 0.5475 - val_loss: 1.1150 - val_accuracy: 0.4286 - 277ms/epoch - 28ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0973 - accuracy: 0.5246 - val_loss: 1.1091 - val_accuracy: 0.4156 - 283ms/epoch - 28ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0835 - accuracy: 0.5377 - val_loss: 1.1096 - val_accuracy: 0.4286 - 269ms/epoch - 27ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0834 - accuracy: 0.5311 - val_loss: 1.0889 - val_accuracy: 0.5195 - 273ms/epoch - 27ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0783 - accuracy: 0.5443 - val_loss: 1.1009 - val_accuracy: 0.4675 - 280ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0760 - accuracy: 0.5607 - val_loss: 1.0893 - val_accuracy: 0.4545 - 275ms/epoch - 27ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0782 - accuracy: 0.5475 - val_loss: 1.0876 - val_accuracy: 0.4545 - 275ms/epoch - 27ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0696 - accuracy: 0.5410 - val_loss: 1.0772 - val_accuracy: 0.4416 - 288ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0749 - accuracy: 0.5541 - val_loss: 1.0801 - val_accuracy: 0.4545 - 278ms/epoch - 28ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0810 - accuracy: 0.5410 - val_loss: 1.0776 - val_accuracy: 0.4545 - 302ms/epoch - 30ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0627 - accuracy: 0.5574 - val_loss: 1.0945 - val_accuracy: 0.4675 - 277ms/epoch - 28ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0727 - accuracy: 0.5672 - val_loss: 1.0745 - val_accuracy: 0.4545 - 277ms/epoch - 28ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0438 - accuracy: 0.5738 - val_loss: 1.0641 - val_accuracy: 0.4805 - 277ms/epoch - 28ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0494 - accuracy: 0.5803 - val_loss: 1.0395 - val_accuracy: 0.4805 - 285ms/epoch - 29ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0298 - accuracy: 0.5705 - val_loss: 1.0409 - val_accuracy: 0.5195 - 278ms/epoch - 28ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0273 - accuracy: 0.5738 - val_loss: 1.0403 - val_accuracy: 0.4805 - 278ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0165 - accuracy: 0.5967 - val_loss: 1.0341 - val_accuracy: 0.4675 - 290ms/epoch - 29ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0181 - accuracy: 0.5967 - val_loss: 1.0058 - val_accuracy: 0.5455 - 285ms/epoch - 29ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0387 - accuracy: 0.5607 - val_loss: 0.9892 - val_accuracy: 0.6234 - 288ms/epoch - 29ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9986 - accuracy: 0.5836 - val_loss: 0.9986 - val_accuracy: 0.5584 - 275ms/epoch - 27ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9850 - accuracy: 0.5934 - val_loss: 1.0048 - val_accuracy: 0.5195 - 279ms/epoch - 28ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0061 - accuracy: 0.6033 - val_loss: 0.9749 - val_accuracy: 0.5325 - 298ms/epoch - 30ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0026 - accuracy: 0.6197 - val_loss: 0.9787 - val_accuracy: 0.5195 - 279ms/epoch - 28ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9938 - accuracy: 0.6164 - val_loss: 0.9730 - val_accuracy: 0.5195 - 278ms/epoch - 28ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9898 - accuracy: 0.6164 - val_loss: 0.9632 - val_accuracy: 0.5195 - 283ms/epoch - 28ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9939 - accuracy: 0.6000 - val_loss: 0.9615 - val_accuracy: 0.5584 - 287ms/epoch - 29ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9489 - accuracy: 0.6164 - val_loss: 0.9496 - val_accuracy: 0.6104 - 310ms/epoch - 31ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9515 - accuracy: 0.6393 - val_loss: 0.9488 - val_accuracy: 0.5065 - 298ms/epoch - 30ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9746 - accuracy: 0.5967 - val_loss: 0.9247 - val_accuracy: 0.5844 - 307ms/epoch - 31ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9692 - accuracy: 0.6230 - val_loss: 0.9232 - val_accuracy: 0.5844 - 301ms/epoch - 30ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9364 - accuracy: 0.6197 - val_loss: 0.9547 - val_accuracy: 0.5455 - 298ms/epoch - 30ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9660 - accuracy: 0.6328 - val_loss: 0.9328 - val_accuracy: 0.5974 - 283ms/epoch - 28ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9488 - accuracy: 0.6131 - val_loss: 0.9288 - val_accuracy: 0.5325 - 276ms/epoch - 28ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9038 - accuracy: 0.6328 - val_loss: 0.9072 - val_accuracy: 0.6104 - 280ms/epoch - 28ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9423 - accuracy: 0.6262 - val_loss: 0.9067 - val_accuracy: 0.6234 - 286ms/epoch - 29ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9324 - accuracy: 0.6295 - val_loss: 0.9151 - val_accuracy: 0.6104 - 279ms/epoch - 28ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9400 - accuracy: 0.6230 - val_loss: 0.9065 - val_accuracy: 0.6104 - 276ms/epoch - 28ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9155 - accuracy: 0.6623 - val_loss: 0.8923 - val_accuracy: 0.6104 - 285ms/epoch - 29ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9370 - accuracy: 0.6623 - val_loss: 0.8974 - val_accuracy: 0.5844 - 316ms/epoch - 32ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.8948 - accuracy: 0.6492 - val_loss: 0.8998 - val_accuracy: 0.5714 - 277ms/epoch - 28ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.8982 - accuracy: 0.6361 - val_loss: 0.8778 - val_accuracy: 0.6234 - 284ms/epoch - 28ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9340 - accuracy: 0.6557 - val_loss: 0.8789 - val_accuracy: 0.6234 - 280ms/epoch - 28ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9107 - accuracy: 0.6262 - val_loss: 0.8925 - val_accuracy: 0.6234 - 285ms/epoch - 28ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.8549 - accuracy: 0.6689 - val_loss: 0.8825 - val_accuracy: 0.6234 - 282ms/epoch - 28ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.8643 - accuracy: 0.6590 - val_loss: 0.8751 - val_accuracy: 0.6234 - 279ms/epoch - 28ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.9017 - accuracy: 0.6721 - val_loss: 0.8838 - val_accuracy: 0.6364 - 287ms/epoch - 29ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.8898 - accuracy: 0.6590 - val_loss: 0.8770 - val_accuracy: 0.6104 - 285ms/epoch - 28ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.8952 - accuracy: 0.6492 - val_loss: 0.8587 - val_accuracy: 0.6234 - 278ms/epoch - 28ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9109 - accuracy: 0.6492 - val_loss: 0.8805 - val_accuracy: 0.6234 - 286ms/epoch - 29ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.8715 - accuracy: 0.6426 - val_loss: 0.8860 - val_accuracy: 0.6104 - 274ms/epoch - 27ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.9024 - accuracy: 0.6525 - val_loss: 0.8624 - val_accuracy: 0.6234 - 279ms/epoch - 28ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.8932 - accuracy: 0.6492 - val_loss: 0.8698 - val_accuracy: 0.6234 - 284ms/epoch - 28ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.8896 - accuracy: 0.6623 - val_loss: 0.8889 - val_accuracy: 0.6234 - 283ms/epoch - 28ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8717 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:42:30,957] Trial 48 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 139}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3859 - accuracy: 0.2525 - val_loss: 1.3842 - val_accuracy: 0.2597 - 4s/epoch - 447ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3849 - accuracy: 0.2656 - val_loss: 1.3805 - val_accuracy: 0.2597 - 225ms/epoch - 22ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3815 - accuracy: 0.2656 - val_loss: 1.3751 - val_accuracy: 0.2597 - 243ms/epoch - 24ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3763 - accuracy: 0.3148 - val_loss: 1.3662 - val_accuracy: 0.3377 - 247ms/epoch - 25ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3605 - accuracy: 0.3902 - val_loss: 1.3469 - val_accuracy: 0.3117 - 239ms/epoch - 24ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3283 - accuracy: 0.3803 - val_loss: 1.3122 - val_accuracy: 0.3117 - 248ms/epoch - 25ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2947 - accuracy: 0.4033 - val_loss: 1.2850 - val_accuracy: 0.4026 - 240ms/epoch - 24ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2588 - accuracy: 0.4754 - val_loss: 1.2668 - val_accuracy: 0.3766 - 247ms/epoch - 25ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2333 - accuracy: 0.4492 - val_loss: 1.2348 - val_accuracy: 0.4026 - 245ms/epoch - 25ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1984 - accuracy: 0.4689 - val_loss: 1.2062 - val_accuracy: 0.3766 - 273ms/epoch - 27ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1799 - accuracy: 0.4885 - val_loss: 1.1850 - val_accuracy: 0.3896 - 267ms/epoch - 27ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1616 - accuracy: 0.4885 - val_loss: 1.1763 - val_accuracy: 0.4026 - 273ms/epoch - 27ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1902 - accuracy: 0.5049 - val_loss: 1.1683 - val_accuracy: 0.3896 - 260ms/epoch - 26ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1421 - accuracy: 0.4885 - val_loss: 1.1655 - val_accuracy: 0.3896 - 255ms/epoch - 26ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1257 - accuracy: 0.4984 - val_loss: 1.1604 - val_accuracy: 0.4026 - 257ms/epoch - 26ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1335 - accuracy: 0.5180 - val_loss: 1.1477 - val_accuracy: 0.4026 - 239ms/epoch - 24ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1318 - accuracy: 0.5213 - val_loss: 1.1406 - val_accuracy: 0.3896 - 241ms/epoch - 24ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1369 - accuracy: 0.5082 - val_loss: 1.1374 - val_accuracy: 0.4026 - 248ms/epoch - 25ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1260 - accuracy: 0.5180 - val_loss: 1.1370 - val_accuracy: 0.4026 - 243ms/epoch - 24ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1259 - accuracy: 0.5148 - val_loss: 1.1301 - val_accuracy: 0.4026 - 243ms/epoch - 24ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1196 - accuracy: 0.5082 - val_loss: 1.1220 - val_accuracy: 0.4156 - 243ms/epoch - 24ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1058 - accuracy: 0.5246 - val_loss: 1.1172 - val_accuracy: 0.4026 - 248ms/epoch - 25ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0940 - accuracy: 0.5311 - val_loss: 1.1148 - val_accuracy: 0.4416 - 238ms/epoch - 24ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.1064 - accuracy: 0.5344 - val_loss: 1.1124 - val_accuracy: 0.4156 - 244ms/epoch - 24ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.1115 - accuracy: 0.5246 - val_loss: 1.1150 - val_accuracy: 0.4156 - 251ms/epoch - 25ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0933 - accuracy: 0.5180 - val_loss: 1.1117 - val_accuracy: 0.4805 - 260ms/epoch - 26ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0941 - accuracy: 0.5246 - val_loss: 1.1089 - val_accuracy: 0.4416 - 249ms/epoch - 25ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0932 - accuracy: 0.5115 - val_loss: 1.0960 - val_accuracy: 0.4026 - 237ms/epoch - 24ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0820 - accuracy: 0.5607 - val_loss: 1.0970 - val_accuracy: 0.4286 - 247ms/epoch - 25ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0937 - accuracy: 0.5443 - val_loss: 1.0930 - val_accuracy: 0.4416 - 251ms/epoch - 25ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0896 - accuracy: 0.5574 - val_loss: 1.1002 - val_accuracy: 0.4156 - 247ms/epoch - 25ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0909 - accuracy: 0.5639 - val_loss: 1.0949 - val_accuracy: 0.4545 - 243ms/epoch - 24ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0832 - accuracy: 0.5639 - val_loss: 1.1031 - val_accuracy: 0.4416 - 237ms/epoch - 24ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0952 - accuracy: 0.5508 - val_loss: 1.0912 - val_accuracy: 0.4805 - 245ms/epoch - 24ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0661 - accuracy: 0.5705 - val_loss: 1.0870 - val_accuracy: 0.4545 - 248ms/epoch - 25ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0716 - accuracy: 0.5672 - val_loss: 1.0721 - val_accuracy: 0.4545 - 252ms/epoch - 25ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0673 - accuracy: 0.5541 - val_loss: 1.0715 - val_accuracy: 0.4675 - 257ms/epoch - 26ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0671 - accuracy: 0.5639 - val_loss: 1.0742 - val_accuracy: 0.4675 - 246ms/epoch - 25ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0385 - accuracy: 0.5869 - val_loss: 1.0791 - val_accuracy: 0.4545 - 241ms/epoch - 24ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0751 - accuracy: 0.5639 - val_loss: 1.0565 - val_accuracy: 0.4805 - 243ms/epoch - 24ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0702 - accuracy: 0.5607 - val_loss: 1.0579 - val_accuracy: 0.6104 - 256ms/epoch - 26ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0549 - accuracy: 0.5803 - val_loss: 1.0482 - val_accuracy: 0.4935 - 244ms/epoch - 24ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0452 - accuracy: 0.5475 - val_loss: 1.0482 - val_accuracy: 0.4545 - 244ms/epoch - 24ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0488 - accuracy: 0.5574 - val_loss: 1.0324 - val_accuracy: 0.5195 - 243ms/epoch - 24ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0379 - accuracy: 0.5902 - val_loss: 1.0288 - val_accuracy: 0.4935 - 238ms/epoch - 24ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 1.0452 - accuracy: 0.5574 - val_loss: 1.0318 - val_accuracy: 0.4805 - 245ms/epoch - 25ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 1.0141 - accuracy: 0.5902 - val_loss: 1.0246 - val_accuracy: 0.5065 - 243ms/epoch - 24ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 1.0037 - accuracy: 0.5934 - val_loss: 1.0124 - val_accuracy: 0.5195 - 239ms/epoch - 24ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 1.0119 - accuracy: 0.6262 - val_loss: 0.9876 - val_accuracy: 0.5455 - 243ms/epoch - 24ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 1.0026 - accuracy: 0.6131 - val_loss: 0.9819 - val_accuracy: 0.5195 - 242ms/epoch - 24ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9999 - accuracy: 0.5803 - val_loss: 0.9807 - val_accuracy: 0.5584 - 243ms/epoch - 24ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 1.0029 - accuracy: 0.6000 - val_loss: 0.9830 - val_accuracy: 0.5195 - 249ms/epoch - 25ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9846 - accuracy: 0.5967 - val_loss: 0.9882 - val_accuracy: 0.5195 - 249ms/epoch - 25ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 1.0225 - accuracy: 0.5869 - val_loss: 0.9912 - val_accuracy: 0.5325 - 243ms/epoch - 24ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9772 - accuracy: 0.6164 - val_loss: 0.9812 - val_accuracy: 0.5195 - 242ms/epoch - 24ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9930 - accuracy: 0.5934 - val_loss: 0.9601 - val_accuracy: 0.5714 - 253ms/epoch - 25ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 1.0161 - accuracy: 0.5934 - val_loss: 0.9570 - val_accuracy: 0.5974 - 239ms/epoch - 24ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9457 - accuracy: 0.6262 - val_loss: 0.9677 - val_accuracy: 0.5195 - 238ms/epoch - 24ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9800 - accuracy: 0.5934 - val_loss: 0.9471 - val_accuracy: 0.5325 - 272ms/epoch - 27ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9433 - accuracy: 0.6066 - val_loss: 0.9285 - val_accuracy: 0.5844 - 252ms/epoch - 25ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 1.0024 - accuracy: 0.6000 - val_loss: 0.9246 - val_accuracy: 0.5974 - 270ms/epoch - 27ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9298 - accuracy: 0.6230 - val_loss: 0.9471 - val_accuracy: 0.5325 - 264ms/epoch - 26ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9947 - accuracy: 0.6033 - val_loss: 0.9243 - val_accuracy: 0.6234 - 260ms/epoch - 26ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9835 - accuracy: 0.6033 - val_loss: 0.9407 - val_accuracy: 0.5974 - 267ms/epoch - 27ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9720 - accuracy: 0.6098 - val_loss: 0.9580 - val_accuracy: 0.5325 - 244ms/epoch - 24ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.9536 - accuracy: 0.6033 - val_loss: 0.9351 - val_accuracy: 0.5714 - 277ms/epoch - 28ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.9314 - accuracy: 0.6000 - val_loss: 0.9120 - val_accuracy: 0.5844 - 255ms/epoch - 26ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.9118 - accuracy: 0.6623 - val_loss: 0.9173 - val_accuracy: 0.5714 - 269ms/epoch - 27ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.9179 - accuracy: 0.6295 - val_loss: 0.9034 - val_accuracy: 0.5974 - 261ms/epoch - 26ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.9518 - accuracy: 0.6066 - val_loss: 0.8969 - val_accuracy: 0.6364 - 263ms/epoch - 26ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9191 - accuracy: 0.6426 - val_loss: 0.9080 - val_accuracy: 0.5974 - 275ms/epoch - 28ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.8955 - accuracy: 0.6525 - val_loss: 0.9133 - val_accuracy: 0.5584 - 270ms/epoch - 27ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.9194 - accuracy: 0.6393 - val_loss: 0.8948 - val_accuracy: 0.6104 - 269ms/epoch - 27ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.9478 - accuracy: 0.5902 - val_loss: 0.8879 - val_accuracy: 0.6364 - 284ms/epoch - 28ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.9179 - accuracy: 0.6393 - val_loss: 0.9033 - val_accuracy: 0.5974 - 270ms/epoch - 27ms/step\n",
      "Epoch 76/10000\n",
      "10/10 - 0s - loss: 0.9240 - accuracy: 0.6459 - val_loss: 0.9114 - val_accuracy: 0.5844 - 284ms/epoch - 28ms/step\n",
      "Epoch 77/10000\n",
      "10/10 - 0s - loss: 0.9097 - accuracy: 0.6426 - val_loss: 0.8960 - val_accuracy: 0.5844 - 274ms/epoch - 27ms/step\n",
      "Epoch 78/10000\n",
      "10/10 - 0s - loss: 0.8811 - accuracy: 0.6459 - val_loss: 0.8914 - val_accuracy: 0.6104 - 266ms/epoch - 27ms/step\n",
      "Epoch 79/10000\n",
      "10/10 - 0s - loss: 0.8825 - accuracy: 0.6623 - val_loss: 0.8846 - val_accuracy: 0.6234 - 247ms/epoch - 25ms/step\n",
      "Epoch 80/10000\n",
      "10/10 - 0s - loss: 0.8816 - accuracy: 0.6623 - val_loss: 0.8848 - val_accuracy: 0.6104 - 243ms/epoch - 24ms/step\n",
      "Epoch 81/10000\n",
      "10/10 - 0s - loss: 0.8982 - accuracy: 0.6492 - val_loss: 0.8623 - val_accuracy: 0.6104 - 245ms/epoch - 25ms/step\n",
      "Epoch 82/10000\n",
      "10/10 - 0s - loss: 0.8735 - accuracy: 0.6689 - val_loss: 0.8803 - val_accuracy: 0.6104 - 244ms/epoch - 24ms/step\n",
      "Epoch 83/10000\n",
      "10/10 - 0s - loss: 0.9083 - accuracy: 0.6459 - val_loss: 0.8481 - val_accuracy: 0.6234 - 239ms/epoch - 24ms/step\n",
      "Epoch 84/10000\n",
      "10/10 - 0s - loss: 0.9274 - accuracy: 0.6557 - val_loss: 0.8660 - val_accuracy: 0.6234 - 255ms/epoch - 26ms/step\n",
      "Epoch 85/10000\n",
      "10/10 - 0s - loss: 0.8946 - accuracy: 0.6721 - val_loss: 0.8777 - val_accuracy: 0.6104 - 263ms/epoch - 26ms/step\n",
      "Epoch 86/10000\n",
      "10/10 - 0s - loss: 0.8797 - accuracy: 0.6852 - val_loss: 0.8822 - val_accuracy: 0.6104 - 240ms/epoch - 24ms/step\n",
      "Epoch 87/10000\n",
      "10/10 - 0s - loss: 0.8716 - accuracy: 0.6492 - val_loss: 0.8708 - val_accuracy: 0.6234 - 253ms/epoch - 25ms/step\n",
      "Epoch 88/10000\n",
      "10/10 - 0s - loss: 0.9039 - accuracy: 0.6492 - val_loss: 0.8577 - val_accuracy: 0.6364 - 245ms/epoch - 24ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8780 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:42:59,021] Trial 49 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 132}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3861 - accuracy: 0.2590 - val_loss: 1.3845 - val_accuracy: 0.2597 - 4s/epoch - 435ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3851 - accuracy: 0.2656 - val_loss: 1.3808 - val_accuracy: 0.2597 - 294ms/epoch - 29ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3819 - accuracy: 0.2787 - val_loss: 1.3757 - val_accuracy: 0.2727 - 315ms/epoch - 31ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3760 - accuracy: 0.3344 - val_loss: 1.3670 - val_accuracy: 0.3377 - 318ms/epoch - 32ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3580 - accuracy: 0.3934 - val_loss: 1.3491 - val_accuracy: 0.2987 - 310ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3212 - accuracy: 0.4033 - val_loss: 1.3220 - val_accuracy: 0.3766 - 305ms/epoch - 30ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2818 - accuracy: 0.4328 - val_loss: 1.2921 - val_accuracy: 0.4026 - 313ms/epoch - 31ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2523 - accuracy: 0.4721 - val_loss: 1.2593 - val_accuracy: 0.3766 - 311ms/epoch - 31ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2098 - accuracy: 0.4754 - val_loss: 1.2172 - val_accuracy: 0.3896 - 317ms/epoch - 32ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1802 - accuracy: 0.4984 - val_loss: 1.2033 - val_accuracy: 0.4026 - 306ms/epoch - 31ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1783 - accuracy: 0.4918 - val_loss: 1.1820 - val_accuracy: 0.3896 - 329ms/epoch - 33ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1582 - accuracy: 0.4918 - val_loss: 1.1915 - val_accuracy: 0.4026 - 313ms/epoch - 31ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1701 - accuracy: 0.4984 - val_loss: 1.1705 - val_accuracy: 0.3896 - 308ms/epoch - 31ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1623 - accuracy: 0.5049 - val_loss: 1.1655 - val_accuracy: 0.3896 - 307ms/epoch - 31ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1485 - accuracy: 0.4918 - val_loss: 1.1613 - val_accuracy: 0.3766 - 312ms/epoch - 31ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1275 - accuracy: 0.5016 - val_loss: 1.1536 - val_accuracy: 0.4026 - 307ms/epoch - 31ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1394 - accuracy: 0.5180 - val_loss: 1.1478 - val_accuracy: 0.3896 - 312ms/epoch - 31ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1214 - accuracy: 0.5049 - val_loss: 1.1391 - val_accuracy: 0.4156 - 325ms/epoch - 32ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1250 - accuracy: 0.5148 - val_loss: 1.1367 - val_accuracy: 0.4026 - 309ms/epoch - 31ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0960 - accuracy: 0.5377 - val_loss: 1.1254 - val_accuracy: 0.4026 - 304ms/epoch - 30ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0993 - accuracy: 0.5279 - val_loss: 1.1219 - val_accuracy: 0.4026 - 332ms/epoch - 33ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1104 - accuracy: 0.5115 - val_loss: 1.1091 - val_accuracy: 0.4156 - 325ms/epoch - 33ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0982 - accuracy: 0.5311 - val_loss: 1.1137 - val_accuracy: 0.4026 - 335ms/epoch - 34ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0988 - accuracy: 0.5377 - val_loss: 1.1043 - val_accuracy: 0.4026 - 325ms/epoch - 32ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.1039 - accuracy: 0.5180 - val_loss: 1.1125 - val_accuracy: 0.4026 - 321ms/epoch - 32ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0864 - accuracy: 0.4984 - val_loss: 1.0969 - val_accuracy: 0.5065 - 316ms/epoch - 32ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0822 - accuracy: 0.5344 - val_loss: 1.1020 - val_accuracy: 0.4675 - 309ms/epoch - 31ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0703 - accuracy: 0.5541 - val_loss: 1.0929 - val_accuracy: 0.4286 - 306ms/epoch - 31ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0777 - accuracy: 0.5279 - val_loss: 1.0897 - val_accuracy: 0.4675 - 312ms/epoch - 31ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0739 - accuracy: 0.5508 - val_loss: 1.0800 - val_accuracy: 0.4545 - 309ms/epoch - 31ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0775 - accuracy: 0.5508 - val_loss: 1.0813 - val_accuracy: 0.4545 - 317ms/epoch - 32ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0904 - accuracy: 0.5541 - val_loss: 1.0821 - val_accuracy: 0.4675 - 319ms/epoch - 32ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0737 - accuracy: 0.5738 - val_loss: 1.0965 - val_accuracy: 0.4805 - 324ms/epoch - 32ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0725 - accuracy: 0.5410 - val_loss: 1.0880 - val_accuracy: 0.4675 - 315ms/epoch - 31ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0587 - accuracy: 0.5770 - val_loss: 1.0732 - val_accuracy: 0.4805 - 331ms/epoch - 33ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0463 - accuracy: 0.5639 - val_loss: 1.0492 - val_accuracy: 0.5195 - 310ms/epoch - 31ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0364 - accuracy: 0.5770 - val_loss: 1.0486 - val_accuracy: 0.5455 - 331ms/epoch - 33ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0552 - accuracy: 0.5639 - val_loss: 1.0479 - val_accuracy: 0.4805 - 315ms/epoch - 31ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0486 - accuracy: 0.5639 - val_loss: 1.0457 - val_accuracy: 0.4675 - 320ms/epoch - 32ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0431 - accuracy: 0.5803 - val_loss: 1.0240 - val_accuracy: 0.4935 - 316ms/epoch - 32ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0476 - accuracy: 0.5574 - val_loss: 1.0117 - val_accuracy: 0.6104 - 313ms/epoch - 31ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0372 - accuracy: 0.5902 - val_loss: 1.0093 - val_accuracy: 0.5325 - 313ms/epoch - 31ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9928 - accuracy: 0.5934 - val_loss: 1.0204 - val_accuracy: 0.4935 - 322ms/epoch - 32ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0119 - accuracy: 0.5902 - val_loss: 0.9887 - val_accuracy: 0.5065 - 319ms/epoch - 32ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0144 - accuracy: 0.6131 - val_loss: 0.9970 - val_accuracy: 0.5195 - 311ms/epoch - 31ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9819 - accuracy: 0.5836 - val_loss: 0.9808 - val_accuracy: 0.5065 - 313ms/epoch - 31ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 1.0056 - accuracy: 0.5934 - val_loss: 0.9854 - val_accuracy: 0.5325 - 307ms/epoch - 31ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9612 - accuracy: 0.6033 - val_loss: 0.9839 - val_accuracy: 0.5065 - 312ms/epoch - 31ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9861 - accuracy: 0.6000 - val_loss: 0.9578 - val_accuracy: 0.5455 - 316ms/epoch - 32ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9733 - accuracy: 0.6164 - val_loss: 0.9556 - val_accuracy: 0.5195 - 312ms/epoch - 31ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9623 - accuracy: 0.6459 - val_loss: 0.9343 - val_accuracy: 0.5844 - 312ms/epoch - 31ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9557 - accuracy: 0.6164 - val_loss: 0.9310 - val_accuracy: 0.5325 - 315ms/epoch - 32ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9512 - accuracy: 0.6098 - val_loss: 0.9659 - val_accuracy: 0.5065 - 307ms/epoch - 31ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9407 - accuracy: 0.6557 - val_loss: 0.9226 - val_accuracy: 0.6104 - 316ms/epoch - 32ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9682 - accuracy: 0.6295 - val_loss: 0.9295 - val_accuracy: 0.5065 - 322ms/epoch - 32ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9604 - accuracy: 0.6230 - val_loss: 0.9312 - val_accuracy: 0.5714 - 314ms/epoch - 31ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9336 - accuracy: 0.6197 - val_loss: 0.9119 - val_accuracy: 0.5974 - 327ms/epoch - 33ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9323 - accuracy: 0.6328 - val_loss: 0.9226 - val_accuracy: 0.5974 - 317ms/epoch - 32ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9300 - accuracy: 0.6525 - val_loss: 0.9099 - val_accuracy: 0.5844 - 309ms/epoch - 31ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9129 - accuracy: 0.6623 - val_loss: 0.8964 - val_accuracy: 0.5974 - 311ms/epoch - 31ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9277 - accuracy: 0.6492 - val_loss: 0.8975 - val_accuracy: 0.5844 - 314ms/epoch - 31ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9295 - accuracy: 0.6262 - val_loss: 0.8844 - val_accuracy: 0.5974 - 312ms/epoch - 31ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9160 - accuracy: 0.6525 - val_loss: 0.8894 - val_accuracy: 0.6104 - 337ms/epoch - 34ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9156 - accuracy: 0.6492 - val_loss: 0.8946 - val_accuracy: 0.6104 - 314ms/epoch - 31ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9097 - accuracy: 0.6590 - val_loss: 0.8982 - val_accuracy: 0.5844 - 313ms/epoch - 31ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.8787 - accuracy: 0.6721 - val_loss: 0.8810 - val_accuracy: 0.6234 - 319ms/epoch - 32ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.9017 - accuracy: 0.6164 - val_loss: 0.8685 - val_accuracy: 0.6234 - 309ms/epoch - 31ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.8837 - accuracy: 0.6590 - val_loss: 0.8891 - val_accuracy: 0.6104 - 318ms/epoch - 32ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.8818 - accuracy: 0.6393 - val_loss: 0.8844 - val_accuracy: 0.6234 - 321ms/epoch - 32ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.8983 - accuracy: 0.6426 - val_loss: 0.8664 - val_accuracy: 0.6234 - 317ms/epoch - 32ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9091 - accuracy: 0.6623 - val_loss: 0.8910 - val_accuracy: 0.6104 - 333ms/epoch - 33ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.9113 - accuracy: 0.6623 - val_loss: 0.8804 - val_accuracy: 0.6104 - 334ms/epoch - 33ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.9170 - accuracy: 0.6393 - val_loss: 0.8818 - val_accuracy: 0.6104 - 329ms/epoch - 33ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.9092 - accuracy: 0.6492 - val_loss: 0.8683 - val_accuracy: 0.6364 - 337ms/epoch - 34ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.9111 - accuracy: 0.6623 - val_loss: 0.8855 - val_accuracy: 0.6234 - 321ms/epoch - 32ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8601 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:43:28,670] Trial 50 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 150}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3860 - accuracy: 0.2525 - val_loss: 1.3844 - val_accuracy: 0.2597 - 5s/epoch - 487ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3849 - accuracy: 0.2656 - val_loss: 1.3809 - val_accuracy: 0.2597 - 337ms/epoch - 34ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3819 - accuracy: 0.2656 - val_loss: 1.3759 - val_accuracy: 0.2987 - 350ms/epoch - 35ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3761 - accuracy: 0.3541 - val_loss: 1.3669 - val_accuracy: 0.3377 - 339ms/epoch - 34ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3613 - accuracy: 0.3803 - val_loss: 1.3464 - val_accuracy: 0.2987 - 342ms/epoch - 34ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3223 - accuracy: 0.3934 - val_loss: 1.3083 - val_accuracy: 0.3117 - 342ms/epoch - 34ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2821 - accuracy: 0.4328 - val_loss: 1.2723 - val_accuracy: 0.3636 - 345ms/epoch - 34ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2299 - accuracy: 0.4525 - val_loss: 1.2352 - val_accuracy: 0.3636 - 345ms/epoch - 35ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2048 - accuracy: 0.4656 - val_loss: 1.1907 - val_accuracy: 0.3896 - 340ms/epoch - 34ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1682 - accuracy: 0.4820 - val_loss: 1.1806 - val_accuracy: 0.3896 - 343ms/epoch - 34ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1685 - accuracy: 0.4984 - val_loss: 1.1724 - val_accuracy: 0.3896 - 344ms/epoch - 34ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1539 - accuracy: 0.4787 - val_loss: 1.1752 - val_accuracy: 0.3896 - 341ms/epoch - 34ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1581 - accuracy: 0.5148 - val_loss: 1.1680 - val_accuracy: 0.4026 - 344ms/epoch - 34ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1404 - accuracy: 0.4721 - val_loss: 1.1621 - val_accuracy: 0.3636 - 345ms/epoch - 35ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1350 - accuracy: 0.5016 - val_loss: 1.1537 - val_accuracy: 0.3766 - 351ms/epoch - 35ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1238 - accuracy: 0.5148 - val_loss: 1.1418 - val_accuracy: 0.4026 - 351ms/epoch - 35ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1245 - accuracy: 0.5115 - val_loss: 1.1344 - val_accuracy: 0.3636 - 352ms/epoch - 35ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1080 - accuracy: 0.5049 - val_loss: 1.1285 - val_accuracy: 0.3636 - 352ms/epoch - 35ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1222 - accuracy: 0.5049 - val_loss: 1.1349 - val_accuracy: 0.3896 - 360ms/epoch - 36ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1161 - accuracy: 0.5180 - val_loss: 1.1223 - val_accuracy: 0.3896 - 341ms/epoch - 34ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0933 - accuracy: 0.5344 - val_loss: 1.1184 - val_accuracy: 0.3896 - 347ms/epoch - 35ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1023 - accuracy: 0.5213 - val_loss: 1.1159 - val_accuracy: 0.4026 - 350ms/epoch - 35ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1033 - accuracy: 0.5213 - val_loss: 1.1160 - val_accuracy: 0.4286 - 355ms/epoch - 35ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0846 - accuracy: 0.5344 - val_loss: 1.1069 - val_accuracy: 0.4156 - 369ms/epoch - 37ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.1065 - accuracy: 0.5213 - val_loss: 1.1188 - val_accuracy: 0.4286 - 369ms/epoch - 37ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0733 - accuracy: 0.5377 - val_loss: 1.0966 - val_accuracy: 0.5065 - 371ms/epoch - 37ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.1061 - accuracy: 0.5377 - val_loss: 1.1034 - val_accuracy: 0.5455 - 370ms/epoch - 37ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0907 - accuracy: 0.5311 - val_loss: 1.0881 - val_accuracy: 0.4416 - 359ms/epoch - 36ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0710 - accuracy: 0.5475 - val_loss: 1.0927 - val_accuracy: 0.4545 - 355ms/epoch - 36ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0805 - accuracy: 0.5541 - val_loss: 1.0806 - val_accuracy: 0.4675 - 354ms/epoch - 35ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0605 - accuracy: 0.5738 - val_loss: 1.0866 - val_accuracy: 0.4545 - 345ms/epoch - 35ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0704 - accuracy: 0.5574 - val_loss: 1.0799 - val_accuracy: 0.4545 - 347ms/epoch - 35ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0722 - accuracy: 0.5574 - val_loss: 1.0846 - val_accuracy: 0.4416 - 348ms/epoch - 35ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0410 - accuracy: 0.5738 - val_loss: 1.0759 - val_accuracy: 0.4545 - 354ms/epoch - 35ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0377 - accuracy: 0.5869 - val_loss: 1.0589 - val_accuracy: 0.4675 - 348ms/epoch - 35ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0502 - accuracy: 0.5705 - val_loss: 1.0399 - val_accuracy: 0.5195 - 351ms/epoch - 35ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0936 - accuracy: 0.5934 - val_loss: 1.0567 - val_accuracy: 0.5455 - 344ms/epoch - 34ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0515 - accuracy: 0.5574 - val_loss: 1.0535 - val_accuracy: 0.4805 - 363ms/epoch - 36ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0611 - accuracy: 0.5639 - val_loss: 1.0558 - val_accuracy: 0.4805 - 354ms/epoch - 35ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0500 - accuracy: 0.5574 - val_loss: 1.0315 - val_accuracy: 0.4805 - 353ms/epoch - 35ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0516 - accuracy: 0.5672 - val_loss: 1.0232 - val_accuracy: 0.5714 - 341ms/epoch - 34ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0356 - accuracy: 0.5836 - val_loss: 1.0224 - val_accuracy: 0.4805 - 364ms/epoch - 36ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0250 - accuracy: 0.5803 - val_loss: 1.0175 - val_accuracy: 0.4935 - 345ms/epoch - 35ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0274 - accuracy: 0.6230 - val_loss: 1.0003 - val_accuracy: 0.4935 - 356ms/epoch - 36ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0177 - accuracy: 0.5902 - val_loss: 1.0003 - val_accuracy: 0.4935 - 346ms/epoch - 35ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9937 - accuracy: 0.6098 - val_loss: 0.9893 - val_accuracy: 0.5195 - 348ms/epoch - 35ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9800 - accuracy: 0.6197 - val_loss: 0.9781 - val_accuracy: 0.5325 - 346ms/epoch - 35ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9795 - accuracy: 0.6098 - val_loss: 0.9629 - val_accuracy: 0.5325 - 345ms/epoch - 35ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 1.0049 - accuracy: 0.6000 - val_loss: 0.9521 - val_accuracy: 0.5844 - 347ms/epoch - 35ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9577 - accuracy: 0.6000 - val_loss: 0.9603 - val_accuracy: 0.5195 - 348ms/epoch - 35ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9903 - accuracy: 0.6361 - val_loss: 0.9443 - val_accuracy: 0.5584 - 348ms/epoch - 35ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 1.0083 - accuracy: 0.6131 - val_loss: 0.9408 - val_accuracy: 0.5974 - 346ms/epoch - 35ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9849 - accuracy: 0.6033 - val_loss: 0.9781 - val_accuracy: 0.5195 - 359ms/epoch - 36ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9654 - accuracy: 0.6295 - val_loss: 0.9633 - val_accuracy: 0.5714 - 352ms/epoch - 35ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9412 - accuracy: 0.6230 - val_loss: 0.9616 - val_accuracy: 0.5325 - 352ms/epoch - 35ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9556 - accuracy: 0.6197 - val_loss: 0.9328 - val_accuracy: 0.5974 - 354ms/epoch - 35ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9468 - accuracy: 0.6197 - val_loss: 0.9250 - val_accuracy: 0.6104 - 349ms/epoch - 35ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9004 - accuracy: 0.6328 - val_loss: 0.9253 - val_accuracy: 0.5714 - 349ms/epoch - 35ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9220 - accuracy: 0.6197 - val_loss: 0.8961 - val_accuracy: 0.5974 - 358ms/epoch - 36ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9429 - accuracy: 0.6590 - val_loss: 0.9059 - val_accuracy: 0.5584 - 347ms/epoch - 35ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9335 - accuracy: 0.6197 - val_loss: 0.8942 - val_accuracy: 0.6104 - 355ms/epoch - 35ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9438 - accuracy: 0.6328 - val_loss: 0.9145 - val_accuracy: 0.5714 - 349ms/epoch - 35ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9532 - accuracy: 0.6295 - val_loss: 0.8976 - val_accuracy: 0.6234 - 355ms/epoch - 35ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9323 - accuracy: 0.6525 - val_loss: 0.9027 - val_accuracy: 0.5974 - 366ms/epoch - 37ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9330 - accuracy: 0.6393 - val_loss: 0.8950 - val_accuracy: 0.5974 - 385ms/epoch - 39ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.9503 - accuracy: 0.6623 - val_loss: 0.8859 - val_accuracy: 0.6234 - 389ms/epoch - 39ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.9247 - accuracy: 0.6361 - val_loss: 0.8863 - val_accuracy: 0.6234 - 363ms/epoch - 36ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.9342 - accuracy: 0.6328 - val_loss: 0.8869 - val_accuracy: 0.5844 - 368ms/epoch - 37ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.9360 - accuracy: 0.6721 - val_loss: 0.8964 - val_accuracy: 0.5844 - 382ms/epoch - 38ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.9199 - accuracy: 0.6361 - val_loss: 0.8940 - val_accuracy: 0.5974 - 386ms/epoch - 39ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9250 - accuracy: 0.6426 - val_loss: 0.8832 - val_accuracy: 0.6234 - 381ms/epoch - 38ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.8633 - accuracy: 0.6689 - val_loss: 0.8946 - val_accuracy: 0.5844 - 388ms/epoch - 39ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.9311 - accuracy: 0.6459 - val_loss: 0.8725 - val_accuracy: 0.6234 - 373ms/epoch - 37ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.9151 - accuracy: 0.6295 - val_loss: 0.8663 - val_accuracy: 0.6234 - 381ms/epoch - 38ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.8620 - accuracy: 0.6623 - val_loss: 0.8778 - val_accuracy: 0.6104 - 353ms/epoch - 35ms/step\n",
      "Epoch 76/10000\n",
      "10/10 - 0s - loss: 0.8971 - accuracy: 0.6557 - val_loss: 0.8818 - val_accuracy: 0.6104 - 362ms/epoch - 36ms/step\n",
      "Epoch 77/10000\n",
      "10/10 - 0s - loss: 0.8944 - accuracy: 0.6459 - val_loss: 0.8643 - val_accuracy: 0.6234 - 346ms/epoch - 35ms/step\n",
      "Epoch 78/10000\n",
      "10/10 - 0s - loss: 0.9064 - accuracy: 0.6295 - val_loss: 0.8711 - val_accuracy: 0.6364 - 373ms/epoch - 37ms/step\n",
      "Epoch 79/10000\n",
      "10/10 - 0s - loss: 0.8588 - accuracy: 0.6557 - val_loss: 0.8566 - val_accuracy: 0.6364 - 346ms/epoch - 35ms/step\n",
      "Epoch 80/10000\n",
      "10/10 - 0s - loss: 0.8873 - accuracy: 0.6295 - val_loss: 0.8659 - val_accuracy: 0.6234 - 350ms/epoch - 35ms/step\n",
      "Epoch 81/10000\n",
      "10/10 - 0s - loss: 0.8734 - accuracy: 0.6426 - val_loss: 0.8477 - val_accuracy: 0.6234 - 352ms/epoch - 35ms/step\n",
      "Epoch 82/10000\n",
      "10/10 - 0s - loss: 0.8668 - accuracy: 0.6820 - val_loss: 0.8655 - val_accuracy: 0.6364 - 351ms/epoch - 35ms/step\n",
      "Epoch 83/10000\n",
      "10/10 - 0s - loss: 0.8893 - accuracy: 0.6557 - val_loss: 0.8461 - val_accuracy: 0.6364 - 349ms/epoch - 35ms/step\n",
      "Epoch 84/10000\n",
      "10/10 - 0s - loss: 0.8737 - accuracy: 0.6459 - val_loss: 0.8666 - val_accuracy: 0.6364 - 348ms/epoch - 35ms/step\n",
      "Epoch 85/10000\n",
      "10/10 - 0s - loss: 0.8607 - accuracy: 0.6852 - val_loss: 0.8614 - val_accuracy: 0.6364 - 357ms/epoch - 36ms/step\n",
      "Epoch 86/10000\n",
      "10/10 - 0s - loss: 0.8564 - accuracy: 0.6689 - val_loss: 0.8618 - val_accuracy: 0.6234 - 346ms/epoch - 35ms/step\n",
      "Epoch 87/10000\n",
      "10/10 - 0s - loss: 0.8725 - accuracy: 0.6721 - val_loss: 0.8602 - val_accuracy: 0.6364 - 348ms/epoch - 35ms/step\n",
      "Epoch 88/10000\n",
      "10/10 - 0s - loss: 0.8932 - accuracy: 0.6197 - val_loss: 0.8508 - val_accuracy: 0.6494 - 361ms/epoch - 36ms/step\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8641 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:44:06,313] Trial 51 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 156}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 4s - loss: 1.3855 - accuracy: 0.2689 - val_loss: 1.3827 - val_accuracy: 0.3247 - 4s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3832 - accuracy: 0.3377 - val_loss: 1.3778 - val_accuracy: 0.3636 - 227ms/epoch - 57ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3781 - accuracy: 0.3410 - val_loss: 1.3716 - val_accuracy: 0.3247 - 248ms/epoch - 62ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.3702 - accuracy: 0.3934 - val_loss: 1.3628 - val_accuracy: 0.3506 - 265ms/epoch - 66ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.3566 - accuracy: 0.4328 - val_loss: 1.3475 - val_accuracy: 0.3766 - 256ms/epoch - 64ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.3336 - accuracy: 0.4492 - val_loss: 1.3252 - val_accuracy: 0.3506 - 251ms/epoch - 63ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.3047 - accuracy: 0.4525 - val_loss: 1.2971 - val_accuracy: 0.3506 - 261ms/epoch - 65ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.2639 - accuracy: 0.4525 - val_loss: 1.2673 - val_accuracy: 0.3506 - 253ms/epoch - 63ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.2345 - accuracy: 0.4492 - val_loss: 1.2317 - val_accuracy: 0.3636 - 257ms/epoch - 64ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.1805 - accuracy: 0.4656 - val_loss: 1.2069 - val_accuracy: 0.3636 - 262ms/epoch - 66ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.1503 - accuracy: 0.5082 - val_loss: 1.1813 - val_accuracy: 0.3766 - 272ms/epoch - 68ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.1632 - accuracy: 0.5016 - val_loss: 1.1614 - val_accuracy: 0.4026 - 247ms/epoch - 62ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.1563 - accuracy: 0.5049 - val_loss: 1.1667 - val_accuracy: 0.4286 - 267ms/epoch - 67ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.1471 - accuracy: 0.5016 - val_loss: 1.1469 - val_accuracy: 0.4156 - 276ms/epoch - 69ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.1287 - accuracy: 0.5180 - val_loss: 1.1472 - val_accuracy: 0.3896 - 269ms/epoch - 67ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.1384 - accuracy: 0.5148 - val_loss: 1.1461 - val_accuracy: 0.4026 - 265ms/epoch - 66ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.1162 - accuracy: 0.5279 - val_loss: 1.1388 - val_accuracy: 0.4156 - 272ms/epoch - 68ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.1171 - accuracy: 0.5115 - val_loss: 1.1350 - val_accuracy: 0.4156 - 274ms/epoch - 69ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.1078 - accuracy: 0.5311 - val_loss: 1.1308 - val_accuracy: 0.4286 - 259ms/epoch - 65ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.1206 - accuracy: 0.5377 - val_loss: 1.1254 - val_accuracy: 0.4286 - 258ms/epoch - 64ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.1064 - accuracy: 0.5508 - val_loss: 1.1092 - val_accuracy: 0.4286 - 249ms/epoch - 62ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.1050 - accuracy: 0.5246 - val_loss: 1.1053 - val_accuracy: 0.4545 - 253ms/epoch - 63ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.0899 - accuracy: 0.5508 - val_loss: 1.1004 - val_accuracy: 0.4545 - 261ms/epoch - 65ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.0861 - accuracy: 0.5541 - val_loss: 1.0835 - val_accuracy: 0.4545 - 252ms/epoch - 63ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.0847 - accuracy: 0.5344 - val_loss: 1.0836 - val_accuracy: 0.4545 - 249ms/epoch - 62ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 1.0450 - accuracy: 0.5541 - val_loss: 1.0672 - val_accuracy: 0.4675 - 254ms/epoch - 64ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.0608 - accuracy: 0.5475 - val_loss: 1.0543 - val_accuracy: 0.5065 - 251ms/epoch - 63ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 1.0501 - accuracy: 0.5738 - val_loss: 1.0395 - val_accuracy: 0.4805 - 253ms/epoch - 63ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 1.0495 - accuracy: 0.5770 - val_loss: 1.0338 - val_accuracy: 0.5065 - 252ms/epoch - 63ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 1.0388 - accuracy: 0.5836 - val_loss: 1.0289 - val_accuracy: 0.5065 - 249ms/epoch - 62ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 1.0290 - accuracy: 0.6000 - val_loss: 1.0150 - val_accuracy: 0.5065 - 254ms/epoch - 63ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 1.0219 - accuracy: 0.5738 - val_loss: 1.0083 - val_accuracy: 0.4675 - 252ms/epoch - 63ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 0.9931 - accuracy: 0.5869 - val_loss: 0.9985 - val_accuracy: 0.4935 - 253ms/epoch - 63ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 0.9956 - accuracy: 0.5934 - val_loss: 0.9951 - val_accuracy: 0.5195 - 260ms/epoch - 65ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 0.9862 - accuracy: 0.6197 - val_loss: 0.9770 - val_accuracy: 0.5065 - 252ms/epoch - 63ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 0.9811 - accuracy: 0.6361 - val_loss: 0.9539 - val_accuracy: 0.5584 - 257ms/epoch - 64ms/step\n",
      "Epoch 37/10000\n",
      "4/4 - 0s - loss: 0.9523 - accuracy: 0.6295 - val_loss: 0.9508 - val_accuracy: 0.5714 - 250ms/epoch - 62ms/step\n",
      "Epoch 38/10000\n",
      "4/4 - 0s - loss: 0.9711 - accuracy: 0.6000 - val_loss: 0.9401 - val_accuracy: 0.5325 - 255ms/epoch - 64ms/step\n",
      "Epoch 39/10000\n",
      "4/4 - 0s - loss: 0.9921 - accuracy: 0.6066 - val_loss: 0.9364 - val_accuracy: 0.5325 - 250ms/epoch - 62ms/step\n",
      "Epoch 40/10000\n",
      "4/4 - 0s - loss: 0.9330 - accuracy: 0.6262 - val_loss: 0.9211 - val_accuracy: 0.5455 - 253ms/epoch - 63ms/step\n",
      "Epoch 41/10000\n",
      "4/4 - 0s - loss: 0.9634 - accuracy: 0.6197 - val_loss: 0.9167 - val_accuracy: 0.6234 - 249ms/epoch - 62ms/step\n",
      "Epoch 42/10000\n",
      "4/4 - 0s - loss: 0.9518 - accuracy: 0.6131 - val_loss: 0.9132 - val_accuracy: 0.5584 - 258ms/epoch - 65ms/step\n",
      "Epoch 43/10000\n",
      "4/4 - 0s - loss: 0.9451 - accuracy: 0.6131 - val_loss: 0.9158 - val_accuracy: 0.5195 - 284ms/epoch - 71ms/step\n",
      "Epoch 44/10000\n",
      "4/4 - 0s - loss: 0.9611 - accuracy: 0.6262 - val_loss: 0.9005 - val_accuracy: 0.5974 - 261ms/epoch - 65ms/step\n",
      "Epoch 45/10000\n",
      "4/4 - 0s - loss: 0.9639 - accuracy: 0.5934 - val_loss: 0.9094 - val_accuracy: 0.5584 - 301ms/epoch - 75ms/step\n",
      "Epoch 46/10000\n",
      "4/4 - 0s - loss: 0.9109 - accuracy: 0.6033 - val_loss: 0.9055 - val_accuracy: 0.5455 - 251ms/epoch - 63ms/step\n",
      "Epoch 47/10000\n",
      "4/4 - 0s - loss: 0.9158 - accuracy: 0.6328 - val_loss: 0.9052 - val_accuracy: 0.5455 - 259ms/epoch - 65ms/step\n",
      "Epoch 48/10000\n",
      "4/4 - 0s - loss: 0.9104 - accuracy: 0.6197 - val_loss: 0.8894 - val_accuracy: 0.5714 - 250ms/epoch - 62ms/step\n",
      "Epoch 49/10000\n",
      "4/4 - 0s - loss: 0.9394 - accuracy: 0.6066 - val_loss: 0.8806 - val_accuracy: 0.6494 - 262ms/epoch - 66ms/step\n",
      "Epoch 50/10000\n",
      "4/4 - 0s - loss: 0.9277 - accuracy: 0.6361 - val_loss: 0.8897 - val_accuracy: 0.5974 - 255ms/epoch - 64ms/step\n",
      "Epoch 51/10000\n",
      "4/4 - 0s - loss: 0.9303 - accuracy: 0.6426 - val_loss: 0.8792 - val_accuracy: 0.5844 - 253ms/epoch - 63ms/step\n",
      "Epoch 52/10000\n",
      "4/4 - 0s - loss: 0.9479 - accuracy: 0.6033 - val_loss: 0.8801 - val_accuracy: 0.5844 - 256ms/epoch - 64ms/step\n",
      "Epoch 53/10000\n",
      "4/4 - 0s - loss: 0.8949 - accuracy: 0.6525 - val_loss: 0.9147 - val_accuracy: 0.5584 - 260ms/epoch - 65ms/step\n",
      "Epoch 54/10000\n",
      "4/4 - 0s - loss: 0.9345 - accuracy: 0.6426 - val_loss: 0.8803 - val_accuracy: 0.5714 - 260ms/epoch - 65ms/step\n",
      "Epoch 55/10000\n",
      "4/4 - 0s - loss: 0.9240 - accuracy: 0.6393 - val_loss: 0.8686 - val_accuracy: 0.5974 - 249ms/epoch - 62ms/step\n",
      "Epoch 56/10000\n",
      "4/4 - 0s - loss: 0.9268 - accuracy: 0.6295 - val_loss: 0.8787 - val_accuracy: 0.6494 - 260ms/epoch - 65ms/step\n",
      "Epoch 57/10000\n",
      "4/4 - 0s - loss: 0.9177 - accuracy: 0.6033 - val_loss: 0.8831 - val_accuracy: 0.5844 - 254ms/epoch - 63ms/step\n",
      "Epoch 58/10000\n",
      "4/4 - 0s - loss: 0.8938 - accuracy: 0.6361 - val_loss: 0.8790 - val_accuracy: 0.5974 - 255ms/epoch - 64ms/step\n",
      "Epoch 59/10000\n",
      "4/4 - 0s - loss: 0.9118 - accuracy: 0.6393 - val_loss: 0.8681 - val_accuracy: 0.6104 - 264ms/epoch - 66ms/step\n",
      "Epoch 60/10000\n",
      "4/4 - 0s - loss: 0.8649 - accuracy: 0.6885 - val_loss: 0.8729 - val_accuracy: 0.5974 - 260ms/epoch - 65ms/step\n",
      "Epoch 61/10000\n",
      "4/4 - 0s - loss: 0.8854 - accuracy: 0.6459 - val_loss: 0.8672 - val_accuracy: 0.6494 - 249ms/epoch - 62ms/step\n",
      "Epoch 62/10000\n",
      "4/4 - 0s - loss: 0.9038 - accuracy: 0.6262 - val_loss: 0.8754 - val_accuracy: 0.5844 - 255ms/epoch - 64ms/step\n",
      "Epoch 63/10000\n",
      "4/4 - 0s - loss: 0.8923 - accuracy: 0.6590 - val_loss: 0.8809 - val_accuracy: 0.6104 - 256ms/epoch - 64ms/step\n",
      "Epoch 64/10000\n",
      "4/4 - 0s - loss: 0.9043 - accuracy: 0.6459 - val_loss: 0.8693 - val_accuracy: 0.6364 - 253ms/epoch - 63ms/step\n",
      "Epoch 65/10000\n",
      "4/4 - 0s - loss: 0.8946 - accuracy: 0.6361 - val_loss: 0.8743 - val_accuracy: 0.5974 - 254ms/epoch - 63ms/step\n",
      "Epoch 66/10000\n",
      "4/4 - 0s - loss: 0.8891 - accuracy: 0.6361 - val_loss: 0.8817 - val_accuracy: 0.5974 - 259ms/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8716 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:44:28,991] Trial 52 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'swish', 'activation_func_3': 'selu', 'batch_size': 80, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 163}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3852 - accuracy: 0.3148 - val_loss: 1.3833 - val_accuracy: 0.3766 - 4s/epoch - 445ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3792 - accuracy: 0.4426 - val_loss: 1.3734 - val_accuracy: 0.4286 - 322ms/epoch - 32ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3578 - accuracy: 0.5016 - val_loss: 1.3321 - val_accuracy: 0.4286 - 336ms/epoch - 34ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2989 - accuracy: 0.4230 - val_loss: 1.2667 - val_accuracy: 0.4286 - 336ms/epoch - 34ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2860 - accuracy: 0.4459 - val_loss: 1.2588 - val_accuracy: 0.4416 - 332ms/epoch - 33ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2267 - accuracy: 0.5082 - val_loss: 1.2321 - val_accuracy: 0.4286 - 332ms/epoch - 33ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2123 - accuracy: 0.4852 - val_loss: 1.2362 - val_accuracy: 0.4545 - 337ms/epoch - 34ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2469 - accuracy: 0.5148 - val_loss: 1.2261 - val_accuracy: 0.3896 - 343ms/epoch - 34ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2284 - accuracy: 0.4984 - val_loss: 1.2090 - val_accuracy: 0.3896 - 337ms/epoch - 34ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.2069 - accuracy: 0.5016 - val_loss: 1.2053 - val_accuracy: 0.4026 - 334ms/epoch - 33ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1975 - accuracy: 0.4820 - val_loss: 1.2067 - val_accuracy: 0.4026 - 337ms/epoch - 34ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1831 - accuracy: 0.4984 - val_loss: 1.2016 - val_accuracy: 0.3896 - 338ms/epoch - 34ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1424 - accuracy: 0.5115 - val_loss: 1.1695 - val_accuracy: 0.3896 - 333ms/epoch - 33ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1515 - accuracy: 0.5148 - val_loss: 1.1416 - val_accuracy: 0.3896 - 361ms/epoch - 36ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1607 - accuracy: 0.5311 - val_loss: 1.1411 - val_accuracy: 0.4286 - 342ms/epoch - 34ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1567 - accuracy: 0.5311 - val_loss: 1.1196 - val_accuracy: 0.4545 - 331ms/epoch - 33ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1514 - accuracy: 0.5115 - val_loss: 1.1226 - val_accuracy: 0.4416 - 332ms/epoch - 33ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0942 - accuracy: 0.5705 - val_loss: 1.0894 - val_accuracy: 0.4805 - 334ms/epoch - 33ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1118 - accuracy: 0.5508 - val_loss: 1.0647 - val_accuracy: 0.4675 - 341ms/epoch - 34ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1083 - accuracy: 0.5344 - val_loss: 1.0329 - val_accuracy: 0.5584 - 335ms/epoch - 33ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0750 - accuracy: 0.5672 - val_loss: 1.0324 - val_accuracy: 0.4935 - 339ms/epoch - 34ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0687 - accuracy: 0.5541 - val_loss: 1.0768 - val_accuracy: 0.4935 - 335ms/epoch - 33ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0932 - accuracy: 0.5475 - val_loss: 1.0786 - val_accuracy: 0.4935 - 345ms/epoch - 35ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0093 - accuracy: 0.5705 - val_loss: 1.0825 - val_accuracy: 0.4805 - 335ms/epoch - 33ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0700 - accuracy: 0.5639 - val_loss: 1.0431 - val_accuracy: 0.4805 - 340ms/epoch - 34ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0145 - accuracy: 0.6098 - val_loss: 1.0036 - val_accuracy: 0.5325 - 337ms/epoch - 34ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0462 - accuracy: 0.5672 - val_loss: 0.9801 - val_accuracy: 0.5455 - 333ms/epoch - 33ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0263 - accuracy: 0.5770 - val_loss: 0.9787 - val_accuracy: 0.5584 - 331ms/epoch - 33ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9881 - accuracy: 0.6066 - val_loss: 0.9881 - val_accuracy: 0.5584 - 343ms/epoch - 34ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0144 - accuracy: 0.5738 - val_loss: 0.9689 - val_accuracy: 0.5325 - 339ms/epoch - 34ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0111 - accuracy: 0.6000 - val_loss: 0.9555 - val_accuracy: 0.5325 - 338ms/epoch - 34ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9561 - accuracy: 0.6033 - val_loss: 0.9357 - val_accuracy: 0.5714 - 337ms/epoch - 34ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9277 - accuracy: 0.6197 - val_loss: 0.9448 - val_accuracy: 0.5584 - 333ms/epoch - 33ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9782 - accuracy: 0.6131 - val_loss: 0.9358 - val_accuracy: 0.6364 - 344ms/epoch - 34ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9476 - accuracy: 0.5967 - val_loss: 0.9535 - val_accuracy: 0.5455 - 344ms/epoch - 34ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9652 - accuracy: 0.6197 - val_loss: 0.9004 - val_accuracy: 0.6364 - 341ms/epoch - 34ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9197 - accuracy: 0.6230 - val_loss: 0.9061 - val_accuracy: 0.6364 - 352ms/epoch - 35ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9010 - accuracy: 0.6230 - val_loss: 0.9102 - val_accuracy: 0.5714 - 375ms/epoch - 37ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9145 - accuracy: 0.6557 - val_loss: 0.8869 - val_accuracy: 0.6364 - 377ms/epoch - 38ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9344 - accuracy: 0.6131 - val_loss: 0.9168 - val_accuracy: 0.6234 - 354ms/epoch - 35ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0242 - accuracy: 0.5902 - val_loss: 0.9690 - val_accuracy: 0.5714 - 355ms/epoch - 36ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0071 - accuracy: 0.6164 - val_loss: 0.9587 - val_accuracy: 0.5455 - 342ms/epoch - 34ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9031 - accuracy: 0.6098 - val_loss: 0.9135 - val_accuracy: 0.6494 - 337ms/epoch - 34ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9382 - accuracy: 0.6328 - val_loss: 0.9168 - val_accuracy: 0.5844 - 335ms/epoch - 34ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9489 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:44:49,907] Trial 53 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'relu', 'activation_func_3': 'swish', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 171}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3846 - accuracy: 0.3049 - val_loss: 1.3795 - val_accuracy: 0.4545 - 5s/epoch - 685ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3742 - accuracy: 0.4197 - val_loss: 1.3692 - val_accuracy: 0.3377 - 308ms/epoch - 44ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3618 - accuracy: 0.4197 - val_loss: 1.3491 - val_accuracy: 0.3506 - 324ms/epoch - 46ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3288 - accuracy: 0.4525 - val_loss: 1.3120 - val_accuracy: 0.3766 - 326ms/epoch - 47ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2853 - accuracy: 0.4721 - val_loss: 1.2833 - val_accuracy: 0.3896 - 334ms/epoch - 48ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2378 - accuracy: 0.4590 - val_loss: 1.2610 - val_accuracy: 0.3636 - 327ms/epoch - 47ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2228 - accuracy: 0.4459 - val_loss: 1.2377 - val_accuracy: 0.3636 - 327ms/epoch - 47ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2341 - accuracy: 0.4525 - val_loss: 1.2314 - val_accuracy: 0.4026 - 326ms/epoch - 47ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2087 - accuracy: 0.4885 - val_loss: 1.2131 - val_accuracy: 0.4416 - 328ms/epoch - 47ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2069 - accuracy: 0.4852 - val_loss: 1.2044 - val_accuracy: 0.4286 - 329ms/epoch - 47ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1745 - accuracy: 0.4820 - val_loss: 1.1835 - val_accuracy: 0.3896 - 331ms/epoch - 47ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1541 - accuracy: 0.4820 - val_loss: 1.1949 - val_accuracy: 0.3766 - 329ms/epoch - 47ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1768 - accuracy: 0.4623 - val_loss: 1.1853 - val_accuracy: 0.3896 - 326ms/epoch - 47ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1321 - accuracy: 0.5049 - val_loss: 1.1693 - val_accuracy: 0.3896 - 331ms/epoch - 47ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1539 - accuracy: 0.4984 - val_loss: 1.1482 - val_accuracy: 0.3896 - 328ms/epoch - 47ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1664 - accuracy: 0.5049 - val_loss: 1.1480 - val_accuracy: 0.4416 - 326ms/epoch - 47ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1539 - accuracy: 0.5049 - val_loss: 1.1653 - val_accuracy: 0.3896 - 330ms/epoch - 47ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1456 - accuracy: 0.5213 - val_loss: 1.1514 - val_accuracy: 0.3766 - 328ms/epoch - 47ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1214 - accuracy: 0.5377 - val_loss: 1.1637 - val_accuracy: 0.3896 - 345ms/epoch - 49ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1344 - accuracy: 0.5180 - val_loss: 1.1403 - val_accuracy: 0.4026 - 325ms/epoch - 46ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1372 - accuracy: 0.5311 - val_loss: 1.1228 - val_accuracy: 0.4156 - 342ms/epoch - 49ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1133 - accuracy: 0.5377 - val_loss: 1.1071 - val_accuracy: 0.4805 - 350ms/epoch - 50ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1301 - accuracy: 0.5213 - val_loss: 1.1200 - val_accuracy: 0.4286 - 364ms/epoch - 52ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1062 - accuracy: 0.5410 - val_loss: 1.0950 - val_accuracy: 0.4286 - 395ms/epoch - 56ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1073 - accuracy: 0.5148 - val_loss: 1.0989 - val_accuracy: 0.4286 - 390ms/epoch - 56ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1019 - accuracy: 0.5311 - val_loss: 1.0787 - val_accuracy: 0.5325 - 371ms/epoch - 53ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1094 - accuracy: 0.5311 - val_loss: 1.0885 - val_accuracy: 0.5455 - 348ms/epoch - 50ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0950 - accuracy: 0.5475 - val_loss: 1.0765 - val_accuracy: 0.5325 - 345ms/epoch - 49ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0848 - accuracy: 0.5574 - val_loss: 1.0759 - val_accuracy: 0.5455 - 336ms/epoch - 48ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1022 - accuracy: 0.5443 - val_loss: 1.0965 - val_accuracy: 0.4675 - 346ms/epoch - 49ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0920 - accuracy: 0.5574 - val_loss: 1.0800 - val_accuracy: 0.4675 - 336ms/epoch - 48ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0821 - accuracy: 0.5443 - val_loss: 1.0924 - val_accuracy: 0.4545 - 340ms/epoch - 49ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0972 - accuracy: 0.5410 - val_loss: 1.1074 - val_accuracy: 0.4545 - 348ms/epoch - 50ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0721 - accuracy: 0.5410 - val_loss: 1.0907 - val_accuracy: 0.4545 - 330ms/epoch - 47ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0399 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:45:07,815] Trial 54 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'linear', 'activation_func_3': 'tanh', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 156}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3861 - accuracy: 0.2492 - val_loss: 1.3854 - val_accuracy: 0.2597 - 5s/epoch - 488ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3854 - accuracy: 0.2689 - val_loss: 1.3837 - val_accuracy: 0.2597 - 269ms/epoch - 27ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3844 - accuracy: 0.2656 - val_loss: 1.3816 - val_accuracy: 0.2597 - 288ms/epoch - 29ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3822 - accuracy: 0.2885 - val_loss: 1.3787 - val_accuracy: 0.3636 - 296ms/epoch - 30ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3778 - accuracy: 0.3803 - val_loss: 1.3730 - val_accuracy: 0.3117 - 309ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3671 - accuracy: 0.3869 - val_loss: 1.3599 - val_accuracy: 0.3247 - 284ms/epoch - 28ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.3492 - accuracy: 0.4295 - val_loss: 1.3363 - val_accuracy: 0.3766 - 293ms/epoch - 29ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.3055 - accuracy: 0.4328 - val_loss: 1.3094 - val_accuracy: 0.3506 - 283ms/epoch - 28ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2646 - accuracy: 0.4459 - val_loss: 1.2693 - val_accuracy: 0.3636 - 287ms/epoch - 29ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.2194 - accuracy: 0.4525 - val_loss: 1.2427 - val_accuracy: 0.3636 - 292ms/epoch - 29ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1751 - accuracy: 0.4656 - val_loss: 1.2103 - val_accuracy: 0.3636 - 297ms/epoch - 30ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1737 - accuracy: 0.4787 - val_loss: 1.1933 - val_accuracy: 0.3896 - 299ms/epoch - 30ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1671 - accuracy: 0.4984 - val_loss: 1.1712 - val_accuracy: 0.4156 - 294ms/epoch - 29ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1497 - accuracy: 0.4918 - val_loss: 1.1525 - val_accuracy: 0.4026 - 283ms/epoch - 28ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1310 - accuracy: 0.5049 - val_loss: 1.1454 - val_accuracy: 0.3766 - 287ms/epoch - 29ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1187 - accuracy: 0.4885 - val_loss: 1.1341 - val_accuracy: 0.4026 - 292ms/epoch - 29ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1022 - accuracy: 0.5180 - val_loss: 1.1271 - val_accuracy: 0.4156 - 285ms/epoch - 28ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1060 - accuracy: 0.5082 - val_loss: 1.1172 - val_accuracy: 0.4156 - 316ms/epoch - 32ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1302 - accuracy: 0.5049 - val_loss: 1.1275 - val_accuracy: 0.4026 - 317ms/epoch - 32ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0957 - accuracy: 0.5180 - val_loss: 1.1093 - val_accuracy: 0.4805 - 313ms/epoch - 31ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0783 - accuracy: 0.5213 - val_loss: 1.1064 - val_accuracy: 0.4416 - 315ms/epoch - 32ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0808 - accuracy: 0.5311 - val_loss: 1.1037 - val_accuracy: 0.4156 - 301ms/epoch - 30ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0904 - accuracy: 0.5377 - val_loss: 1.1024 - val_accuracy: 0.4675 - 317ms/epoch - 32ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0684 - accuracy: 0.5475 - val_loss: 1.0997 - val_accuracy: 0.4416 - 303ms/epoch - 30ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0498 - accuracy: 0.5377 - val_loss: 1.0952 - val_accuracy: 0.4545 - 294ms/epoch - 29ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0794 - accuracy: 0.5279 - val_loss: 1.0701 - val_accuracy: 0.5844 - 298ms/epoch - 30ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0655 - accuracy: 0.5607 - val_loss: 1.0783 - val_accuracy: 0.4935 - 288ms/epoch - 29ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0815 - accuracy: 0.5344 - val_loss: 1.0766 - val_accuracy: 0.4935 - 305ms/epoch - 30ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0531 - accuracy: 0.5738 - val_loss: 1.0824 - val_accuracy: 0.4675 - 309ms/epoch - 31ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0434 - accuracy: 0.5836 - val_loss: 1.0763 - val_accuracy: 0.4545 - 294ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0703 - accuracy: 0.5607 - val_loss: 1.0768 - val_accuracy: 0.4805 - 290ms/epoch - 29ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0226 - accuracy: 0.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:45:23,357] Trial 55 finished with value: 0.6176470518112183 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 143}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3750 - accuracy: 0.2754 - val_loss: 1.3606 - val_accuracy: 0.3247 - 4s/epoch - 406ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3225 - accuracy: 0.4393 - val_loss: 1.2947 - val_accuracy: 0.4026 - 329ms/epoch - 33ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.2626 - accuracy: 0.5082 - val_loss: 1.2491 - val_accuracy: 0.4156 - 327ms/epoch - 33ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2269 - accuracy: 0.5049 - val_loss: 1.1962 - val_accuracy: 0.4156 - 340ms/epoch - 34ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.1860 - accuracy: 0.5246 - val_loss: 1.1704 - val_accuracy: 0.4416 - 324ms/epoch - 32ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1703 - accuracy: 0.5279 - val_loss: 1.1720 - val_accuracy: 0.4545 - 323ms/epoch - 32ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1507 - accuracy: 0.5410 - val_loss: 1.1559 - val_accuracy: 0.4156 - 329ms/epoch - 33ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1539 - accuracy: 0.5377 - val_loss: 1.1393 - val_accuracy: 0.4935 - 323ms/epoch - 32ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1147 - accuracy: 0.5377 - val_loss: 1.0955 - val_accuracy: 0.4545 - 332ms/epoch - 33ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.0666 - accuracy: 0.5770 - val_loss: 1.0789 - val_accuracy: 0.4675 - 330ms/epoch - 33ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.0764 - accuracy: 0.5475 - val_loss: 1.0598 - val_accuracy: 0.4805 - 323ms/epoch - 32ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.0615 - accuracy: 0.5508 - val_loss: 1.0410 - val_accuracy: 0.5455 - 325ms/epoch - 33ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.0692 - accuracy: 0.5639 - val_loss: 1.0212 - val_accuracy: 0.5584 - 329ms/epoch - 33ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0018 - accuracy: 0.5902 - val_loss: 0.9861 - val_accuracy: 0.5455 - 328ms/epoch - 33ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0135 - accuracy: 0.5902 - val_loss: 0.9736 - val_accuracy: 0.5844 - 327ms/epoch - 33ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0022 - accuracy: 0.6164 - val_loss: 0.9774 - val_accuracy: 0.5844 - 327ms/epoch - 33ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0018 - accuracy: 0.5672 - val_loss: 1.0198 - val_accuracy: 0.5065 - 340ms/epoch - 34ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 0.9754 - accuracy: 0.5902 - val_loss: 0.9614 - val_accuracy: 0.5714 - 326ms/epoch - 33ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 0.9957 - accuracy: 0.6033 - val_loss: 0.9500 - val_accuracy: 0.5974 - 330ms/epoch - 33ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 0.9422 - accuracy: 0.6131 - val_loss: 0.9777 - val_accuracy: 0.5584 - 357ms/epoch - 36ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 0.9532 - accuracy: 0.5934 - val_loss: 0.9648 - val_accuracy: 0.5714 - 358ms/epoch - 36ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 0.9485 - accuracy: 0.6459 - val_loss: 0.9222 - val_accuracy: 0.6364 - 352ms/epoch - 35ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 0.9702 - accuracy: 0.6262 - val_loss: 0.9427 - val_accuracy: 0.5974 - 350ms/epoch - 35ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 0.9395 - accuracy: 0.6295 - val_loss: 0.9210 - val_accuracy: 0.6494 - 346ms/epoch - 35ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9126 - accuracy: 0.6426 - val_loss: 0.9149 - val_accuracy: 0.6364 - 339ms/epoch - 34ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.8935 - accuracy: 0.6426 - val_loss: 0.8734 - val_accuracy: 0.6364 - 345ms/epoch - 35ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.8785 - accuracy: 0.6525 - val_loss: 0.9514 - val_accuracy: 0.5844 - 344ms/epoch - 34ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9233 - accuracy: 0.6393 - val_loss: 0.9423 - val_accuracy: 0.6234 - 329ms/epoch - 33ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.8921 - accuracy: 0.6393 - val_loss: 0.9525 - val_accuracy: 0.5584 - 337ms/epoch - 34ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.8725 - accuracy: 0.6230 - val_loss: 0.8851 - val_accuracy: 0.6753 - 329ms/epoch - 33ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.8476 - accuracy: 0.6623 - val_loss: 0.9207 - val_accuracy: 0.6234 - 330ms/epoch - 33ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8943 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:45:39,188] Trial 56 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'selu', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 147}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3843 - accuracy: 0.2951 - val_loss: 1.3769 - val_accuracy: 0.3766 - 4s/epoch - 571ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3754 - accuracy: 0.3672 - val_loss: 1.3652 - val_accuracy: 0.3117 - 326ms/epoch - 47ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3547 - accuracy: 0.4033 - val_loss: 1.3432 - val_accuracy: 0.3506 - 341ms/epoch - 49ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3209 - accuracy: 0.4230 - val_loss: 1.3047 - val_accuracy: 0.3766 - 353ms/epoch - 50ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2774 - accuracy: 0.4426 - val_loss: 1.2700 - val_accuracy: 0.3766 - 350ms/epoch - 50ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2361 - accuracy: 0.4525 - val_loss: 1.2344 - val_accuracy: 0.3636 - 340ms/epoch - 49ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2076 - accuracy: 0.4754 - val_loss: 1.2063 - val_accuracy: 0.3766 - 346ms/epoch - 49ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2222 - accuracy: 0.4820 - val_loss: 1.1923 - val_accuracy: 0.4156 - 342ms/epoch - 49ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.1902 - accuracy: 0.4689 - val_loss: 1.1983 - val_accuracy: 0.4156 - 343ms/epoch - 49ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2174 - accuracy: 0.4623 - val_loss: 1.1778 - val_accuracy: 0.4156 - 338ms/epoch - 48ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1491 - accuracy: 0.5016 - val_loss: 1.1632 - val_accuracy: 0.3636 - 353ms/epoch - 50ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1422 - accuracy: 0.5311 - val_loss: 1.1854 - val_accuracy: 0.4286 - 341ms/epoch - 49ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1390 - accuracy: 0.5213 - val_loss: 1.1547 - val_accuracy: 0.4026 - 339ms/epoch - 48ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1490 - accuracy: 0.5049 - val_loss: 1.1412 - val_accuracy: 0.4156 - 348ms/epoch - 50ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1076 - accuracy: 0.5344 - val_loss: 1.1305 - val_accuracy: 0.4545 - 337ms/epoch - 48ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1401 - accuracy: 0.5410 - val_loss: 1.1207 - val_accuracy: 0.4675 - 340ms/epoch - 49ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1613 - accuracy: 0.5049 - val_loss: 1.1191 - val_accuracy: 0.4805 - 344ms/epoch - 49ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1242 - accuracy: 0.5180 - val_loss: 1.1117 - val_accuracy: 0.4805 - 349ms/epoch - 50ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1105 - accuracy: 0.5475 - val_loss: 1.0804 - val_accuracy: 0.4416 - 351ms/epoch - 50ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1460 - accuracy: 0.5148 - val_loss: 1.1017 - val_accuracy: 0.5195 - 366ms/epoch - 52ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1332 - accuracy: 0.5344 - val_loss: 1.0733 - val_accuracy: 0.5065 - 364ms/epoch - 52ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.0881 - accuracy: 0.5541 - val_loss: 1.0810 - val_accuracy: 0.4805 - 368ms/epoch - 53ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.0908 - accuracy: 0.5344 - val_loss: 1.0713 - val_accuracy: 0.4935 - 374ms/epoch - 53ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.0993 - accuracy: 0.5344 - val_loss: 1.0714 - val_accuracy: 0.4935 - 357ms/epoch - 51ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0799 - accuracy: 0.5311 - val_loss: 1.0467 - val_accuracy: 0.4935 - 354ms/epoch - 51ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0797 - accuracy: 0.5443 - val_loss: 1.0378 - val_accuracy: 0.5195 - 346ms/epoch - 49ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0790 - accuracy: 0.5541 - val_loss: 1.0230 - val_accuracy: 0.5455 - 343ms/epoch - 49ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0662 - accuracy: 0.5607 - val_loss: 1.0087 - val_accuracy: 0.5455 - 370ms/epoch - 53ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0566 - accuracy: 0.5574 - val_loss: 1.0209 - val_accuracy: 0.5325 - 345ms/epoch - 49ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0547 - accuracy: 0.5574 - val_loss: 1.0553 - val_accuracy: 0.4805 - 342ms/epoch - 49ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0688 - accuracy: 0.5344 - val_loss: 1.0064 - val_accuracy: 0.5195 - 346ms/epoch - 49ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0295 - accuracy: 0.5508 - val_loss: 1.0051 - val_accuracy: 0.4935 - 348ms/epoch - 50ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0079 - accuracy: 0.6000 - val_loss: 0.9946 - val_accuracy: 0.4935 - 352ms/epoch - 50ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0265 - accuracy: 0.6033 - val_loss: 0.9886 - val_accuracy: 0.5065 - 343ms/epoch - 49ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0291 - accuracy: 0.5803 - val_loss: 0.9698 - val_accuracy: 0.5714 - 343ms/epoch - 49ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 0.9795 - accuracy: 0.5770 - val_loss: 0.9652 - val_accuracy: 0.5584 - 344ms/epoch - 49ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0139 - accuracy: 0.5738 - val_loss: 0.9680 - val_accuracy: 0.5974 - 356ms/epoch - 51ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 0.9743 - accuracy: 0.6164 - val_loss: 0.9624 - val_accuracy: 0.5195 - 338ms/epoch - 48ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 0.9782 - accuracy: 0.5738 - val_loss: 0.9706 - val_accuracy: 0.5195 - 345ms/epoch - 49ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 0.9799 - accuracy: 0.6197 - val_loss: 0.9485 - val_accuracy: 0.5195 - 379ms/epoch - 54ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 0.9777 - accuracy: 0.6066 - val_loss: 0.9229 - val_accuracy: 0.6364 - 398ms/epoch - 57ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 0.9785 - accuracy: 0.6033 - val_loss: 0.9232 - val_accuracy: 0.6104 - 376ms/epoch - 54ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9464 - accuracy: 0.6197 - val_loss: 0.9053 - val_accuracy: 0.5714 - 350ms/epoch - 50ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 0.9431 - accuracy: 0.6492 - val_loss: 0.9029 - val_accuracy: 0.5844 - 351ms/epoch - 50ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9542 - accuracy: 0.6197 - val_loss: 0.8981 - val_accuracy: 0.5844 - 358ms/epoch - 51ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9671 - accuracy: 0.6164 - val_loss: 0.9114 - val_accuracy: 0.5325 - 364ms/epoch - 52ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9450 - accuracy: 0.6230 - val_loss: 0.9009 - val_accuracy: 0.5714 - 370ms/epoch - 53ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 0.9623 - accuracy: 0.6295 - val_loss: 0.9148 - val_accuracy: 0.5844 - 376ms/epoch - 54ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 0.9425 - accuracy: 0.6459 - val_loss: 0.8883 - val_accuracy: 0.5714 - 389ms/epoch - 56ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 0.9388 - accuracy: 0.6689 - val_loss: 0.8944 - val_accuracy: 0.5974 - 364ms/epoch - 52ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 0.9080 - accuracy: 0.6656 - val_loss: 0.8892 - val_accuracy: 0.6234 - 388ms/epoch - 55ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 0.9482 - accuracy: 0.6131 - val_loss: 0.8888 - val_accuracy: 0.5974 - 358ms/epoch - 51ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 0.9180 - accuracy: 0.6459 - val_loss: 0.9257 - val_accuracy: 0.5844 - 376ms/epoch - 54ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 0.9588 - accuracy: 0.6328 - val_loss: 0.9293 - val_accuracy: 0.5584 - 375ms/epoch - 54ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9138 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:46:04,671] Trial 57 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'selu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 159}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 6s - loss: 1.3851 - accuracy: 0.3311 - val_loss: 1.3831 - val_accuracy: 0.4026 - 6s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3822 - accuracy: 0.3574 - val_loss: 1.3791 - val_accuracy: 0.3506 - 300ms/epoch - 60ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3767 - accuracy: 0.4066 - val_loss: 1.3722 - val_accuracy: 0.4805 - 333ms/epoch - 67ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3678 - accuracy: 0.4295 - val_loss: 1.3610 - val_accuracy: 0.4935 - 329ms/epoch - 66ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3488 - accuracy: 0.4689 - val_loss: 1.3415 - val_accuracy: 0.4805 - 318ms/epoch - 64ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3221 - accuracy: 0.4689 - val_loss: 1.3124 - val_accuracy: 0.4416 - 323ms/epoch - 65ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3069 - accuracy: 0.4689 - val_loss: 1.2801 - val_accuracy: 0.3636 - 307ms/epoch - 61ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2630 - accuracy: 0.4820 - val_loss: 1.2488 - val_accuracy: 0.3636 - 306ms/epoch - 61ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2362 - accuracy: 0.4754 - val_loss: 1.2192 - val_accuracy: 0.3506 - 306ms/epoch - 61ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2313 - accuracy: 0.4820 - val_loss: 1.2089 - val_accuracy: 0.3766 - 293ms/epoch - 59ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1980 - accuracy: 0.5279 - val_loss: 1.1988 - val_accuracy: 0.3896 - 300ms/epoch - 60ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1927 - accuracy: 0.4885 - val_loss: 1.1818 - val_accuracy: 0.3766 - 299ms/epoch - 60ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1795 - accuracy: 0.5115 - val_loss: 1.1676 - val_accuracy: 0.3896 - 297ms/epoch - 59ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1728 - accuracy: 0.5016 - val_loss: 1.1570 - val_accuracy: 0.4026 - 265ms/epoch - 53ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1604 - accuracy: 0.4852 - val_loss: 1.1461 - val_accuracy: 0.3896 - 266ms/epoch - 53ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1465 - accuracy: 0.5115 - val_loss: 1.1304 - val_accuracy: 0.4156 - 261ms/epoch - 52ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1335 - accuracy: 0.5213 - val_loss: 1.1127 - val_accuracy: 0.4026 - 262ms/epoch - 52ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1223 - accuracy: 0.5213 - val_loss: 1.1035 - val_accuracy: 0.4026 - 268ms/epoch - 54ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1345 - accuracy: 0.5148 - val_loss: 1.1116 - val_accuracy: 0.4286 - 262ms/epoch - 52ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1143 - accuracy: 0.5180 - val_loss: 1.1026 - val_accuracy: 0.4545 - 270ms/epoch - 54ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1041 - accuracy: 0.5410 - val_loss: 1.0896 - val_accuracy: 0.4675 - 266ms/epoch - 53ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.0937 - accuracy: 0.5311 - val_loss: 1.0776 - val_accuracy: 0.4675 - 271ms/epoch - 54ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1111 - accuracy: 0.5508 - val_loss: 1.0750 - val_accuracy: 0.4675 - 271ms/epoch - 54ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0777 - accuracy: 0.5475 - val_loss: 1.0674 - val_accuracy: 0.4805 - 268ms/epoch - 54ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.0631 - accuracy: 0.5541 - val_loss: 1.0530 - val_accuracy: 0.4805 - 267ms/epoch - 53ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0530 - accuracy: 0.5738 - val_loss: 1.0388 - val_accuracy: 0.4675 - 266ms/epoch - 53ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0738 - accuracy: 0.5475 - val_loss: 1.0270 - val_accuracy: 0.5455 - 261ms/epoch - 52ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0595 - accuracy: 0.5803 - val_loss: 1.0175 - val_accuracy: 0.4935 - 271ms/epoch - 54ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0390 - accuracy: 0.5803 - val_loss: 1.0089 - val_accuracy: 0.5195 - 275ms/epoch - 55ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0543 - accuracy: 0.5639 - val_loss: 0.9954 - val_accuracy: 0.5195 - 274ms/epoch - 55ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0449 - accuracy: 0.5738 - val_loss: 0.9887 - val_accuracy: 0.5455 - 264ms/epoch - 53ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0181 - accuracy: 0.5836 - val_loss: 0.9795 - val_accuracy: 0.5195 - 270ms/epoch - 54ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0351 - accuracy: 0.5934 - val_loss: 0.9716 - val_accuracy: 0.5325 - 265ms/epoch - 53ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 0.9932 - accuracy: 0.6033 - val_loss: 0.9625 - val_accuracy: 0.5455 - 265ms/epoch - 53ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0004 - accuracy: 0.5738 - val_loss: 0.9365 - val_accuracy: 0.6104 - 267ms/epoch - 53ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0195 - accuracy: 0.5770 - val_loss: 0.9282 - val_accuracy: 0.5455 - 260ms/epoch - 52ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.9535 - accuracy: 0.6131 - val_loss: 0.9305 - val_accuracy: 0.5714 - 264ms/epoch - 53ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.9865 - accuracy: 0.6164 - val_loss: 0.9172 - val_accuracy: 0.5455 - 263ms/epoch - 53ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.9651 - accuracy: 0.5672 - val_loss: 0.8982 - val_accuracy: 0.5584 - 263ms/epoch - 53ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.9539 - accuracy: 0.6361 - val_loss: 0.9017 - val_accuracy: 0.6234 - 268ms/epoch - 54ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.9454 - accuracy: 0.6262 - val_loss: 0.8877 - val_accuracy: 0.5455 - 294ms/epoch - 59ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.9107 - accuracy: 0.6656 - val_loss: 0.8881 - val_accuracy: 0.5584 - 281ms/epoch - 56ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.9564 - accuracy: 0.6164 - val_loss: 0.8769 - val_accuracy: 0.6364 - 281ms/epoch - 56ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.9531 - accuracy: 0.6361 - val_loss: 0.8915 - val_accuracy: 0.5974 - 279ms/epoch - 56ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.9277 - accuracy: 0.6230 - val_loss: 0.8771 - val_accuracy: 0.5584 - 280ms/epoch - 56ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9363 - accuracy: 0.6262 - val_loss: 0.8969 - val_accuracy: 0.5584 - 268ms/epoch - 54ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9716 - accuracy: 0.6230 - val_loss: 0.9073 - val_accuracy: 0.5455 - 275ms/epoch - 55ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 0.9109 - accuracy: 0.6328 - val_loss: 0.8779 - val_accuracy: 0.6234 - 262ms/epoch - 52ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8961 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:46:25,343] Trial 58 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 175}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3786 - accuracy: 0.2492 - val_loss: 1.3666 - val_accuracy: 0.3247 - 5s/epoch - 543ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3321 - accuracy: 0.4623 - val_loss: 1.2991 - val_accuracy: 0.4156 - 411ms/epoch - 41ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.2706 - accuracy: 0.4787 - val_loss: 1.2539 - val_accuracy: 0.4156 - 427ms/epoch - 43ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2292 - accuracy: 0.4885 - val_loss: 1.2217 - val_accuracy: 0.4545 - 445ms/epoch - 44ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.1934 - accuracy: 0.5279 - val_loss: 1.1939 - val_accuracy: 0.4156 - 424ms/epoch - 42ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1670 - accuracy: 0.5115 - val_loss: 1.1694 - val_accuracy: 0.4156 - 427ms/epoch - 43ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1498 - accuracy: 0.5213 - val_loss: 1.1655 - val_accuracy: 0.4286 - 424ms/epoch - 42ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1586 - accuracy: 0.5213 - val_loss: 1.1384 - val_accuracy: 0.4286 - 427ms/epoch - 43ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1182 - accuracy: 0.5475 - val_loss: 1.0942 - val_accuracy: 0.4286 - 432ms/epoch - 43ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.0948 - accuracy: 0.5475 - val_loss: 1.0710 - val_accuracy: 0.4545 - 445ms/epoch - 45ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.0766 - accuracy: 0.5607 - val_loss: 1.0522 - val_accuracy: 0.4935 - 426ms/epoch - 43ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.0675 - accuracy: 0.5607 - val_loss: 1.0292 - val_accuracy: 0.5065 - 426ms/epoch - 43ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.0639 - accuracy: 0.5344 - val_loss: 1.0309 - val_accuracy: 0.5455 - 439ms/epoch - 44ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0405 - accuracy: 0.5836 - val_loss: 1.0049 - val_accuracy: 0.4935 - 424ms/epoch - 42ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0302 - accuracy: 0.5770 - val_loss: 0.9783 - val_accuracy: 0.5325 - 449ms/epoch - 45ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0180 - accuracy: 0.5836 - val_loss: 0.9802 - val_accuracy: 0.6234 - 468ms/epoch - 47ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 0.9987 - accuracy: 0.6033 - val_loss: 1.0240 - val_accuracy: 0.4935 - 467ms/epoch - 47ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 0.9687 - accuracy: 0.6131 - val_loss: 0.9465 - val_accuracy: 0.6364 - 461ms/epoch - 46ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 0.9738 - accuracy: 0.6098 - val_loss: 0.9190 - val_accuracy: 0.5844 - 442ms/epoch - 44ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 0.9327 - accuracy: 0.6131 - val_loss: 0.9624 - val_accuracy: 0.5714 - 428ms/epoch - 43ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 0.9130 - accuracy: 0.6459 - val_loss: 0.9425 - val_accuracy: 0.6234 - 430ms/epoch - 43ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 0.8989 - accuracy: 0.6098 - val_loss: 0.8977 - val_accuracy: 0.6364 - 431ms/epoch - 43ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 0.9012 - accuracy: 0.6492 - val_loss: 0.9400 - val_accuracy: 0.5714 - 431ms/epoch - 43ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 0.9298 - accuracy: 0.6033 - val_loss: 0.9324 - val_accuracy: 0.5714 - 428ms/epoch - 43ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9083 - accuracy: 0.6525 - val_loss: 0.8785 - val_accuracy: 0.6753 - 431ms/epoch - 43ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.8748 - accuracy: 0.6459 - val_loss: 0.8816 - val_accuracy: 0.6494 - 433ms/epoch - 43ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.8745 - accuracy: 0.6492 - val_loss: 0.9936 - val_accuracy: 0.5455 - 439ms/epoch - 44ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.8661 - accuracy: 0.6328 - val_loss: 0.9032 - val_accuracy: 0.6364 - 430ms/epoch - 43ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.8423 - accuracy: 0.6492 - val_loss: 0.8910 - val_accuracy: 0.6623 - 459ms/epoch - 46ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.8792 - accuracy: 0.6459 - val_loss: 0.9005 - val_accuracy: 0.6104 - 428ms/epoch - 43ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8872 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:46:45,803] Trial 59 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'tanh', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 184}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3861 - accuracy: 0.2721 - val_loss: 1.3848 - val_accuracy: 0.2597 - 4s/epoch - 622ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3852 - accuracy: 0.2656 - val_loss: 1.3835 - val_accuracy: 0.2597 - 346ms/epoch - 49ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3836 - accuracy: 0.2656 - val_loss: 1.3817 - val_accuracy: 0.2597 - 364ms/epoch - 52ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3810 - accuracy: 0.2689 - val_loss: 1.3778 - val_accuracy: 0.3117 - 364ms/epoch - 52ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3760 - accuracy: 0.3738 - val_loss: 1.3733 - val_accuracy: 0.3766 - 368ms/epoch - 53ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3654 - accuracy: 0.4656 - val_loss: 1.3625 - val_accuracy: 0.3636 - 386ms/epoch - 55ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.3465 - accuracy: 0.4623 - val_loss: 1.3430 - val_accuracy: 0.3636 - 361ms/epoch - 52ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.3163 - accuracy: 0.4885 - val_loss: 1.3247 - val_accuracy: 0.3896 - 379ms/epoch - 54ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2888 - accuracy: 0.4525 - val_loss: 1.2806 - val_accuracy: 0.3766 - 361ms/epoch - 52ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2568 - accuracy: 0.4426 - val_loss: 1.2559 - val_accuracy: 0.3636 - 383ms/epoch - 55ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2184 - accuracy: 0.4656 - val_loss: 1.2374 - val_accuracy: 0.3896 - 399ms/epoch - 57ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1987 - accuracy: 0.4754 - val_loss: 1.2232 - val_accuracy: 0.3636 - 395ms/epoch - 56ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1890 - accuracy: 0.4787 - val_loss: 1.2012 - val_accuracy: 0.4026 - 390ms/epoch - 56ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1830 - accuracy: 0.4852 - val_loss: 1.1897 - val_accuracy: 0.3896 - 385ms/epoch - 55ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1610 - accuracy: 0.4951 - val_loss: 1.1748 - val_accuracy: 0.3766 - 381ms/epoch - 54ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1693 - accuracy: 0.4951 - val_loss: 1.1633 - val_accuracy: 0.3766 - 362ms/epoch - 52ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1545 - accuracy: 0.5016 - val_loss: 1.1625 - val_accuracy: 0.4026 - 363ms/epoch - 52ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1499 - accuracy: 0.5016 - val_loss: 1.1662 - val_accuracy: 0.3896 - 364ms/epoch - 52ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1623 - accuracy: 0.4918 - val_loss: 1.1449 - val_accuracy: 0.3766 - 374ms/epoch - 53ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1347 - accuracy: 0.4787 - val_loss: 1.1551 - val_accuracy: 0.4805 - 362ms/epoch - 52ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1584 - accuracy: 0.4951 - val_loss: 1.1281 - val_accuracy: 0.4286 - 377ms/epoch - 54ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1091 - accuracy: 0.4918 - val_loss: 1.1154 - val_accuracy: 0.4286 - 375ms/epoch - 54ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1198 - accuracy: 0.5180 - val_loss: 1.1158 - val_accuracy: 0.3896 - 363ms/epoch - 52ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1140 - accuracy: 0.5115 - val_loss: 1.1042 - val_accuracy: 0.4156 - 362ms/epoch - 52ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0937 - accuracy: 0.5246 - val_loss: 1.0966 - val_accuracy: 0.4156 - 381ms/epoch - 54ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1000 - accuracy: 0.5410 - val_loss: 1.0849 - val_accuracy: 0.5065 - 380ms/epoch - 54ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1050 - accuracy: 0.5279 - val_loss: 1.0920 - val_accuracy: 0.5065 - 363ms/epoch - 52ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0899 - accuracy: 0.5377 - val_loss: 1.0787 - val_accuracy: 0.4935 - 393ms/epoch - 56ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0916 - accuracy: 0.5607 - val_loss: 1.0683 - val_accuracy: 0.5325 - 364ms/epoch - 52ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0838 - accuracy: 0.5410 - val_loss: 1.0695 - val_accuracy: 0.4675 - 368ms/epoch - 53ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0653 - accuracy: 0.5541 - val_loss: 1.0624 - val_accuracy: 0.4805 - 375ms/epoch - 54ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0569 - accuracy: 0.5770 - val_loss: 1.0668 - val_accuracy: 0.4675 - 367ms/epoch - 52ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0843 - accuracy: 0.5410 - val_loss: 1.0628 - val_accuracy: 0.4935 - 376ms/epoch - 54ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0405 - accuracy: 0.5672 - val_loss: 1.0515 - val_accuracy: 0.4675 - 368ms/epoch - 53ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0263 - accuracy: 0.5803 - val_loss: 1.0430 - val_accuracy: 0.4935 - 365ms/epoch - 52ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0357 - accuracy: 0.5607 - val_loss: 1.0406 - val_accuracy: 0.5065 - 373ms/epoch - 53ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 1.0595 - accuracy: 0.5574 - val_loss: 1.0529 - val_accuracy: 0.5714 - 373ms/epoch - 53ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0469 - accuracy: 0.5607 - val_loss: 1.0381 - val_accuracy: 0.4935 - 371ms/epoch - 53ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0210 - accuracy: 0.5541 - val_loss: 1.0464 - val_accuracy: 0.4935 - 367ms/epoch - 52ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0543 - accuracy: 0.5541 - val_loss: 1.0068 - val_accuracy: 0.4935 - 365ms/epoch - 52ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 1.0183 - accuracy: 0.5902 - val_loss: 0.9955 - val_accuracy: 0.6234 - 370ms/epoch - 53ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0654 - accuracy: 0.5607 - val_loss: 0.9820 - val_accuracy: 0.6234 - 368ms/epoch - 53ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9993 - accuracy: 0.6066 - val_loss: 0.9728 - val_accuracy: 0.5584 - 370ms/epoch - 53ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 1.0118 - accuracy: 0.6033 - val_loss: 0.9643 - val_accuracy: 0.5584 - 376ms/epoch - 54ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9981 - accuracy: 0.5902 - val_loss: 0.9800 - val_accuracy: 0.5714 - 362ms/epoch - 52ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9945 - accuracy: 0.6131 - val_loss: 0.9926 - val_accuracy: 0.5195 - 367ms/epoch - 52ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9724 - accuracy: 0.5869 - val_loss: 0.9846 - val_accuracy: 0.5065 - 363ms/epoch - 52ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 0.9886 - accuracy: 0.5738 - val_loss: 0.9757 - val_accuracy: 0.5714 - 382ms/epoch - 55ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 0.9672 - accuracy: 0.5934 - val_loss: 0.9556 - val_accuracy: 0.5974 - 366ms/epoch - 52ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 0.9882 - accuracy: 0.5869 - val_loss: 0.9273 - val_accuracy: 0.5844 - 389ms/epoch - 56ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 0.9635 - accuracy: 0.6164 - val_loss: 0.9265 - val_accuracy: 0.6364 - 383ms/epoch - 55ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 0.9883 - accuracy: 0.6033 - val_loss: 0.9280 - val_accuracy: 0.5974 - 364ms/epoch - 52ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 0.9725 - accuracy: 0.6000 - val_loss: 0.9345 - val_accuracy: 0.5974 - 387ms/epoch - 55ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 0.9855 - accuracy: 0.6164 - val_loss: 0.9339 - val_accuracy: 0.5584 - 398ms/epoch - 57ms/step\n",
      "Epoch 55/10000\n",
      "7/7 - 0s - loss: 0.9858 - accuracy: 0.6033 - val_loss: 0.9357 - val_accuracy: 0.5584 - 394ms/epoch - 56ms/step\n",
      "Epoch 56/10000\n",
      "7/7 - 0s - loss: 0.9378 - accuracy: 0.6000 - val_loss: 0.9476 - val_accuracy: 0.5455 - 403ms/epoch - 58ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8659 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:47:12,269] Trial 60 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'swish', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 164}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3859 - accuracy: 0.3213 - val_loss: 1.3845 - val_accuracy: 0.2857 - 4s/epoch - 437ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3842 - accuracy: 0.3246 - val_loss: 1.3812 - val_accuracy: 0.3117 - 294ms/epoch - 29ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3810 - accuracy: 0.3148 - val_loss: 1.3762 - val_accuracy: 0.3377 - 249ms/epoch - 25ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3729 - accuracy: 0.4361 - val_loss: 1.3646 - val_accuracy: 0.3896 - 265ms/epoch - 26ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3564 - accuracy: 0.4393 - val_loss: 1.3406 - val_accuracy: 0.3766 - 267ms/epoch - 27ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3144 - accuracy: 0.4590 - val_loss: 1.2907 - val_accuracy: 0.3766 - 253ms/epoch - 25ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2792 - accuracy: 0.4590 - val_loss: 1.2421 - val_accuracy: 0.3766 - 277ms/epoch - 28ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2535 - accuracy: 0.4525 - val_loss: 1.2149 - val_accuracy: 0.3636 - 257ms/epoch - 26ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2222 - accuracy: 0.4689 - val_loss: 1.1994 - val_accuracy: 0.3896 - 251ms/epoch - 25ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1807 - accuracy: 0.4820 - val_loss: 1.1832 - val_accuracy: 0.3766 - 256ms/epoch - 26ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1685 - accuracy: 0.4787 - val_loss: 1.1649 - val_accuracy: 0.3766 - 261ms/epoch - 26ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1357 - accuracy: 0.5016 - val_loss: 1.1727 - val_accuracy: 0.4026 - 259ms/epoch - 26ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1224 - accuracy: 0.5049 - val_loss: 1.1422 - val_accuracy: 0.3766 - 262ms/epoch - 26ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1235 - accuracy: 0.5082 - val_loss: 1.1333 - val_accuracy: 0.3896 - 255ms/epoch - 25ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1318 - accuracy: 0.4984 - val_loss: 1.1258 - val_accuracy: 0.4026 - 257ms/epoch - 26ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1038 - accuracy: 0.5213 - val_loss: 1.1158 - val_accuracy: 0.3896 - 258ms/epoch - 26ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1259 - accuracy: 0.4820 - val_loss: 1.1083 - val_accuracy: 0.4156 - 272ms/epoch - 27ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0961 - accuracy: 0.5475 - val_loss: 1.1051 - val_accuracy: 0.4675 - 256ms/epoch - 26ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1293 - accuracy: 0.5180 - val_loss: 1.1124 - val_accuracy: 0.4675 - 266ms/epoch - 27ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0872 - accuracy: 0.5377 - val_loss: 1.0911 - val_accuracy: 0.4805 - 254ms/epoch - 25ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0862 - accuracy: 0.5148 - val_loss: 1.0868 - val_accuracy: 0.4545 - 259ms/epoch - 26ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0788 - accuracy: 0.5344 - val_loss: 1.0871 - val_accuracy: 0.4675 - 259ms/epoch - 26ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0666 - accuracy: 0.5377 - val_loss: 1.0891 - val_accuracy: 0.4675 - 254ms/epoch - 25ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0808 - accuracy: 0.5213 - val_loss: 1.0842 - val_accuracy: 0.4675 - 253ms/epoch - 25ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0596 - accuracy: 0.5475 - val_loss: 1.0944 - val_accuracy: 0.4805 - 267ms/epoch - 27ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0775 - accuracy: 0.5213 - val_loss: 1.0678 - val_accuracy: 0.5584 - 255ms/epoch - 26ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0639 - accuracy: 0.5377 - val_loss: 1.0695 - val_accuracy: 0.4545 - 270ms/epoch - 27ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0517 - accuracy: 0.5705 - val_loss: 1.0633 - val_accuracy: 0.4935 - 257ms/epoch - 26ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0707 - accuracy: 0.5475 - val_loss: 1.0646 - val_accuracy: 0.4805 - 255ms/epoch - 26ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0323 - accuracy: 0.5836 - val_loss: 1.0615 - val_accuracy: 0.4805 - 266ms/epoch - 27ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0724 - accuracy: 0.5344 - val_loss: 1.0553 - val_accuracy: 0.4805 - 263ms/epoch - 26ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0415 - accuracy: 0.5508 - val_loss: 1.0462 - val_accuracy: 0.4935 - 269ms/epoch - 27ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0691 - accuracy: 0.5639 - val_loss: 1.0527 - val_accuracy: 0.4935 - 289ms/epoch - 29ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0230 - accuracy: 0.5836 - val_loss: 1.0489 - val_accuracy: 0.5065 - 272ms/epoch - 27ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0163 - accuracy: 0.5934 - val_loss: 1.0328 - val_accuracy: 0.5065 - 275ms/epoch - 27ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0252 - accuracy: 0.5672 - val_loss: 1.0187 - val_accuracy: 0.5065 - 274ms/epoch - 27ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0074 - accuracy: 0.5803 - val_loss: 1.0224 - val_accuracy: 0.5584 - 284ms/epoch - 28ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0220 - accuracy: 0.5639 - val_loss: 1.0149 - val_accuracy: 0.5195 - 276ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0217 - accuracy: 0.6000 - val_loss: 1.0039 - val_accuracy: 0.5195 - 270ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9994 - accuracy: 0.5902 - val_loss: 0.9965 - val_accuracy: 0.5195 - 268ms/epoch - 27ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0145 - accuracy: 0.5574 - val_loss: 0.9777 - val_accuracy: 0.5714 - 263ms/epoch - 26ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9919 - accuracy: 0.5803 - val_loss: 0.9696 - val_accuracy: 0.5455 - 264ms/epoch - 26ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9685 - accuracy: 0.5902 - val_loss: 0.9652 - val_accuracy: 0.5714 - 257ms/epoch - 26ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9675 - accuracy: 0.6000 - val_loss: 0.9468 - val_accuracy: 0.5584 - 259ms/epoch - 26ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9668 - accuracy: 0.6262 - val_loss: 0.9539 - val_accuracy: 0.5714 - 254ms/epoch - 25ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9433 - accuracy: 0.6131 - val_loss: 0.9452 - val_accuracy: 0.5325 - 258ms/epoch - 26ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9738 - accuracy: 0.6164 - val_loss: 0.9226 - val_accuracy: 0.5844 - 267ms/epoch - 27ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9806 - accuracy: 0.6164 - val_loss: 0.9327 - val_accuracy: 0.5844 - 261ms/epoch - 26ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9867 - accuracy: 0.5902 - val_loss: 0.9293 - val_accuracy: 0.6104 - 253ms/epoch - 25ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9619 - accuracy: 0.6098 - val_loss: 0.9282 - val_accuracy: 0.5714 - 267ms/epoch - 27ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9267 - accuracy: 0.6230 - val_loss: 0.9130 - val_accuracy: 0.6104 - 254ms/epoch - 25ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9508 - accuracy: 0.6164 - val_loss: 0.9098 - val_accuracy: 0.5844 - 260ms/epoch - 26ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9430 - accuracy: 0.6262 - val_loss: 0.9564 - val_accuracy: 0.5714 - 258ms/epoch - 26ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9111 - accuracy: 0.6557 - val_loss: 0.9204 - val_accuracy: 0.5974 - 267ms/epoch - 27ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9157 - accuracy: 0.6262 - val_loss: 0.9201 - val_accuracy: 0.5455 - 249ms/epoch - 25ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.8898 - accuracy: 0.6328 - val_loss: 0.8944 - val_accuracy: 0.6234 - 261ms/epoch - 26ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9158 - accuracy: 0.6525 - val_loss: 0.8899 - val_accuracy: 0.6364 - 259ms/epoch - 26ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.8747 - accuracy: 0.6459 - val_loss: 0.8868 - val_accuracy: 0.6234 - 270ms/epoch - 27ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9434 - accuracy: 0.6426 - val_loss: 0.8922 - val_accuracy: 0.6234 - 289ms/epoch - 29ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.8921 - accuracy: 0.6590 - val_loss: 0.8962 - val_accuracy: 0.6104 - 268ms/epoch - 27ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9224 - accuracy: 0.6164 - val_loss: 0.8931 - val_accuracy: 0.6364 - 260ms/epoch - 26ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.8584 - accuracy: 0.6656 - val_loss: 0.9073 - val_accuracy: 0.5714 - 295ms/epoch - 30ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.8926 - accuracy: 0.6328 - val_loss: 0.8834 - val_accuracy: 0.6364 - 285ms/epoch - 29ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.8972 - accuracy: 0.6459 - val_loss: 0.8915 - val_accuracy: 0.6364 - 270ms/epoch - 27ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9285 - accuracy: 0.6361 - val_loss: 0.8957 - val_accuracy: 0.6104 - 274ms/epoch - 27ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.9222 - accuracy: 0.6557 - val_loss: 0.8805 - val_accuracy: 0.6364 - 252ms/epoch - 25ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.8616 - accuracy: 0.6525 - val_loss: 0.8808 - val_accuracy: 0.6234 - 269ms/epoch - 27ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.8670 - accuracy: 0.6656 - val_loss: 0.8677 - val_accuracy: 0.6364 - 254ms/epoch - 25ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.8772 - accuracy: 0.6393 - val_loss: 0.8797 - val_accuracy: 0.6364 - 256ms/epoch - 26ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.9053 - accuracy: 0.6721 - val_loss: 0.8574 - val_accuracy: 0.6364 - 268ms/epoch - 27ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9100 - accuracy: 0.6557 - val_loss: 0.8985 - val_accuracy: 0.6234 - 264ms/epoch - 26ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.8607 - accuracy: 0.6787 - val_loss: 0.9118 - val_accuracy: 0.6234 - 268ms/epoch - 27ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.8908 - accuracy: 0.6459 - val_loss: 0.8911 - val_accuracy: 0.6364 - 255ms/epoch - 25ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.8760 - accuracy: 0.6557 - val_loss: 0.8825 - val_accuracy: 0.6364 - 268ms/epoch - 27ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.8941 - accuracy: 0.6590 - val_loss: 0.8846 - val_accuracy: 0.6234 - 265ms/epoch - 26ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8579 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:47:38,080] Trial 61 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 139}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3857 - accuracy: 0.2918 - val_loss: 1.3846 - val_accuracy: 0.3506 - 5s/epoch - 492ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3839 - accuracy: 0.3475 - val_loss: 1.3817 - val_accuracy: 0.3766 - 275ms/epoch - 27ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3796 - accuracy: 0.3869 - val_loss: 1.3768 - val_accuracy: 0.3766 - 289ms/epoch - 29ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3681 - accuracy: 0.4656 - val_loss: 1.3656 - val_accuracy: 0.3896 - 287ms/epoch - 29ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3447 - accuracy: 0.4525 - val_loss: 1.3409 - val_accuracy: 0.3766 - 286ms/epoch - 29ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2993 - accuracy: 0.4426 - val_loss: 1.3029 - val_accuracy: 0.3896 - 289ms/epoch - 29ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2497 - accuracy: 0.4689 - val_loss: 1.2602 - val_accuracy: 0.3636 - 290ms/epoch - 29ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2294 - accuracy: 0.4393 - val_loss: 1.2232 - val_accuracy: 0.3636 - 289ms/epoch - 29ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2286 - accuracy: 0.4820 - val_loss: 1.2011 - val_accuracy: 0.3636 - 288ms/epoch - 29ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1835 - accuracy: 0.4885 - val_loss: 1.2008 - val_accuracy: 0.3766 - 292ms/epoch - 29ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1773 - accuracy: 0.4721 - val_loss: 1.1731 - val_accuracy: 0.3896 - 297ms/epoch - 30ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1485 - accuracy: 0.4951 - val_loss: 1.1798 - val_accuracy: 0.3896 - 288ms/epoch - 29ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1395 - accuracy: 0.4820 - val_loss: 1.1547 - val_accuracy: 0.3896 - 289ms/epoch - 29ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1212 - accuracy: 0.4951 - val_loss: 1.1364 - val_accuracy: 0.3896 - 288ms/epoch - 29ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1233 - accuracy: 0.5016 - val_loss: 1.1267 - val_accuracy: 0.4545 - 291ms/epoch - 29ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1172 - accuracy: 0.5180 - val_loss: 1.1034 - val_accuracy: 0.4545 - 297ms/epoch - 30ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1182 - accuracy: 0.5148 - val_loss: 1.1004 - val_accuracy: 0.4416 - 294ms/epoch - 29ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1028 - accuracy: 0.5016 - val_loss: 1.1047 - val_accuracy: 0.4805 - 286ms/epoch - 29ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1172 - accuracy: 0.5213 - val_loss: 1.1080 - val_accuracy: 0.4545 - 289ms/epoch - 29ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0975 - accuracy: 0.5082 - val_loss: 1.0939 - val_accuracy: 0.4545 - 288ms/epoch - 29ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0853 - accuracy: 0.5279 - val_loss: 1.0912 - val_accuracy: 0.4545 - 292ms/epoch - 29ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0913 - accuracy: 0.5180 - val_loss: 1.0873 - val_accuracy: 0.4545 - 287ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0876 - accuracy: 0.5410 - val_loss: 1.0890 - val_accuracy: 0.4545 - 290ms/epoch - 29ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0856 - accuracy: 0.5410 - val_loss: 1.0854 - val_accuracy: 0.4675 - 293ms/epoch - 29ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0859 - accuracy: 0.5344 - val_loss: 1.0813 - val_accuracy: 0.4675 - 317ms/epoch - 32ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0535 - accuracy: 0.5607 - val_loss: 1.0651 - val_accuracy: 0.4805 - 290ms/epoch - 29ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0793 - accuracy: 0.5672 - val_loss: 1.0665 - val_accuracy: 0.4675 - 297ms/epoch - 30ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0660 - accuracy: 0.5410 - val_loss: 1.0663 - val_accuracy: 0.4935 - 290ms/epoch - 29ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0673 - accuracy: 0.5377 - val_loss: 1.0573 - val_accuracy: 0.4935 - 289ms/epoch - 29ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0439 - accuracy: 0.5705 - val_loss: 1.0543 - val_accuracy: 0.4935 - 304ms/epoch - 30ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0441 - accuracy: 0.5574 - val_loss: 1.0445 - val_accuracy: 0.5065 - 293ms/epoch - 29ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0556 - accuracy: 0.5410 - val_loss: 1.0458 - val_accuracy: 0.5065 - 292ms/epoch - 29ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0357 - accuracy: 0.5836 - val_loss: 1.0427 - val_accuracy: 0.4805 - 296ms/epoch - 30ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0091 - accuracy: 0.5705 - val_loss: 1.0383 - val_accuracy: 0.4935 - 299ms/epoch - 30ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0400 - accuracy: 0.5639 - val_loss: 1.0181 - val_accuracy: 0.4805 - 293ms/epoch - 29ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0228 - accuracy: 0.5607 - val_loss: 0.9980 - val_accuracy: 0.5195 - 299ms/epoch - 30ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0127 - accuracy: 0.5770 - val_loss: 1.0004 - val_accuracy: 0.5065 - 288ms/epoch - 29ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0324 - accuracy: 0.5803 - val_loss: 1.0031 - val_accuracy: 0.5065 - 300ms/epoch - 30ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0374 - accuracy: 0.5607 - val_loss: 0.9825 - val_accuracy: 0.5065 - 298ms/epoch - 30ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0232 - accuracy: 0.5803 - val_loss: 0.9752 - val_accuracy: 0.5455 - 287ms/epoch - 29ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9902 - accuracy: 0.5705 - val_loss: 0.9570 - val_accuracy: 0.5844 - 288ms/epoch - 29ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0029 - accuracy: 0.5967 - val_loss: 0.9559 - val_accuracy: 0.5714 - 298ms/epoch - 30ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9537 - accuracy: 0.5869 - val_loss: 0.9619 - val_accuracy: 0.5584 - 292ms/epoch - 29ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9821 - accuracy: 0.5934 - val_loss: 0.9431 - val_accuracy: 0.5325 - 303ms/epoch - 30ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9669 - accuracy: 0.6197 - val_loss: 0.9445 - val_accuracy: 0.5325 - 292ms/epoch - 29ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9654 - accuracy: 0.6361 - val_loss: 0.9389 - val_accuracy: 0.5455 - 293ms/epoch - 29ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9575 - accuracy: 0.6197 - val_loss: 0.9276 - val_accuracy: 0.5455 - 299ms/epoch - 30ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9730 - accuracy: 0.6164 - val_loss: 0.9272 - val_accuracy: 0.5584 - 297ms/epoch - 30ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9767 - accuracy: 0.6098 - val_loss: 0.9156 - val_accuracy: 0.6234 - 290ms/epoch - 29ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9742 - accuracy: 0.6164 - val_loss: 0.9159 - val_accuracy: 0.5325 - 309ms/epoch - 31ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9518 - accuracy: 0.6066 - val_loss: 0.9080 - val_accuracy: 0.5844 - 324ms/epoch - 32ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9497 - accuracy: 0.6295 - val_loss: 0.8941 - val_accuracy: 0.5844 - 340ms/epoch - 34ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9211 - accuracy: 0.6164 - val_loss: 0.9233 - val_accuracy: 0.5974 - 337ms/epoch - 34ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9470 - accuracy: 0.6623 - val_loss: 0.9164 - val_accuracy: 0.5974 - 313ms/epoch - 31ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9284 - accuracy: 0.6230 - val_loss: 0.9122 - val_accuracy: 0.5584 - 318ms/epoch - 32ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9670 - accuracy: 0.6557 - val_loss: 0.8992 - val_accuracy: 0.5974 - 288ms/epoch - 29ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9114 - accuracy: 0.6328 - val_loss: 0.8997 - val_accuracy: 0.6234 - 300ms/epoch - 30ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8887 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:48:01,483] Trial 62 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 141}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3856 - accuracy: 0.2820 - val_loss: 1.3847 - val_accuracy: 0.3506 - 4s/epoch - 427ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3836 - accuracy: 0.3803 - val_loss: 1.3804 - val_accuracy: 0.3506 - 358ms/epoch - 36ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3775 - accuracy: 0.3705 - val_loss: 1.3717 - val_accuracy: 0.3506 - 359ms/epoch - 36ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3649 - accuracy: 0.4426 - val_loss: 1.3516 - val_accuracy: 0.3896 - 381ms/epoch - 38ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3325 - accuracy: 0.4918 - val_loss: 1.3071 - val_accuracy: 0.4156 - 356ms/epoch - 36ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2779 - accuracy: 0.5016 - val_loss: 1.2475 - val_accuracy: 0.4156 - 351ms/epoch - 35ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2511 - accuracy: 0.4984 - val_loss: 1.2196 - val_accuracy: 0.4156 - 358ms/epoch - 36ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2208 - accuracy: 0.5246 - val_loss: 1.1956 - val_accuracy: 0.3636 - 357ms/epoch - 36ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2206 - accuracy: 0.4951 - val_loss: 1.1769 - val_accuracy: 0.3896 - 356ms/epoch - 36ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1831 - accuracy: 0.4885 - val_loss: 1.1711 - val_accuracy: 0.3766 - 357ms/epoch - 36ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1436 - accuracy: 0.4984 - val_loss: 1.1605 - val_accuracy: 0.3766 - 361ms/epoch - 36ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1283 - accuracy: 0.4852 - val_loss: 1.1491 - val_accuracy: 0.3896 - 348ms/epoch - 35ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1317 - accuracy: 0.5180 - val_loss: 1.1389 - val_accuracy: 0.3766 - 360ms/epoch - 36ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1115 - accuracy: 0.5180 - val_loss: 1.1229 - val_accuracy: 0.4026 - 353ms/epoch - 35ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1046 - accuracy: 0.5213 - val_loss: 1.1066 - val_accuracy: 0.4416 - 362ms/epoch - 36ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1048 - accuracy: 0.5246 - val_loss: 1.0956 - val_accuracy: 0.4286 - 350ms/epoch - 35ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0999 - accuracy: 0.5574 - val_loss: 1.0938 - val_accuracy: 0.5065 - 360ms/epoch - 36ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0933 - accuracy: 0.5377 - val_loss: 1.0931 - val_accuracy: 0.4286 - 361ms/epoch - 36ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1088 - accuracy: 0.5279 - val_loss: 1.1011 - val_accuracy: 0.4545 - 347ms/epoch - 35ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1030 - accuracy: 0.5475 - val_loss: 1.0756 - val_accuracy: 0.5065 - 368ms/epoch - 37ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0864 - accuracy: 0.5311 - val_loss: 1.0709 - val_accuracy: 0.4675 - 350ms/epoch - 35ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0642 - accuracy: 0.5541 - val_loss: 1.0752 - val_accuracy: 0.4545 - 362ms/epoch - 36ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0724 - accuracy: 0.5475 - val_loss: 1.0694 - val_accuracy: 0.4675 - 378ms/epoch - 38ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0470 - accuracy: 0.5475 - val_loss: 1.0637 - val_accuracy: 0.4805 - 443ms/epoch - 44ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0524 - accuracy: 0.5508 - val_loss: 1.0560 - val_accuracy: 0.4805 - 422ms/epoch - 42ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0529 - accuracy: 0.5344 - val_loss: 1.0304 - val_accuracy: 0.5455 - 431ms/epoch - 43ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0886 - accuracy: 0.5508 - val_loss: 1.0540 - val_accuracy: 0.4675 - 431ms/epoch - 43ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0679 - accuracy: 0.5639 - val_loss: 1.0402 - val_accuracy: 0.4805 - 396ms/epoch - 40ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0546 - accuracy: 0.5770 - val_loss: 1.0409 - val_accuracy: 0.4805 - 406ms/epoch - 41ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0328 - accuracy: 0.5672 - val_loss: 1.0386 - val_accuracy: 0.5065 - 375ms/epoch - 38ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0647 - accuracy: 0.5738 - val_loss: 1.0228 - val_accuracy: 0.4935 - 381ms/epoch - 38ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0318 - accuracy: 0.5770 - val_loss: 1.0148 - val_accuracy: 0.4805 - 362ms/epoch - 36ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0129 - accuracy: 0.5836 - val_loss: 1.0189 - val_accuracy: 0.5065 - 369ms/epoch - 37ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0447 - accuracy: 0.5574 - val_loss: 1.0050 - val_accuracy: 0.5065 - 371ms/epoch - 37ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0231 - accuracy: 0.5967 - val_loss: 0.9869 - val_accuracy: 0.5455 - 360ms/epoch - 36ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9989 - accuracy: 0.5902 - val_loss: 0.9644 - val_accuracy: 0.5195 - 365ms/epoch - 36ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9916 - accuracy: 0.6295 - val_loss: 0.9773 - val_accuracy: 0.5714 - 390ms/epoch - 39ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0005 - accuracy: 0.6066 - val_loss: 0.9668 - val_accuracy: 0.5195 - 393ms/epoch - 39ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9877 - accuracy: 0.5770 - val_loss: 0.9615 - val_accuracy: 0.5195 - 375ms/epoch - 38ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9889 - accuracy: 0.6262 - val_loss: 0.9330 - val_accuracy: 0.5714 - 388ms/epoch - 39ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9624 - accuracy: 0.5902 - val_loss: 0.9065 - val_accuracy: 0.5974 - 375ms/epoch - 38ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9705 - accuracy: 0.6262 - val_loss: 0.9094 - val_accuracy: 0.5584 - 382ms/epoch - 38ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9522 - accuracy: 0.5836 - val_loss: 0.9070 - val_accuracy: 0.6234 - 373ms/epoch - 37ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9518 - accuracy: 0.6295 - val_loss: 0.8928 - val_accuracy: 0.6104 - 390ms/epoch - 39ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9593 - accuracy: 0.6426 - val_loss: 0.9022 - val_accuracy: 0.5844 - 390ms/epoch - 39ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9680 - accuracy: 0.6754 - val_loss: 0.8983 - val_accuracy: 0.5844 - 382ms/epoch - 38ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9195 - accuracy: 0.6459 - val_loss: 0.8939 - val_accuracy: 0.6234 - 364ms/epoch - 36ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9662 - accuracy: 0.6393 - val_loss: 0.9120 - val_accuracy: 0.5844 - 394ms/epoch - 39ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9556 - accuracy: 0.6131 - val_loss: 0.8911 - val_accuracy: 0.6234 - 381ms/epoch - 38ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9159 - accuracy: 0.6328 - val_loss: 0.8960 - val_accuracy: 0.5714 - 363ms/epoch - 36ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9204 - accuracy: 0.6393 - val_loss: 0.8829 - val_accuracy: 0.6234 - 372ms/epoch - 37ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9448 - accuracy: 0.6361 - val_loss: 0.8613 - val_accuracy: 0.6234 - 360ms/epoch - 36ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9270 - accuracy: 0.6393 - val_loss: 0.9128 - val_accuracy: 0.6364 - 361ms/epoch - 36ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9540 - accuracy: 0.6393 - val_loss: 0.8922 - val_accuracy: 0.6234 - 370ms/epoch - 37ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9114 - accuracy: 0.6426 - val_loss: 0.9025 - val_accuracy: 0.5455 - 369ms/epoch - 37ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9003 - accuracy: 0.6721 - val_loss: 0.8867 - val_accuracy: 0.6234 - 376ms/epoch - 38ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9135 - accuracy: 0.6623 - val_loss: 0.8730 - val_accuracy: 0.6364 - 366ms/epoch - 37ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9117 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:48:28,523] Trial 63 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 152}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3856 - accuracy: 0.2951 - val_loss: 1.3848 - val_accuracy: 0.2597 - 5s/epoch - 498ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3835 - accuracy: 0.2689 - val_loss: 1.3814 - val_accuracy: 0.2857 - 318ms/epoch - 32ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3786 - accuracy: 0.3279 - val_loss: 1.3747 - val_accuracy: 0.3766 - 329ms/epoch - 33ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3709 - accuracy: 0.4230 - val_loss: 1.3611 - val_accuracy: 0.3636 - 319ms/epoch - 32ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3476 - accuracy: 0.4557 - val_loss: 1.3306 - val_accuracy: 0.3506 - 318ms/epoch - 32ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3001 - accuracy: 0.4459 - val_loss: 1.2720 - val_accuracy: 0.3636 - 313ms/epoch - 31ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2475 - accuracy: 0.4623 - val_loss: 1.2502 - val_accuracy: 0.4026 - 316ms/epoch - 32ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2420 - accuracy: 0.4623 - val_loss: 1.2120 - val_accuracy: 0.3636 - 302ms/epoch - 30ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2223 - accuracy: 0.4656 - val_loss: 1.1974 - val_accuracy: 0.3896 - 270ms/epoch - 27ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1725 - accuracy: 0.4721 - val_loss: 1.1797 - val_accuracy: 0.3766 - 281ms/epoch - 28ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1647 - accuracy: 0.5049 - val_loss: 1.1596 - val_accuracy: 0.3636 - 275ms/epoch - 27ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1229 - accuracy: 0.5082 - val_loss: 1.1584 - val_accuracy: 0.3896 - 273ms/epoch - 27ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1378 - accuracy: 0.4984 - val_loss: 1.1356 - val_accuracy: 0.3766 - 270ms/epoch - 27ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1328 - accuracy: 0.5180 - val_loss: 1.1217 - val_accuracy: 0.3896 - 280ms/epoch - 28ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1526 - accuracy: 0.5082 - val_loss: 1.1177 - val_accuracy: 0.4416 - 276ms/epoch - 28ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1251 - accuracy: 0.4787 - val_loss: 1.1085 - val_accuracy: 0.4156 - 272ms/epoch - 27ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1083 - accuracy: 0.5213 - val_loss: 1.1048 - val_accuracy: 0.4286 - 282ms/epoch - 28ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1210 - accuracy: 0.5180 - val_loss: 1.1000 - val_accuracy: 0.4675 - 291ms/epoch - 29ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1345 - accuracy: 0.5115 - val_loss: 1.1074 - val_accuracy: 0.4286 - 282ms/epoch - 28ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0839 - accuracy: 0.5443 - val_loss: 1.0909 - val_accuracy: 0.4935 - 277ms/epoch - 28ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0915 - accuracy: 0.5115 - val_loss: 1.0898 - val_accuracy: 0.4545 - 270ms/epoch - 27ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1118 - accuracy: 0.5279 - val_loss: 1.0844 - val_accuracy: 0.4675 - 274ms/epoch - 27ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0829 - accuracy: 0.5246 - val_loss: 1.0880 - val_accuracy: 0.4805 - 295ms/epoch - 29ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0625 - accuracy: 0.5279 - val_loss: 1.0831 - val_accuracy: 0.4675 - 290ms/epoch - 29ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0583 - accuracy: 0.5541 - val_loss: 1.0811 - val_accuracy: 0.4675 - 270ms/epoch - 27ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0805 - accuracy: 0.5311 - val_loss: 1.0571 - val_accuracy: 0.5455 - 280ms/epoch - 28ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0907 - accuracy: 0.5311 - val_loss: 1.0619 - val_accuracy: 0.4805 - 280ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0499 - accuracy: 0.5475 - val_loss: 1.0585 - val_accuracy: 0.4805 - 270ms/epoch - 27ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0938 - accuracy: 0.5639 - val_loss: 1.0568 - val_accuracy: 0.4675 - 276ms/epoch - 28ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0662 - accuracy: 0.5508 - val_loss: 1.0574 - val_accuracy: 0.4805 - 276ms/epoch - 28ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0797 - accuracy: 0.5607 - val_loss: 1.0563 - val_accuracy: 0.4805 - 276ms/epoch - 28ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0509 - accuracy: 0.5738 - val_loss: 1.0467 - val_accuracy: 0.4675 - 267ms/epoch - 27ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0323 - accuracy: 0.5738 - val_loss: 1.0510 - val_accuracy: 0.4805 - 270ms/epoch - 27ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0489 - accuracy: 0.5541 - val_loss: 1.0480 - val_accuracy: 0.4805 - 268ms/epoch - 27ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0480 - accuracy: 0.5574 - val_loss: 1.0313 - val_accuracy: 0.4805 - 270ms/epoch - 27ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0487 - accuracy: 0.5443 - val_loss: 1.0135 - val_accuracy: 0.5065 - 268ms/epoch - 27ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0472 - accuracy: 0.5443 - val_loss: 1.0128 - val_accuracy: 0.5455 - 283ms/epoch - 28ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0272 - accuracy: 0.5803 - val_loss: 1.0067 - val_accuracy: 0.5195 - 282ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9975 - accuracy: 0.5836 - val_loss: 1.0009 - val_accuracy: 0.5195 - 269ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0173 - accuracy: 0.5836 - val_loss: 0.9849 - val_accuracy: 0.5584 - 274ms/epoch - 27ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0251 - accuracy: 0.5902 - val_loss: 0.9685 - val_accuracy: 0.5844 - 280ms/epoch - 28ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0171 - accuracy: 0.5770 - val_loss: 0.9590 - val_accuracy: 0.5195 - 278ms/epoch - 28ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9870 - accuracy: 0.5934 - val_loss: 0.9561 - val_accuracy: 0.5844 - 289ms/epoch - 29ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9736 - accuracy: 0.5934 - val_loss: 0.9384 - val_accuracy: 0.5584 - 306ms/epoch - 31ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0399 - accuracy: 0.5639 - val_loss: 0.9408 - val_accuracy: 0.5584 - 299ms/epoch - 30ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9831 - accuracy: 0.5869 - val_loss: 0.9467 - val_accuracy: 0.5325 - 302ms/epoch - 30ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9570 - accuracy: 0.6000 - val_loss: 0.9439 - val_accuracy: 0.5455 - 303ms/epoch - 30ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9748 - accuracy: 0.6098 - val_loss: 0.9304 - val_accuracy: 0.5844 - 280ms/epoch - 28ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9655 - accuracy: 0.6295 - val_loss: 0.9070 - val_accuracy: 0.5844 - 275ms/epoch - 28ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9394 - accuracy: 0.6623 - val_loss: 0.9212 - val_accuracy: 0.5195 - 273ms/epoch - 27ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9878 - accuracy: 0.6131 - val_loss: 0.9016 - val_accuracy: 0.5974 - 277ms/epoch - 28ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9362 - accuracy: 0.6328 - val_loss: 0.9036 - val_accuracy: 0.5844 - 277ms/epoch - 28ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9732 - accuracy: 0.6066 - val_loss: 0.9317 - val_accuracy: 0.5455 - 304ms/epoch - 30ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9761 - accuracy: 0.6197 - val_loss: 0.9313 - val_accuracy: 0.6234 - 287ms/epoch - 29ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9411 - accuracy: 0.6033 - val_loss: 0.9148 - val_accuracy: 0.5325 - 270ms/epoch - 27ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9333 - accuracy: 0.6361 - val_loss: 0.8860 - val_accuracy: 0.5974 - 273ms/epoch - 27ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9268 - accuracy: 0.6361 - val_loss: 0.8959 - val_accuracy: 0.6494 - 271ms/epoch - 27ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9280 - accuracy: 0.6295 - val_loss: 0.8887 - val_accuracy: 0.6234 - 283ms/epoch - 28ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9165 - accuracy: 0.6557 - val_loss: 0.8803 - val_accuracy: 0.5974 - 268ms/epoch - 27ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9188 - accuracy: 0.6492 - val_loss: 0.8731 - val_accuracy: 0.6234 - 276ms/epoch - 28ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9143 - accuracy: 0.6426 - val_loss: 0.8822 - val_accuracy: 0.5974 - 272ms/epoch - 27ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9267 - accuracy: 0.6393 - val_loss: 0.8728 - val_accuracy: 0.6104 - 273ms/epoch - 27ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9242 - accuracy: 0.6492 - val_loss: 0.8671 - val_accuracy: 0.6364 - 297ms/epoch - 30ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.8822 - accuracy: 0.6590 - val_loss: 0.8737 - val_accuracy: 0.6364 - 278ms/epoch - 28ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.8916 - accuracy: 0.6721 - val_loss: 0.8729 - val_accuracy: 0.6234 - 276ms/epoch - 28ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.8810 - accuracy: 0.6721 - val_loss: 0.8704 - val_accuracy: 0.6364 - 271ms/epoch - 27ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.9067 - accuracy: 0.6492 - val_loss: 0.8648 - val_accuracy: 0.6234 - 275ms/epoch - 28ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.8843 - accuracy: 0.6656 - val_loss: 0.8653 - val_accuracy: 0.6364 - 279ms/epoch - 28ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.8892 - accuracy: 0.6393 - val_loss: 0.8575 - val_accuracy: 0.6364 - 285ms/epoch - 29ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.8998 - accuracy: 0.6656 - val_loss: 0.8590 - val_accuracy: 0.6364 - 277ms/epoch - 28ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9090 - accuracy: 0.6623 - val_loss: 0.8941 - val_accuracy: 0.6104 - 290ms/epoch - 29ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.8890 - accuracy: 0.6525 - val_loss: 0.8776 - val_accuracy: 0.6234 - 276ms/epoch - 28ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.9001 - accuracy: 0.6525 - val_loss: 0.8644 - val_accuracy: 0.6364 - 269ms/epoch - 27ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.8614 - accuracy: 0.6361 - val_loss: 0.8648 - val_accuracy: 0.6494 - 280ms/epoch - 28ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8804 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:48:55,704] Trial 64 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 137}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3829 - accuracy: 0.3049 - val_loss: 1.3793 - val_accuracy: 0.3636 - 4s/epoch - 429ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3732 - accuracy: 0.3574 - val_loss: 1.3587 - val_accuracy: 0.3377 - 300ms/epoch - 30ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3483 - accuracy: 0.3967 - val_loss: 1.3269 - val_accuracy: 0.3766 - 308ms/epoch - 31ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2909 - accuracy: 0.4492 - val_loss: 1.2682 - val_accuracy: 0.3506 - 317ms/epoch - 32ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2214 - accuracy: 0.4459 - val_loss: 1.2187 - val_accuracy: 0.3636 - 311ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1830 - accuracy: 0.4721 - val_loss: 1.1747 - val_accuracy: 0.3636 - 330ms/epoch - 33ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1692 - accuracy: 0.4787 - val_loss: 1.1702 - val_accuracy: 0.3766 - 331ms/epoch - 33ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1867 - accuracy: 0.4689 - val_loss: 1.1829 - val_accuracy: 0.4156 - 338ms/epoch - 34ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1824 - accuracy: 0.4918 - val_loss: 1.1591 - val_accuracy: 0.3766 - 330ms/epoch - 33ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1561 - accuracy: 0.4918 - val_loss: 1.1553 - val_accuracy: 0.4286 - 328ms/epoch - 33ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1338 - accuracy: 0.4885 - val_loss: 1.1497 - val_accuracy: 0.4156 - 324ms/epoch - 32ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1241 - accuracy: 0.5016 - val_loss: 1.1378 - val_accuracy: 0.4286 - 320ms/epoch - 32ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1112 - accuracy: 0.5180 - val_loss: 1.1318 - val_accuracy: 0.4416 - 317ms/epoch - 32ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1215 - accuracy: 0.5213 - val_loss: 1.1171 - val_accuracy: 0.4545 - 312ms/epoch - 31ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1076 - accuracy: 0.5082 - val_loss: 1.1110 - val_accuracy: 0.4286 - 322ms/epoch - 32ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1099 - accuracy: 0.5344 - val_loss: 1.0980 - val_accuracy: 0.4545 - 333ms/epoch - 33ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0876 - accuracy: 0.5311 - val_loss: 1.0937 - val_accuracy: 0.4805 - 316ms/epoch - 32ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0902 - accuracy: 0.5443 - val_loss: 1.0960 - val_accuracy: 0.4545 - 321ms/epoch - 32ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1142 - accuracy: 0.5377 - val_loss: 1.0999 - val_accuracy: 0.4545 - 314ms/epoch - 31ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0933 - accuracy: 0.5443 - val_loss: 1.0724 - val_accuracy: 0.5584 - 318ms/epoch - 32ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0527 - accuracy: 0.5607 - val_loss: 1.0652 - val_accuracy: 0.4416 - 321ms/epoch - 32ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0599 - accuracy: 0.5541 - val_loss: 1.0495 - val_accuracy: 0.4805 - 333ms/epoch - 33ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0767 - accuracy: 0.5377 - val_loss: 1.0601 - val_accuracy: 0.4675 - 308ms/epoch - 31ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0471 - accuracy: 0.5738 - val_loss: 1.0505 - val_accuracy: 0.4675 - 318ms/epoch - 32ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0214 - accuracy: 0.5705 - val_loss: 1.0345 - val_accuracy: 0.4805 - 316ms/epoch - 32ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0273 - accuracy: 0.5541 - val_loss: 0.9925 - val_accuracy: 0.6104 - 315ms/epoch - 32ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0417 - accuracy: 0.5770 - val_loss: 1.0015 - val_accuracy: 0.5195 - 318ms/epoch - 32ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0261 - accuracy: 0.5869 - val_loss: 0.9993 - val_accuracy: 0.5195 - 316ms/epoch - 32ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9977 - accuracy: 0.6000 - val_loss: 0.9869 - val_accuracy: 0.5195 - 317ms/epoch - 32ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9913 - accuracy: 0.5902 - val_loss: 0.9573 - val_accuracy: 0.5455 - 314ms/epoch - 31ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9988 - accuracy: 0.6033 - val_loss: 0.9506 - val_accuracy: 0.5844 - 313ms/epoch - 31ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9604 - accuracy: 0.6393 - val_loss: 0.9359 - val_accuracy: 0.5195 - 317ms/epoch - 32ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9814 - accuracy: 0.6131 - val_loss: 0.9436 - val_accuracy: 0.5325 - 316ms/epoch - 32ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9998 - accuracy: 0.5902 - val_loss: 0.9229 - val_accuracy: 0.6234 - 317ms/epoch - 32ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9842 - accuracy: 0.6328 - val_loss: 0.9082 - val_accuracy: 0.5584 - 313ms/epoch - 31ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9438 - accuracy: 0.6525 - val_loss: 0.8895 - val_accuracy: 0.5844 - 308ms/epoch - 31ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9368 - accuracy: 0.6623 - val_loss: 0.9122 - val_accuracy: 0.5584 - 316ms/epoch - 32ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9227 - accuracy: 0.6492 - val_loss: 0.8857 - val_accuracy: 0.5844 - 320ms/epoch - 32ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9356 - accuracy: 0.6525 - val_loss: 0.8906 - val_accuracy: 0.5844 - 313ms/epoch - 31ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.8979 - accuracy: 0.6557 - val_loss: 0.8885 - val_accuracy: 0.5844 - 323ms/epoch - 32ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9617 - accuracy: 0.6295 - val_loss: 0.9228 - val_accuracy: 0.6234 - 323ms/epoch - 32ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9556 - accuracy: 0.6197 - val_loss: 0.8819 - val_accuracy: 0.5844 - 331ms/epoch - 33ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9027 - accuracy: 0.6525 - val_loss: 0.8891 - val_accuracy: 0.5844 - 329ms/epoch - 33ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9189 - accuracy: 0.6689 - val_loss: 0.8576 - val_accuracy: 0.6104 - 311ms/epoch - 31ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9218 - accuracy: 0.6361 - val_loss: 0.8828 - val_accuracy: 0.6104 - 315ms/epoch - 31ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9223 - accuracy: 0.6393 - val_loss: 0.8830 - val_accuracy: 0.5844 - 314ms/epoch - 31ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8970 - accuracy: 0.6492 - val_loss: 0.8753 - val_accuracy: 0.6104 - 314ms/epoch - 31ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9244 - accuracy: 0.6492 - val_loss: 0.9032 - val_accuracy: 0.5974 - 318ms/epoch - 32ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9255 - accuracy: 0.6656 - val_loss: 0.8681 - val_accuracy: 0.6234 - 316ms/epoch - 32ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9291 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:49:17,002] Trial 65 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'selu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 146}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3853 - accuracy: 0.3082 - val_loss: 1.3824 - val_accuracy: 0.3636 - 4s/epoch - 408ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3817 - accuracy: 0.3607 - val_loss: 1.3766 - val_accuracy: 0.3896 - 238ms/epoch - 24ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3725 - accuracy: 0.4393 - val_loss: 1.3629 - val_accuracy: 0.3636 - 285ms/epoch - 28ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3489 - accuracy: 0.4328 - val_loss: 1.3282 - val_accuracy: 0.3766 - 257ms/epoch - 26ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2904 - accuracy: 0.4525 - val_loss: 1.2614 - val_accuracy: 0.3766 - 263ms/epoch - 26ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2338 - accuracy: 0.4754 - val_loss: 1.2093 - val_accuracy: 0.3896 - 256ms/epoch - 26ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2305 - accuracy: 0.4721 - val_loss: 1.2183 - val_accuracy: 0.3896 - 261ms/epoch - 26ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2506 - accuracy: 0.4754 - val_loss: 1.2191 - val_accuracy: 0.4026 - 264ms/epoch - 26ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2190 - accuracy: 0.4656 - val_loss: 1.2005 - val_accuracy: 0.4156 - 258ms/epoch - 26ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1856 - accuracy: 0.4852 - val_loss: 1.1795 - val_accuracy: 0.3896 - 256ms/epoch - 26ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1423 - accuracy: 0.5082 - val_loss: 1.1562 - val_accuracy: 0.4416 - 259ms/epoch - 26ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1558 - accuracy: 0.5082 - val_loss: 1.1227 - val_accuracy: 0.4286 - 261ms/epoch - 26ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1353 - accuracy: 0.5115 - val_loss: 1.1228 - val_accuracy: 0.4675 - 257ms/epoch - 26ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1169 - accuracy: 0.5180 - val_loss: 1.1127 - val_accuracy: 0.4156 - 258ms/epoch - 26ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1145 - accuracy: 0.5213 - val_loss: 1.0944 - val_accuracy: 0.4545 - 257ms/epoch - 26ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0976 - accuracy: 0.5541 - val_loss: 1.0694 - val_accuracy: 0.4805 - 266ms/epoch - 27ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1053 - accuracy: 0.5115 - val_loss: 1.0867 - val_accuracy: 0.5195 - 277ms/epoch - 28ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0721 - accuracy: 0.5377 - val_loss: 1.0655 - val_accuracy: 0.4935 - 275ms/epoch - 28ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1142 - accuracy: 0.5508 - val_loss: 1.0830 - val_accuracy: 0.4805 - 274ms/epoch - 27ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0761 - accuracy: 0.5377 - val_loss: 1.0578 - val_accuracy: 0.5325 - 282ms/epoch - 28ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0714 - accuracy: 0.5705 - val_loss: 1.0487 - val_accuracy: 0.4935 - 273ms/epoch - 27ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0870 - accuracy: 0.5541 - val_loss: 1.0317 - val_accuracy: 0.4805 - 268ms/epoch - 27ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0691 - accuracy: 0.5508 - val_loss: 1.0305 - val_accuracy: 0.5065 - 283ms/epoch - 28ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0543 - accuracy: 0.5541 - val_loss: 1.0228 - val_accuracy: 0.5065 - 278ms/epoch - 28ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0297 - accuracy: 0.5672 - val_loss: 1.0069 - val_accuracy: 0.5325 - 281ms/epoch - 28ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0552 - accuracy: 0.5607 - val_loss: 0.9792 - val_accuracy: 0.5844 - 280ms/epoch - 28ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9966 - accuracy: 0.6262 - val_loss: 0.9788 - val_accuracy: 0.5195 - 282ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9719 - accuracy: 0.6066 - val_loss: 0.9696 - val_accuracy: 0.5714 - 267ms/epoch - 27ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9867 - accuracy: 0.6131 - val_loss: 0.9840 - val_accuracy: 0.5325 - 273ms/epoch - 27ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0057 - accuracy: 0.6000 - val_loss: 0.9486 - val_accuracy: 0.5844 - 286ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9983 - accuracy: 0.5902 - val_loss: 0.9193 - val_accuracy: 0.6104 - 288ms/epoch - 29ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9838 - accuracy: 0.6066 - val_loss: 0.9201 - val_accuracy: 0.5844 - 279ms/epoch - 28ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9932 - accuracy: 0.6164 - val_loss: 0.9116 - val_accuracy: 0.5714 - 288ms/epoch - 29ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9504 - accuracy: 0.6164 - val_loss: 0.9240 - val_accuracy: 0.5714 - 285ms/epoch - 29ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9606 - accuracy: 0.6164 - val_loss: 0.9023 - val_accuracy: 0.5714 - 268ms/epoch - 27ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9505 - accuracy: 0.5836 - val_loss: 0.8960 - val_accuracy: 0.6494 - 265ms/epoch - 27ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9666 - accuracy: 0.6393 - val_loss: 0.9050 - val_accuracy: 0.5974 - 267ms/epoch - 27ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9048 - accuracy: 0.6459 - val_loss: 0.8783 - val_accuracy: 0.6104 - 262ms/epoch - 26ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9202 - accuracy: 0.6295 - val_loss: 0.8560 - val_accuracy: 0.6364 - 269ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9331 - accuracy: 0.6164 - val_loss: 0.8967 - val_accuracy: 0.6364 - 260ms/epoch - 26ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9648 - accuracy: 0.6492 - val_loss: 0.8946 - val_accuracy: 0.6234 - 274ms/epoch - 27ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9213 - accuracy: 0.6361 - val_loss: 0.8635 - val_accuracy: 0.6234 - 282ms/epoch - 28ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.8615 - accuracy: 0.6164 - val_loss: 0.8723 - val_accuracy: 0.6494 - 267ms/epoch - 27ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.8828 - accuracy: 0.6393 - val_loss: 0.8530 - val_accuracy: 0.6364 - 254ms/epoch - 25ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9002 - accuracy: 0.6590 - val_loss: 0.8958 - val_accuracy: 0.6104 - 269ms/epoch - 27ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9023 - accuracy: 0.6590 - val_loss: 0.8596 - val_accuracy: 0.6623 - 259ms/epoch - 26ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8445 - accuracy: 0.6623 - val_loss: 0.8570 - val_accuracy: 0.6494 - 280ms/epoch - 28ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9609 - accuracy: 0.6197 - val_loss: 0.9354 - val_accuracy: 0.5714 - 281ms/epoch - 28ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9060 - accuracy: 0.6623 - val_loss: 0.9120 - val_accuracy: 0.5974 - 290ms/epoch - 29ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9559 - accuracy: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:49:35,485] Trial 66 finished with value: 0.5735294222831726 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 133}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3854 - accuracy: 0.2918 - val_loss: 1.3842 - val_accuracy: 0.3117 - 5s/epoch - 500ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3817 - accuracy: 0.3770 - val_loss: 1.3776 - val_accuracy: 0.3117 - 301ms/epoch - 30ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3706 - accuracy: 0.3836 - val_loss: 1.3629 - val_accuracy: 0.3117 - 318ms/epoch - 32ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3424 - accuracy: 0.3836 - val_loss: 1.3312 - val_accuracy: 0.3117 - 314ms/epoch - 31ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3051 - accuracy: 0.3803 - val_loss: 1.3018 - val_accuracy: 0.3117 - 312ms/epoch - 31ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2790 - accuracy: 0.4459 - val_loss: 1.2924 - val_accuracy: 0.3766 - 314ms/epoch - 31ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2719 - accuracy: 0.4426 - val_loss: 1.2713 - val_accuracy: 0.3636 - 315ms/epoch - 31ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2390 - accuracy: 0.4590 - val_loss: 1.2380 - val_accuracy: 0.3636 - 324ms/epoch - 32ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2091 - accuracy: 0.4721 - val_loss: 1.1931 - val_accuracy: 0.3896 - 313ms/epoch - 31ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1725 - accuracy: 0.4984 - val_loss: 1.1847 - val_accuracy: 0.4026 - 320ms/epoch - 32ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1550 - accuracy: 0.4885 - val_loss: 1.1727 - val_accuracy: 0.3896 - 314ms/epoch - 31ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1550 - accuracy: 0.4984 - val_loss: 1.1777 - val_accuracy: 0.4156 - 323ms/epoch - 32ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1460 - accuracy: 0.5082 - val_loss: 1.1621 - val_accuracy: 0.3896 - 328ms/epoch - 33ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1288 - accuracy: 0.4984 - val_loss: 1.1555 - val_accuracy: 0.3896 - 318ms/epoch - 32ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1463 - accuracy: 0.5016 - val_loss: 1.1489 - val_accuracy: 0.3766 - 323ms/epoch - 32ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1143 - accuracy: 0.5213 - val_loss: 1.1371 - val_accuracy: 0.4026 - 343ms/epoch - 34ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1217 - accuracy: 0.5049 - val_loss: 1.1340 - val_accuracy: 0.3896 - 345ms/epoch - 35ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1274 - accuracy: 0.5082 - val_loss: 1.1325 - val_accuracy: 0.4026 - 324ms/epoch - 32ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1245 - accuracy: 0.5311 - val_loss: 1.1404 - val_accuracy: 0.4156 - 323ms/epoch - 32ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1008 - accuracy: 0.5508 - val_loss: 1.1220 - val_accuracy: 0.4286 - 322ms/epoch - 32ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0990 - accuracy: 0.5344 - val_loss: 1.1152 - val_accuracy: 0.4156 - 319ms/epoch - 32ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0971 - accuracy: 0.5443 - val_loss: 1.1111 - val_accuracy: 0.4286 - 318ms/epoch - 32ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1125 - accuracy: 0.5279 - val_loss: 1.1092 - val_accuracy: 0.4545 - 315ms/epoch - 31ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0751 - accuracy: 0.5541 - val_loss: 1.1057 - val_accuracy: 0.4286 - 316ms/epoch - 32ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0851 - accuracy: 0.5508 - val_loss: 1.0920 - val_accuracy: 0.4545 - 318ms/epoch - 32ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0828 - accuracy: 0.5574 - val_loss: 1.0733 - val_accuracy: 0.5455 - 322ms/epoch - 32ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0793 - accuracy: 0.5672 - val_loss: 1.0834 - val_accuracy: 0.4805 - 340ms/epoch - 34ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0670 - accuracy: 0.5738 - val_loss: 1.0681 - val_accuracy: 0.4416 - 352ms/epoch - 35ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0627 - accuracy: 0.5803 - val_loss: 1.0689 - val_accuracy: 0.4675 - 348ms/epoch - 35ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0623 - accuracy: 0.5475 - val_loss: 1.0657 - val_accuracy: 0.4675 - 342ms/epoch - 34ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0530 - accuracy: 0.5803 - val_loss: 1.0625 - val_accuracy: 0.5065 - 343ms/epoch - 34ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0443 - accuracy: 0.5672 - val_loss: 1.0555 - val_accuracy: 0.4545 - 322ms/epoch - 32ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0207 - accuracy: 0.5705 - val_loss: 1.0489 - val_accuracy: 0.5065 - 332ms/epoch - 33ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0212 - accuracy: 0.5672 - val_loss: 1.0299 - val_accuracy: 0.4935 - 312ms/epoch - 31ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9943 - accuracy: 0.6066 - val_loss: 1.0074 - val_accuracy: 0.5584 - 348ms/epoch - 35ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9962 - accuracy: 0.6131 - val_loss: 0.9791 - val_accuracy: 0.5714 - 333ms/epoch - 33ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9760 - accuracy: 0.6230 - val_loss: 0.9764 - val_accuracy: 0.5714 - 329ms/epoch - 33ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9637 - accuracy: 0.6066 - val_loss: 0.9785 - val_accuracy: 0.5195 - 314ms/epoch - 31ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9528 - accuracy: 0.6164 - val_loss: 0.9515 - val_accuracy: 0.5714 - 319ms/epoch - 32ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9724 - accuracy: 0.6000 - val_loss: 0.9314 - val_accuracy: 0.5974 - 322ms/epoch - 32ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9627 - accuracy: 0.6164 - val_loss: 0.9567 - val_accuracy: 0.5714 - 316ms/epoch - 32ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9890 - accuracy: 0.6066 - val_loss: 0.9451 - val_accuracy: 0.5714 - 341ms/epoch - 34ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9573 - accuracy: 0.6230 - val_loss: 0.9356 - val_accuracy: 0.5844 - 326ms/epoch - 33ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9093 - accuracy: 0.6459 - val_loss: 0.8982 - val_accuracy: 0.5974 - 322ms/epoch - 32ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9529 - accuracy: 0.6426 - val_loss: 0.9086 - val_accuracy: 0.6104 - 374ms/epoch - 37ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9187 - accuracy: 0.6525 - val_loss: 0.9146 - val_accuracy: 0.5844 - 403ms/epoch - 40ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9208 - accuracy: 0.6393 - val_loss: 0.9003 - val_accuracy: 0.6104 - 365ms/epoch - 36ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9596 - accuracy: 0.6197 - val_loss: 0.9311 - val_accuracy: 0.5974 - 346ms/epoch - 35ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.8897 - accuracy: 0.6656 - val_loss: 0.8841 - val_accuracy: 0.6104 - 325ms/epoch - 33ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9272 - accuracy: 0.6230 - val_loss: 0.9135 - val_accuracy: 0.5974 - 411ms/epoch - 41ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.8910 - accuracy: 0.6656 - val_loss: 0.8697 - val_accuracy: 0.6104 - 364ms/epoch - 36ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9064 - accuracy: 0.6295 - val_loss: 0.8696 - val_accuracy: 0.6234 - 339ms/epoch - 34ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.8946 - accuracy: 0.6525 - val_loss: 0.9184 - val_accuracy: 0.6104 - 321ms/epoch - 32ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.8881 - accuracy: 0.6590 - val_loss: 0.8788 - val_accuracy: 0.6104 - 321ms/epoch - 32ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.8813 - accuracy: 0.6492 - val_loss: 0.8704 - val_accuracy: 0.6104 - 335ms/epoch - 34ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 1s - loss: 0.8842 - accuracy: 0.6525 - val_loss: 0.8827 - val_accuracy: 0.6104 - 503ms/epoch - 50ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.8697 - accuracy: 0.6459 - val_loss: 0.8768 - val_accuracy: 0.6234 - 394ms/epoch - 39ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8737 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:50:01,503] Trial 67 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'tanh', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 144}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 4s - loss: 1.3855 - accuracy: 0.3016 - val_loss: 1.3834 - val_accuracy: 0.3896 - 4s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3824 - accuracy: 0.4033 - val_loss: 1.3799 - val_accuracy: 0.3766 - 317ms/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3775 - accuracy: 0.4525 - val_loss: 1.3745 - val_accuracy: 0.3636 - 366ms/epoch - 92ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.3703 - accuracy: 0.4918 - val_loss: 1.3656 - val_accuracy: 0.4026 - 338ms/epoch - 84ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.3552 - accuracy: 0.4918 - val_loss: 1.3497 - val_accuracy: 0.4545 - 305ms/epoch - 76ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.3242 - accuracy: 0.5213 - val_loss: 1.3268 - val_accuracy: 0.4416 - 288ms/epoch - 72ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.3082 - accuracy: 0.4557 - val_loss: 1.2970 - val_accuracy: 0.3896 - 293ms/epoch - 73ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.2606 - accuracy: 0.4984 - val_loss: 1.2597 - val_accuracy: 0.3636 - 283ms/epoch - 71ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.2451 - accuracy: 0.4459 - val_loss: 1.2310 - val_accuracy: 0.3636 - 285ms/epoch - 71ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.2367 - accuracy: 0.4590 - val_loss: 1.2193 - val_accuracy: 0.3636 - 280ms/epoch - 70ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.2110 - accuracy: 0.4820 - val_loss: 1.2168 - val_accuracy: 0.3766 - 315ms/epoch - 79ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.2056 - accuracy: 0.5016 - val_loss: 1.2066 - val_accuracy: 0.3766 - 307ms/epoch - 77ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.1802 - accuracy: 0.4852 - val_loss: 1.1989 - val_accuracy: 0.4026 - 307ms/epoch - 77ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.1756 - accuracy: 0.4984 - val_loss: 1.1840 - val_accuracy: 0.3896 - 333ms/epoch - 83ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.1800 - accuracy: 0.4885 - val_loss: 1.1707 - val_accuracy: 0.4026 - 345ms/epoch - 86ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.1547 - accuracy: 0.5082 - val_loss: 1.1601 - val_accuracy: 0.4026 - 298ms/epoch - 74ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.1509 - accuracy: 0.5049 - val_loss: 1.1552 - val_accuracy: 0.4026 - 282ms/epoch - 70ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.1416 - accuracy: 0.4852 - val_loss: 1.1423 - val_accuracy: 0.4026 - 295ms/epoch - 74ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.1385 - accuracy: 0.5213 - val_loss: 1.1575 - val_accuracy: 0.4026 - 280ms/epoch - 70ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.1297 - accuracy: 0.5082 - val_loss: 1.1305 - val_accuracy: 0.4156 - 274ms/epoch - 68ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.0973 - accuracy: 0.5410 - val_loss: 1.1407 - val_accuracy: 0.4156 - 275ms/epoch - 69ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.1411 - accuracy: 0.5082 - val_loss: 1.1056 - val_accuracy: 0.4416 - 274ms/epoch - 68ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.1118 - accuracy: 0.5180 - val_loss: 1.1158 - val_accuracy: 0.4026 - 271ms/epoch - 68ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.1138 - accuracy: 0.5115 - val_loss: 1.1166 - val_accuracy: 0.4286 - 271ms/epoch - 68ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.1222 - accuracy: 0.5213 - val_loss: 1.1153 - val_accuracy: 0.4026 - 270ms/epoch - 67ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 1.1051 - accuracy: 0.5279 - val_loss: 1.1145 - val_accuracy: 0.4156 - 302ms/epoch - 76ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.1060 - accuracy: 0.5410 - val_loss: 1.1000 - val_accuracy: 0.4026 - 277ms/epoch - 69ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 1.1187 - accuracy: 0.5344 - val_loss: 1.1016 - val_accuracy: 0.4545 - 271ms/epoch - 68ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 1.0886 - accuracy: 0.5639 - val_loss: 1.0885 - val_accuracy: 0.4286 - 281ms/epoch - 70ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 1.1025 - accuracy: 0.5443 - val_loss: 1.0846 - val_accuracy: 0.4286 - 266ms/epoch - 67ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 1.1055 - accuracy: 0.5344 - val_loss: 1.0992 - val_accuracy: 0.4416 - 277ms/epoch - 69ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 1.0966 - accuracy: 0.5344 - val_loss: 1.0886 - val_accuracy: 0.4675 - 268ms/epoch - 67ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 1.0993 - accuracy: 0.5180 - val_loss: 1.0891 - val_accuracy: 0.4286 - 271ms/epoch - 68ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 1.0802 - accuracy: 0.5443 - val_loss: 1.0910 - val_accuracy: 0.4286 - 274ms/epoch - 68ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 1.0723 - accuracy: 0.5541 - val_loss: 1.0845 - val_accuracy: 0.4416 - 265ms/epoch - 66ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 1.0768 - accuracy: 0.5705 - val_loss: 1.0761 - val_accuracy: 0.4545 - 272ms/epoch - 68ms/step\n",
      "Epoch 37/10000\n",
      "4/4 - 0s - loss: 1.0664 - accuracy: 0.5475 - val_loss: 1.0642 - val_accuracy: 0.4805 - 272ms/epoch - 68ms/step\n",
      "Epoch 38/10000\n",
      "4/4 - 0s - loss: 1.0655 - accuracy: 0.5311 - val_loss: 1.0580 - val_accuracy: 0.4935 - 274ms/epoch - 68ms/step\n",
      "Epoch 39/10000\n",
      "4/4 - 0s - loss: 1.0492 - accuracy: 0.5607 - val_loss: 1.0513 - val_accuracy: 0.4805 - 279ms/epoch - 70ms/step\n",
      "Epoch 40/10000\n",
      "4/4 - 0s - loss: 1.0740 - accuracy: 0.5705 - val_loss: 1.0443 - val_accuracy: 0.4675 - 271ms/epoch - 68ms/step\n",
      "Epoch 41/10000\n",
      "4/4 - 0s - loss: 1.0451 - accuracy: 0.5443 - val_loss: 1.0456 - val_accuracy: 0.4935 - 272ms/epoch - 68ms/step\n",
      "Epoch 42/10000\n",
      "4/4 - 0s - loss: 1.0473 - accuracy: 0.5607 - val_loss: 1.0346 - val_accuracy: 0.4805 - 266ms/epoch - 67ms/step\n",
      "Epoch 43/10000\n",
      "4/4 - 0s - loss: 1.0351 - accuracy: 0.5508 - val_loss: 1.0228 - val_accuracy: 0.5325 - 266ms/epoch - 66ms/step\n",
      "Epoch 44/10000\n",
      "4/4 - 0s - loss: 1.0429 - accuracy: 0.5410 - val_loss: 1.0086 - val_accuracy: 0.5325 - 276ms/epoch - 69ms/step\n",
      "Epoch 45/10000\n",
      "4/4 - 0s - loss: 1.0399 - accuracy: 0.5639 - val_loss: 0.9975 - val_accuracy: 0.5325 - 278ms/epoch - 69ms/step\n",
      "Epoch 46/10000\n",
      "4/4 - 0s - loss: 1.0061 - accuracy: 0.5934 - val_loss: 0.9865 - val_accuracy: 0.5455 - 275ms/epoch - 69ms/step\n",
      "Epoch 47/10000\n",
      "4/4 - 0s - loss: 1.0111 - accuracy: 0.5836 - val_loss: 0.9808 - val_accuracy: 0.5325 - 287ms/epoch - 72ms/step\n",
      "Epoch 48/10000\n",
      "4/4 - 0s - loss: 1.0063 - accuracy: 0.6164 - val_loss: 0.9868 - val_accuracy: 0.5325 - 292ms/epoch - 73ms/step\n",
      "Epoch 49/10000\n",
      "4/4 - 0s - loss: 1.0136 - accuracy: 0.5869 - val_loss: 1.0031 - val_accuracy: 0.5455 - 277ms/epoch - 69ms/step\n",
      "Epoch 50/10000\n",
      "4/4 - 0s - loss: 1.0410 - accuracy: 0.5607 - val_loss: 0.9894 - val_accuracy: 0.5455 - 266ms/epoch - 66ms/step\n",
      "Epoch 51/10000\n",
      "4/4 - 0s - loss: 0.9876 - accuracy: 0.5934 - val_loss: 0.9707 - val_accuracy: 0.5455 - 272ms/epoch - 68ms/step\n",
      "Epoch 52/10000\n",
      "4/4 - 0s - loss: 0.9874 - accuracy: 0.6361 - val_loss: 0.9511 - val_accuracy: 0.5455 - 272ms/epoch - 68ms/step\n",
      "Epoch 53/10000\n",
      "4/4 - 0s - loss: 1.0008 - accuracy: 0.5770 - val_loss: 0.9358 - val_accuracy: 0.5325 - 276ms/epoch - 69ms/step\n",
      "Epoch 54/10000\n",
      "4/4 - 0s - loss: 1.0016 - accuracy: 0.5967 - val_loss: 0.9315 - val_accuracy: 0.5714 - 279ms/epoch - 70ms/step\n",
      "Epoch 55/10000\n",
      "4/4 - 0s - loss: 1.0098 - accuracy: 0.5934 - val_loss: 0.9289 - val_accuracy: 0.5584 - 305ms/epoch - 76ms/step\n",
      "Epoch 56/10000\n",
      "4/4 - 0s - loss: 0.9736 - accuracy: 0.6033 - val_loss: 0.9249 - val_accuracy: 0.5714 - 304ms/epoch - 76ms/step\n",
      "Epoch 57/10000\n",
      "4/4 - 0s - loss: 0.9748 - accuracy: 0.5770 - val_loss: 0.9194 - val_accuracy: 0.5325 - 294ms/epoch - 73ms/step\n",
      "Epoch 58/10000\n",
      "4/4 - 0s - loss: 0.9372 - accuracy: 0.6393 - val_loss: 0.9162 - val_accuracy: 0.5974 - 300ms/epoch - 75ms/step\n",
      "Epoch 59/10000\n",
      "4/4 - 0s - loss: 0.9253 - accuracy: 0.6328 - val_loss: 0.9023 - val_accuracy: 0.5714 - 293ms/epoch - 73ms/step\n",
      "Epoch 60/10000\n",
      "4/4 - 0s - loss: 0.9932 - accuracy: 0.5967 - val_loss: 0.8806 - val_accuracy: 0.6104 - 286ms/epoch - 71ms/step\n",
      "Epoch 61/10000\n",
      "4/4 - 0s - loss: 0.9919 - accuracy: 0.6131 - val_loss: 0.8939 - val_accuracy: 0.6234 - 278ms/epoch - 69ms/step\n",
      "Epoch 62/10000\n",
      "4/4 - 0s - loss: 0.9519 - accuracy: 0.6033 - val_loss: 0.9051 - val_accuracy: 0.5325 - 270ms/epoch - 68ms/step\n",
      "Epoch 63/10000\n",
      "4/4 - 0s - loss: 0.9199 - accuracy: 0.6328 - val_loss: 0.9069 - val_accuracy: 0.5455 - 279ms/epoch - 70ms/step\n",
      "Epoch 64/10000\n",
      "4/4 - 0s - loss: 0.9402 - accuracy: 0.6164 - val_loss: 0.8914 - val_accuracy: 0.6623 - 280ms/epoch - 70ms/step\n",
      "Epoch 65/10000\n",
      "4/4 - 0s - loss: 0.9190 - accuracy: 0.6295 - val_loss: 0.8940 - val_accuracy: 0.5584 - 277ms/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8537 - accuracy: 0.6875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9054 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:50:26,203] Trial 68 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 80, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 149}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3862 - accuracy: 0.2754 - val_loss: 1.3854 - val_accuracy: 0.2727 - 4s/epoch - 616ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3858 - accuracy: 0.2689 - val_loss: 1.3847 - val_accuracy: 0.2597 - 266ms/epoch - 38ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3850 - accuracy: 0.2656 - val_loss: 1.3836 - val_accuracy: 0.2597 - 270ms/epoch - 39ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3839 - accuracy: 0.2656 - val_loss: 1.3819 - val_accuracy: 0.2597 - 280ms/epoch - 40ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3823 - accuracy: 0.2852 - val_loss: 1.3804 - val_accuracy: 0.3636 - 284ms/epoch - 41ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3799 - accuracy: 0.3738 - val_loss: 1.3779 - val_accuracy: 0.3117 - 278ms/epoch - 40ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.3754 - accuracy: 0.4098 - val_loss: 1.3735 - val_accuracy: 0.3896 - 264ms/epoch - 38ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.3673 - accuracy: 0.4230 - val_loss: 1.3665 - val_accuracy: 0.3247 - 280ms/epoch - 40ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.3513 - accuracy: 0.4295 - val_loss: 1.3510 - val_accuracy: 0.3636 - 274ms/epoch - 39ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.3184 - accuracy: 0.4721 - val_loss: 1.3345 - val_accuracy: 0.3766 - 267ms/epoch - 38ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2796 - accuracy: 0.4525 - val_loss: 1.3136 - val_accuracy: 0.3896 - 273ms/epoch - 39ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2697 - accuracy: 0.4689 - val_loss: 1.2503 - val_accuracy: 0.3636 - 264ms/epoch - 38ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2528 - accuracy: 0.4459 - val_loss: 1.2535 - val_accuracy: 0.3766 - 282ms/epoch - 40ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.2452 - accuracy: 0.4459 - val_loss: 1.2490 - val_accuracy: 0.3766 - 261ms/epoch - 37ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.2383 - accuracy: 0.4689 - val_loss: 1.2514 - val_accuracy: 0.3636 - 282ms/epoch - 40ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.2118 - accuracy: 0.4721 - val_loss: 1.2436 - val_accuracy: 0.3766 - 265ms/epoch - 38ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.2030 - accuracy: 0.4852 - val_loss: 1.2420 - val_accuracy: 0.3896 - 277ms/epoch - 40ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1864 - accuracy: 0.4721 - val_loss: 1.2158 - val_accuracy: 0.3896 - 277ms/epoch - 40ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1722 - accuracy: 0.4721 - val_loss: 1.1991 - val_accuracy: 0.3636 - 265ms/epoch - 38ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1775 - accuracy: 0.4689 - val_loss: 1.2057 - val_accuracy: 0.3766 - 280ms/epoch - 40ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1810 - accuracy: 0.4689 - val_loss: 1.1748 - val_accuracy: 0.3766 - 281ms/epoch - 40ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1596 - accuracy: 0.4852 - val_loss: 1.1655 - val_accuracy: 0.3766 - 265ms/epoch - 38ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1508 - accuracy: 0.4885 - val_loss: 1.1544 - val_accuracy: 0.4026 - 267ms/epoch - 38ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1435 - accuracy: 0.4951 - val_loss: 1.1401 - val_accuracy: 0.4286 - 259ms/epoch - 37ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1820 - accuracy: 0.4951 - val_loss: 1.1344 - val_accuracy: 0.4286 - 271ms/epoch - 39ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1252 - accuracy: 0.5049 - val_loss: 1.1348 - val_accuracy: 0.3766 - 271ms/epoch - 39ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1342 - accuracy: 0.4885 - val_loss: 1.1347 - val_accuracy: 0.4026 - 284ms/epoch - 41ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1270 - accuracy: 0.4820 - val_loss: 1.1268 - val_accuracy: 0.4026 - 294ms/epoch - 42ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1250 - accuracy: 0.4820 - val_loss: 1.1313 - val_accuracy: 0.4026 - 287ms/epoch - 41ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1313 - accuracy: 0.4885 - val_loss: 1.1265 - val_accuracy: 0.3896 - 280ms/epoch - 40ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1172 - accuracy: 0.5049 - val_loss: 1.1173 - val_accuracy: 0.3766 - 277ms/epoch - 40ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.1024 - accuracy: 0.5082 - val_loss: 1.1220 - val_accuracy: 0.3766 - 279ms/epoch - 40ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.1251 - accuracy: 0.4951 - val_loss: 1.1239 - val_accuracy: 0.3766 - 267ms/epoch - 38ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.1076 - accuracy: 0.4787 - val_loss: 1.1242 - val_accuracy: 0.3766 - 261ms/epoch - 37ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.1143 - accuracy: 0.4885 - val_loss: 1.1200 - val_accuracy: 0.3766 - 272ms/epoch - 39ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0879 - accuracy: 0.5311 - val_loss: 1.1242 - val_accuracy: 0.3896 - 265ms/epoch - 38ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0173 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:50:41,529] Trial 69 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'swish', 'batch_size': 50, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 154}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3798 - accuracy: 0.3115 - val_loss: 1.3733 - val_accuracy: 0.2597 - 4s/epoch - 390ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3595 - accuracy: 0.3803 - val_loss: 1.3442 - val_accuracy: 0.4286 - 277ms/epoch - 28ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3176 - accuracy: 0.4328 - val_loss: 1.2929 - val_accuracy: 0.3766 - 286ms/epoch - 29ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2615 - accuracy: 0.4754 - val_loss: 1.2342 - val_accuracy: 0.3896 - 285ms/epoch - 29ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2421 - accuracy: 0.4852 - val_loss: 1.2235 - val_accuracy: 0.4416 - 292ms/epoch - 29ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2043 - accuracy: 0.5246 - val_loss: 1.1995 - val_accuracy: 0.4156 - 278ms/epoch - 28ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1688 - accuracy: 0.5082 - val_loss: 1.1743 - val_accuracy: 0.4156 - 300ms/epoch - 30ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1741 - accuracy: 0.5115 - val_loss: 1.1692 - val_accuracy: 0.4026 - 283ms/epoch - 28ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1687 - accuracy: 0.5049 - val_loss: 1.1473 - val_accuracy: 0.4156 - 276ms/epoch - 28ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1328 - accuracy: 0.5443 - val_loss: 1.1346 - val_accuracy: 0.4675 - 290ms/epoch - 29ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1127 - accuracy: 0.5344 - val_loss: 1.1273 - val_accuracy: 0.4545 - 278ms/epoch - 28ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1411 - accuracy: 0.5180 - val_loss: 1.1215 - val_accuracy: 0.4675 - 284ms/epoch - 28ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1316 - accuracy: 0.5246 - val_loss: 1.1027 - val_accuracy: 0.4675 - 285ms/epoch - 28ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0927 - accuracy: 0.5443 - val_loss: 1.0749 - val_accuracy: 0.4805 - 291ms/epoch - 29ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0787 - accuracy: 0.5377 - val_loss: 1.0583 - val_accuracy: 0.4416 - 283ms/epoch - 28ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0663 - accuracy: 0.5344 - val_loss: 1.0438 - val_accuracy: 0.5065 - 289ms/epoch - 29ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0692 - accuracy: 0.5443 - val_loss: 1.0387 - val_accuracy: 0.4805 - 294ms/epoch - 29ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0761 - accuracy: 0.5311 - val_loss: 1.0511 - val_accuracy: 0.4805 - 287ms/epoch - 29ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0862 - accuracy: 0.5639 - val_loss: 1.0430 - val_accuracy: 0.5065 - 288ms/epoch - 29ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0665 - accuracy: 0.5115 - val_loss: 1.0181 - val_accuracy: 0.5584 - 282ms/epoch - 28ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0531 - accuracy: 0.5770 - val_loss: 1.0197 - val_accuracy: 0.4935 - 288ms/epoch - 29ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0384 - accuracy: 0.5639 - val_loss: 0.9909 - val_accuracy: 0.5325 - 287ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0094 - accuracy: 0.5836 - val_loss: 0.9910 - val_accuracy: 0.5714 - 289ms/epoch - 29ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 0.9968 - accuracy: 0.6033 - val_loss: 1.0014 - val_accuracy: 0.5195 - 286ms/epoch - 29ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9941 - accuracy: 0.6066 - val_loss: 0.9770 - val_accuracy: 0.5844 - 306ms/epoch - 31ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0049 - accuracy: 0.5836 - val_loss: 0.9268 - val_accuracy: 0.5844 - 308ms/epoch - 31ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9669 - accuracy: 0.6262 - val_loss: 0.9460 - val_accuracy: 0.5065 - 280ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9681 - accuracy: 0.6066 - val_loss: 0.9560 - val_accuracy: 0.6104 - 291ms/epoch - 29ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9189 - accuracy: 0.6262 - val_loss: 0.9505 - val_accuracy: 0.5195 - 301ms/epoch - 30ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9705 - accuracy: 0.6164 - val_loss: 0.9129 - val_accuracy: 0.5844 - 301ms/epoch - 30ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9326 - accuracy: 0.6164 - val_loss: 0.9119 - val_accuracy: 0.6104 - 305ms/epoch - 31ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9315 - accuracy: 0.6492 - val_loss: 0.9166 - val_accuracy: 0.5714 - 295ms/epoch - 29ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9290 - accuracy: 0.6197 - val_loss: 0.9101 - val_accuracy: 0.5714 - 303ms/epoch - 30ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.8972 - accuracy: 0.6230 - val_loss: 0.9183 - val_accuracy: 0.5974 - 285ms/epoch - 28ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9096 - accuracy: 0.6361 - val_loss: 0.8967 - val_accuracy: 0.6104 - 284ms/epoch - 28ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9010 - accuracy: 0.6393 - val_loss: 0.8846 - val_accuracy: 0.6364 - 284ms/epoch - 28ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9213 - accuracy: 0.6656 - val_loss: 0.8958 - val_accuracy: 0.6234 - 294ms/epoch - 29ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9186 - accuracy: 0.6393 - val_loss: 0.8884 - val_accuracy: 0.6234 - 283ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9050 - accuracy: 0.6393 - val_loss: 0.8772 - val_accuracy: 0.6623 - 282ms/epoch - 28ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.8972 - accuracy: 0.6525 - val_loss: 0.8968 - val_accuracy: 0.5844 - 295ms/epoch - 30ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9073 - accuracy: 0.6492 - val_loss: 0.9078 - val_accuracy: 0.6364 - 289ms/epoch - 29ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.8825 - accuracy: 0.6459 - val_loss: 0.8791 - val_accuracy: 0.6234 - 285ms/epoch - 28ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.8981 - accuracy: 0.6131 - val_loss: 0.8927 - val_accuracy: 0.6364 - 288ms/epoch - 29ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.8676 - accuracy: 0.6459 - val_loss: 0.8575 - val_accuracy: 0.6494 - 303ms/epoch - 30ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.8943 - accuracy: 0.6787 - val_loss: 0.8806 - val_accuracy: 0.6234 - 297ms/epoch - 30ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9024 - accuracy: 0.6459 - val_loss: 0.8662 - val_accuracy: 0.6364 - 282ms/epoch - 28ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8919 - accuracy: 0.6557 - val_loss: 0.8907 - val_accuracy: 0.6364 - 295ms/epoch - 29ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9023 - accuracy: 0.6230 - val_loss: 0.9290 - val_accuracy: 0.6104 - 296ms/epoch - 30ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.8936 - accuracy: 0.6525 - val_loss: 0.8914 - val_accuracy: 0.6364 - 287ms/epoch - 29ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8957 - accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:51:00,850] Trial 70 finished with value: 0.5882353186607361 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'selu', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 166}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3844 - accuracy: 0.2525 - val_loss: 1.3813 - val_accuracy: 0.2468 - 4s/epoch - 771ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3764 - accuracy: 0.3836 - val_loss: 1.3731 - val_accuracy: 0.4026 - 220ms/epoch - 44ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3639 - accuracy: 0.4754 - val_loss: 1.3585 - val_accuracy: 0.3896 - 228ms/epoch - 46ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3390 - accuracy: 0.4721 - val_loss: 1.3327 - val_accuracy: 0.3896 - 233ms/epoch - 47ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.2962 - accuracy: 0.4721 - val_loss: 1.2908 - val_accuracy: 0.3636 - 232ms/epoch - 46ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.2400 - accuracy: 0.4623 - val_loss: 1.2524 - val_accuracy: 0.3766 - 233ms/epoch - 47ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.2316 - accuracy: 0.4557 - val_loss: 1.2270 - val_accuracy: 0.3636 - 233ms/epoch - 47ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.1881 - accuracy: 0.4656 - val_loss: 1.1926 - val_accuracy: 0.3636 - 238ms/epoch - 48ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.1814 - accuracy: 0.4689 - val_loss: 1.1827 - val_accuracy: 0.4026 - 228ms/epoch - 46ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.1472 - accuracy: 0.5049 - val_loss: 1.1667 - val_accuracy: 0.4156 - 228ms/epoch - 46ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1428 - accuracy: 0.4918 - val_loss: 1.1668 - val_accuracy: 0.4416 - 230ms/epoch - 46ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1122 - accuracy: 0.5115 - val_loss: 1.1520 - val_accuracy: 0.4416 - 237ms/epoch - 47ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1260 - accuracy: 0.5016 - val_loss: 1.1367 - val_accuracy: 0.4286 - 226ms/epoch - 45ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.0977 - accuracy: 0.5311 - val_loss: 1.1109 - val_accuracy: 0.4416 - 229ms/epoch - 46ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.0984 - accuracy: 0.5541 - val_loss: 1.0893 - val_accuracy: 0.4675 - 231ms/epoch - 46ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.0736 - accuracy: 0.5770 - val_loss: 1.0700 - val_accuracy: 0.4545 - 231ms/epoch - 46ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.0752 - accuracy: 0.5574 - val_loss: 1.0536 - val_accuracy: 0.4935 - 245ms/epoch - 49ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.0786 - accuracy: 0.5311 - val_loss: 1.0530 - val_accuracy: 0.4935 - 237ms/epoch - 47ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.0660 - accuracy: 0.5410 - val_loss: 1.0515 - val_accuracy: 0.4545 - 236ms/epoch - 47ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.0412 - accuracy: 0.5869 - val_loss: 1.0388 - val_accuracy: 0.4805 - 257ms/epoch - 51ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.0277 - accuracy: 0.5475 - val_loss: 1.0089 - val_accuracy: 0.5065 - 253ms/epoch - 51ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.0204 - accuracy: 0.5705 - val_loss: 0.9983 - val_accuracy: 0.4935 - 251ms/epoch - 50ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.0349 - accuracy: 0.5672 - val_loss: 1.0072 - val_accuracy: 0.5325 - 245ms/epoch - 49ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 0.9975 - accuracy: 0.5967 - val_loss: 0.9853 - val_accuracy: 0.5065 - 245ms/epoch - 49ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 0.9971 - accuracy: 0.5574 - val_loss: 0.9850 - val_accuracy: 0.5195 - 238ms/epoch - 48ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 0.9462 - accuracy: 0.6197 - val_loss: 0.9580 - val_accuracy: 0.5974 - 232ms/epoch - 46ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 0.9525 - accuracy: 0.5869 - val_loss: 0.9340 - val_accuracy: 0.5844 - 238ms/epoch - 48ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 0.9501 - accuracy: 0.6098 - val_loss: 0.9341 - val_accuracy: 0.5584 - 234ms/epoch - 47ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 0.9354 - accuracy: 0.6164 - val_loss: 0.9482 - val_accuracy: 0.5455 - 226ms/epoch - 45ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 0.9522 - accuracy: 0.6098 - val_loss: 0.9111 - val_accuracy: 0.6104 - 231ms/epoch - 46ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 0.9316 - accuracy: 0.6426 - val_loss: 0.9325 - val_accuracy: 0.5844 - 236ms/epoch - 47ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 0.8909 - accuracy: 0.6066 - val_loss: 0.9038 - val_accuracy: 0.6753 - 229ms/epoch - 46ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 0.9093 - accuracy: 0.6098 - val_loss: 0.9246 - val_accuracy: 0.5584 - 232ms/epoch - 46ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 0.9129 - accuracy: 0.6361 - val_loss: 0.9071 - val_accuracy: 0.6494 - 237ms/epoch - 47ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 0.8519 - accuracy: 0.6689 - val_loss: 0.8790 - val_accuracy: 0.6234 - 230ms/epoch - 46ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 0.8966 - accuracy: 0.6459 - val_loss: 0.8749 - val_accuracy: 0.6623 - 232ms/epoch - 46ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.8562 - accuracy: 0.6492 - val_loss: 0.8925 - val_accuracy: 0.6623 - 237ms/epoch - 47ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.8626 - accuracy: 0.6525 - val_loss: 0.9110 - val_accuracy: 0.5844 - 233ms/epoch - 47ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.8535 - accuracy: 0.6623 - val_loss: 0.8824 - val_accuracy: 0.6494 - 227ms/epoch - 45ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.8826 - accuracy: 0.6656 - val_loss: 0.9056 - val_accuracy: 0.6234 - 235ms/epoch - 47ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.8819 - accuracy: 0.6557 - val_loss: 0.8814 - val_accuracy: 0.6623 - 229ms/epoch - 46ms/step\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8836 - accuracy: 0.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:51:16,029] Trial 71 finished with value: 0.6176470518112183 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'selu', 'activation_func_3': 'linear', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 134}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3845 - accuracy: 0.2984 - val_loss: 1.3819 - val_accuracy: 0.4286 - 4s/epoch - 798ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3760 - accuracy: 0.3770 - val_loss: 1.3731 - val_accuracy: 0.2987 - 184ms/epoch - 37ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3638 - accuracy: 0.4295 - val_loss: 1.3584 - val_accuracy: 0.3766 - 203ms/epoch - 41ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3374 - accuracy: 0.4557 - val_loss: 1.3348 - val_accuracy: 0.3766 - 195ms/epoch - 39ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.2979 - accuracy: 0.4426 - val_loss: 1.3076 - val_accuracy: 0.3766 - 198ms/epoch - 40ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.2662 - accuracy: 0.4656 - val_loss: 1.2885 - val_accuracy: 0.3506 - 198ms/epoch - 40ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.2582 - accuracy: 0.4393 - val_loss: 1.2669 - val_accuracy: 0.3636 - 198ms/epoch - 40ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2071 - accuracy: 0.4590 - val_loss: 1.2185 - val_accuracy: 0.3506 - 205ms/epoch - 41ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.1818 - accuracy: 0.4721 - val_loss: 1.1813 - val_accuracy: 0.3896 - 194ms/epoch - 39ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.1616 - accuracy: 0.5016 - val_loss: 1.1658 - val_accuracy: 0.3896 - 198ms/epoch - 40ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1550 - accuracy: 0.4951 - val_loss: 1.1585 - val_accuracy: 0.3766 - 195ms/epoch - 39ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1389 - accuracy: 0.4951 - val_loss: 1.1569 - val_accuracy: 0.3766 - 202ms/epoch - 40ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1410 - accuracy: 0.5115 - val_loss: 1.1474 - val_accuracy: 0.4026 - 197ms/epoch - 39ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1064 - accuracy: 0.5311 - val_loss: 1.1328 - val_accuracy: 0.4026 - 204ms/epoch - 41ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.0940 - accuracy: 0.5574 - val_loss: 1.1153 - val_accuracy: 0.4286 - 204ms/epoch - 41ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1141 - accuracy: 0.5148 - val_loss: 1.0980 - val_accuracy: 0.4545 - 208ms/epoch - 42ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.0889 - accuracy: 0.5344 - val_loss: 1.0792 - val_accuracy: 0.5065 - 198ms/epoch - 40ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.0832 - accuracy: 0.5574 - val_loss: 1.0712 - val_accuracy: 0.4805 - 197ms/epoch - 39ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.0846 - accuracy: 0.5475 - val_loss: 1.0677 - val_accuracy: 0.4545 - 205ms/epoch - 41ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.0548 - accuracy: 0.5639 - val_loss: 1.0457 - val_accuracy: 0.4805 - 195ms/epoch - 39ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.0437 - accuracy: 0.5672 - val_loss: 1.0301 - val_accuracy: 0.4935 - 197ms/epoch - 39ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.0419 - accuracy: 0.5475 - val_loss: 1.0161 - val_accuracy: 0.4935 - 196ms/epoch - 39ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.0339 - accuracy: 0.5770 - val_loss: 1.0330 - val_accuracy: 0.4935 - 200ms/epoch - 40ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0213 - accuracy: 0.5672 - val_loss: 1.0156 - val_accuracy: 0.5065 - 198ms/epoch - 40ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 0.9926 - accuracy: 0.6066 - val_loss: 0.9961 - val_accuracy: 0.5065 - 201ms/epoch - 40ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 0.9962 - accuracy: 0.6098 - val_loss: 0.9713 - val_accuracy: 0.6234 - 199ms/epoch - 40ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 0.9873 - accuracy: 0.5869 - val_loss: 0.9602 - val_accuracy: 0.5714 - 195ms/epoch - 39ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 0.9705 - accuracy: 0.5738 - val_loss: 0.9423 - val_accuracy: 0.5584 - 226ms/epoch - 45ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 0.9722 - accuracy: 0.6328 - val_loss: 0.9391 - val_accuracy: 0.5584 - 224ms/epoch - 45ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 0.9501 - accuracy: 0.6131 - val_loss: 0.9260 - val_accuracy: 0.5584 - 217ms/epoch - 43ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 0.9160 - accuracy: 0.6197 - val_loss: 0.9099 - val_accuracy: 0.6494 - 215ms/epoch - 43ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 0.9594 - accuracy: 0.6066 - val_loss: 0.9246 - val_accuracy: 0.5844 - 221ms/epoch - 44ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 0.9436 - accuracy: 0.6328 - val_loss: 0.8934 - val_accuracy: 0.5974 - 216ms/epoch - 43ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 0.8862 - accuracy: 0.6426 - val_loss: 0.9107 - val_accuracy: 0.6234 - 203ms/epoch - 41ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 0.9107 - accuracy: 0.6230 - val_loss: 0.8883 - val_accuracy: 0.6104 - 211ms/epoch - 42ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 0.8838 - accuracy: 0.6393 - val_loss: 0.8677 - val_accuracy: 0.6364 - 198ms/epoch - 40ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.8657 - accuracy: 0.6689 - val_loss: 0.9261 - val_accuracy: 0.6234 - 205ms/epoch - 41ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.8804 - accuracy: 0.6197 - val_loss: 0.8826 - val_accuracy: 0.6494 - 200ms/epoch - 40ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.8963 - accuracy: 0.6525 - val_loss: 0.8659 - val_accuracy: 0.6883 - 202ms/epoch - 40ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.8631 - accuracy: 0.6393 - val_loss: 0.8621 - val_accuracy: 0.6623 - 201ms/epoch - 40ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.8573 - accuracy: 0.6525 - val_loss: 0.8729 - val_accuracy: 0.6364 - 197ms/epoch - 39ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.8672 - accuracy: 0.6590 - val_loss: 0.8923 - val_accuracy: 0.5974 - 196ms/epoch - 39ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.8722 - accuracy: 0.6721 - val_loss: 0.8894 - val_accuracy: 0.6494 - 199ms/epoch - 40ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.8811 - accuracy: 0.6754 - val_loss: 0.9055 - val_accuracy: 0.6364 - 207ms/epoch - 41ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.8529 - accuracy: 0.6820 - val_loss: 0.8803 - val_accuracy: 0.6623 - 202ms/epoch - 40ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8857 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:51:30,423] Trial 72 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'selu', 'activation_func_3': 'linear', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 129}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3828 - accuracy: 0.3148 - val_loss: 1.3777 - val_accuracy: 0.3506 - 4s/epoch - 756ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3720 - accuracy: 0.4459 - val_loss: 1.3640 - val_accuracy: 0.4286 - 181ms/epoch - 36ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3538 - accuracy: 0.4852 - val_loss: 1.3378 - val_accuracy: 0.4416 - 190ms/epoch - 38ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3218 - accuracy: 0.5049 - val_loss: 1.2954 - val_accuracy: 0.4286 - 187ms/epoch - 37ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.2730 - accuracy: 0.5016 - val_loss: 1.2425 - val_accuracy: 0.4026 - 199ms/epoch - 40ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.2489 - accuracy: 0.5016 - val_loss: 1.2141 - val_accuracy: 0.4026 - 202ms/epoch - 40ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.2205 - accuracy: 0.4951 - val_loss: 1.1975 - val_accuracy: 0.4416 - 207ms/epoch - 41ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.1932 - accuracy: 0.5049 - val_loss: 1.1785 - val_accuracy: 0.4156 - 193ms/epoch - 39ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.1716 - accuracy: 0.4557 - val_loss: 1.1673 - val_accuracy: 0.4026 - 192ms/epoch - 38ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.1432 - accuracy: 0.5344 - val_loss: 1.1534 - val_accuracy: 0.4026 - 187ms/epoch - 37ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1286 - accuracy: 0.5311 - val_loss: 1.1469 - val_accuracy: 0.4286 - 184ms/epoch - 37ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1314 - accuracy: 0.5377 - val_loss: 1.1403 - val_accuracy: 0.4156 - 186ms/epoch - 37ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1383 - accuracy: 0.5311 - val_loss: 1.1309 - val_accuracy: 0.4156 - 195ms/epoch - 39ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.0969 - accuracy: 0.5279 - val_loss: 1.1142 - val_accuracy: 0.4416 - 183ms/epoch - 37ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.0987 - accuracy: 0.5639 - val_loss: 1.0976 - val_accuracy: 0.4675 - 206ms/epoch - 41ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.0910 - accuracy: 0.5475 - val_loss: 1.0824 - val_accuracy: 0.4675 - 208ms/epoch - 42ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.0737 - accuracy: 0.5475 - val_loss: 1.0696 - val_accuracy: 0.4545 - 192ms/epoch - 38ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.0643 - accuracy: 0.5705 - val_loss: 1.0550 - val_accuracy: 0.4675 - 205ms/epoch - 41ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.0578 - accuracy: 0.5705 - val_loss: 1.0504 - val_accuracy: 0.4545 - 189ms/epoch - 38ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.0243 - accuracy: 0.5738 - val_loss: 1.0308 - val_accuracy: 0.5065 - 216ms/epoch - 43ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.0362 - accuracy: 0.5738 - val_loss: 1.0179 - val_accuracy: 0.4545 - 192ms/epoch - 38ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.0317 - accuracy: 0.5508 - val_loss: 1.0061 - val_accuracy: 0.4935 - 210ms/epoch - 42ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.0244 - accuracy: 0.5672 - val_loss: 1.0039 - val_accuracy: 0.5195 - 192ms/epoch - 38ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0099 - accuracy: 0.5869 - val_loss: 0.9883 - val_accuracy: 0.5065 - 206ms/epoch - 41ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.0041 - accuracy: 0.5836 - val_loss: 0.9960 - val_accuracy: 0.5065 - 186ms/epoch - 37ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 0.9662 - accuracy: 0.5902 - val_loss: 0.9613 - val_accuracy: 0.5844 - 205ms/epoch - 41ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 0.9562 - accuracy: 0.5836 - val_loss: 0.9435 - val_accuracy: 0.5584 - 194ms/epoch - 39ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 0.9844 - accuracy: 0.5902 - val_loss: 0.9296 - val_accuracy: 0.5584 - 192ms/epoch - 38ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 0.9356 - accuracy: 0.6525 - val_loss: 0.9292 - val_accuracy: 0.6234 - 198ms/epoch - 40ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 0.9024 - accuracy: 0.6262 - val_loss: 0.9207 - val_accuracy: 0.5455 - 198ms/epoch - 40ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 0.9276 - accuracy: 0.6197 - val_loss: 0.8971 - val_accuracy: 0.6623 - 188ms/epoch - 38ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 0.8957 - accuracy: 0.6230 - val_loss: 0.9211 - val_accuracy: 0.6234 - 204ms/epoch - 41ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 0.9090 - accuracy: 0.6066 - val_loss: 0.9024 - val_accuracy: 0.5455 - 203ms/epoch - 41ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 0.9140 - accuracy: 0.6525 - val_loss: 0.9335 - val_accuracy: 0.6364 - 189ms/epoch - 38ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 0.8783 - accuracy: 0.6525 - val_loss: 0.8779 - val_accuracy: 0.6623 - 197ms/epoch - 39ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 0.9273 - accuracy: 0.6361 - val_loss: 0.8839 - val_accuracy: 0.6494 - 204ms/epoch - 41ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.8578 - accuracy: 0.6459 - val_loss: 0.9181 - val_accuracy: 0.6364 - 186ms/epoch - 37ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.8591 - accuracy: 0.6557 - val_loss: 0.8800 - val_accuracy: 0.6234 - 198ms/epoch - 40ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.8493 - accuracy: 0.6459 - val_loss: 0.8629 - val_accuracy: 0.6494 - 216ms/epoch - 43ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.8286 - accuracy: 0.6820 - val_loss: 0.8970 - val_accuracy: 0.6623 - 221ms/epoch - 44ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.8451 - accuracy: 0.6459 - val_loss: 0.9060 - val_accuracy: 0.6494 - 214ms/epoch - 43ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.8413 - accuracy: 0.6721 - val_loss: 0.9066 - val_accuracy: 0.6234 - 200ms/epoch - 40ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.8529 - accuracy: 0.6557 - val_loss: 0.8966 - val_accuracy: 0.6623 - 211ms/epoch - 42ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.8608 - accuracy: 0.6557 - val_loss: 0.8935 - val_accuracy: 0.6623 - 204ms/epoch - 41ms/step\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:51:44,409] Trial 73 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'selu', 'activation_func_3': 'linear', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 131}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3854 - accuracy: 0.3607 - val_loss: 1.3848 - val_accuracy: 0.3506 - 4s/epoch - 752ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3832 - accuracy: 0.4164 - val_loss: 1.3819 - val_accuracy: 0.3117 - 175ms/epoch - 35ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3782 - accuracy: 0.4230 - val_loss: 1.3764 - val_accuracy: 0.3506 - 190ms/epoch - 38ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3717 - accuracy: 0.4590 - val_loss: 1.3672 - val_accuracy: 0.3506 - 197ms/epoch - 39ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3562 - accuracy: 0.4459 - val_loss: 1.3510 - val_accuracy: 0.3636 - 194ms/epoch - 39ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3312 - accuracy: 0.4557 - val_loss: 1.3231 - val_accuracy: 0.3636 - 195ms/epoch - 39ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3039 - accuracy: 0.4623 - val_loss: 1.2879 - val_accuracy: 0.3766 - 198ms/epoch - 40ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2532 - accuracy: 0.4590 - val_loss: 1.2514 - val_accuracy: 0.3636 - 188ms/epoch - 38ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2268 - accuracy: 0.4590 - val_loss: 1.2240 - val_accuracy: 0.3506 - 189ms/epoch - 38ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2006 - accuracy: 0.4590 - val_loss: 1.2076 - val_accuracy: 0.3636 - 182ms/epoch - 36ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1803 - accuracy: 0.4885 - val_loss: 1.1887 - val_accuracy: 0.3896 - 188ms/epoch - 38ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1633 - accuracy: 0.4820 - val_loss: 1.1740 - val_accuracy: 0.4026 - 199ms/epoch - 40ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1741 - accuracy: 0.4918 - val_loss: 1.1725 - val_accuracy: 0.4026 - 193ms/epoch - 39ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1443 - accuracy: 0.5049 - val_loss: 1.1553 - val_accuracy: 0.4026 - 183ms/epoch - 37ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1445 - accuracy: 0.5082 - val_loss: 1.1429 - val_accuracy: 0.4026 - 190ms/epoch - 38ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1235 - accuracy: 0.5016 - val_loss: 1.1368 - val_accuracy: 0.4026 - 190ms/epoch - 38ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1119 - accuracy: 0.5311 - val_loss: 1.1229 - val_accuracy: 0.3896 - 184ms/epoch - 37ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1105 - accuracy: 0.5377 - val_loss: 1.1067 - val_accuracy: 0.4286 - 184ms/epoch - 37ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1079 - accuracy: 0.5213 - val_loss: 1.0978 - val_accuracy: 0.4156 - 185ms/epoch - 37ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.0836 - accuracy: 0.5344 - val_loss: 1.0867 - val_accuracy: 0.4416 - 185ms/epoch - 37ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.0894 - accuracy: 0.5705 - val_loss: 1.0825 - val_accuracy: 0.4416 - 187ms/epoch - 37ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.0889 - accuracy: 0.5541 - val_loss: 1.0665 - val_accuracy: 0.4286 - 188ms/epoch - 38ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.0839 - accuracy: 0.5508 - val_loss: 1.0737 - val_accuracy: 0.5065 - 187ms/epoch - 37ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0524 - accuracy: 0.5705 - val_loss: 1.0523 - val_accuracy: 0.4805 - 189ms/epoch - 38ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.0482 - accuracy: 0.5639 - val_loss: 1.0434 - val_accuracy: 0.5065 - 199ms/epoch - 40ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0387 - accuracy: 0.5803 - val_loss: 1.0230 - val_accuracy: 0.5195 - 187ms/epoch - 37ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0258 - accuracy: 0.5803 - val_loss: 1.0139 - val_accuracy: 0.5455 - 191ms/epoch - 38ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0218 - accuracy: 0.5803 - val_loss: 1.0053 - val_accuracy: 0.5195 - 189ms/epoch - 38ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0217 - accuracy: 0.6098 - val_loss: 1.0004 - val_accuracy: 0.5584 - 195ms/epoch - 39ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0138 - accuracy: 0.6000 - val_loss: 0.9769 - val_accuracy: 0.5195 - 187ms/epoch - 37ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 0.9972 - accuracy: 0.6000 - val_loss: 0.9749 - val_accuracy: 0.5325 - 187ms/epoch - 37ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 0.9615 - accuracy: 0.6066 - val_loss: 0.9621 - val_accuracy: 0.5714 - 198ms/epoch - 40ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 0.9830 - accuracy: 0.6000 - val_loss: 0.9443 - val_accuracy: 0.5584 - 185ms/epoch - 37ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 0.9642 - accuracy: 0.6328 - val_loss: 0.9460 - val_accuracy: 0.5714 - 194ms/epoch - 39ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 0.9159 - accuracy: 0.6197 - val_loss: 0.9187 - val_accuracy: 0.5455 - 193ms/epoch - 39ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 0.9431 - accuracy: 0.6098 - val_loss: 0.9100 - val_accuracy: 0.5714 - 191ms/epoch - 38ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.9340 - accuracy: 0.6197 - val_loss: 0.9239 - val_accuracy: 0.6364 - 184ms/epoch - 37ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.9358 - accuracy: 0.6033 - val_loss: 0.8998 - val_accuracy: 0.5714 - 197ms/epoch - 39ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.9361 - accuracy: 0.6131 - val_loss: 0.8933 - val_accuracy: 0.5974 - 190ms/epoch - 38ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.9255 - accuracy: 0.6459 - val_loss: 0.8893 - val_accuracy: 0.6364 - 191ms/epoch - 38ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.9188 - accuracy: 0.6459 - val_loss: 0.8696 - val_accuracy: 0.6494 - 185ms/epoch - 37ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.9157 - accuracy: 0.6426 - val_loss: 0.8810 - val_accuracy: 0.5974 - 189ms/epoch - 38ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.8871 - accuracy: 0.6197 - val_loss: 0.8896 - val_accuracy: 0.6234 - 186ms/epoch - 37ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.9181 - accuracy: 0.6492 - val_loss: 0.8958 - val_accuracy: 0.6104 - 190ms/epoch - 38ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.8994 - accuracy: 0.6459 - val_loss: 0.8768 - val_accuracy: 0.6234 - 190ms/epoch - 38ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9025 - accuracy: 0.6492 - val_loss: 0.9022 - val_accuracy: 0.6364 - 192ms/epoch - 38ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8389 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:51:58,459] Trial 74 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'relu', 'activation_func_3': 'linear', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 135}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 5s - loss: 1.3791 - accuracy: 0.3213 - val_loss: 1.3719 - val_accuracy: 0.4545 - 5s/epoch - 908ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3613 - accuracy: 0.4000 - val_loss: 1.3500 - val_accuracy: 0.3766 - 230ms/epoch - 46ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3292 - accuracy: 0.4393 - val_loss: 1.3127 - val_accuracy: 0.4286 - 250ms/epoch - 50ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.2842 - accuracy: 0.4754 - val_loss: 1.2645 - val_accuracy: 0.3506 - 246ms/epoch - 49ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.2283 - accuracy: 0.4820 - val_loss: 1.2191 - val_accuracy: 0.3636 - 247ms/epoch - 49ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.1819 - accuracy: 0.5115 - val_loss: 1.1945 - val_accuracy: 0.4286 - 253ms/epoch - 51ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.1951 - accuracy: 0.5279 - val_loss: 1.1720 - val_accuracy: 0.4416 - 251ms/epoch - 50ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.1543 - accuracy: 0.5246 - val_loss: 1.1481 - val_accuracy: 0.4286 - 248ms/epoch - 50ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.1402 - accuracy: 0.5180 - val_loss: 1.1442 - val_accuracy: 0.4545 - 243ms/epoch - 49ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.1283 - accuracy: 0.5508 - val_loss: 1.1268 - val_accuracy: 0.4675 - 251ms/epoch - 50ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1117 - accuracy: 0.5475 - val_loss: 1.1177 - val_accuracy: 0.4805 - 242ms/epoch - 48ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1007 - accuracy: 0.5344 - val_loss: 1.0955 - val_accuracy: 0.4805 - 241ms/epoch - 48ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.0704 - accuracy: 0.5574 - val_loss: 1.0750 - val_accuracy: 0.4935 - 243ms/epoch - 49ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.0619 - accuracy: 0.5574 - val_loss: 1.0501 - val_accuracy: 0.5195 - 248ms/epoch - 50ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.0598 - accuracy: 0.5705 - val_loss: 1.0397 - val_accuracy: 0.4935 - 248ms/epoch - 50ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.0495 - accuracy: 0.5541 - val_loss: 1.0260 - val_accuracy: 0.5065 - 267ms/epoch - 53ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.0411 - accuracy: 0.5607 - val_loss: 1.0107 - val_accuracy: 0.5195 - 262ms/epoch - 52ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.0376 - accuracy: 0.5443 - val_loss: 1.0075 - val_accuracy: 0.4935 - 247ms/epoch - 49ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.0242 - accuracy: 0.5639 - val_loss: 0.9981 - val_accuracy: 0.5195 - 244ms/epoch - 49ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 0.9803 - accuracy: 0.5836 - val_loss: 0.9969 - val_accuracy: 0.5844 - 247ms/epoch - 49ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 0.9943 - accuracy: 0.5705 - val_loss: 0.9511 - val_accuracy: 0.5455 - 245ms/epoch - 49ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 0.9794 - accuracy: 0.5836 - val_loss: 0.9508 - val_accuracy: 0.5325 - 246ms/epoch - 49ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 0.9797 - accuracy: 0.6131 - val_loss: 1.0016 - val_accuracy: 0.5714 - 248ms/epoch - 50ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 0.9604 - accuracy: 0.6262 - val_loss: 0.9299 - val_accuracy: 0.5844 - 250ms/epoch - 50ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 0.9245 - accuracy: 0.6164 - val_loss: 0.9462 - val_accuracy: 0.5455 - 243ms/epoch - 49ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 0.9414 - accuracy: 0.5934 - val_loss: 0.9045 - val_accuracy: 0.6364 - 245ms/epoch - 49ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 0.9006 - accuracy: 0.6393 - val_loss: 0.9063 - val_accuracy: 0.5974 - 246ms/epoch - 49ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 0.8998 - accuracy: 0.6197 - val_loss: 0.9003 - val_accuracy: 0.5844 - 249ms/epoch - 50ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 0.8997 - accuracy: 0.6328 - val_loss: 0.9227 - val_accuracy: 0.5455 - 248ms/epoch - 50ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 0.8721 - accuracy: 0.6459 - val_loss: 0.8770 - val_accuracy: 0.6234 - 243ms/epoch - 49ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 0.8924 - accuracy: 0.6492 - val_loss: 0.8749 - val_accuracy: 0.6364 - 255ms/epoch - 51ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 0.8932 - accuracy: 0.6557 - val_loss: 0.9071 - val_accuracy: 0.6234 - 248ms/epoch - 50ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 0.8924 - accuracy: 0.6000 - val_loss: 0.9047 - val_accuracy: 0.5714 - 247ms/epoch - 49ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 0.8596 - accuracy: 0.6492 - val_loss: 0.8976 - val_accuracy: 0.6364 - 247ms/epoch - 49ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 0.8340 - accuracy: 0.6852 - val_loss: 0.8670 - val_accuracy: 0.6494 - 254ms/epoch - 51ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 0.8665 - accuracy: 0.6426 - val_loss: 0.8905 - val_accuracy: 0.5974 - 246ms/epoch - 49ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 0.8208 - accuracy: 0.6623 - val_loss: 0.8915 - val_accuracy: 0.6364 - 255ms/epoch - 51ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 0.8766 - accuracy: 0.6754 - val_loss: 0.9104 - val_accuracy: 0.5714 - 248ms/epoch - 50ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 0.8457 - accuracy: 0.6754 - val_loss: 0.8632 - val_accuracy: 0.6364 - 252ms/epoch - 50ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.8489 - accuracy: 0.6689 - val_loss: 0.9276 - val_accuracy: 0.5974 - 251ms/epoch - 50ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.8314 - accuracy: 0.6689 - val_loss: 0.8797 - val_accuracy: 0.6364 - 246ms/epoch - 49ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 0.8439 - accuracy: 0.6525 - val_loss: 0.9332 - val_accuracy: 0.5584 - 244ms/epoch - 49ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.8167 - accuracy: 0.6754 - val_loss: 0.9032 - val_accuracy: 0.6494 - 259ms/epoch - 52ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.8358 - accuracy: 0.6525 - val_loss: 0.9000 - val_accuracy: 0.6364 - 273ms/epoch - 55ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8485 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:52:15,443] Trial 75 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'selu', 'activation_func_3': 'selu', 'batch_size': 64, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 140}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3858 - accuracy: 0.2689 - val_loss: 1.3834 - val_accuracy: 0.2857 - 4s/epoch - 562ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3832 - accuracy: 0.3180 - val_loss: 1.3799 - val_accuracy: 0.3117 - 235ms/epoch - 34ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3782 - accuracy: 0.3049 - val_loss: 1.3739 - val_accuracy: 0.2857 - 255ms/epoch - 36ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3700 - accuracy: 0.3410 - val_loss: 1.3617 - val_accuracy: 0.3506 - 257ms/epoch - 37ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3535 - accuracy: 0.3803 - val_loss: 1.3455 - val_accuracy: 0.3117 - 256ms/epoch - 37ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3246 - accuracy: 0.3836 - val_loss: 1.3232 - val_accuracy: 0.3247 - 252ms/epoch - 36ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2932 - accuracy: 0.4262 - val_loss: 1.2938 - val_accuracy: 0.3636 - 263ms/epoch - 38ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2638 - accuracy: 0.4557 - val_loss: 1.2758 - val_accuracy: 0.3636 - 253ms/epoch - 36ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2524 - accuracy: 0.4393 - val_loss: 1.2526 - val_accuracy: 0.3766 - 256ms/epoch - 37ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2171 - accuracy: 0.4590 - val_loss: 1.2392 - val_accuracy: 0.3766 - 254ms/epoch - 36ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1959 - accuracy: 0.4623 - val_loss: 1.2206 - val_accuracy: 0.3766 - 378ms/epoch - 54ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1792 - accuracy: 0.4852 - val_loss: 1.2069 - val_accuracy: 0.3766 - 309ms/epoch - 44ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1810 - accuracy: 0.4754 - val_loss: 1.1926 - val_accuracy: 0.3766 - 313ms/epoch - 45ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1644 - accuracy: 0.4623 - val_loss: 1.1830 - val_accuracy: 0.3766 - 315ms/epoch - 45ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1736 - accuracy: 0.4721 - val_loss: 1.1621 - val_accuracy: 0.4156 - 370ms/epoch - 53ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1650 - accuracy: 0.5016 - val_loss: 1.1782 - val_accuracy: 0.4286 - 318ms/epoch - 45ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1645 - accuracy: 0.5213 - val_loss: 1.1709 - val_accuracy: 0.4156 - 304ms/epoch - 43ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1644 - accuracy: 0.4852 - val_loss: 1.1574 - val_accuracy: 0.3766 - 314ms/epoch - 45ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1400 - accuracy: 0.5049 - val_loss: 1.1637 - val_accuracy: 0.4026 - 300ms/epoch - 43ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1390 - accuracy: 0.4951 - val_loss: 1.1512 - val_accuracy: 0.3896 - 314ms/epoch - 45ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1383 - accuracy: 0.4787 - val_loss: 1.1388 - val_accuracy: 0.3896 - 299ms/epoch - 43ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1226 - accuracy: 0.5213 - val_loss: 1.1261 - val_accuracy: 0.4156 - 285ms/epoch - 41ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1365 - accuracy: 0.5344 - val_loss: 1.1304 - val_accuracy: 0.4156 - 287ms/epoch - 41ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1155 - accuracy: 0.5279 - val_loss: 1.1161 - val_accuracy: 0.4026 - 268ms/epoch - 38ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1164 - accuracy: 0.5016 - val_loss: 1.1182 - val_accuracy: 0.4026 - 283ms/epoch - 40ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1185 - accuracy: 0.5180 - val_loss: 1.1071 - val_accuracy: 0.4545 - 288ms/epoch - 41ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1168 - accuracy: 0.5213 - val_loss: 1.1134 - val_accuracy: 0.4935 - 273ms/epoch - 39ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1058 - accuracy: 0.5311 - val_loss: 1.1061 - val_accuracy: 0.4805 - 268ms/epoch - 38ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1059 - accuracy: 0.5475 - val_loss: 1.1041 - val_accuracy: 0.5195 - 270ms/epoch - 39ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1100 - accuracy: 0.5508 - val_loss: 1.1247 - val_accuracy: 0.4416 - 306ms/epoch - 44ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1219 - accuracy: 0.5344 - val_loss: 1.1082 - val_accuracy: 0.4416 - 278ms/epoch - 40ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0952 - accuracy: 0.5246 - val_loss: 1.1289 - val_accuracy: 0.4286 - 289ms/epoch - 41ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.1205 - accuracy: 0.5246 - val_loss: 1.1386 - val_accuracy: 0.4286 - 284ms/epoch - 41ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0888 - accuracy: 0.5279 - val_loss: 1.1284 - val_accuracy: 0.4286 - 277ms/epoch - 40ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0438 - accuracy: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:52:30,583] Trial 76 finished with value: 0.5735294222831726 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'linear', 'batch_size': 50, 'dropout_1': 0.25, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 138}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 6s - loss: 1.3847 - accuracy: 0.3246 - val_loss: 1.3821 - val_accuracy: 0.3636 - 6s/epoch - 612ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3776 - accuracy: 0.3902 - val_loss: 1.3713 - val_accuracy: 0.3506 - 235ms/epoch - 23ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3607 - accuracy: 0.4623 - val_loss: 1.3491 - val_accuracy: 0.4545 - 261ms/epoch - 26ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3250 - accuracy: 0.4492 - val_loss: 1.3088 - val_accuracy: 0.4156 - 254ms/epoch - 25ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2723 - accuracy: 0.4918 - val_loss: 1.2549 - val_accuracy: 0.3766 - 262ms/epoch - 26ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2282 - accuracy: 0.4689 - val_loss: 1.2177 - val_accuracy: 0.3896 - 275ms/epoch - 27ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1951 - accuracy: 0.5016 - val_loss: 1.1953 - val_accuracy: 0.4026 - 253ms/epoch - 25ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2157 - accuracy: 0.4656 - val_loss: 1.1763 - val_accuracy: 0.4286 - 266ms/epoch - 27ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1976 - accuracy: 0.4951 - val_loss: 1.1556 - val_accuracy: 0.4026 - 255ms/epoch - 26ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1438 - accuracy: 0.4984 - val_loss: 1.1372 - val_accuracy: 0.4156 - 268ms/epoch - 27ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1259 - accuracy: 0.5049 - val_loss: 1.1316 - val_accuracy: 0.4156 - 259ms/epoch - 26ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1172 - accuracy: 0.5213 - val_loss: 1.1144 - val_accuracy: 0.4545 - 272ms/epoch - 27ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.0971 - accuracy: 0.5377 - val_loss: 1.1045 - val_accuracy: 0.4416 - 267ms/epoch - 27ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1029 - accuracy: 0.5705 - val_loss: 1.0842 - val_accuracy: 0.5065 - 263ms/epoch - 26ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0774 - accuracy: 0.5705 - val_loss: 1.0805 - val_accuracy: 0.4545 - 261ms/epoch - 26ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0776 - accuracy: 0.5508 - val_loss: 1.0741 - val_accuracy: 0.4545 - 263ms/epoch - 26ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0885 - accuracy: 0.5344 - val_loss: 1.0650 - val_accuracy: 0.5325 - 261ms/epoch - 26ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0730 - accuracy: 0.5541 - val_loss: 1.0700 - val_accuracy: 0.4805 - 266ms/epoch - 27ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0813 - accuracy: 0.5607 - val_loss: 1.0712 - val_accuracy: 0.4675 - 260ms/epoch - 26ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0516 - accuracy: 0.5344 - val_loss: 1.0321 - val_accuracy: 0.5455 - 252ms/epoch - 25ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0529 - accuracy: 0.5574 - val_loss: 1.0316 - val_accuracy: 0.4935 - 258ms/epoch - 26ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0544 - accuracy: 0.5508 - val_loss: 1.0267 - val_accuracy: 0.4675 - 274ms/epoch - 27ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0429 - accuracy: 0.5836 - val_loss: 1.0172 - val_accuracy: 0.5455 - 289ms/epoch - 29ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0304 - accuracy: 0.5639 - val_loss: 1.0187 - val_accuracy: 0.5455 - 268ms/epoch - 27ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9829 - accuracy: 0.5902 - val_loss: 0.9928 - val_accuracy: 0.5065 - 256ms/epoch - 26ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0117 - accuracy: 0.5836 - val_loss: 0.9661 - val_accuracy: 0.5844 - 275ms/epoch - 28ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9815 - accuracy: 0.6066 - val_loss: 0.9682 - val_accuracy: 0.5195 - 279ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9664 - accuracy: 0.5902 - val_loss: 0.9540 - val_accuracy: 0.5844 - 262ms/epoch - 26ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9699 - accuracy: 0.6328 - val_loss: 0.9474 - val_accuracy: 0.5455 - 272ms/epoch - 27ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9706 - accuracy: 0.6262 - val_loss: 0.9194 - val_accuracy: 0.6234 - 276ms/epoch - 28ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9808 - accuracy: 0.5934 - val_loss: 0.9181 - val_accuracy: 0.5974 - 274ms/epoch - 27ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9538 - accuracy: 0.6262 - val_loss: 0.9160 - val_accuracy: 0.5455 - 273ms/epoch - 27ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9576 - accuracy: 0.6066 - val_loss: 0.9142 - val_accuracy: 0.5584 - 283ms/epoch - 28ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9508 - accuracy: 0.6131 - val_loss: 0.9091 - val_accuracy: 0.6234 - 294ms/epoch - 29ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9624 - accuracy: 0.6230 - val_loss: 0.9012 - val_accuracy: 0.6234 - 281ms/epoch - 28ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9237 - accuracy: 0.6262 - val_loss: 0.8902 - val_accuracy: 0.6364 - 277ms/epoch - 28ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.8971 - accuracy: 0.6459 - val_loss: 0.8876 - val_accuracy: 0.6364 - 288ms/epoch - 29ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9030 - accuracy: 0.6328 - val_loss: 0.8932 - val_accuracy: 0.6104 - 275ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9117 - accuracy: 0.6164 - val_loss: 0.9005 - val_accuracy: 0.6364 - 278ms/epoch - 28ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9220 - accuracy: 0.6426 - val_loss: 0.8821 - val_accuracy: 0.6234 - 255ms/epoch - 25ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9281 - accuracy: 0.6393 - val_loss: 0.8877 - val_accuracy: 0.6364 - 256ms/epoch - 26ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9281 - accuracy: 0.6295 - val_loss: 0.9008 - val_accuracy: 0.5584 - 267ms/epoch - 27ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9010 - accuracy: 0.6426 - val_loss: 0.9021 - val_accuracy: 0.6234 - 280ms/epoch - 28ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.8880 - accuracy: 0.6689 - val_loss: 0.8766 - val_accuracy: 0.6234 - 260ms/epoch - 26ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9288 - accuracy: 0.6557 - val_loss: 0.8762 - val_accuracy: 0.6494 - 269ms/epoch - 27ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.8950 - accuracy: 0.6426 - val_loss: 0.8739 - val_accuracy: 0.6364 - 256ms/epoch - 26ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.8921 - accuracy: 0.6361 - val_loss: 0.8639 - val_accuracy: 0.6494 - 263ms/epoch - 26ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.8914 - accuracy: 0.6721 - val_loss: 0.8920 - val_accuracy: 0.6364 - 258ms/epoch - 26ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9093 - accuracy: 0.6525 - val_loss: 0.8630 - val_accuracy: 0.6364 - 264ms/epoch - 26ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.8792 - accuracy: 0.6361 - val_loss: 0.9035 - val_accuracy: 0.6494 - 271ms/epoch - 27ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.8715 - accuracy: 0.6820 - val_loss: 0.8701 - val_accuracy: 0.6364 - 262ms/epoch - 26ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.8689 - accuracy: 0.6820 - val_loss: 0.8674 - val_accuracy: 0.6364 - 266ms/epoch - 27ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.8643 - accuracy: 0.6459 - val_loss: 0.8958 - val_accuracy: 0.6104 - 256ms/epoch - 26ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.8746 - accuracy: 0.6787 - val_loss: 0.8769 - val_accuracy: 0.6494 - 268ms/epoch - 27ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8828 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:52:53,014] Trial 77 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'tanh', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 142}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3855 - accuracy: 0.2820 - val_loss: 1.3835 - val_accuracy: 0.2468 - 4s/epoch - 412ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3828 - accuracy: 0.3344 - val_loss: 1.3786 - val_accuracy: 0.3636 - 219ms/epoch - 22ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3753 - accuracy: 0.4033 - val_loss: 1.3684 - val_accuracy: 0.3766 - 235ms/epoch - 24ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3562 - accuracy: 0.4656 - val_loss: 1.3439 - val_accuracy: 0.3766 - 238ms/epoch - 24ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3036 - accuracy: 0.4492 - val_loss: 1.3042 - val_accuracy: 0.3896 - 232ms/epoch - 23ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2350 - accuracy: 0.4721 - val_loss: 1.2274 - val_accuracy: 0.3896 - 229ms/epoch - 23ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2102 - accuracy: 0.4590 - val_loss: 1.1946 - val_accuracy: 0.3766 - 225ms/epoch - 22ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2027 - accuracy: 0.4820 - val_loss: 1.1939 - val_accuracy: 0.4026 - 228ms/epoch - 23ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1983 - accuracy: 0.4820 - val_loss: 1.1847 - val_accuracy: 0.4156 - 230ms/epoch - 23ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1736 - accuracy: 0.4918 - val_loss: 1.1779 - val_accuracy: 0.4156 - 226ms/epoch - 23ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1730 - accuracy: 0.4852 - val_loss: 1.1777 - val_accuracy: 0.4156 - 237ms/epoch - 24ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1428 - accuracy: 0.5082 - val_loss: 1.1836 - val_accuracy: 0.4026 - 224ms/epoch - 22ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1782 - accuracy: 0.4918 - val_loss: 1.1624 - val_accuracy: 0.4156 - 233ms/epoch - 23ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1771 - accuracy: 0.4918 - val_loss: 1.1497 - val_accuracy: 0.4026 - 231ms/epoch - 23ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1361 - accuracy: 0.5082 - val_loss: 1.1388 - val_accuracy: 0.4156 - 231ms/epoch - 23ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1409 - accuracy: 0.5082 - val_loss: 1.1271 - val_accuracy: 0.4026 - 223ms/epoch - 22ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1345 - accuracy: 0.5082 - val_loss: 1.1303 - val_accuracy: 0.4026 - 225ms/epoch - 22ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1301 - accuracy: 0.5180 - val_loss: 1.1183 - val_accuracy: 0.4026 - 222ms/epoch - 22ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1319 - accuracy: 0.5115 - val_loss: 1.1280 - val_accuracy: 0.4026 - 234ms/epoch - 23ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1192 - accuracy: 0.5115 - val_loss: 1.1280 - val_accuracy: 0.4286 - 241ms/epoch - 24ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1220 - accuracy: 0.5311 - val_loss: 1.1165 - val_accuracy: 0.4156 - 256ms/epoch - 26ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1223 - accuracy: 0.5213 - val_loss: 1.1131 - val_accuracy: 0.4026 - 255ms/epoch - 25ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1282 - accuracy: 0.5115 - val_loss: 1.1170 - val_accuracy: 0.4026 - 249ms/epoch - 25ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.1101 - accuracy: 0.5148 - val_loss: 1.1082 - val_accuracy: 0.4026 - 251ms/epoch - 25ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.1026 - accuracy: 0.5148 - val_loss: 1.1068 - val_accuracy: 0.4156 - 253ms/epoch - 25ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0918 - accuracy: 0.5574 - val_loss: 1.0964 - val_accuracy: 0.4156 - 242ms/epoch - 24ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.1361 - accuracy: 0.5443 - val_loss: 1.1084 - val_accuracy: 0.4156 - 233ms/epoch - 23ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.1017 - accuracy: 0.5311 - val_loss: 1.0974 - val_accuracy: 0.4156 - 225ms/epoch - 22ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0764 - accuracy: 0.5344 - val_loss: 1.1043 - val_accuracy: 0.4286 - 232ms/epoch - 23ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0746 - accuracy: 0.5344 - val_loss: 1.0991 - val_accuracy: 0.4286 - 230ms/epoch - 23ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0959 - accuracy: 0.5246 - val_loss: 1.0908 - val_accuracy: 0.4416 - 230ms/epoch - 23ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.1102 - accuracy: 0.5213 - val_loss: 1.0968 - val_accuracy: 0.4805 - 227ms/epoch - 23ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0713 - accuracy: 0.5246 - val_loss: 1.0954 - val_accuracy: 0.4545 - 245ms/epoch - 25ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.1129 - accuracy: 0.5410 - val_loss: 1.0923 - val_accuracy: 0.4545 - 255ms/epoch - 25ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0773 - accuracy: 0.5344 - val_loss: 1.0796 - val_accuracy: 0.4675 - 227ms/epoch - 23ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0712 - accuracy: 0.5541 - val_loss: 1.0680 - val_accuracy: 0.4545 - 230ms/epoch - 23ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0714 - accuracy: 0.5607 - val_loss: 1.0679 - val_accuracy: 0.5065 - 229ms/epoch - 23ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0711 - accuracy: 0.5672 - val_loss: 1.0664 - val_accuracy: 0.5065 - 229ms/epoch - 23ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0665 - accuracy: 0.5639 - val_loss: 1.0809 - val_accuracy: 0.4935 - 226ms/epoch - 23ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0522 - accuracy: 0.5869 - val_loss: 1.0549 - val_accuracy: 0.4935 - 233ms/epoch - 23ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0809 - accuracy: 0.5672 - val_loss: 1.0360 - val_accuracy: 0.5844 - 231ms/epoch - 23ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0587 - accuracy: 0.5672 - val_loss: 1.0294 - val_accuracy: 0.5065 - 231ms/epoch - 23ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0453 - accuracy: 0.6000 - val_loss: 1.0397 - val_accuracy: 0.4935 - 228ms/epoch - 23ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0963 - accuracy: 0.5508 - val_loss: 1.0350 - val_accuracy: 0.5065 - 231ms/epoch - 23ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0316 - accuracy: 0.5738 - val_loss: 1.0279 - val_accuracy: 0.5195 - 232ms/epoch - 23ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 1.0279 - accuracy: 0.5672 - val_loss: 1.0133 - val_accuracy: 0.5325 - 223ms/epoch - 22ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 1.0216 - accuracy: 0.5869 - val_loss: 1.0063 - val_accuracy: 0.5195 - 221ms/epoch - 22ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 1.0463 - accuracy: 0.5541 - val_loss: 0.9976 - val_accuracy: 0.5195 - 239ms/epoch - 24ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 1.0163 - accuracy: 0.5803 - val_loss: 1.0017 - val_accuracy: 0.5325 - 231ms/epoch - 23ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 1.0217 - accuracy: 0.6000 - val_loss: 0.9794 - val_accuracy: 0.5325 - 225ms/epoch - 22ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 1.0459 - accuracy: 0.5803 - val_loss: 0.9656 - val_accuracy: 0.5455 - 235ms/epoch - 23ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 1.0226 - accuracy: 0.5869 - val_loss: 0.9664 - val_accuracy: 0.5455 - 239ms/epoch - 24ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9721 - accuracy: 0.5639 - val_loss: 0.9840 - val_accuracy: 0.5325 - 229ms/epoch - 23ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9977 - accuracy: 0.6098 - val_loss: 0.9707 - val_accuracy: 0.5325 - 233ms/epoch - 23ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9593 - accuracy: 0.6164 - val_loss: 0.9461 - val_accuracy: 0.5325 - 232ms/epoch - 23ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9900 - accuracy: 0.6033 - val_loss: 0.9442 - val_accuracy: 0.5714 - 226ms/epoch - 23ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9824 - accuracy: 0.6230 - val_loss: 0.9367 - val_accuracy: 0.5974 - 244ms/epoch - 24ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9489 - accuracy: 0.6000 - val_loss: 0.9338 - val_accuracy: 0.5844 - 226ms/epoch - 23ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9469 - accuracy: 0.5869 - val_loss: 0.9075 - val_accuracy: 0.5844 - 228ms/epoch - 23ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9449 - accuracy: 0.6000 - val_loss: 0.9219 - val_accuracy: 0.5844 - 227ms/epoch - 23ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9777 - accuracy: 0.6197 - val_loss: 0.8989 - val_accuracy: 0.5974 - 255ms/epoch - 25ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9315 - accuracy: 0.6131 - val_loss: 0.9065 - val_accuracy: 0.5584 - 234ms/epoch - 23ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9691 - accuracy: 0.6131 - val_loss: 0.9104 - val_accuracy: 0.5974 - 238ms/epoch - 24ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9415 - accuracy: 0.6361 - val_loss: 0.9020 - val_accuracy: 0.5455 - 225ms/epoch - 22ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9512 - accuracy: 0.6131 - val_loss: 0.8983 - val_accuracy: 0.5974 - 240ms/epoch - 24ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.9622 - accuracy: 0.6393 - val_loss: 0.9081 - val_accuracy: 0.5714 - 219ms/epoch - 22ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.9184 - accuracy: 0.6393 - val_loss: 0.8848 - val_accuracy: 0.6234 - 228ms/epoch - 23ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.9412 - accuracy: 0.6557 - val_loss: 0.8821 - val_accuracy: 0.5844 - 240ms/epoch - 24ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.9062 - accuracy: 0.6262 - val_loss: 0.8840 - val_accuracy: 0.6234 - 259ms/epoch - 26ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.9466 - accuracy: 0.6623 - val_loss: 0.8895 - val_accuracy: 0.5844 - 234ms/epoch - 23ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9346 - accuracy: 0.6426 - val_loss: 0.8855 - val_accuracy: 0.6104 - 242ms/epoch - 24ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.9448 - accuracy: 0.6066 - val_loss: 0.8967 - val_accuracy: 0.5844 - 234ms/epoch - 23ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.9683 - accuracy: 0.6262 - val_loss: 0.8815 - val_accuracy: 0.6234 - 228ms/epoch - 23ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.9075 - accuracy: 0.6426 - val_loss: 0.8583 - val_accuracy: 0.6364 - 239ms/epoch - 24ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.9168 - accuracy: 0.6525 - val_loss: 0.8627 - val_accuracy: 0.6104 - 225ms/epoch - 22ms/step\n",
      "Epoch 76/10000\n",
      "10/10 - 0s - loss: 0.9099 - accuracy: 0.6557 - val_loss: 0.8714 - val_accuracy: 0.6364 - 238ms/epoch - 24ms/step\n",
      "Epoch 77/10000\n",
      "10/10 - 0s - loss: 0.8749 - accuracy: 0.6721 - val_loss: 0.8805 - val_accuracy: 0.5974 - 243ms/epoch - 24ms/step\n",
      "Epoch 78/10000\n",
      "10/10 - 0s - loss: 0.9406 - accuracy: 0.6492 - val_loss: 0.8840 - val_accuracy: 0.6104 - 233ms/epoch - 23ms/step\n",
      "Epoch 79/10000\n",
      "10/10 - 0s - loss: 0.9110 - accuracy: 0.6590 - val_loss: 0.8941 - val_accuracy: 0.5844 - 233ms/epoch - 23ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8685 - accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:53:17,212] Trial 78 finished with value: 0.7058823704719543 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 131}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3857 - accuracy: 0.3148 - val_loss: 1.3850 - val_accuracy: 0.3636 - 5s/epoch - 495ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3840 - accuracy: 0.3738 - val_loss: 1.3820 - val_accuracy: 0.3117 - 249ms/epoch - 25ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3798 - accuracy: 0.3836 - val_loss: 1.3762 - val_accuracy: 0.3117 - 255ms/epoch - 25ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3700 - accuracy: 0.4131 - val_loss: 1.3632 - val_accuracy: 0.3377 - 260ms/epoch - 26ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3482 - accuracy: 0.4098 - val_loss: 1.3349 - val_accuracy: 0.3636 - 253ms/epoch - 25ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.3000 - accuracy: 0.4852 - val_loss: 1.2892 - val_accuracy: 0.3636 - 250ms/epoch - 25ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.3017 - accuracy: 0.4426 - val_loss: 1.2529 - val_accuracy: 0.3636 - 254ms/epoch - 25ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2827 - accuracy: 0.4525 - val_loss: 1.2570 - val_accuracy: 0.3636 - 251ms/epoch - 25ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2597 - accuracy: 0.4656 - val_loss: 1.2211 - val_accuracy: 0.3896 - 255ms/epoch - 26ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.2081 - accuracy: 0.4689 - val_loss: 1.2016 - val_accuracy: 0.3896 - 256ms/epoch - 26ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1676 - accuracy: 0.4918 - val_loss: 1.1803 - val_accuracy: 0.3766 - 246ms/epoch - 25ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1589 - accuracy: 0.4852 - val_loss: 1.1888 - val_accuracy: 0.4026 - 270ms/epoch - 27ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1807 - accuracy: 0.4852 - val_loss: 1.1625 - val_accuracy: 0.3766 - 243ms/epoch - 24ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1541 - accuracy: 0.4918 - val_loss: 1.1421 - val_accuracy: 0.4156 - 246ms/epoch - 25ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1456 - accuracy: 0.4918 - val_loss: 1.1424 - val_accuracy: 0.3766 - 251ms/epoch - 25ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1314 - accuracy: 0.5344 - val_loss: 1.1237 - val_accuracy: 0.4026 - 249ms/epoch - 25ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1491 - accuracy: 0.4951 - val_loss: 1.1104 - val_accuracy: 0.4286 - 265ms/epoch - 27ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1298 - accuracy: 0.4951 - val_loss: 1.1056 - val_accuracy: 0.4286 - 242ms/epoch - 24ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1353 - accuracy: 0.5016 - val_loss: 1.1056 - val_accuracy: 0.4286 - 251ms/epoch - 25ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1114 - accuracy: 0.5049 - val_loss: 1.0965 - val_accuracy: 0.4935 - 253ms/epoch - 25ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1164 - accuracy: 0.4984 - val_loss: 1.0864 - val_accuracy: 0.4416 - 245ms/epoch - 25ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1236 - accuracy: 0.5115 - val_loss: 1.0871 - val_accuracy: 0.4675 - 249ms/epoch - 25ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1257 - accuracy: 0.5213 - val_loss: 1.1030 - val_accuracy: 0.4805 - 259ms/epoch - 26ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.1198 - accuracy: 0.5377 - val_loss: 1.0950 - val_accuracy: 0.4416 - 253ms/epoch - 25ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.1355 - accuracy: 0.5311 - val_loss: 1.1078 - val_accuracy: 0.4805 - 248ms/epoch - 25ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.1281 - accuracy: 0.5508 - val_loss: 1.0823 - val_accuracy: 0.4675 - 245ms/epoch - 25ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.1135 - accuracy: 0.5246 - val_loss: 1.0804 - val_accuracy: 0.4675 - 256ms/epoch - 26ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0837 - accuracy: 0.5377 - val_loss: 1.0795 - val_accuracy: 0.4675 - 253ms/epoch - 25ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0818 - accuracy: 0.5443 - val_loss: 1.0784 - val_accuracy: 0.4935 - 249ms/epoch - 25ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.1235 - accuracy: 0.5443 - val_loss: 1.0740 - val_accuracy: 0.4805 - 281ms/epoch - 28ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.1007 - accuracy: 0.5410 - val_loss: 1.0717 - val_accuracy: 0.4935 - 260ms/epoch - 26ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0741 - accuracy: 0.5672 - val_loss: 1.0589 - val_accuracy: 0.4805 - 246ms/epoch - 25ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0900 - accuracy: 0.5541 - val_loss: 1.0632 - val_accuracy: 0.4675 - 251ms/epoch - 25ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0733 - accuracy: 0.5607 - val_loss: 1.0603 - val_accuracy: 0.4935 - 248ms/epoch - 25ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0599 - accuracy: 0.5508 - val_loss: 1.0508 - val_accuracy: 0.4805 - 247ms/epoch - 25ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0944 - accuracy: 0.5148 - val_loss: 1.0384 - val_accuracy: 0.4805 - 247ms/epoch - 25ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0624 - accuracy: 0.5672 - val_loss: 1.0400 - val_accuracy: 0.5195 - 251ms/epoch - 25ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0476 - accuracy: 0.5803 - val_loss: 1.0402 - val_accuracy: 0.4675 - 250ms/epoch - 25ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0205 - accuracy: 0.5639 - val_loss: 1.0333 - val_accuracy: 0.4935 - 266ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0482 - accuracy: 0.5672 - val_loss: 1.0293 - val_accuracy: 0.4805 - 256ms/epoch - 26ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0806 - accuracy: 0.5344 - val_loss: 1.0244 - val_accuracy: 0.5844 - 260ms/epoch - 26ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0317 - accuracy: 0.5803 - val_loss: 1.0226 - val_accuracy: 0.5325 - 259ms/epoch - 26ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0474 - accuracy: 0.5639 - val_loss: 1.0276 - val_accuracy: 0.4805 - 253ms/epoch - 25ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0475 - accuracy: 0.5508 - val_loss: 1.0073 - val_accuracy: 0.5325 - 266ms/epoch - 27ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9819 - accuracy: 0.6000 - val_loss: 1.0052 - val_accuracy: 0.5065 - 254ms/epoch - 25ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 1.0503 - accuracy: 0.5705 - val_loss: 0.9920 - val_accuracy: 0.4935 - 276ms/epoch - 28ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9950 - accuracy: 0.5639 - val_loss: 0.9795 - val_accuracy: 0.4935 - 278ms/epoch - 28ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 1.0557 - accuracy: 0.5705 - val_loss: 0.9853 - val_accuracy: 0.5455 - 283ms/epoch - 28ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 1.0087 - accuracy: 0.5836 - val_loss: 0.9825 - val_accuracy: 0.5584 - 297ms/epoch - 30ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 1.0284 - accuracy: 0.5770 - val_loss: 0.9684 - val_accuracy: 0.5065 - 270ms/epoch - 27ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 1.0186 - accuracy: 0.5705 - val_loss: 0.9576 - val_accuracy: 0.5325 - 268ms/epoch - 27ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 1.0072 - accuracy: 0.5934 - val_loss: 0.9502 - val_accuracy: 0.5714 - 262ms/epoch - 26ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9711 - accuracy: 0.6197 - val_loss: 0.9696 - val_accuracy: 0.5325 - 260ms/epoch - 26ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9980 - accuracy: 0.6098 - val_loss: 0.9447 - val_accuracy: 0.5714 - 258ms/epoch - 26ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9840 - accuracy: 0.5770 - val_loss: 0.9294 - val_accuracy: 0.5455 - 258ms/epoch - 26ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9488 - accuracy: 0.6098 - val_loss: 0.9368 - val_accuracy: 0.5974 - 279ms/epoch - 28ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 1.0193 - accuracy: 0.6164 - val_loss: 0.9255 - val_accuracy: 0.5844 - 249ms/epoch - 25ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9750 - accuracy: 0.6230 - val_loss: 0.9387 - val_accuracy: 0.5584 - 258ms/epoch - 26ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9465 - accuracy: 0.6033 - val_loss: 0.9280 - val_accuracy: 0.5974 - 267ms/epoch - 27ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9583 - accuracy: 0.5934 - val_loss: 0.9142 - val_accuracy: 0.5974 - 257ms/epoch - 26ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9679 - accuracy: 0.6098 - val_loss: 0.9106 - val_accuracy: 0.5844 - 261ms/epoch - 26ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9538 - accuracy: 0.6000 - val_loss: 0.9070 - val_accuracy: 0.5714 - 283ms/epoch - 28ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9587 - accuracy: 0.5770 - val_loss: 0.8920 - val_accuracy: 0.6104 - 258ms/epoch - 26ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9771 - accuracy: 0.6066 - val_loss: 0.8857 - val_accuracy: 0.5974 - 268ms/epoch - 27ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9704 - accuracy: 0.6164 - val_loss: 0.8961 - val_accuracy: 0.5844 - 262ms/epoch - 26ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.9418 - accuracy: 0.6361 - val_loss: 0.9018 - val_accuracy: 0.5844 - 263ms/epoch - 26ms/step\n",
      "Epoch 67/10000\n",
      "10/10 - 0s - loss: 0.9165 - accuracy: 0.6787 - val_loss: 0.8926 - val_accuracy: 0.5974 - 262ms/epoch - 26ms/step\n",
      "Epoch 68/10000\n",
      "10/10 - 0s - loss: 0.9327 - accuracy: 0.6525 - val_loss: 0.8877 - val_accuracy: 0.5974 - 250ms/epoch - 25ms/step\n",
      "Epoch 69/10000\n",
      "10/10 - 0s - loss: 0.9189 - accuracy: 0.6230 - val_loss: 0.8844 - val_accuracy: 0.6234 - 256ms/epoch - 26ms/step\n",
      "Epoch 70/10000\n",
      "10/10 - 0s - loss: 0.9287 - accuracy: 0.6426 - val_loss: 0.8836 - val_accuracy: 0.5974 - 256ms/epoch - 26ms/step\n",
      "Epoch 71/10000\n",
      "10/10 - 0s - loss: 0.9157 - accuracy: 0.6426 - val_loss: 0.8876 - val_accuracy: 0.5974 - 264ms/epoch - 26ms/step\n",
      "Epoch 72/10000\n",
      "10/10 - 0s - loss: 0.9711 - accuracy: 0.6262 - val_loss: 0.8873 - val_accuracy: 0.6234 - 249ms/epoch - 25ms/step\n",
      "Epoch 73/10000\n",
      "10/10 - 0s - loss: 0.9430 - accuracy: 0.6525 - val_loss: 0.8816 - val_accuracy: 0.5974 - 274ms/epoch - 27ms/step\n",
      "Epoch 74/10000\n",
      "10/10 - 0s - loss: 0.9381 - accuracy: 0.6098 - val_loss: 0.8792 - val_accuracy: 0.6234 - 249ms/epoch - 25ms/step\n",
      "Epoch 75/10000\n",
      "10/10 - 0s - loss: 0.9071 - accuracy: 0.6459 - val_loss: 0.8936 - val_accuracy: 0.5974 - 257ms/epoch - 26ms/step\n",
      "Epoch 76/10000\n",
      "10/10 - 0s - loss: 0.9298 - accuracy: 0.6295 - val_loss: 0.8937 - val_accuracy: 0.6234 - 260ms/epoch - 26ms/step\n",
      "Epoch 77/10000\n",
      "10/10 - 0s - loss: 0.9162 - accuracy: 0.6197 - val_loss: 0.8789 - val_accuracy: 0.6364 - 261ms/epoch - 26ms/step\n",
      "Epoch 78/10000\n",
      "10/10 - 0s - loss: 0.9319 - accuracy: 0.6426 - val_loss: 0.8884 - val_accuracy: 0.5974 - 255ms/epoch - 26ms/step\n",
      "Epoch 79/10000\n",
      "10/10 - 0s - loss: 0.9144 - accuracy: 0.6656 - val_loss: 0.8731 - val_accuracy: 0.6104 - 267ms/epoch - 27ms/step\n",
      "Epoch 80/10000\n",
      "10/10 - 0s - loss: 0.8745 - accuracy: 0.6721 - val_loss: 0.8744 - val_accuracy: 0.5974 - 258ms/epoch - 26ms/step\n",
      "Epoch 81/10000\n",
      "10/10 - 0s - loss: 0.8873 - accuracy: 0.6459 - val_loss: 0.8527 - val_accuracy: 0.6494 - 263ms/epoch - 26ms/step\n",
      "Epoch 82/10000\n",
      "10/10 - 0s - loss: 0.9296 - accuracy: 0.6623 - val_loss: 0.8799 - val_accuracy: 0.5974 - 270ms/epoch - 27ms/step\n",
      "Epoch 83/10000\n",
      "10/10 - 0s - loss: 0.8648 - accuracy: 0.6721 - val_loss: 0.8629 - val_accuracy: 0.6494 - 259ms/epoch - 26ms/step\n",
      "Epoch 84/10000\n",
      "10/10 - 0s - loss: 0.8835 - accuracy: 0.6557 - val_loss: 0.8653 - val_accuracy: 0.6494 - 260ms/epoch - 26ms/step\n",
      "Epoch 85/10000\n",
      "10/10 - 0s - loss: 0.8777 - accuracy: 0.6492 - val_loss: 0.8817 - val_accuracy: 0.6104 - 268ms/epoch - 27ms/step\n",
      "Epoch 86/10000\n",
      "10/10 - 0s - loss: 0.8834 - accuracy: 0.6590 - val_loss: 0.8675 - val_accuracy: 0.6104 - 254ms/epoch - 25ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8792 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:53:46,015] Trial 79 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 131}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3835 - accuracy: 0.3148 - val_loss: 1.3805 - val_accuracy: 0.3247 - 5s/epoch - 492ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3762 - accuracy: 0.3803 - val_loss: 1.3672 - val_accuracy: 0.3506 - 272ms/epoch - 27ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3550 - accuracy: 0.4328 - val_loss: 1.3349 - val_accuracy: 0.3636 - 289ms/epoch - 29ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3085 - accuracy: 0.4623 - val_loss: 1.2723 - val_accuracy: 0.3506 - 290ms/epoch - 29ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2287 - accuracy: 0.4656 - val_loss: 1.2265 - val_accuracy: 0.3636 - 283ms/epoch - 28ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2108 - accuracy: 0.4754 - val_loss: 1.1867 - val_accuracy: 0.3636 - 291ms/epoch - 29ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1761 - accuracy: 0.4918 - val_loss: 1.1745 - val_accuracy: 0.3636 - 297ms/epoch - 30ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1927 - accuracy: 0.4984 - val_loss: 1.1694 - val_accuracy: 0.3896 - 295ms/epoch - 30ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1699 - accuracy: 0.5115 - val_loss: 1.1505 - val_accuracy: 0.4026 - 285ms/epoch - 28ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1504 - accuracy: 0.4918 - val_loss: 1.1539 - val_accuracy: 0.3896 - 262ms/epoch - 26ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1374 - accuracy: 0.5082 - val_loss: 1.1481 - val_accuracy: 0.3766 - 308ms/epoch - 31ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1022 - accuracy: 0.5213 - val_loss: 1.1362 - val_accuracy: 0.4026 - 259ms/epoch - 26ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1246 - accuracy: 0.5180 - val_loss: 1.1177 - val_accuracy: 0.4026 - 288ms/epoch - 29ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1257 - accuracy: 0.5082 - val_loss: 1.1065 - val_accuracy: 0.4286 - 271ms/epoch - 27ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0799 - accuracy: 0.5541 - val_loss: 1.1027 - val_accuracy: 0.4286 - 264ms/epoch - 26ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1111 - accuracy: 0.5311 - val_loss: 1.0849 - val_accuracy: 0.4156 - 276ms/epoch - 28ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1192 - accuracy: 0.5049 - val_loss: 1.1021 - val_accuracy: 0.5325 - 265ms/epoch - 27ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0955 - accuracy: 0.5279 - val_loss: 1.1010 - val_accuracy: 0.4545 - 292ms/epoch - 29ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1335 - accuracy: 0.5213 - val_loss: 1.1064 - val_accuracy: 0.4545 - 264ms/epoch - 26ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0954 - accuracy: 0.5410 - val_loss: 1.0884 - val_accuracy: 0.5325 - 258ms/epoch - 26ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0663 - accuracy: 0.5705 - val_loss: 1.0778 - val_accuracy: 0.4805 - 266ms/epoch - 27ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0743 - accuracy: 0.5607 - val_loss: 1.0608 - val_accuracy: 0.4675 - 267ms/epoch - 27ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0766 - accuracy: 0.5541 - val_loss: 1.0636 - val_accuracy: 0.4935 - 275ms/epoch - 28ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0430 - accuracy: 0.5508 - val_loss: 1.0546 - val_accuracy: 0.4935 - 259ms/epoch - 26ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0813 - accuracy: 0.5377 - val_loss: 1.0467 - val_accuracy: 0.4805 - 272ms/epoch - 27ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0448 - accuracy: 0.5705 - val_loss: 1.0202 - val_accuracy: 0.5844 - 313ms/epoch - 31ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0491 - accuracy: 0.5902 - val_loss: 1.0133 - val_accuracy: 0.5065 - 331ms/epoch - 33ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0331 - accuracy: 0.5738 - val_loss: 1.0183 - val_accuracy: 0.5065 - 297ms/epoch - 30ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0389 - accuracy: 0.5738 - val_loss: 1.0147 - val_accuracy: 0.5065 - 282ms/epoch - 28ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0190 - accuracy: 0.5738 - val_loss: 0.9874 - val_accuracy: 0.5195 - 294ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0410 - accuracy: 0.5508 - val_loss: 0.9779 - val_accuracy: 0.5195 - 299ms/epoch - 30ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0211 - accuracy: 0.6098 - val_loss: 0.9821 - val_accuracy: 0.5455 - 288ms/epoch - 29ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0093 - accuracy: 0.5738 - val_loss: 0.9781 - val_accuracy: 0.5195 - 297ms/epoch - 30ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9999 - accuracy: 0.6000 - val_loss: 0.9590 - val_accuracy: 0.5584 - 282ms/epoch - 28ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9681 - accuracy: 0.6393 - val_loss: 0.9370 - val_accuracy: 0.5455 - 271ms/epoch - 27ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0022 - accuracy: 0.5869 - val_loss: 0.9258 - val_accuracy: 0.5974 - 275ms/epoch - 27ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0000 - accuracy: 0.6164 - val_loss: 0.9394 - val_accuracy: 0.5844 - 280ms/epoch - 28ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9743 - accuracy: 0.5967 - val_loss: 0.9383 - val_accuracy: 0.5065 - 268ms/epoch - 27ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9519 - accuracy: 0.6197 - val_loss: 0.9143 - val_accuracy: 0.5584 - 263ms/epoch - 26ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0099 - accuracy: 0.6033 - val_loss: 0.9143 - val_accuracy: 0.5844 - 264ms/epoch - 26ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0386 - accuracy: 0.5705 - val_loss: 0.9230 - val_accuracy: 0.5714 - 286ms/epoch - 29ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0094 - accuracy: 0.5869 - val_loss: 0.9239 - val_accuracy: 0.5455 - 285ms/epoch - 28ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9694 - accuracy: 0.6197 - val_loss: 0.9279 - val_accuracy: 0.5844 - 271ms/epoch - 27ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9478 - accuracy: 0.6393 - val_loss: 0.9085 - val_accuracy: 0.5844 - 266ms/epoch - 27ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9326 - accuracy: 0.6459 - val_loss: 0.9081 - val_accuracy: 0.5974 - 307ms/epoch - 31ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9322 - accuracy: 0.6525 - val_loss: 0.8993 - val_accuracy: 0.5714 - 258ms/epoch - 26ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9125 - accuracy: 0.6262 - val_loss: 0.8980 - val_accuracy: 0.6104 - 250ms/epoch - 25ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9803 - accuracy: 0.6262 - val_loss: 0.9217 - val_accuracy: 0.5714 - 263ms/epoch - 26ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9310 - accuracy: 0.6197 - val_loss: 0.8857 - val_accuracy: 0.6104 - 262ms/epoch - 26ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9355 - accuracy: 0.6492 - val_loss: 0.9050 - val_accuracy: 0.5455 - 255ms/epoch - 26ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9151 - accuracy: 0.6295 - val_loss: 0.8727 - val_accuracy: 0.6104 - 255ms/epoch - 26ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9057 - accuracy: 0.6328 - val_loss: 0.8601 - val_accuracy: 0.6234 - 266ms/epoch - 27ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9246 - accuracy: 0.6361 - val_loss: 0.9084 - val_accuracy: 0.6234 - 285ms/epoch - 28ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9201 - accuracy: 0.6459 - val_loss: 0.8921 - val_accuracy: 0.5325 - 289ms/epoch - 29ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9333 - accuracy: 0.6230 - val_loss: 0.8846 - val_accuracy: 0.5844 - 278ms/epoch - 28ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9049 - accuracy: 0.6492 - val_loss: 0.8912 - val_accuracy: 0.6234 - 273ms/epoch - 27ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9462 - accuracy: 0.6262 - val_loss: 0.8933 - val_accuracy: 0.5714 - 323ms/epoch - 32ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9383 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:54:08,073] Trial 80 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'selu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 136}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3854 - accuracy: 0.3016 - val_loss: 1.3836 - val_accuracy: 0.3636 - 5s/epoch - 456ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3824 - accuracy: 0.3639 - val_loss: 1.3777 - val_accuracy: 0.3506 - 220ms/epoch - 22ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3740 - accuracy: 0.4000 - val_loss: 1.3650 - val_accuracy: 0.4026 - 240ms/epoch - 24ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3515 - accuracy: 0.4098 - val_loss: 1.3300 - val_accuracy: 0.3766 - 239ms/epoch - 24ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3007 - accuracy: 0.4623 - val_loss: 1.2733 - val_accuracy: 0.3636 - 240ms/epoch - 24ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2407 - accuracy: 0.4656 - val_loss: 1.2450 - val_accuracy: 0.3766 - 236ms/epoch - 24ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2408 - accuracy: 0.4590 - val_loss: 1.2244 - val_accuracy: 0.3636 - 239ms/epoch - 24ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2260 - accuracy: 0.4754 - val_loss: 1.2156 - val_accuracy: 0.3896 - 247ms/epoch - 25ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2097 - accuracy: 0.4787 - val_loss: 1.1917 - val_accuracy: 0.4026 - 261ms/epoch - 26ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1641 - accuracy: 0.4918 - val_loss: 1.1729 - val_accuracy: 0.3766 - 242ms/epoch - 24ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1396 - accuracy: 0.5049 - val_loss: 1.1659 - val_accuracy: 0.3766 - 251ms/epoch - 25ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1451 - accuracy: 0.4951 - val_loss: 1.1569 - val_accuracy: 0.3896 - 300ms/epoch - 30ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1238 - accuracy: 0.5180 - val_loss: 1.1457 - val_accuracy: 0.4026 - 305ms/epoch - 30ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1574 - accuracy: 0.5049 - val_loss: 1.1419 - val_accuracy: 0.3896 - 347ms/epoch - 35ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1293 - accuracy: 0.5082 - val_loss: 1.1307 - val_accuracy: 0.4026 - 369ms/epoch - 37ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1578 - accuracy: 0.5082 - val_loss: 1.1242 - val_accuracy: 0.3896 - 314ms/epoch - 31ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1212 - accuracy: 0.5115 - val_loss: 1.1302 - val_accuracy: 0.3766 - 322ms/epoch - 32ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1172 - accuracy: 0.5082 - val_loss: 1.1176 - val_accuracy: 0.3766 - 322ms/epoch - 32ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1250 - accuracy: 0.4951 - val_loss: 1.1311 - val_accuracy: 0.4026 - 290ms/epoch - 29ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1069 - accuracy: 0.5246 - val_loss: 1.1224 - val_accuracy: 0.3766 - 290ms/epoch - 29ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1196 - accuracy: 0.5279 - val_loss: 1.1178 - val_accuracy: 0.3896 - 333ms/epoch - 33ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1127 - accuracy: 0.5049 - val_loss: 1.1035 - val_accuracy: 0.4026 - 291ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1231 - accuracy: 0.5115 - val_loss: 1.1046 - val_accuracy: 0.4026 - 334ms/epoch - 33ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0926 - accuracy: 0.5246 - val_loss: 1.0990 - val_accuracy: 0.4156 - 305ms/epoch - 31ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0779 - accuracy: 0.5443 - val_loss: 1.1065 - val_accuracy: 0.4156 - 254ms/epoch - 25ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0959 - accuracy: 0.5049 - val_loss: 1.0850 - val_accuracy: 0.4286 - 262ms/epoch - 26ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.1109 - accuracy: 0.5410 - val_loss: 1.0977 - val_accuracy: 0.4545 - 332ms/epoch - 33ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0964 - accuracy: 0.5443 - val_loss: 1.0829 - val_accuracy: 0.4286 - 307ms/epoch - 31ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0872 - accuracy: 0.5803 - val_loss: 1.0977 - val_accuracy: 0.4286 - 308ms/epoch - 31ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0881 - accuracy: 0.5410 - val_loss: 1.0867 - val_accuracy: 0.4416 - 297ms/epoch - 30ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.1070 - accuracy: 0.5377 - val_loss: 1.0886 - val_accuracy: 0.4286 - 260ms/epoch - 26ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.1112 - accuracy: 0.5639 - val_loss: 1.0860 - val_accuracy: 0.4545 - 263ms/epoch - 26ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.1029 - accuracy: 0.5410 - val_loss: 1.0994 - val_accuracy: 0.4805 - 347ms/epoch - 35ms/step\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0272 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:54:23,345] Trial 81 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 133}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3855 - accuracy: 0.2852 - val_loss: 1.3834 - val_accuracy: 0.3117 - 4s/epoch - 447ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3824 - accuracy: 0.3574 - val_loss: 1.3779 - val_accuracy: 0.3117 - 204ms/epoch - 20ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3732 - accuracy: 0.3803 - val_loss: 1.3653 - val_accuracy: 0.3117 - 216ms/epoch - 22ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3500 - accuracy: 0.3934 - val_loss: 1.3380 - val_accuracy: 0.3117 - 219ms/epoch - 22ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3045 - accuracy: 0.3967 - val_loss: 1.2963 - val_accuracy: 0.3766 - 232ms/epoch - 23ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2600 - accuracy: 0.4557 - val_loss: 1.2533 - val_accuracy: 0.3636 - 228ms/epoch - 23ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2617 - accuracy: 0.4492 - val_loss: 1.2258 - val_accuracy: 0.3896 - 238ms/epoch - 24ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2279 - accuracy: 0.4754 - val_loss: 1.2198 - val_accuracy: 0.3896 - 231ms/epoch - 23ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1846 - accuracy: 0.4787 - val_loss: 1.1962 - val_accuracy: 0.4156 - 271ms/epoch - 27ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1747 - accuracy: 0.4885 - val_loss: 1.1687 - val_accuracy: 0.4026 - 312ms/epoch - 31ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1683 - accuracy: 0.4951 - val_loss: 1.1636 - val_accuracy: 0.4026 - 310ms/epoch - 31ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1428 - accuracy: 0.4918 - val_loss: 1.1966 - val_accuracy: 0.4156 - 265ms/epoch - 27ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1595 - accuracy: 0.5016 - val_loss: 1.1734 - val_accuracy: 0.4156 - 295ms/epoch - 30ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1591 - accuracy: 0.4951 - val_loss: 1.1392 - val_accuracy: 0.4026 - 347ms/epoch - 35ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1536 - accuracy: 0.5049 - val_loss: 1.1470 - val_accuracy: 0.3896 - 396ms/epoch - 40ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1506 - accuracy: 0.4918 - val_loss: 1.1217 - val_accuracy: 0.4026 - 324ms/epoch - 32ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1494 - accuracy: 0.5115 - val_loss: 1.1255 - val_accuracy: 0.4156 - 319ms/epoch - 32ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1309 - accuracy: 0.5016 - val_loss: 1.1282 - val_accuracy: 0.4026 - 316ms/epoch - 32ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1292 - accuracy: 0.5148 - val_loss: 1.1353 - val_accuracy: 0.4026 - 329ms/epoch - 33ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1253 - accuracy: 0.5049 - val_loss: 1.1205 - val_accuracy: 0.4286 - 287ms/epoch - 29ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1325 - accuracy: 0.5213 - val_loss: 1.1225 - val_accuracy: 0.4026 - 261ms/epoch - 26ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0871 - accuracy: 0.5279 - val_loss: 1.1062 - val_accuracy: 0.4026 - 291ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1263 - accuracy: 0.5410 - val_loss: 1.1104 - val_accuracy: 0.4026 - 285ms/epoch - 28ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.1176 - accuracy: 0.5115 - val_loss: 1.1054 - val_accuracy: 0.4156 - 287ms/epoch - 29ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.1119 - accuracy: 0.4951 - val_loss: 1.1183 - val_accuracy: 0.4026 - 299ms/epoch - 30ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0964 - accuracy: 0.5115 - val_loss: 1.1040 - val_accuracy: 0.4416 - 321ms/epoch - 32ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.1105 - accuracy: 0.5344 - val_loss: 1.1163 - val_accuracy: 0.4156 - 279ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.1072 - accuracy: 0.5508 - val_loss: 1.0955 - val_accuracy: 0.4026 - 299ms/epoch - 30ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.1086 - accuracy: 0.5279 - val_loss: 1.0998 - val_accuracy: 0.4026 - 300ms/epoch - 30ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.1059 - accuracy: 0.5213 - val_loss: 1.0943 - val_accuracy: 0.4286 - 265ms/epoch - 26ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0724 - accuracy: 0.5311 - val_loss: 1.0964 - val_accuracy: 0.4416 - 261ms/epoch - 26ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.1103 - accuracy: 0.5246 - val_loss: 1.0944 - val_accuracy: 0.4675 - 303ms/epoch - 30ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.1060 - accuracy: 0.5377 - val_loss: 1.0970 - val_accuracy: 0.4545 - 330ms/epoch - 33ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0630 - accuracy: 0.5639 - val_loss: 1.0938 - val_accuracy: 0.4675 - 276ms/epoch - 28ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0562 - accuracy: 0.5607 - val_loss: 1.0834 - val_accuracy: 0.4416 - 247ms/epoch - 25ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0934 - accuracy: 0.5672 - val_loss: 1.0648 - val_accuracy: 0.4675 - 286ms/epoch - 29ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0831 - accuracy: 0.5475 - val_loss: 1.0708 - val_accuracy: 0.5844 - 266ms/epoch - 27ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0593 - accuracy: 0.5803 - val_loss: 1.0598 - val_accuracy: 0.4675 - 276ms/epoch - 28ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0815 - accuracy: 0.5508 - val_loss: 1.0745 - val_accuracy: 0.4805 - 275ms/epoch - 27ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0741 - accuracy: 0.5738 - val_loss: 1.0570 - val_accuracy: 0.4805 - 277ms/epoch - 28ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0776 - accuracy: 0.5475 - val_loss: 1.0450 - val_accuracy: 0.5584 - 259ms/epoch - 26ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0294 - accuracy: 0.5672 - val_loss: 1.0364 - val_accuracy: 0.5195 - 228ms/epoch - 23ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0496 - accuracy: 0.5836 - val_loss: 1.0354 - val_accuracy: 0.5065 - 298ms/epoch - 30ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0419 - accuracy: 0.5902 - val_loss: 1.0224 - val_accuracy: 0.5065 - 231ms/epoch - 23ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0284 - accuracy: 0.5967 - val_loss: 1.0142 - val_accuracy: 0.5195 - 222ms/epoch - 22ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 1.0589 - accuracy: 0.5770 - val_loss: 0.9970 - val_accuracy: 0.5195 - 226ms/epoch - 23ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 1.0310 - accuracy: 0.5705 - val_loss: 0.9987 - val_accuracy: 0.5325 - 234ms/epoch - 23ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 1.0232 - accuracy: 0.5803 - val_loss: 0.9979 - val_accuracy: 0.5065 - 233ms/epoch - 23ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 1.0379 - accuracy: 0.5869 - val_loss: 0.9999 - val_accuracy: 0.4935 - 235ms/epoch - 24ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 1.0061 - accuracy: 0.5869 - val_loss: 0.9897 - val_accuracy: 0.5325 - 234ms/epoch - 23ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 1.0252 - accuracy: 0.5574 - val_loss: 0.9628 - val_accuracy: 0.5325 - 230ms/epoch - 23ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 1.0084 - accuracy: 0.6098 - val_loss: 0.9598 - val_accuracy: 0.5714 - 225ms/epoch - 22ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9686 - accuracy: 0.6098 - val_loss: 0.9848 - val_accuracy: 0.5584 - 226ms/epoch - 23ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9985 - accuracy: 0.6098 - val_loss: 0.9679 - val_accuracy: 0.5714 - 225ms/epoch - 23ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 1.0414 - accuracy: 0.5738 - val_loss: 0.9460 - val_accuracy: 0.5584 - 222ms/epoch - 22ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9912 - accuracy: 0.6098 - val_loss: 0.9613 - val_accuracy: 0.5714 - 223ms/epoch - 22ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9964 - accuracy: 0.5902 - val_loss: 0.9409 - val_accuracy: 0.5714 - 231ms/epoch - 23ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9765 - accuracy: 0.6295 - val_loss: 0.9432 - val_accuracy: 0.5455 - 229ms/epoch - 23ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9592 - accuracy: 0.6197 - val_loss: 0.9308 - val_accuracy: 0.5844 - 225ms/epoch - 23ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9374 - accuracy: 0.6197 - val_loss: 0.9056 - val_accuracy: 0.5844 - 240ms/epoch - 24ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9831 - accuracy: 0.6328 - val_loss: 0.9063 - val_accuracy: 0.6234 - 236ms/epoch - 24ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9224 - accuracy: 0.6459 - val_loss: 0.9118 - val_accuracy: 0.5844 - 245ms/epoch - 24ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9618 - accuracy: 0.6066 - val_loss: 0.9235 - val_accuracy: 0.6234 - 233ms/epoch - 23ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9807 - accuracy: 0.6328 - val_loss: 0.9152 - val_accuracy: 0.5844 - 226ms/epoch - 23ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9656 - accuracy: 0.6328 - val_loss: 0.9106 - val_accuracy: 0.5974 - 238ms/epoch - 24ms/step\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8714 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:54:46,724] Trial 82 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 129}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "4/4 - 4s - loss: 1.3849 - accuracy: 0.3311 - val_loss: 1.3827 - val_accuracy: 0.4805 - 4s/epoch - 993ms/step\n",
      "Epoch 2/10000\n",
      "4/4 - 0s - loss: 1.3803 - accuracy: 0.3836 - val_loss: 1.3779 - val_accuracy: 0.3506 - 196ms/epoch - 49ms/step\n",
      "Epoch 3/10000\n",
      "4/4 - 0s - loss: 1.3735 - accuracy: 0.4131 - val_loss: 1.3692 - val_accuracy: 0.4545 - 210ms/epoch - 53ms/step\n",
      "Epoch 4/10000\n",
      "4/4 - 0s - loss: 1.3611 - accuracy: 0.4656 - val_loss: 1.3543 - val_accuracy: 0.4416 - 219ms/epoch - 55ms/step\n",
      "Epoch 5/10000\n",
      "4/4 - 0s - loss: 1.3399 - accuracy: 0.5049 - val_loss: 1.3297 - val_accuracy: 0.4156 - 212ms/epoch - 53ms/step\n",
      "Epoch 6/10000\n",
      "4/4 - 0s - loss: 1.3081 - accuracy: 0.5279 - val_loss: 1.2961 - val_accuracy: 0.3896 - 207ms/epoch - 52ms/step\n",
      "Epoch 7/10000\n",
      "4/4 - 0s - loss: 1.2743 - accuracy: 0.5082 - val_loss: 1.2624 - val_accuracy: 0.4026 - 213ms/epoch - 53ms/step\n",
      "Epoch 8/10000\n",
      "4/4 - 0s - loss: 1.2471 - accuracy: 0.4623 - val_loss: 1.2473 - val_accuracy: 0.3896 - 216ms/epoch - 54ms/step\n",
      "Epoch 9/10000\n",
      "4/4 - 0s - loss: 1.2598 - accuracy: 0.4721 - val_loss: 1.2262 - val_accuracy: 0.4026 - 229ms/epoch - 57ms/step\n",
      "Epoch 10/10000\n",
      "4/4 - 0s - loss: 1.2279 - accuracy: 0.4885 - val_loss: 1.2198 - val_accuracy: 0.3896 - 240ms/epoch - 60ms/step\n",
      "Epoch 11/10000\n",
      "4/4 - 0s - loss: 1.2056 - accuracy: 0.5213 - val_loss: 1.2133 - val_accuracy: 0.4156 - 208ms/epoch - 52ms/step\n",
      "Epoch 12/10000\n",
      "4/4 - 0s - loss: 1.2081 - accuracy: 0.5311 - val_loss: 1.2035 - val_accuracy: 0.4416 - 213ms/epoch - 53ms/step\n",
      "Epoch 13/10000\n",
      "4/4 - 0s - loss: 1.1846 - accuracy: 0.5180 - val_loss: 1.1916 - val_accuracy: 0.4156 - 210ms/epoch - 52ms/step\n",
      "Epoch 14/10000\n",
      "4/4 - 0s - loss: 1.1791 - accuracy: 0.5115 - val_loss: 1.1782 - val_accuracy: 0.3766 - 223ms/epoch - 56ms/step\n",
      "Epoch 15/10000\n",
      "4/4 - 0s - loss: 1.1868 - accuracy: 0.4984 - val_loss: 1.1682 - val_accuracy: 0.4026 - 229ms/epoch - 57ms/step\n",
      "Epoch 16/10000\n",
      "4/4 - 0s - loss: 1.1544 - accuracy: 0.5246 - val_loss: 1.1613 - val_accuracy: 0.4156 - 228ms/epoch - 57ms/step\n",
      "Epoch 17/10000\n",
      "4/4 - 0s - loss: 1.1545 - accuracy: 0.5311 - val_loss: 1.1482 - val_accuracy: 0.4156 - 248ms/epoch - 62ms/step\n",
      "Epoch 18/10000\n",
      "4/4 - 0s - loss: 1.1409 - accuracy: 0.5148 - val_loss: 1.1369 - val_accuracy: 0.4286 - 249ms/epoch - 62ms/step\n",
      "Epoch 19/10000\n",
      "4/4 - 0s - loss: 1.1294 - accuracy: 0.5443 - val_loss: 1.1441 - val_accuracy: 0.4416 - 246ms/epoch - 61ms/step\n",
      "Epoch 20/10000\n",
      "4/4 - 0s - loss: 1.1235 - accuracy: 0.5246 - val_loss: 1.1184 - val_accuracy: 0.4026 - 246ms/epoch - 62ms/step\n",
      "Epoch 21/10000\n",
      "4/4 - 0s - loss: 1.1105 - accuracy: 0.5410 - val_loss: 1.1387 - val_accuracy: 0.4156 - 231ms/epoch - 58ms/step\n",
      "Epoch 22/10000\n",
      "4/4 - 0s - loss: 1.1156 - accuracy: 0.5180 - val_loss: 1.1033 - val_accuracy: 0.4156 - 229ms/epoch - 57ms/step\n",
      "Epoch 23/10000\n",
      "4/4 - 0s - loss: 1.1358 - accuracy: 0.5377 - val_loss: 1.1087 - val_accuracy: 0.4286 - 231ms/epoch - 58ms/step\n",
      "Epoch 24/10000\n",
      "4/4 - 0s - loss: 1.0912 - accuracy: 0.5443 - val_loss: 1.0962 - val_accuracy: 0.4545 - 232ms/epoch - 58ms/step\n",
      "Epoch 25/10000\n",
      "4/4 - 0s - loss: 1.0815 - accuracy: 0.5541 - val_loss: 1.0857 - val_accuracy: 0.4286 - 207ms/epoch - 52ms/step\n",
      "Epoch 26/10000\n",
      "4/4 - 0s - loss: 1.0808 - accuracy: 0.5607 - val_loss: 1.0766 - val_accuracy: 0.4286 - 233ms/epoch - 58ms/step\n",
      "Epoch 27/10000\n",
      "4/4 - 0s - loss: 1.0596 - accuracy: 0.5738 - val_loss: 1.0589 - val_accuracy: 0.4935 - 209ms/epoch - 52ms/step\n",
      "Epoch 28/10000\n",
      "4/4 - 0s - loss: 1.0779 - accuracy: 0.5607 - val_loss: 1.0380 - val_accuracy: 0.5065 - 238ms/epoch - 60ms/step\n",
      "Epoch 29/10000\n",
      "4/4 - 0s - loss: 1.0556 - accuracy: 0.5344 - val_loss: 1.0288 - val_accuracy: 0.4935 - 216ms/epoch - 54ms/step\n",
      "Epoch 30/10000\n",
      "4/4 - 0s - loss: 1.0599 - accuracy: 0.5475 - val_loss: 1.0208 - val_accuracy: 0.4935 - 229ms/epoch - 57ms/step\n",
      "Epoch 31/10000\n",
      "4/4 - 0s - loss: 1.0399 - accuracy: 0.5607 - val_loss: 1.0137 - val_accuracy: 0.4935 - 226ms/epoch - 57ms/step\n",
      "Epoch 32/10000\n",
      "4/4 - 0s - loss: 1.0105 - accuracy: 0.5803 - val_loss: 0.9989 - val_accuracy: 0.5065 - 238ms/epoch - 59ms/step\n",
      "Epoch 33/10000\n",
      "4/4 - 0s - loss: 1.0299 - accuracy: 0.5803 - val_loss: 0.9918 - val_accuracy: 0.5065 - 211ms/epoch - 53ms/step\n",
      "Epoch 34/10000\n",
      "4/4 - 0s - loss: 1.0184 - accuracy: 0.5967 - val_loss: 0.9827 - val_accuracy: 0.5325 - 217ms/epoch - 54ms/step\n",
      "Epoch 35/10000\n",
      "4/4 - 0s - loss: 1.0089 - accuracy: 0.5639 - val_loss: 0.9736 - val_accuracy: 0.5455 - 234ms/epoch - 59ms/step\n",
      "Epoch 36/10000\n",
      "4/4 - 0s - loss: 0.9947 - accuracy: 0.6000 - val_loss: 0.9702 - val_accuracy: 0.5455 - 212ms/epoch - 53ms/step\n",
      "Epoch 37/10000\n",
      "4/4 - 0s - loss: 0.9772 - accuracy: 0.6197 - val_loss: 0.9453 - val_accuracy: 0.5584 - 241ms/epoch - 60ms/step\n",
      "Epoch 38/10000\n",
      "4/4 - 0s - loss: 0.9977 - accuracy: 0.6066 - val_loss: 0.9345 - val_accuracy: 0.5844 - 210ms/epoch - 53ms/step\n",
      "Epoch 39/10000\n",
      "4/4 - 0s - loss: 0.9583 - accuracy: 0.6361 - val_loss: 0.9198 - val_accuracy: 0.5584 - 213ms/epoch - 53ms/step\n",
      "Epoch 40/10000\n",
      "4/4 - 0s - loss: 0.9858 - accuracy: 0.6262 - val_loss: 0.9171 - val_accuracy: 0.5325 - 213ms/epoch - 53ms/step\n",
      "Epoch 41/10000\n",
      "4/4 - 0s - loss: 0.9796 - accuracy: 0.6033 - val_loss: 0.8964 - val_accuracy: 0.6234 - 208ms/epoch - 52ms/step\n",
      "Epoch 42/10000\n",
      "4/4 - 0s - loss: 0.9623 - accuracy: 0.6131 - val_loss: 0.9413 - val_accuracy: 0.5584 - 211ms/epoch - 53ms/step\n",
      "Epoch 43/10000\n",
      "4/4 - 0s - loss: 0.9533 - accuracy: 0.6164 - val_loss: 0.9279 - val_accuracy: 0.5844 - 208ms/epoch - 52ms/step\n",
      "Epoch 44/10000\n",
      "4/4 - 0s - loss: 0.9528 - accuracy: 0.6164 - val_loss: 0.9090 - val_accuracy: 0.5584 - 236ms/epoch - 59ms/step\n",
      "Epoch 45/10000\n",
      "4/4 - 0s - loss: 0.9313 - accuracy: 0.6230 - val_loss: 0.9124 - val_accuracy: 0.5584 - 206ms/epoch - 51ms/step\n",
      "Epoch 46/10000\n",
      "4/4 - 0s - loss: 0.9190 - accuracy: 0.6361 - val_loss: 0.9080 - val_accuracy: 0.6104 - 237ms/epoch - 59ms/step\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8825 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:55:02,311] Trial 83 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'relu', 'activation_func_3': 'linear', 'batch_size': 80, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 138}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3864 - accuracy: 0.2459 - val_loss: 1.3851 - val_accuracy: 0.2597 - 5s/epoch - 716ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3854 - accuracy: 0.2623 - val_loss: 1.3831 - val_accuracy: 0.2597 - 286ms/epoch - 41ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3841 - accuracy: 0.2656 - val_loss: 1.3811 - val_accuracy: 0.2597 - 300ms/epoch - 43ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3831 - accuracy: 0.2656 - val_loss: 1.3780 - val_accuracy: 0.2597 - 296ms/epoch - 42ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3815 - accuracy: 0.2656 - val_loss: 1.3756 - val_accuracy: 0.2597 - 294ms/epoch - 42ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3776 - accuracy: 0.3049 - val_loss: 1.3718 - val_accuracy: 0.3506 - 295ms/epoch - 42ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.3718 - accuracy: 0.3770 - val_loss: 1.3660 - val_accuracy: 0.3117 - 313ms/epoch - 45ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.3620 - accuracy: 0.3869 - val_loss: 1.3560 - val_accuracy: 0.3117 - 309ms/epoch - 44ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.3485 - accuracy: 0.3770 - val_loss: 1.3376 - val_accuracy: 0.3247 - 319ms/epoch - 46ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.3218 - accuracy: 0.4393 - val_loss: 1.3131 - val_accuracy: 0.3636 - 315ms/epoch - 45ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2827 - accuracy: 0.4623 - val_loss: 1.2839 - val_accuracy: 0.3636 - 317ms/epoch - 45ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.2502 - accuracy: 0.4721 - val_loss: 1.2658 - val_accuracy: 0.3636 - 318ms/epoch - 45ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2469 - accuracy: 0.4492 - val_loss: 1.2517 - val_accuracy: 0.3766 - 305ms/epoch - 44ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.2228 - accuracy: 0.4393 - val_loss: 1.2183 - val_accuracy: 0.3636 - 294ms/epoch - 42ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.2109 - accuracy: 0.4590 - val_loss: 1.2150 - val_accuracy: 0.3506 - 297ms/epoch - 42ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1965 - accuracy: 0.4525 - val_loss: 1.2068 - val_accuracy: 0.3636 - 293ms/epoch - 42ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1935 - accuracy: 0.4656 - val_loss: 1.2077 - val_accuracy: 0.3766 - 298ms/epoch - 43ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1661 - accuracy: 0.4918 - val_loss: 1.1995 - val_accuracy: 0.3766 - 297ms/epoch - 42ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1849 - accuracy: 0.4852 - val_loss: 1.1814 - val_accuracy: 0.3636 - 302ms/epoch - 43ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1524 - accuracy: 0.4820 - val_loss: 1.1737 - val_accuracy: 0.3766 - 291ms/epoch - 42ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1686 - accuracy: 0.4754 - val_loss: 1.1690 - val_accuracy: 0.3766 - 301ms/epoch - 43ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1633 - accuracy: 0.4918 - val_loss: 1.1533 - val_accuracy: 0.4026 - 297ms/epoch - 42ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1410 - accuracy: 0.5213 - val_loss: 1.1679 - val_accuracy: 0.4286 - 296ms/epoch - 42ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1450 - accuracy: 0.5049 - val_loss: 1.1444 - val_accuracy: 0.4026 - 295ms/epoch - 42ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1327 - accuracy: 0.5115 - val_loss: 1.1415 - val_accuracy: 0.3896 - 297ms/epoch - 42ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1351 - accuracy: 0.5082 - val_loss: 1.1341 - val_accuracy: 0.4026 - 296ms/epoch - 42ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1357 - accuracy: 0.5049 - val_loss: 1.1397 - val_accuracy: 0.3766 - 308ms/epoch - 44ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1123 - accuracy: 0.5049 - val_loss: 1.1329 - val_accuracy: 0.3766 - 289ms/epoch - 41ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1275 - accuracy: 0.5016 - val_loss: 1.1311 - val_accuracy: 0.4026 - 298ms/epoch - 43ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1369 - accuracy: 0.5049 - val_loss: 1.1471 - val_accuracy: 0.3896 - 298ms/epoch - 43ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1384 - accuracy: 0.4721 - val_loss: 1.1370 - val_accuracy: 0.3896 - 292ms/epoch - 42ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.1192 - accuracy: 0.4918 - val_loss: 1.1338 - val_accuracy: 0.4026 - 295ms/epoch - 42ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.1395 - accuracy: 0.5082 - val_loss: 1.1436 - val_accuracy: 0.3896 - 299ms/epoch - 43ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.1063 - accuracy: 0.5016 - val_loss: 1.1427 - val_accuracy: 0.4026 - 306ms/epoch - 44ms/step\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0447 - accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:55:18,788] Trial 84 finished with value: 0.5882353186607361 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 135}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3841 - accuracy: 0.3279 - val_loss: 1.3796 - val_accuracy: 0.3896 - 4s/epoch - 409ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3716 - accuracy: 0.4328 - val_loss: 1.3601 - val_accuracy: 0.3896 - 311ms/epoch - 31ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3375 - accuracy: 0.4820 - val_loss: 1.3106 - val_accuracy: 0.4286 - 307ms/epoch - 31ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2679 - accuracy: 0.5016 - val_loss: 1.2500 - val_accuracy: 0.4026 - 300ms/epoch - 30ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2275 - accuracy: 0.4951 - val_loss: 1.2126 - val_accuracy: 0.4026 - 300ms/epoch - 30ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2160 - accuracy: 0.4852 - val_loss: 1.1867 - val_accuracy: 0.3636 - 306ms/epoch - 31ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1844 - accuracy: 0.5082 - val_loss: 1.1728 - val_accuracy: 0.3766 - 310ms/epoch - 31ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1772 - accuracy: 0.4984 - val_loss: 1.1830 - val_accuracy: 0.3766 - 295ms/epoch - 29ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1733 - accuracy: 0.4918 - val_loss: 1.1464 - val_accuracy: 0.3896 - 307ms/epoch - 31ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1407 - accuracy: 0.4951 - val_loss: 1.1551 - val_accuracy: 0.3766 - 335ms/epoch - 33ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1293 - accuracy: 0.5049 - val_loss: 1.1281 - val_accuracy: 0.4156 - 323ms/epoch - 32ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1218 - accuracy: 0.5180 - val_loss: 1.1262 - val_accuracy: 0.4156 - 320ms/epoch - 32ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1098 - accuracy: 0.5344 - val_loss: 1.1131 - val_accuracy: 0.3896 - 328ms/epoch - 33ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1075 - accuracy: 0.5377 - val_loss: 1.0935 - val_accuracy: 0.4156 - 326ms/epoch - 33ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.0931 - accuracy: 0.5344 - val_loss: 1.0786 - val_accuracy: 0.4545 - 316ms/epoch - 32ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0779 - accuracy: 0.5443 - val_loss: 1.0654 - val_accuracy: 0.4286 - 306ms/epoch - 31ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0806 - accuracy: 0.5541 - val_loss: 1.0825 - val_accuracy: 0.5325 - 298ms/epoch - 30ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0580 - accuracy: 0.5672 - val_loss: 1.0514 - val_accuracy: 0.4935 - 305ms/epoch - 30ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0434 - accuracy: 0.5770 - val_loss: 1.0614 - val_accuracy: 0.4675 - 302ms/epoch - 30ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0448 - accuracy: 0.5672 - val_loss: 1.0301 - val_accuracy: 0.5584 - 306ms/epoch - 31ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0222 - accuracy: 0.5738 - val_loss: 1.0122 - val_accuracy: 0.5195 - 303ms/epoch - 30ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0086 - accuracy: 0.5672 - val_loss: 0.9925 - val_accuracy: 0.5195 - 316ms/epoch - 32ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0337 - accuracy: 0.5934 - val_loss: 0.9863 - val_accuracy: 0.5325 - 308ms/epoch - 31ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0078 - accuracy: 0.5574 - val_loss: 0.9819 - val_accuracy: 0.5455 - 303ms/epoch - 30ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9697 - accuracy: 0.5869 - val_loss: 0.9664 - val_accuracy: 0.5455 - 309ms/epoch - 31ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9622 - accuracy: 0.6361 - val_loss: 0.8963 - val_accuracy: 0.6234 - 299ms/epoch - 30ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9492 - accuracy: 0.6459 - val_loss: 0.9221 - val_accuracy: 0.5584 - 306ms/epoch - 31ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9385 - accuracy: 0.6000 - val_loss: 0.9140 - val_accuracy: 0.6104 - 306ms/epoch - 31ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9173 - accuracy: 0.6098 - val_loss: 0.8784 - val_accuracy: 0.6104 - 303ms/epoch - 30ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9338 - accuracy: 0.6295 - val_loss: 0.8877 - val_accuracy: 0.5974 - 304ms/epoch - 30ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9274 - accuracy: 0.6262 - val_loss: 0.8845 - val_accuracy: 0.6364 - 326ms/epoch - 33ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.8998 - accuracy: 0.6328 - val_loss: 0.8733 - val_accuracy: 0.5844 - 304ms/epoch - 30ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9249 - accuracy: 0.6393 - val_loss: 0.8683 - val_accuracy: 0.6104 - 320ms/epoch - 32ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9130 - accuracy: 0.6590 - val_loss: 0.8662 - val_accuracy: 0.6494 - 305ms/epoch - 30ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.8872 - accuracy: 0.6557 - val_loss: 0.8897 - val_accuracy: 0.5455 - 300ms/epoch - 30ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.8691 - accuracy: 0.6361 - val_loss: 0.8664 - val_accuracy: 0.6494 - 313ms/epoch - 31ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.8935 - accuracy: 0.6492 - val_loss: 0.8616 - val_accuracy: 0.6364 - 345ms/epoch - 35ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.8876 - accuracy: 0.6459 - val_loss: 0.8737 - val_accuracy: 0.6364 - 322ms/epoch - 32ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.8952 - accuracy: 0.6492 - val_loss: 0.8737 - val_accuracy: 0.5714 - 312ms/epoch - 31ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.8586 - accuracy: 0.6623 - val_loss: 0.8376 - val_accuracy: 0.6494 - 314ms/epoch - 31ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9208 - accuracy: 0.6590 - val_loss: 0.8841 - val_accuracy: 0.6364 - 318ms/epoch - 32ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.8649 - accuracy: 0.6656 - val_loss: 0.8537 - val_accuracy: 0.6234 - 307ms/epoch - 31ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.8602 - accuracy: 0.6590 - val_loss: 0.8746 - val_accuracy: 0.6234 - 305ms/epoch - 31ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.8682 - accuracy: 0.6590 - val_loss: 0.8450 - val_accuracy: 0.6364 - 302ms/epoch - 30ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.8914 - accuracy: 0.6492 - val_loss: 0.8635 - val_accuracy: 0.6364 - 303ms/epoch - 30ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8704 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:55:38,350] Trial 85 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 145}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 5s - loss: 1.3857 - accuracy: 0.3049 - val_loss: 1.3839 - val_accuracy: 0.3636 - 5s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3835 - accuracy: 0.3344 - val_loss: 1.3808 - val_accuracy: 0.3506 - 321ms/epoch - 64ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3806 - accuracy: 0.3213 - val_loss: 1.3759 - val_accuracy: 0.3506 - 335ms/epoch - 67ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3768 - accuracy: 0.3607 - val_loss: 1.3697 - val_accuracy: 0.3117 - 334ms/epoch - 67ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3680 - accuracy: 0.3803 - val_loss: 1.3593 - val_accuracy: 0.3377 - 341ms/epoch - 68ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3519 - accuracy: 0.4262 - val_loss: 1.3424 - val_accuracy: 0.3766 - 326ms/epoch - 65ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3290 - accuracy: 0.4361 - val_loss: 1.3170 - val_accuracy: 0.3636 - 330ms/epoch - 66ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2911 - accuracy: 0.4656 - val_loss: 1.2833 - val_accuracy: 0.3636 - 342ms/epoch - 68ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2524 - accuracy: 0.4393 - val_loss: 1.2461 - val_accuracy: 0.3636 - 326ms/epoch - 65ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2038 - accuracy: 0.4492 - val_loss: 1.2246 - val_accuracy: 0.3636 - 330ms/epoch - 66ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.1762 - accuracy: 0.4525 - val_loss: 1.2125 - val_accuracy: 0.3636 - 337ms/epoch - 67ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1692 - accuracy: 0.4590 - val_loss: 1.1885 - val_accuracy: 0.3636 - 341ms/epoch - 68ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1576 - accuracy: 0.4885 - val_loss: 1.1940 - val_accuracy: 0.4026 - 324ms/epoch - 65ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1715 - accuracy: 0.4984 - val_loss: 1.1696 - val_accuracy: 0.3896 - 328ms/epoch - 66ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1473 - accuracy: 0.5082 - val_loss: 1.1627 - val_accuracy: 0.3636 - 331ms/epoch - 66ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1483 - accuracy: 0.5016 - val_loss: 1.1645 - val_accuracy: 0.4026 - 325ms/epoch - 65ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1394 - accuracy: 0.5148 - val_loss: 1.1571 - val_accuracy: 0.3766 - 343ms/epoch - 69ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1311 - accuracy: 0.5016 - val_loss: 1.1545 - val_accuracy: 0.3766 - 327ms/epoch - 65ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1460 - accuracy: 0.5082 - val_loss: 1.1560 - val_accuracy: 0.4026 - 338ms/epoch - 68ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1374 - accuracy: 0.5115 - val_loss: 1.1492 - val_accuracy: 0.4026 - 334ms/epoch - 67ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1068 - accuracy: 0.5180 - val_loss: 1.1464 - val_accuracy: 0.3896 - 347ms/epoch - 69ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1119 - accuracy: 0.5246 - val_loss: 1.1437 - val_accuracy: 0.4026 - 354ms/epoch - 71ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1220 - accuracy: 0.5180 - val_loss: 1.1392 - val_accuracy: 0.4156 - 326ms/epoch - 65ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.1238 - accuracy: 0.5246 - val_loss: 1.1326 - val_accuracy: 0.4286 - 340ms/epoch - 68ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1181 - accuracy: 0.5049 - val_loss: 1.1325 - val_accuracy: 0.4286 - 329ms/epoch - 66ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.1126 - accuracy: 0.5475 - val_loss: 1.1225 - val_accuracy: 0.4286 - 334ms/epoch - 67ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.1032 - accuracy: 0.5246 - val_loss: 1.1158 - val_accuracy: 0.4286 - 331ms/epoch - 66ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.1022 - accuracy: 0.5574 - val_loss: 1.1087 - val_accuracy: 0.4545 - 337ms/epoch - 67ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0957 - accuracy: 0.5311 - val_loss: 1.1085 - val_accuracy: 0.4416 - 333ms/epoch - 67ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0954 - accuracy: 0.5639 - val_loss: 1.1056 - val_accuracy: 0.4416 - 345ms/epoch - 69ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0849 - accuracy: 0.5443 - val_loss: 1.1105 - val_accuracy: 0.4416 - 330ms/epoch - 66ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0999 - accuracy: 0.5344 - val_loss: 1.1063 - val_accuracy: 0.4545 - 342ms/epoch - 68ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.1049 - accuracy: 0.5475 - val_loss: 1.1148 - val_accuracy: 0.4545 - 328ms/epoch - 66ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0718 - accuracy: 0.5770 - val_loss: 1.1010 - val_accuracy: 0.4545 - 342ms/epoch - 68ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0889 - accuracy: 0.5311 - val_loss: 1.0989 - val_accuracy: 0.4416 - 339ms/epoch - 68ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0707 - accuracy: 0.5607 - val_loss: 1.0921 - val_accuracy: 0.4545 - 328ms/epoch - 66ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0727 - accuracy: 0.5443 - val_loss: 1.1041 - val_accuracy: 0.4416 - 330ms/epoch - 66ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0618 - accuracy: 0.5311 - val_loss: 1.0880 - val_accuracy: 0.4545 - 329ms/epoch - 66ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0748 - accuracy: 0.5410 - val_loss: 1.0883 - val_accuracy: 0.4416 - 347ms/epoch - 69ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0607 - accuracy: 0.5311 - val_loss: 1.0854 - val_accuracy: 0.4675 - 331ms/epoch - 66ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 1.0842 - accuracy: 0.5574 - val_loss: 1.0810 - val_accuracy: 0.4545 - 337ms/epoch - 67ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 1.0632 - accuracy: 0.5574 - val_loss: 1.0625 - val_accuracy: 0.4805 - 337ms/epoch - 67ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 1.0678 - accuracy: 0.5770 - val_loss: 1.0602 - val_accuracy: 0.4935 - 362ms/epoch - 72ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 1.0335 - accuracy: 0.5738 - val_loss: 1.0510 - val_accuracy: 0.4675 - 362ms/epoch - 72ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 1.0490 - accuracy: 0.5541 - val_loss: 1.0548 - val_accuracy: 0.4545 - 370ms/epoch - 74ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 1.0402 - accuracy: 0.5738 - val_loss: 1.0475 - val_accuracy: 0.4416 - 377ms/epoch - 75ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 1.0310 - accuracy: 0.5672 - val_loss: 1.0421 - val_accuracy: 0.4416 - 329ms/epoch - 66ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 1.0377 - accuracy: 0.5770 - val_loss: 1.0362 - val_accuracy: 0.4545 - 340ms/epoch - 68ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 1.0297 - accuracy: 0.5836 - val_loss: 1.0345 - val_accuracy: 0.4545 - 374ms/epoch - 75ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 1.0198 - accuracy: 0.5639 - val_loss: 1.0277 - val_accuracy: 0.4935 - 356ms/epoch - 71ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 1.0171 - accuracy: 0.5869 - val_loss: 1.0192 - val_accuracy: 0.4805 - 359ms/epoch - 72ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 1.0009 - accuracy: 0.6000 - val_loss: 1.0091 - val_accuracy: 0.5325 - 346ms/epoch - 69ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 1.0356 - accuracy: 0.5738 - val_loss: 1.0023 - val_accuracy: 0.4935 - 365ms/epoch - 73ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9664 - accuracy: 0.6197 - val_loss: 0.9929 - val_accuracy: 0.5065 - 347ms/epoch - 69ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9897 - accuracy: 0.5803 - val_loss: 0.9846 - val_accuracy: 0.5065 - 354ms/epoch - 71ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9926 - accuracy: 0.5967 - val_loss: 0.9751 - val_accuracy: 0.5195 - 350ms/epoch - 70ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9975 - accuracy: 0.5836 - val_loss: 0.9746 - val_accuracy: 0.5455 - 334ms/epoch - 67ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.9867 - accuracy: 0.5902 - val_loss: 0.9776 - val_accuracy: 0.5455 - 368ms/epoch - 74ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.9952 - accuracy: 0.5967 - val_loss: 0.9556 - val_accuracy: 0.5584 - 332ms/epoch - 66ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.9904 - accuracy: 0.6131 - val_loss: 0.9523 - val_accuracy: 0.5195 - 358ms/epoch - 72ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.9879 - accuracy: 0.6000 - val_loss: 0.9278 - val_accuracy: 0.5844 - 335ms/epoch - 67ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.9400 - accuracy: 0.6328 - val_loss: 0.9316 - val_accuracy: 0.5714 - 350ms/epoch - 70ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.9639 - accuracy: 0.5902 - val_loss: 0.9524 - val_accuracy: 0.5584 - 335ms/epoch - 67ms/step\n",
      "Epoch 64/10000\n",
      "5/5 - 0s - loss: 0.9702 - accuracy: 0.6393 - val_loss: 0.9227 - val_accuracy: 0.6104 - 339ms/epoch - 68ms/step\n",
      "Epoch 65/10000\n",
      "5/5 - 0s - loss: 0.9370 - accuracy: 0.6197 - val_loss: 0.9160 - val_accuracy: 0.5714 - 345ms/epoch - 69ms/step\n",
      "Epoch 66/10000\n",
      "5/5 - 0s - loss: 0.9364 - accuracy: 0.6393 - val_loss: 0.9165 - val_accuracy: 0.5844 - 333ms/epoch - 67ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/10000\n",
      "5/5 - 0s - loss: 0.9370 - accuracy: 0.6393 - val_loss: 0.8948 - val_accuracy: 0.6234 - 337ms/epoch - 67ms/step\n",
      "Epoch 68/10000\n",
      "5/5 - 0s - loss: 0.9056 - accuracy: 0.6492 - val_loss: 0.8940 - val_accuracy: 0.5974 - 335ms/epoch - 67ms/step\n",
      "Epoch 69/10000\n",
      "5/5 - 0s - loss: 0.9097 - accuracy: 0.6361 - val_loss: 0.9082 - val_accuracy: 0.5714 - 345ms/epoch - 69ms/step\n",
      "Epoch 70/10000\n",
      "5/5 - 0s - loss: 0.9341 - accuracy: 0.6361 - val_loss: 0.9060 - val_accuracy: 0.5974 - 356ms/epoch - 71ms/step\n",
      "Epoch 71/10000\n",
      "5/5 - 0s - loss: 0.9215 - accuracy: 0.6131 - val_loss: 0.8958 - val_accuracy: 0.6234 - 351ms/epoch - 70ms/step\n",
      "Epoch 72/10000\n",
      "5/5 - 0s - loss: 0.9278 - accuracy: 0.6033 - val_loss: 0.8931 - val_accuracy: 0.6234 - 350ms/epoch - 70ms/step\n",
      "Epoch 73/10000\n",
      "5/5 - 0s - loss: 0.9107 - accuracy: 0.6492 - val_loss: 0.8902 - val_accuracy: 0.6104 - 351ms/epoch - 70ms/step\n",
      "Epoch 74/10000\n",
      "5/5 - 0s - loss: 0.9453 - accuracy: 0.6230 - val_loss: 0.8791 - val_accuracy: 0.6234 - 333ms/epoch - 67ms/step\n",
      "Epoch 75/10000\n",
      "5/5 - 0s - loss: 0.9170 - accuracy: 0.6492 - val_loss: 0.8974 - val_accuracy: 0.5844 - 339ms/epoch - 68ms/step\n",
      "Epoch 76/10000\n",
      "5/5 - 0s - loss: 0.8971 - accuracy: 0.6590 - val_loss: 0.9025 - val_accuracy: 0.5714 - 330ms/epoch - 66ms/step\n",
      "Epoch 77/10000\n",
      "5/5 - 0s - loss: 0.9205 - accuracy: 0.6459 - val_loss: 0.8761 - val_accuracy: 0.6234 - 345ms/epoch - 69ms/step\n",
      "Epoch 78/10000\n",
      "5/5 - 0s - loss: 0.9201 - accuracy: 0.6328 - val_loss: 0.8833 - val_accuracy: 0.6104 - 329ms/epoch - 66ms/step\n",
      "Epoch 79/10000\n",
      "5/5 - 0s - loss: 0.9031 - accuracy: 0.6557 - val_loss: 0.8959 - val_accuracy: 0.5844 - 326ms/epoch - 65ms/step\n",
      "Epoch 80/10000\n",
      "5/5 - 0s - loss: 0.9134 - accuracy: 0.6328 - val_loss: 0.8921 - val_accuracy: 0.5844 - 326ms/epoch - 65ms/step\n",
      "Epoch 81/10000\n",
      "5/5 - 0s - loss: 0.8998 - accuracy: 0.6623 - val_loss: 0.8726 - val_accuracy: 0.6234 - 334ms/epoch - 67ms/step\n",
      "Epoch 82/10000\n",
      "5/5 - 0s - loss: 0.9001 - accuracy: 0.6361 - val_loss: 0.8650 - val_accuracy: 0.6234 - 342ms/epoch - 68ms/step\n",
      "Epoch 83/10000\n",
      "5/5 - 0s - loss: 0.8834 - accuracy: 0.6393 - val_loss: 0.8643 - val_accuracy: 0.6234 - 333ms/epoch - 67ms/step\n",
      "Epoch 84/10000\n",
      "5/5 - 0s - loss: 0.9158 - accuracy: 0.6525 - val_loss: 0.8676 - val_accuracy: 0.6234 - 332ms/epoch - 66ms/step\n",
      "Epoch 85/10000\n",
      "5/5 - 0s - loss: 0.8670 - accuracy: 0.6689 - val_loss: 0.8736 - val_accuracy: 0.6234 - 334ms/epoch - 67ms/step\n",
      "Epoch 86/10000\n",
      "5/5 - 0s - loss: 0.9014 - accuracy: 0.6590 - val_loss: 0.8748 - val_accuracy: 0.6234 - 335ms/epoch - 67ms/step\n",
      "Epoch 87/10000\n",
      "5/5 - 0s - loss: 0.8911 - accuracy: 0.6426 - val_loss: 0.8810 - val_accuracy: 0.6104 - 338ms/epoch - 68ms/step\n",
      "Epoch 88/10000\n",
      "5/5 - 0s - loss: 0.9077 - accuracy: 0.6393 - val_loss: 0.8636 - val_accuracy: 0.6494 - 349ms/epoch - 70ms/step\n",
      "Epoch 89/10000\n",
      "5/5 - 0s - loss: 0.9248 - accuracy: 0.6459 - val_loss: 0.8750 - val_accuracy: 0.6104 - 346ms/epoch - 69ms/step\n",
      "Epoch 90/10000\n",
      "5/5 - 0s - loss: 0.8774 - accuracy: 0.6492 - val_loss: 0.8793 - val_accuracy: 0.6104 - 354ms/epoch - 71ms/step\n",
      "Epoch 91/10000\n",
      "5/5 - 0s - loss: 0.8533 - accuracy: 0.6852 - val_loss: 0.8619 - val_accuracy: 0.6234 - 354ms/epoch - 71ms/step\n",
      "Epoch 92/10000\n",
      "5/5 - 0s - loss: 0.8988 - accuracy: 0.6656 - val_loss: 0.8700 - val_accuracy: 0.6104 - 341ms/epoch - 68ms/step\n",
      "Epoch 93/10000\n",
      "5/5 - 0s - loss: 0.8746 - accuracy: 0.6393 - val_loss: 0.8916 - val_accuracy: 0.6104 - 331ms/epoch - 66ms/step\n",
      "Epoch 94/10000\n",
      "5/5 - 0s - loss: 0.8836 - accuracy: 0.6459 - val_loss: 0.8631 - val_accuracy: 0.6364 - 348ms/epoch - 70ms/step\n",
      "Epoch 95/10000\n",
      "5/5 - 0s - loss: 0.8412 - accuracy: 0.6525 - val_loss: 0.8607 - val_accuracy: 0.6494 - 346ms/epoch - 69ms/step\n",
      "Epoch 96/10000\n",
      "5/5 - 0s - loss: 0.8843 - accuracy: 0.6590 - val_loss: 0.8816 - val_accuracy: 0.6104 - 329ms/epoch - 66ms/step\n",
      "Epoch 97/10000\n",
      "5/5 - 0s - loss: 0.8567 - accuracy: 0.6820 - val_loss: 0.8775 - val_accuracy: 0.6364 - 341ms/epoch - 68ms/step\n",
      "Epoch 98/10000\n",
      "5/5 - 0s - loss: 0.8859 - accuracy: 0.6295 - val_loss: 0.8659 - val_accuracy: 0.6364 - 331ms/epoch - 66ms/step\n",
      "Epoch 99/10000\n",
      "5/5 - 0s - loss: 0.8454 - accuracy: 0.6984 - val_loss: 0.8624 - val_accuracy: 0.6234 - 335ms/epoch - 67ms/step\n",
      "Epoch 100/10000\n",
      "5/5 - 0s - loss: 0.8502 - accuracy: 0.6656 - val_loss: 0.8718 - val_accuracy: 0.6104 - 340ms/epoch - 68ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8268 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:56:19,315] Trial 86 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'linear', 'activation_func_3': 'tanh', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 148}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3857 - accuracy: 0.3049 - val_loss: 1.3847 - val_accuracy: 0.3506 - 4s/epoch - 426ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3840 - accuracy: 0.3574 - val_loss: 1.3817 - val_accuracy: 0.3117 - 336ms/epoch - 34ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3782 - accuracy: 0.3869 - val_loss: 1.3743 - val_accuracy: 0.3247 - 335ms/epoch - 34ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3622 - accuracy: 0.4000 - val_loss: 1.3543 - val_accuracy: 0.3117 - 332ms/epoch - 33ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3183 - accuracy: 0.4164 - val_loss: 1.3194 - val_accuracy: 0.3896 - 332ms/epoch - 33ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2564 - accuracy: 0.4656 - val_loss: 1.2797 - val_accuracy: 0.3636 - 330ms/epoch - 33ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2505 - accuracy: 0.4590 - val_loss: 1.2561 - val_accuracy: 0.3636 - 334ms/epoch - 33ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2518 - accuracy: 0.4459 - val_loss: 1.2532 - val_accuracy: 0.3766 - 328ms/epoch - 33ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2244 - accuracy: 0.4590 - val_loss: 1.2246 - val_accuracy: 0.4156 - 338ms/epoch - 34ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1905 - accuracy: 0.4721 - val_loss: 1.1975 - val_accuracy: 0.4026 - 331ms/epoch - 33ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1720 - accuracy: 0.4820 - val_loss: 1.1723 - val_accuracy: 0.3766 - 337ms/epoch - 34ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1647 - accuracy: 0.4885 - val_loss: 1.1666 - val_accuracy: 0.3636 - 332ms/epoch - 33ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1458 - accuracy: 0.4984 - val_loss: 1.1499 - val_accuracy: 0.4156 - 332ms/epoch - 33ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1397 - accuracy: 0.4984 - val_loss: 1.1294 - val_accuracy: 0.4156 - 367ms/epoch - 37ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1627 - accuracy: 0.5016 - val_loss: 1.1563 - val_accuracy: 0.4026 - 395ms/epoch - 40ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1550 - accuracy: 0.5016 - val_loss: 1.1218 - val_accuracy: 0.4286 - 374ms/epoch - 37ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1445 - accuracy: 0.4787 - val_loss: 1.1197 - val_accuracy: 0.4026 - 379ms/epoch - 38ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1105 - accuracy: 0.5148 - val_loss: 1.1131 - val_accuracy: 0.4156 - 386ms/epoch - 39ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1338 - accuracy: 0.4984 - val_loss: 1.1293 - val_accuracy: 0.4026 - 435ms/epoch - 43ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.1157 - accuracy: 0.5410 - val_loss: 1.1078 - val_accuracy: 0.4805 - 401ms/epoch - 40ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.1030 - accuracy: 0.5148 - val_loss: 1.0983 - val_accuracy: 0.4416 - 385ms/epoch - 38ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.1062 - accuracy: 0.5279 - val_loss: 1.0902 - val_accuracy: 0.4156 - 365ms/epoch - 37ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0923 - accuracy: 0.5344 - val_loss: 1.0918 - val_accuracy: 0.4416 - 401ms/epoch - 40ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0959 - accuracy: 0.5475 - val_loss: 1.0907 - val_accuracy: 0.4545 - 378ms/epoch - 38ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0840 - accuracy: 0.5705 - val_loss: 1.0934 - val_accuracy: 0.4675 - 351ms/epoch - 35ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0740 - accuracy: 0.5443 - val_loss: 1.0671 - val_accuracy: 0.5844 - 345ms/epoch - 34ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0534 - accuracy: 0.5639 - val_loss: 1.0740 - val_accuracy: 0.4935 - 341ms/epoch - 34ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0765 - accuracy: 0.5574 - val_loss: 1.0511 - val_accuracy: 0.5195 - 350ms/epoch - 35ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0582 - accuracy: 0.5508 - val_loss: 1.0493 - val_accuracy: 0.5065 - 345ms/epoch - 35ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0778 - accuracy: 0.5639 - val_loss: 1.0538 - val_accuracy: 0.5325 - 333ms/epoch - 33ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0602 - accuracy: 0.5475 - val_loss: 1.0586 - val_accuracy: 0.5195 - 337ms/epoch - 34ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0409 - accuracy: 0.5803 - val_loss: 1.0503 - val_accuracy: 0.4675 - 344ms/epoch - 34ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0542 - accuracy: 0.5607 - val_loss: 1.0457 - val_accuracy: 0.4935 - 338ms/epoch - 34ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0715 - accuracy: 0.5475 - val_loss: 1.0251 - val_accuracy: 0.5325 - 361ms/epoch - 36ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0257 - accuracy: 0.5836 - val_loss: 1.0084 - val_accuracy: 0.5195 - 354ms/epoch - 35ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0543 - accuracy: 0.5639 - val_loss: 0.9927 - val_accuracy: 0.5455 - 340ms/epoch - 34ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0080 - accuracy: 0.5803 - val_loss: 1.0024 - val_accuracy: 0.5195 - 345ms/epoch - 34ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0080 - accuracy: 0.5672 - val_loss: 0.9869 - val_accuracy: 0.5195 - 354ms/epoch - 35ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9782 - accuracy: 0.5902 - val_loss: 0.9730 - val_accuracy: 0.5065 - 348ms/epoch - 35ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9859 - accuracy: 0.5967 - val_loss: 0.9518 - val_accuracy: 0.5844 - 347ms/epoch - 35ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0668 - accuracy: 0.5508 - val_loss: 0.9397 - val_accuracy: 0.5844 - 346ms/epoch - 35ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 1.0255 - accuracy: 0.6000 - val_loss: 0.9567 - val_accuracy: 0.5584 - 353ms/epoch - 35ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0134 - accuracy: 0.6164 - val_loss: 0.9660 - val_accuracy: 0.5325 - 353ms/epoch - 35ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9766 - accuracy: 0.6328 - val_loss: 0.9449 - val_accuracy: 0.5195 - 345ms/epoch - 34ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9474 - accuracy: 0.6361 - val_loss: 0.9334 - val_accuracy: 0.5844 - 342ms/epoch - 34ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9588 - accuracy: 0.6393 - val_loss: 0.9289 - val_accuracy: 0.5455 - 351ms/epoch - 35ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9685 - accuracy: 0.6295 - val_loss: 0.9092 - val_accuracy: 0.5974 - 340ms/epoch - 34ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9842 - accuracy: 0.5934 - val_loss: 0.9189 - val_accuracy: 0.5455 - 335ms/epoch - 34ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9642 - accuracy: 0.5869 - val_loss: 0.9080 - val_accuracy: 0.6234 - 378ms/epoch - 38ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9718 - accuracy: 0.5902 - val_loss: 0.8986 - val_accuracy: 0.5714 - 351ms/epoch - 35ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9566 - accuracy: 0.6197 - val_loss: 0.8949 - val_accuracy: 0.6494 - 384ms/epoch - 38ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9328 - accuracy: 0.6262 - val_loss: 0.8851 - val_accuracy: 0.6234 - 419ms/epoch - 42ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9647 - accuracy: 0.6295 - val_loss: 0.9297 - val_accuracy: 0.6234 - 397ms/epoch - 40ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9534 - accuracy: 0.6393 - val_loss: 0.9056 - val_accuracy: 0.6104 - 390ms/epoch - 39ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9394 - accuracy: 0.6262 - val_loss: 0.9106 - val_accuracy: 0.5455 - 401ms/epoch - 40ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9228 - accuracy: 0.6164 - val_loss: 0.8983 - val_accuracy: 0.6234 - 398ms/epoch - 40ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9227 - accuracy: 0.6164 - val_loss: 0.8918 - val_accuracy: 0.6104 - 417ms/epoch - 42ms/step\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9971 - accuracy: 0.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:56:45,302] Trial 87 finished with value: 0.6029411554336548 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 160}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3847 - accuracy: 0.2656 - val_loss: 1.3810 - val_accuracy: 0.3896 - 5s/epoch - 777ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3758 - accuracy: 0.4557 - val_loss: 1.3713 - val_accuracy: 0.4286 - 266ms/epoch - 38ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3603 - accuracy: 0.4656 - val_loss: 1.3497 - val_accuracy: 0.3896 - 282ms/epoch - 40ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3220 - accuracy: 0.4918 - val_loss: 1.3068 - val_accuracy: 0.4156 - 288ms/epoch - 41ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2918 - accuracy: 0.4820 - val_loss: 1.2641 - val_accuracy: 0.3766 - 292ms/epoch - 42ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2550 - accuracy: 0.4557 - val_loss: 1.2611 - val_accuracy: 0.3896 - 282ms/epoch - 40ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.2366 - accuracy: 0.4852 - val_loss: 1.2573 - val_accuracy: 0.4286 - 283ms/epoch - 40ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2684 - accuracy: 0.4852 - val_loss: 1.2520 - val_accuracy: 0.4675 - 290ms/epoch - 41ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.2129 - accuracy: 0.4951 - val_loss: 1.2404 - val_accuracy: 0.4026 - 312ms/epoch - 45ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.2519 - accuracy: 0.4525 - val_loss: 1.2179 - val_accuracy: 0.4156 - 288ms/epoch - 41ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.2061 - accuracy: 0.5049 - val_loss: 1.2200 - val_accuracy: 0.4286 - 281ms/epoch - 40ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1825 - accuracy: 0.5279 - val_loss: 1.2137 - val_accuracy: 0.4286 - 286ms/epoch - 41ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1999 - accuracy: 0.5082 - val_loss: 1.1892 - val_accuracy: 0.4156 - 280ms/epoch - 40ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1677 - accuracy: 0.5115 - val_loss: 1.2017 - val_accuracy: 0.4156 - 280ms/epoch - 40ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1684 - accuracy: 0.4984 - val_loss: 1.1486 - val_accuracy: 0.4416 - 274ms/epoch - 39ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1947 - accuracy: 0.5049 - val_loss: 1.1452 - val_accuracy: 0.4416 - 274ms/epoch - 39ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1486 - accuracy: 0.5180 - val_loss: 1.1569 - val_accuracy: 0.4156 - 283ms/epoch - 40ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1346 - accuracy: 0.5246 - val_loss: 1.1671 - val_accuracy: 0.4675 - 277ms/epoch - 40ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1331 - accuracy: 0.5344 - val_loss: 1.1339 - val_accuracy: 0.4156 - 282ms/epoch - 40ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1189 - accuracy: 0.5377 - val_loss: 1.1314 - val_accuracy: 0.4286 - 283ms/epoch - 40ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1221 - accuracy: 0.5377 - val_loss: 1.0978 - val_accuracy: 0.4545 - 276ms/epoch - 39ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.0855 - accuracy: 0.5410 - val_loss: 1.0922 - val_accuracy: 0.4675 - 283ms/epoch - 40ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1176 - accuracy: 0.5410 - val_loss: 1.0819 - val_accuracy: 0.4805 - 299ms/epoch - 43ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1059 - accuracy: 0.5213 - val_loss: 1.1049 - val_accuracy: 0.4416 - 280ms/epoch - 40ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0950 - accuracy: 0.5541 - val_loss: 1.0755 - val_accuracy: 0.4675 - 285ms/epoch - 41ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0711 - accuracy: 0.5443 - val_loss: 1.0450 - val_accuracy: 0.5325 - 288ms/epoch - 41ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0839 - accuracy: 0.5508 - val_loss: 1.0384 - val_accuracy: 0.5195 - 286ms/epoch - 41ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0802 - accuracy: 0.5705 - val_loss: 1.0251 - val_accuracy: 0.4935 - 279ms/epoch - 40ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0703 - accuracy: 0.5377 - val_loss: 1.0363 - val_accuracy: 0.4935 - 283ms/epoch - 40ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0347 - accuracy: 0.5836 - val_loss: 1.0631 - val_accuracy: 0.4675 - 282ms/epoch - 40ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0502 - accuracy: 0.5541 - val_loss: 1.0308 - val_accuracy: 0.4545 - 279ms/epoch - 40ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0448 - accuracy: 0.5574 - val_loss: 1.0397 - val_accuracy: 0.4805 - 284ms/epoch - 41ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0445 - accuracy: 0.5508 - val_loss: 1.0378 - val_accuracy: 0.4675 - 280ms/epoch - 40ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0040 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:57:01,396] Trial 88 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'selu', 'activation_func_2': 'selu', 'activation_func_3': 'swish', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.25, 'dropout_3': 0.5, 'neurons': 131}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3856 - accuracy: 0.2689 - val_loss: 1.3837 - val_accuracy: 0.3377 - 4s/epoch - 447ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3838 - accuracy: 0.3443 - val_loss: 1.3782 - val_accuracy: 0.3636 - 270ms/epoch - 27ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3778 - accuracy: 0.3541 - val_loss: 1.3700 - val_accuracy: 0.3377 - 272ms/epoch - 27ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3648 - accuracy: 0.3902 - val_loss: 1.3530 - val_accuracy: 0.2987 - 276ms/epoch - 28ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3340 - accuracy: 0.3934 - val_loss: 1.3194 - val_accuracy: 0.3117 - 270ms/epoch - 27ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2816 - accuracy: 0.4328 - val_loss: 1.2714 - val_accuracy: 0.3506 - 279ms/epoch - 28ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2547 - accuracy: 0.4459 - val_loss: 1.2313 - val_accuracy: 0.3766 - 300ms/epoch - 30ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2288 - accuracy: 0.4492 - val_loss: 1.1925 - val_accuracy: 0.3896 - 268ms/epoch - 27ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1790 - accuracy: 0.4984 - val_loss: 1.1768 - val_accuracy: 0.4026 - 282ms/epoch - 28ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1691 - accuracy: 0.4918 - val_loss: 1.1668 - val_accuracy: 0.4026 - 276ms/epoch - 28ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1593 - accuracy: 0.4984 - val_loss: 1.1625 - val_accuracy: 0.3896 - 269ms/epoch - 27ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1707 - accuracy: 0.4984 - val_loss: 1.1690 - val_accuracy: 0.3766 - 283ms/epoch - 28ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1567 - accuracy: 0.4918 - val_loss: 1.1543 - val_accuracy: 0.3896 - 262ms/epoch - 26ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1401 - accuracy: 0.4951 - val_loss: 1.1460 - val_accuracy: 0.4026 - 266ms/epoch - 27ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1378 - accuracy: 0.5082 - val_loss: 1.1370 - val_accuracy: 0.3896 - 275ms/epoch - 28ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1216 - accuracy: 0.5148 - val_loss: 1.1219 - val_accuracy: 0.4156 - 270ms/epoch - 27ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1242 - accuracy: 0.4951 - val_loss: 1.1223 - val_accuracy: 0.3766 - 282ms/epoch - 28ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1290 - accuracy: 0.5279 - val_loss: 1.1141 - val_accuracy: 0.4156 - 253ms/epoch - 25ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1120 - accuracy: 0.5115 - val_loss: 1.1156 - val_accuracy: 0.4156 - 270ms/epoch - 27ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0975 - accuracy: 0.5279 - val_loss: 1.1048 - val_accuracy: 0.4416 - 255ms/epoch - 25ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0969 - accuracy: 0.5541 - val_loss: 1.0959 - val_accuracy: 0.4416 - 255ms/epoch - 26ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0770 - accuracy: 0.5344 - val_loss: 1.0884 - val_accuracy: 0.4416 - 273ms/epoch - 27ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0986 - accuracy: 0.5377 - val_loss: 1.0909 - val_accuracy: 0.4675 - 266ms/epoch - 27ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0960 - accuracy: 0.5475 - val_loss: 1.0843 - val_accuracy: 0.4416 - 274ms/epoch - 27ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0730 - accuracy: 0.5705 - val_loss: 1.0836 - val_accuracy: 0.4675 - 261ms/epoch - 26ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0668 - accuracy: 0.5279 - val_loss: 1.0618 - val_accuracy: 0.5065 - 272ms/epoch - 27ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0672 - accuracy: 0.5508 - val_loss: 1.0507 - val_accuracy: 0.4935 - 263ms/epoch - 26ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0647 - accuracy: 0.5541 - val_loss: 1.0499 - val_accuracy: 0.4675 - 263ms/epoch - 26ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0469 - accuracy: 0.5672 - val_loss: 1.0545 - val_accuracy: 0.4935 - 258ms/epoch - 26ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0557 - accuracy: 0.5607 - val_loss: 1.0429 - val_accuracy: 0.4545 - 290ms/epoch - 29ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0328 - accuracy: 0.5279 - val_loss: 1.0216 - val_accuracy: 0.4675 - 256ms/epoch - 26ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0285 - accuracy: 0.5541 - val_loss: 1.0214 - val_accuracy: 0.4805 - 253ms/epoch - 25ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0385 - accuracy: 0.5705 - val_loss: 1.0066 - val_accuracy: 0.5065 - 259ms/epoch - 26ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0123 - accuracy: 0.5639 - val_loss: 1.0039 - val_accuracy: 0.5455 - 257ms/epoch - 26ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0138 - accuracy: 0.5803 - val_loss: 0.9738 - val_accuracy: 0.5455 - 262ms/epoch - 26ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9995 - accuracy: 0.5869 - val_loss: 0.9540 - val_accuracy: 0.5714 - 254ms/epoch - 25ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9570 - accuracy: 0.6131 - val_loss: 0.9490 - val_accuracy: 0.5584 - 251ms/epoch - 25ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9700 - accuracy: 0.5705 - val_loss: 0.9380 - val_accuracy: 0.5455 - 258ms/epoch - 26ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9811 - accuracy: 0.5902 - val_loss: 0.9352 - val_accuracy: 0.5584 - 262ms/epoch - 26ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9991 - accuracy: 0.5902 - val_loss: 0.9220 - val_accuracy: 0.5844 - 249ms/epoch - 25ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9540 - accuracy: 0.6098 - val_loss: 0.9004 - val_accuracy: 0.6364 - 261ms/epoch - 26ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9405 - accuracy: 0.6033 - val_loss: 0.9223 - val_accuracy: 0.5714 - 254ms/epoch - 25ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9820 - accuracy: 0.5934 - val_loss: 0.9184 - val_accuracy: 0.5455 - 255ms/epoch - 25ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9451 - accuracy: 0.6262 - val_loss: 0.9176 - val_accuracy: 0.5714 - 262ms/epoch - 26ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9767 - accuracy: 0.6033 - val_loss: 0.9056 - val_accuracy: 0.5844 - 276ms/epoch - 28ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9504 - accuracy: 0.6295 - val_loss: 0.9081 - val_accuracy: 0.5844 - 289ms/epoch - 29ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8863 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:57:19,692] Trial 89 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 128}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3858 - accuracy: 0.3148 - val_loss: 1.3850 - val_accuracy: 0.3506 - 4s/epoch - 433ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3846 - accuracy: 0.3639 - val_loss: 1.3826 - val_accuracy: 0.3117 - 276ms/epoch - 28ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3807 - accuracy: 0.3803 - val_loss: 1.3782 - val_accuracy: 0.3766 - 292ms/epoch - 29ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3723 - accuracy: 0.4393 - val_loss: 1.3664 - val_accuracy: 0.3896 - 297ms/epoch - 30ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3466 - accuracy: 0.4393 - val_loss: 1.3394 - val_accuracy: 0.4156 - 291ms/epoch - 29ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2979 - accuracy: 0.4885 - val_loss: 1.2876 - val_accuracy: 0.3636 - 296ms/epoch - 30ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2701 - accuracy: 0.4557 - val_loss: 1.2547 - val_accuracy: 0.3636 - 282ms/epoch - 28ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2472 - accuracy: 0.4656 - val_loss: 1.2305 - val_accuracy: 0.3896 - 286ms/epoch - 29ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2293 - accuracy: 0.4852 - val_loss: 1.2078 - val_accuracy: 0.4026 - 285ms/epoch - 28ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.2082 - accuracy: 0.4852 - val_loss: 1.1822 - val_accuracy: 0.3896 - 282ms/epoch - 28ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1639 - accuracy: 0.4852 - val_loss: 1.1690 - val_accuracy: 0.3896 - 287ms/epoch - 29ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1499 - accuracy: 0.4984 - val_loss: 1.1640 - val_accuracy: 0.3896 - 278ms/epoch - 28ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1441 - accuracy: 0.4984 - val_loss: 1.1600 - val_accuracy: 0.4026 - 283ms/epoch - 28ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1488 - accuracy: 0.5148 - val_loss: 1.1391 - val_accuracy: 0.4026 - 284ms/epoch - 28ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1491 - accuracy: 0.5115 - val_loss: 1.1601 - val_accuracy: 0.3766 - 285ms/epoch - 28ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1482 - accuracy: 0.5049 - val_loss: 1.1311 - val_accuracy: 0.4286 - 284ms/epoch - 28ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1253 - accuracy: 0.5311 - val_loss: 1.1200 - val_accuracy: 0.4156 - 296ms/epoch - 30ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1293 - accuracy: 0.5082 - val_loss: 1.1169 - val_accuracy: 0.4156 - 283ms/epoch - 28ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.1368 - accuracy: 0.5082 - val_loss: 1.1227 - val_accuracy: 0.4156 - 278ms/epoch - 28ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0998 - accuracy: 0.5279 - val_loss: 1.1041 - val_accuracy: 0.4286 - 286ms/epoch - 29ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0985 - accuracy: 0.5148 - val_loss: 1.0934 - val_accuracy: 0.4286 - 284ms/epoch - 28ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0942 - accuracy: 0.5115 - val_loss: 1.0906 - val_accuracy: 0.4286 - 291ms/epoch - 29ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.1031 - accuracy: 0.5410 - val_loss: 1.1047 - val_accuracy: 0.4545 - 301ms/epoch - 30ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.1100 - accuracy: 0.5213 - val_loss: 1.0900 - val_accuracy: 0.4416 - 288ms/epoch - 29ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.1171 - accuracy: 0.5246 - val_loss: 1.1082 - val_accuracy: 0.4545 - 276ms/epoch - 28ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.1020 - accuracy: 0.5246 - val_loss: 1.1030 - val_accuracy: 0.5325 - 283ms/epoch - 28ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.1120 - accuracy: 0.5541 - val_loss: 1.0810 - val_accuracy: 0.4935 - 285ms/epoch - 28ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0985 - accuracy: 0.5410 - val_loss: 1.0669 - val_accuracy: 0.4805 - 285ms/epoch - 29ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0788 - accuracy: 0.5607 - val_loss: 1.0606 - val_accuracy: 0.4675 - 280ms/epoch - 28ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0675 - accuracy: 0.5443 - val_loss: 1.0575 - val_accuracy: 0.4805 - 276ms/epoch - 28ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 1.0923 - accuracy: 0.5377 - val_loss: 1.0592 - val_accuracy: 0.4675 - 291ms/epoch - 29ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 1.0577 - accuracy: 0.5672 - val_loss: 1.0584 - val_accuracy: 0.4805 - 282ms/epoch - 28ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0671 - accuracy: 0.5705 - val_loss: 1.0618 - val_accuracy: 0.4935 - 289ms/epoch - 29ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 1.0450 - accuracy: 0.5836 - val_loss: 1.0503 - val_accuracy: 0.4935 - 321ms/epoch - 32ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 1.0596 - accuracy: 0.5672 - val_loss: 1.0384 - val_accuracy: 0.5195 - 313ms/epoch - 31ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 1.0479 - accuracy: 0.5639 - val_loss: 1.0221 - val_accuracy: 0.5195 - 325ms/epoch - 32ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 1.0460 - accuracy: 0.5541 - val_loss: 1.0225 - val_accuracy: 0.5065 - 330ms/epoch - 33ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 1.0553 - accuracy: 0.5902 - val_loss: 1.0149 - val_accuracy: 0.5065 - 337ms/epoch - 34ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 1.0393 - accuracy: 0.5738 - val_loss: 1.0055 - val_accuracy: 0.5195 - 327ms/epoch - 33ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 1.0400 - accuracy: 0.5836 - val_loss: 0.9949 - val_accuracy: 0.5195 - 329ms/epoch - 33ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 1.0171 - accuracy: 0.5967 - val_loss: 0.9825 - val_accuracy: 0.5584 - 310ms/epoch - 31ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9951 - accuracy: 0.5738 - val_loss: 0.9821 - val_accuracy: 0.5455 - 308ms/epoch - 31ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 1.0024 - accuracy: 0.5803 - val_loss: 0.9708 - val_accuracy: 0.5325 - 306ms/epoch - 31ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 1.0135 - accuracy: 0.5836 - val_loss: 0.9668 - val_accuracy: 0.5844 - 271ms/epoch - 27ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 1.0150 - accuracy: 0.5934 - val_loss: 0.9555 - val_accuracy: 0.5325 - 294ms/epoch - 29ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9516 - accuracy: 0.6426 - val_loss: 0.9549 - val_accuracy: 0.5455 - 284ms/epoch - 28ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9945 - accuracy: 0.6230 - val_loss: 0.9394 - val_accuracy: 0.5584 - 297ms/epoch - 30ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 1.0147 - accuracy: 0.5967 - val_loss: 0.9431 - val_accuracy: 0.5325 - 290ms/epoch - 29ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 1.0175 - accuracy: 0.5803 - val_loss: 0.9496 - val_accuracy: 0.5974 - 295ms/epoch - 30ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 1.0091 - accuracy: 0.6066 - val_loss: 0.9485 - val_accuracy: 0.5195 - 306ms/epoch - 31ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9624 - accuracy: 0.6131 - val_loss: 0.9318 - val_accuracy: 0.5584 - 303ms/epoch - 30ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9520 - accuracy: 0.6131 - val_loss: 0.9199 - val_accuracy: 0.5455 - 286ms/epoch - 29ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9444 - accuracy: 0.6197 - val_loss: 0.9257 - val_accuracy: 0.5974 - 284ms/epoch - 28ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9661 - accuracy: 0.5967 - val_loss: 0.9030 - val_accuracy: 0.5584 - 285ms/epoch - 29ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9517 - accuracy: 0.6361 - val_loss: 0.9023 - val_accuracy: 0.5325 - 294ms/epoch - 29ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9727 - accuracy: 0.6000 - val_loss: 0.9051 - val_accuracy: 0.5844 - 289ms/epoch - 29ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9254 - accuracy: 0.6393 - val_loss: 0.8936 - val_accuracy: 0.5974 - 289ms/epoch - 29ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.9136 - accuracy: 0.6525 - val_loss: 0.8950 - val_accuracy: 0.5974 - 290ms/epoch - 29ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.9260 - accuracy: 0.6623 - val_loss: 0.8782 - val_accuracy: 0.6104 - 284ms/epoch - 28ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9227 - accuracy: 0.6557 - val_loss: 0.8893 - val_accuracy: 0.5844 - 293ms/epoch - 29ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9487 - accuracy: 0.6328 - val_loss: 0.8678 - val_accuracy: 0.6364 - 286ms/epoch - 29ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.9129 - accuracy: 0.6525 - val_loss: 0.8848 - val_accuracy: 0.5714 - 296ms/epoch - 30ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.8859 - accuracy: 0.6492 - val_loss: 0.8861 - val_accuracy: 0.6364 - 287ms/epoch - 29ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9277 - accuracy: 0.6656 - val_loss: 0.8869 - val_accuracy: 0.5844 - 300ms/epoch - 30ms/step\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.9319 - accuracy: 0.6197 - val_loss: 0.8818 - val_accuracy: 0.6494 - 288ms/epoch - 29ms/step\n",
      "Epoch 66/10000\n",
      "10/10 - 0s - loss: 0.9316 - accuracy: 0.6262 - val_loss: 0.8785 - val_accuracy: 0.6104 - 282ms/epoch - 28ms/step\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8836 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:57:44,886] Trial 90 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'swish', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 141}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3856 - accuracy: 0.3475 - val_loss: 1.3843 - val_accuracy: 0.3766 - 4s/epoch - 808ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3831 - accuracy: 0.3967 - val_loss: 1.3811 - val_accuracy: 0.3506 - 310ms/epoch - 62ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3786 - accuracy: 0.4328 - val_loss: 1.3763 - val_accuracy: 0.3766 - 327ms/epoch - 65ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3732 - accuracy: 0.4754 - val_loss: 1.3684 - val_accuracy: 0.4026 - 343ms/epoch - 69ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3591 - accuracy: 0.4623 - val_loss: 1.3554 - val_accuracy: 0.3896 - 335ms/epoch - 67ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3389 - accuracy: 0.4590 - val_loss: 1.3349 - val_accuracy: 0.3896 - 331ms/epoch - 66ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3135 - accuracy: 0.4689 - val_loss: 1.3051 - val_accuracy: 0.3766 - 330ms/epoch - 66ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2807 - accuracy: 0.4459 - val_loss: 1.2733 - val_accuracy: 0.3506 - 325ms/epoch - 65ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2479 - accuracy: 0.4525 - val_loss: 1.2323 - val_accuracy: 0.3766 - 309ms/epoch - 62ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2055 - accuracy: 0.4721 - val_loss: 1.2289 - val_accuracy: 0.3636 - 316ms/epoch - 63ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.2087 - accuracy: 0.4623 - val_loss: 1.2146 - val_accuracy: 0.3896 - 315ms/epoch - 63ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.2177 - accuracy: 0.4689 - val_loss: 1.1864 - val_accuracy: 0.3896 - 312ms/epoch - 62ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1978 - accuracy: 0.4787 - val_loss: 1.1839 - val_accuracy: 0.4026 - 317ms/epoch - 63ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1706 - accuracy: 0.4984 - val_loss: 1.1698 - val_accuracy: 0.4156 - 311ms/epoch - 62ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1623 - accuracy: 0.5115 - val_loss: 1.1572 - val_accuracy: 0.4026 - 332ms/epoch - 66ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1717 - accuracy: 0.5016 - val_loss: 1.1483 - val_accuracy: 0.4026 - 319ms/epoch - 64ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1482 - accuracy: 0.5016 - val_loss: 1.1417 - val_accuracy: 0.4026 - 308ms/epoch - 62ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.0923 - accuracy: 0.5213 - val_loss: 1.1222 - val_accuracy: 0.4286 - 313ms/epoch - 63ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1200 - accuracy: 0.5213 - val_loss: 1.1155 - val_accuracy: 0.4286 - 306ms/epoch - 61ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1128 - accuracy: 0.5148 - val_loss: 1.1081 - val_accuracy: 0.4286 - 342ms/epoch - 68ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1270 - accuracy: 0.4984 - val_loss: 1.1078 - val_accuracy: 0.4286 - 324ms/epoch - 65ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1272 - accuracy: 0.5049 - val_loss: 1.0923 - val_accuracy: 0.4416 - 309ms/epoch - 62ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1369 - accuracy: 0.5082 - val_loss: 1.1056 - val_accuracy: 0.4545 - 322ms/epoch - 64ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.1101 - accuracy: 0.5574 - val_loss: 1.1018 - val_accuracy: 0.4675 - 316ms/epoch - 63ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1071 - accuracy: 0.5410 - val_loss: 1.0919 - val_accuracy: 0.4675 - 317ms/epoch - 63ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0994 - accuracy: 0.5574 - val_loss: 1.0884 - val_accuracy: 0.4675 - 310ms/epoch - 62ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0604 - accuracy: 0.5344 - val_loss: 1.0709 - val_accuracy: 0.4935 - 317ms/epoch - 63ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0819 - accuracy: 0.5574 - val_loss: 1.0572 - val_accuracy: 0.4675 - 312ms/epoch - 62ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0926 - accuracy: 0.5443 - val_loss: 1.0519 - val_accuracy: 0.4805 - 318ms/epoch - 64ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0595 - accuracy: 0.5672 - val_loss: 1.0487 - val_accuracy: 0.4805 - 318ms/epoch - 64ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0821 - accuracy: 0.5443 - val_loss: 1.0443 - val_accuracy: 0.4675 - 318ms/epoch - 64ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0524 - accuracy: 0.5475 - val_loss: 1.0363 - val_accuracy: 0.4935 - 328ms/epoch - 66ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0351 - accuracy: 0.5574 - val_loss: 1.0342 - val_accuracy: 0.4935 - 340ms/epoch - 68ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0429 - accuracy: 0.5738 - val_loss: 1.0295 - val_accuracy: 0.4935 - 323ms/epoch - 65ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0278 - accuracy: 0.5443 - val_loss: 1.0140 - val_accuracy: 0.5195 - 336ms/epoch - 67ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0144 - accuracy: 0.5672 - val_loss: 0.9897 - val_accuracy: 0.5325 - 318ms/epoch - 64ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0338 - accuracy: 0.5705 - val_loss: 0.9756 - val_accuracy: 0.5195 - 306ms/epoch - 61ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0181 - accuracy: 0.5738 - val_loss: 0.9773 - val_accuracy: 0.5195 - 331ms/epoch - 66ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0126 - accuracy: 0.5770 - val_loss: 0.9764 - val_accuracy: 0.5325 - 309ms/epoch - 62ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0096 - accuracy: 0.5836 - val_loss: 0.9596 - val_accuracy: 0.5325 - 323ms/epoch - 65ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 0.9875 - accuracy: 0.5869 - val_loss: 0.9534 - val_accuracy: 0.5974 - 326ms/epoch - 65ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 1.0123 - accuracy: 0.5803 - val_loss: 0.9471 - val_accuracy: 0.5325 - 328ms/epoch - 66ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 1.0148 - accuracy: 0.5475 - val_loss: 0.9381 - val_accuracy: 0.5325 - 332ms/epoch - 66ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 1.0304 - accuracy: 0.5967 - val_loss: 0.9328 - val_accuracy: 0.5455 - 311ms/epoch - 62ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.9837 - accuracy: 0.5770 - val_loss: 0.9281 - val_accuracy: 0.5584 - 345ms/epoch - 69ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9929 - accuracy: 0.6262 - val_loss: 0.9212 - val_accuracy: 0.5584 - 346ms/epoch - 69ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9651 - accuracy: 0.6262 - val_loss: 0.9226 - val_accuracy: 0.5714 - 317ms/epoch - 63ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 0.9738 - accuracy: 0.6000 - val_loss: 0.9075 - val_accuracy: 0.5714 - 316ms/epoch - 63ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9435 - accuracy: 0.6295 - val_loss: 0.9112 - val_accuracy: 0.5584 - 328ms/epoch - 66ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.9492 - accuracy: 0.6098 - val_loss: 0.9031 - val_accuracy: 0.5455 - 318ms/epoch - 64ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.9479 - accuracy: 0.5836 - val_loss: 0.8930 - val_accuracy: 0.5455 - 329ms/epoch - 66ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.9351 - accuracy: 0.6557 - val_loss: 0.8791 - val_accuracy: 0.6104 - 335ms/epoch - 67ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.9635 - accuracy: 0.6066 - val_loss: 0.9081 - val_accuracy: 0.5844 - 358ms/epoch - 72ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9829 - accuracy: 0.6426 - val_loss: 0.8956 - val_accuracy: 0.6234 - 365ms/epoch - 73ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9487 - accuracy: 0.6164 - val_loss: 0.9006 - val_accuracy: 0.5455 - 360ms/epoch - 72ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9424 - accuracy: 0.6033 - val_loss: 0.9057 - val_accuracy: 0.5455 - 338ms/epoch - 68ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9264 - accuracy: 0.6131 - val_loss: 0.9025 - val_accuracy: 0.5584 - 329ms/epoch - 66ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8741 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:58:08,899] Trial 91 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 153}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 5s - loss: 1.3856 - accuracy: 0.2852 - val_loss: 1.3848 - val_accuracy: 0.3506 - 5s/epoch - 1s/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3836 - accuracy: 0.4164 - val_loss: 1.3824 - val_accuracy: 0.3117 - 353ms/epoch - 71ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3796 - accuracy: 0.4295 - val_loss: 1.3789 - val_accuracy: 0.3896 - 371ms/epoch - 74ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3732 - accuracy: 0.4230 - val_loss: 1.3737 - val_accuracy: 0.4026 - 378ms/epoch - 76ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3655 - accuracy: 0.4262 - val_loss: 1.3643 - val_accuracy: 0.4545 - 375ms/epoch - 75ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3446 - accuracy: 0.4623 - val_loss: 1.3502 - val_accuracy: 0.4545 - 373ms/epoch - 75ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3272 - accuracy: 0.4262 - val_loss: 1.3351 - val_accuracy: 0.3636 - 369ms/epoch - 74ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.3033 - accuracy: 0.4721 - val_loss: 1.3004 - val_accuracy: 0.3636 - 412ms/epoch - 82ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2851 - accuracy: 0.4361 - val_loss: 1.2636 - val_accuracy: 0.3636 - 349ms/epoch - 70ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2452 - accuracy: 0.4557 - val_loss: 1.2526 - val_accuracy: 0.3636 - 355ms/epoch - 71ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.2408 - accuracy: 0.4689 - val_loss: 1.2366 - val_accuracy: 0.3766 - 368ms/epoch - 74ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.2307 - accuracy: 0.4557 - val_loss: 1.2154 - val_accuracy: 0.3636 - 369ms/epoch - 74ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.2210 - accuracy: 0.4754 - val_loss: 1.2041 - val_accuracy: 0.4026 - 364ms/epoch - 73ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.2074 - accuracy: 0.4984 - val_loss: 1.1985 - val_accuracy: 0.3766 - 358ms/epoch - 72ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.2001 - accuracy: 0.4918 - val_loss: 1.1886 - val_accuracy: 0.4156 - 356ms/epoch - 71ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1769 - accuracy: 0.5180 - val_loss: 1.1809 - val_accuracy: 0.4026 - 363ms/epoch - 73ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1589 - accuracy: 0.5180 - val_loss: 1.1633 - val_accuracy: 0.4026 - 385ms/epoch - 77ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1473 - accuracy: 0.5213 - val_loss: 1.1528 - val_accuracy: 0.4156 - 363ms/epoch - 73ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1333 - accuracy: 0.5115 - val_loss: 1.1655 - val_accuracy: 0.4286 - 358ms/epoch - 72ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1403 - accuracy: 0.5115 - val_loss: 1.1265 - val_accuracy: 0.4156 - 354ms/epoch - 71ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1168 - accuracy: 0.5246 - val_loss: 1.1126 - val_accuracy: 0.4156 - 352ms/epoch - 70ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1256 - accuracy: 0.5016 - val_loss: 1.1055 - val_accuracy: 0.4545 - 395ms/epoch - 79ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1148 - accuracy: 0.5344 - val_loss: 1.1070 - val_accuracy: 0.4805 - 383ms/epoch - 77ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0912 - accuracy: 0.5541 - val_loss: 1.1068 - val_accuracy: 0.4545 - 394ms/epoch - 79ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1367 - accuracy: 0.5311 - val_loss: 1.1068 - val_accuracy: 0.4805 - 375ms/epoch - 75ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.1290 - accuracy: 0.5541 - val_loss: 1.0857 - val_accuracy: 0.4675 - 377ms/epoch - 75ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0975 - accuracy: 0.5508 - val_loss: 1.0767 - val_accuracy: 0.4805 - 372ms/epoch - 74ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0942 - accuracy: 0.5607 - val_loss: 1.0681 - val_accuracy: 0.4675 - 351ms/epoch - 70ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.1038 - accuracy: 0.5639 - val_loss: 1.0600 - val_accuracy: 0.4935 - 352ms/epoch - 70ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0924 - accuracy: 0.5541 - val_loss: 1.0554 - val_accuracy: 0.4675 - 355ms/epoch - 71ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0734 - accuracy: 0.5541 - val_loss: 1.0620 - val_accuracy: 0.4935 - 360ms/epoch - 72ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0676 - accuracy: 0.5639 - val_loss: 1.0388 - val_accuracy: 0.4935 - 375ms/epoch - 75ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0459 - accuracy: 0.5705 - val_loss: 1.0458 - val_accuracy: 0.4935 - 360ms/epoch - 72ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0840 - accuracy: 0.5508 - val_loss: 1.0290 - val_accuracy: 0.5325 - 378ms/epoch - 76ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0531 - accuracy: 0.5902 - val_loss: 1.0198 - val_accuracy: 0.5455 - 349ms/epoch - 70ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0291 - accuracy: 0.5738 - val_loss: 1.0046 - val_accuracy: 0.5195 - 367ms/epoch - 73ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0571 - accuracy: 0.5934 - val_loss: 0.9993 - val_accuracy: 0.4935 - 360ms/epoch - 72ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0275 - accuracy: 0.5574 - val_loss: 1.0003 - val_accuracy: 0.4935 - 352ms/epoch - 70ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0288 - accuracy: 0.5836 - val_loss: 0.9926 - val_accuracy: 0.5195 - 373ms/epoch - 75ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0253 - accuracy: 0.5803 - val_loss: 0.9784 - val_accuracy: 0.5455 - 366ms/epoch - 73ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 1.0588 - accuracy: 0.5967 - val_loss: 0.9622 - val_accuracy: 0.5325 - 356ms/epoch - 71ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 1.0096 - accuracy: 0.5803 - val_loss: 0.9669 - val_accuracy: 0.5325 - 355ms/epoch - 71ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.9939 - accuracy: 0.5738 - val_loss: 0.9362 - val_accuracy: 0.5195 - 354ms/epoch - 71ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 1.0210 - accuracy: 0.6197 - val_loss: 0.9223 - val_accuracy: 0.6104 - 364ms/epoch - 73ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 1.0197 - accuracy: 0.5770 - val_loss: 0.9362 - val_accuracy: 0.5195 - 364ms/epoch - 73ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 1.0075 - accuracy: 0.5869 - val_loss: 0.9375 - val_accuracy: 0.5325 - 369ms/epoch - 74ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9673 - accuracy: 0.6131 - val_loss: 0.9451 - val_accuracy: 0.5325 - 357ms/epoch - 71ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 1.0255 - accuracy: 0.5770 - val_loss: 0.9187 - val_accuracy: 0.5584 - 359ms/epoch - 72ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9563 - accuracy: 0.6066 - val_loss: 0.9123 - val_accuracy: 0.5714 - 366ms/epoch - 73ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.9960 - accuracy: 0.6361 - val_loss: 0.9177 - val_accuracy: 0.5325 - 359ms/epoch - 72ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 1.0052 - accuracy: 0.5836 - val_loss: 0.9136 - val_accuracy: 0.5455 - 362ms/epoch - 72ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.9960 - accuracy: 0.6066 - val_loss: 0.9210 - val_accuracy: 0.5195 - 368ms/epoch - 74ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.9750 - accuracy: 0.5869 - val_loss: 0.9214 - val_accuracy: 0.5455 - 350ms/epoch - 70ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9526 - accuracy: 0.6197 - val_loss: 0.9094 - val_accuracy: 0.5455 - 364ms/epoch - 73ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9600 - accuracy: 0.6328 - val_loss: 0.8919 - val_accuracy: 0.5714 - 367ms/epoch - 73ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9716 - accuracy: 0.6098 - val_loss: 0.8921 - val_accuracy: 0.5844 - 352ms/epoch - 70ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9339 - accuracy: 0.6328 - val_loss: 0.8944 - val_accuracy: 0.5455 - 358ms/epoch - 72ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.9419 - accuracy: 0.6197 - val_loss: 0.8845 - val_accuracy: 0.6234 - 358ms/epoch - 72ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.9531 - accuracy: 0.6033 - val_loss: 0.8798 - val_accuracy: 0.5584 - 376ms/epoch - 75ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.9563 - accuracy: 0.6295 - val_loss: 0.8748 - val_accuracy: 0.5714 - 374ms/epoch - 75ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.9444 - accuracy: 0.6131 - val_loss: 0.8706 - val_accuracy: 0.6364 - 366ms/epoch - 73ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.9170 - accuracy: 0.6918 - val_loss: 0.8829 - val_accuracy: 0.5584 - 374ms/epoch - 75ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.9994 - accuracy: 0.6295 - val_loss: 0.8940 - val_accuracy: 0.5584 - 359ms/epoch - 72ms/step\n",
      "Epoch 64/10000\n",
      "5/5 - 0s - loss: 0.9349 - accuracy: 0.6197 - val_loss: 0.8986 - val_accuracy: 0.6104 - 350ms/epoch - 70ms/step\n",
      "Epoch 65/10000\n",
      "5/5 - 0s - loss: 0.9785 - accuracy: 0.6033 - val_loss: 0.8843 - val_accuracy: 0.5584 - 371ms/epoch - 74ms/step\n",
      "Epoch 66/10000\n",
      "5/5 - 0s - loss: 0.9155 - accuracy: 0.6197 - val_loss: 0.9026 - val_accuracy: 0.5584 - 399ms/epoch - 80ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9040 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:58:39,578] Trial 92 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 151}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3857 - accuracy: 0.3311 - val_loss: 1.3847 - val_accuracy: 0.3636 - 4s/epoch - 826ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3840 - accuracy: 0.3607 - val_loss: 1.3822 - val_accuracy: 0.3117 - 340ms/epoch - 68ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3808 - accuracy: 0.3738 - val_loss: 1.3775 - val_accuracy: 0.3506 - 350ms/epoch - 70ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3753 - accuracy: 0.4492 - val_loss: 1.3706 - val_accuracy: 0.3766 - 379ms/epoch - 76ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3664 - accuracy: 0.4689 - val_loss: 1.3584 - val_accuracy: 0.3636 - 361ms/epoch - 72ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3508 - accuracy: 0.4918 - val_loss: 1.3384 - val_accuracy: 0.3766 - 361ms/epoch - 72ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3225 - accuracy: 0.4820 - val_loss: 1.3073 - val_accuracy: 0.4026 - 356ms/epoch - 71ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2806 - accuracy: 0.4689 - val_loss: 1.2720 - val_accuracy: 0.4156 - 350ms/epoch - 70ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2382 - accuracy: 0.4951 - val_loss: 1.2329 - val_accuracy: 0.3766 - 361ms/epoch - 72ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2212 - accuracy: 0.4951 - val_loss: 1.2132 - val_accuracy: 0.3766 - 356ms/epoch - 71ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.2087 - accuracy: 0.4689 - val_loss: 1.2040 - val_accuracy: 0.3506 - 348ms/epoch - 70ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.1972 - accuracy: 0.5049 - val_loss: 1.1931 - val_accuracy: 0.3766 - 358ms/epoch - 72ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.1944 - accuracy: 0.5049 - val_loss: 1.1848 - val_accuracy: 0.4026 - 359ms/epoch - 72ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1765 - accuracy: 0.5016 - val_loss: 1.1827 - val_accuracy: 0.3766 - 354ms/epoch - 71ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1722 - accuracy: 0.4984 - val_loss: 1.1744 - val_accuracy: 0.3766 - 359ms/epoch - 72ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1489 - accuracy: 0.5049 - val_loss: 1.1717 - val_accuracy: 0.3896 - 356ms/epoch - 71ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1497 - accuracy: 0.5246 - val_loss: 1.1585 - val_accuracy: 0.3896 - 347ms/epoch - 69ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1167 - accuracy: 0.5279 - val_loss: 1.1502 - val_accuracy: 0.3896 - 362ms/epoch - 72ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1483 - accuracy: 0.5213 - val_loss: 1.1462 - val_accuracy: 0.4026 - 357ms/epoch - 71ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1216 - accuracy: 0.5082 - val_loss: 1.1254 - val_accuracy: 0.4026 - 355ms/epoch - 71ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1171 - accuracy: 0.5344 - val_loss: 1.1159 - val_accuracy: 0.4286 - 360ms/epoch - 72ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1439 - accuracy: 0.5180 - val_loss: 1.1147 - val_accuracy: 0.4416 - 346ms/epoch - 69ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1252 - accuracy: 0.5475 - val_loss: 1.1118 - val_accuracy: 0.4675 - 351ms/epoch - 70ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.1089 - accuracy: 0.5344 - val_loss: 1.0995 - val_accuracy: 0.4675 - 359ms/epoch - 72ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1117 - accuracy: 0.5639 - val_loss: 1.0987 - val_accuracy: 0.4675 - 353ms/epoch - 71ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0875 - accuracy: 0.5279 - val_loss: 1.0861 - val_accuracy: 0.4675 - 350ms/epoch - 70ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.1222 - accuracy: 0.5475 - val_loss: 1.0909 - val_accuracy: 0.4935 - 386ms/epoch - 77ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0885 - accuracy: 0.5443 - val_loss: 1.0713 - val_accuracy: 0.4675 - 353ms/epoch - 71ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0701 - accuracy: 0.5639 - val_loss: 1.0651 - val_accuracy: 0.4675 - 398ms/epoch - 80ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0902 - accuracy: 0.5672 - val_loss: 1.0573 - val_accuracy: 0.4675 - 381ms/epoch - 76ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0588 - accuracy: 0.5508 - val_loss: 1.0491 - val_accuracy: 0.4805 - 391ms/epoch - 78ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0499 - accuracy: 0.5508 - val_loss: 1.0439 - val_accuracy: 0.4675 - 367ms/epoch - 73ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0546 - accuracy: 0.5705 - val_loss: 1.0468 - val_accuracy: 0.4805 - 378ms/epoch - 76ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0787 - accuracy: 0.5475 - val_loss: 1.0374 - val_accuracy: 0.4935 - 377ms/epoch - 75ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0472 - accuracy: 0.5803 - val_loss: 1.0324 - val_accuracy: 0.4935 - 343ms/epoch - 69ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0384 - accuracy: 0.5639 - val_loss: 1.0184 - val_accuracy: 0.4935 - 354ms/epoch - 71ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0468 - accuracy: 0.6033 - val_loss: 1.0004 - val_accuracy: 0.5065 - 355ms/epoch - 71ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0318 - accuracy: 0.5836 - val_loss: 1.0058 - val_accuracy: 0.5195 - 355ms/epoch - 71ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0179 - accuracy: 0.5836 - val_loss: 0.9762 - val_accuracy: 0.5065 - 355ms/epoch - 71ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0158 - accuracy: 0.5869 - val_loss: 0.9763 - val_accuracy: 0.5065 - 357ms/epoch - 71ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 1.0083 - accuracy: 0.5738 - val_loss: 0.9554 - val_accuracy: 0.5844 - 368ms/epoch - 74ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 1.0216 - accuracy: 0.5705 - val_loss: 0.9551 - val_accuracy: 0.5455 - 369ms/epoch - 74ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 1.0088 - accuracy: 0.5639 - val_loss: 0.9581 - val_accuracy: 0.5195 - 407ms/epoch - 81ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 0.9835 - accuracy: 0.6098 - val_loss: 0.9408 - val_accuracy: 0.5195 - 449ms/epoch - 90ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.9785 - accuracy: 0.6164 - val_loss: 0.9197 - val_accuracy: 0.5844 - 441ms/epoch - 88ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 0.9809 - accuracy: 0.6164 - val_loss: 0.9210 - val_accuracy: 0.5325 - 423ms/epoch - 85ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9559 - accuracy: 0.6131 - val_loss: 0.9345 - val_accuracy: 0.5455 - 401ms/epoch - 80ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 0.9837 - accuracy: 0.6033 - val_loss: 0.9195 - val_accuracy: 0.5714 - 397ms/epoch - 79ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9453 - accuracy: 0.6066 - val_loss: 0.9172 - val_accuracy: 0.5584 - 493ms/epoch - 99ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.9510 - accuracy: 0.6098 - val_loss: 0.8917 - val_accuracy: 0.5974 - 396ms/epoch - 79ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.9561 - accuracy: 0.6328 - val_loss: 0.8892 - val_accuracy: 0.5714 - 376ms/epoch - 75ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.9384 - accuracy: 0.6131 - val_loss: 0.8880 - val_accuracy: 0.5844 - 363ms/epoch - 73ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.9869 - accuracy: 0.5836 - val_loss: 0.9298 - val_accuracy: 0.5455 - 386ms/epoch - 77ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9765 - accuracy: 0.6361 - val_loss: 0.9099 - val_accuracy: 0.5844 - 350ms/epoch - 70ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9661 - accuracy: 0.6262 - val_loss: 0.9060 - val_accuracy: 0.5455 - 402ms/epoch - 80ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9475 - accuracy: 0.6197 - val_loss: 0.8982 - val_accuracy: 0.5455 - 390ms/epoch - 78ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9473 - accuracy: 0.6328 - val_loss: 0.8902 - val_accuracy: 0.5844 - 365ms/epoch - 73ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8876 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:59:06,140] Trial 93 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 156}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 5s - loss: 1.3852 - accuracy: 0.3246 - val_loss: 1.3847 - val_accuracy: 0.3896 - 5s/epoch - 967ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3828 - accuracy: 0.3705 - val_loss: 1.3823 - val_accuracy: 0.3247 - 363ms/epoch - 73ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3775 - accuracy: 0.3836 - val_loss: 1.3781 - val_accuracy: 0.4156 - 374ms/epoch - 75ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3711 - accuracy: 0.4361 - val_loss: 1.3720 - val_accuracy: 0.4675 - 389ms/epoch - 78ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3545 - accuracy: 0.4721 - val_loss: 1.3622 - val_accuracy: 0.4805 - 364ms/epoch - 73ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3414 - accuracy: 0.4262 - val_loss: 1.3525 - val_accuracy: 0.4675 - 350ms/epoch - 70ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3355 - accuracy: 0.4197 - val_loss: 1.3325 - val_accuracy: 0.3636 - 359ms/epoch - 72ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.2941 - accuracy: 0.4525 - val_loss: 1.2959 - val_accuracy: 0.3636 - 352ms/epoch - 70ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.2804 - accuracy: 0.4361 - val_loss: 1.2598 - val_accuracy: 0.3636 - 364ms/epoch - 73ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.2607 - accuracy: 0.4689 - val_loss: 1.2441 - val_accuracy: 0.3766 - 329ms/epoch - 66ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.2264 - accuracy: 0.4754 - val_loss: 1.2324 - val_accuracy: 0.3766 - 302ms/epoch - 60ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.2305 - accuracy: 0.4820 - val_loss: 1.2094 - val_accuracy: 0.4026 - 303ms/epoch - 61ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.2270 - accuracy: 0.4721 - val_loss: 1.2037 - val_accuracy: 0.4026 - 309ms/epoch - 62ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.1790 - accuracy: 0.5049 - val_loss: 1.1995 - val_accuracy: 0.4026 - 302ms/epoch - 60ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1785 - accuracy: 0.4951 - val_loss: 1.1917 - val_accuracy: 0.3896 - 299ms/epoch - 60ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1811 - accuracy: 0.4984 - val_loss: 1.1805 - val_accuracy: 0.3896 - 273ms/epoch - 55ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1549 - accuracy: 0.5246 - val_loss: 1.1654 - val_accuracy: 0.4156 - 285ms/epoch - 57ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1457 - accuracy: 0.5180 - val_loss: 1.1503 - val_accuracy: 0.4156 - 281ms/epoch - 56ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1436 - accuracy: 0.5082 - val_loss: 1.1461 - val_accuracy: 0.4156 - 278ms/epoch - 56ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1403 - accuracy: 0.5377 - val_loss: 1.1341 - val_accuracy: 0.4156 - 275ms/epoch - 55ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1170 - accuracy: 0.5377 - val_loss: 1.1242 - val_accuracy: 0.4416 - 293ms/epoch - 59ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1005 - accuracy: 0.5279 - val_loss: 1.1211 - val_accuracy: 0.4286 - 320ms/epoch - 64ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1500 - accuracy: 0.5049 - val_loss: 1.1087 - val_accuracy: 0.4675 - 317ms/epoch - 63ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.0929 - accuracy: 0.5344 - val_loss: 1.1007 - val_accuracy: 0.4675 - 293ms/epoch - 59ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1044 - accuracy: 0.5377 - val_loss: 1.1002 - val_accuracy: 0.4286 - 286ms/epoch - 57ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0684 - accuracy: 0.5148 - val_loss: 1.0807 - val_accuracy: 0.4545 - 285ms/epoch - 57ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.0960 - accuracy: 0.5115 - val_loss: 1.0686 - val_accuracy: 0.4935 - 310ms/epoch - 62ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.0734 - accuracy: 0.5311 - val_loss: 1.0592 - val_accuracy: 0.4935 - 282ms/epoch - 56ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.0955 - accuracy: 0.5508 - val_loss: 1.0525 - val_accuracy: 0.4935 - 299ms/epoch - 60ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0474 - accuracy: 0.5607 - val_loss: 1.0494 - val_accuracy: 0.4935 - 290ms/epoch - 58ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.0933 - accuracy: 0.5803 - val_loss: 1.0459 - val_accuracy: 0.4935 - 284ms/epoch - 57ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0818 - accuracy: 0.5475 - val_loss: 1.0424 - val_accuracy: 0.4935 - 299ms/epoch - 60ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.1003 - accuracy: 0.5869 - val_loss: 1.0418 - val_accuracy: 0.4935 - 287ms/epoch - 57ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0522 - accuracy: 0.5410 - val_loss: 1.0299 - val_accuracy: 0.5195 - 289ms/epoch - 58ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0381 - accuracy: 0.5607 - val_loss: 1.0173 - val_accuracy: 0.5325 - 292ms/epoch - 58ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0505 - accuracy: 0.5934 - val_loss: 1.0077 - val_accuracy: 0.5065 - 284ms/epoch - 57ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0300 - accuracy: 0.5836 - val_loss: 1.0025 - val_accuracy: 0.5195 - 305ms/epoch - 61ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0195 - accuracy: 0.5705 - val_loss: 1.0023 - val_accuracy: 0.5195 - 278ms/epoch - 56ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0330 - accuracy: 0.5705 - val_loss: 0.9854 - val_accuracy: 0.5584 - 284ms/epoch - 57ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 0.9955 - accuracy: 0.5607 - val_loss: 0.9682 - val_accuracy: 0.5195 - 273ms/epoch - 55ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 1.0342 - accuracy: 0.5770 - val_loss: 0.9636 - val_accuracy: 0.5844 - 283ms/epoch - 57ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 1.0206 - accuracy: 0.6000 - val_loss: 0.9764 - val_accuracy: 0.5455 - 283ms/epoch - 57ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 0.9819 - accuracy: 0.6066 - val_loss: 0.9471 - val_accuracy: 0.5455 - 283ms/epoch - 57ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 1.0106 - accuracy: 0.5672 - val_loss: 0.9351 - val_accuracy: 0.5455 - 271ms/epoch - 54ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 0.9969 - accuracy: 0.5869 - val_loss: 0.9419 - val_accuracy: 0.5455 - 285ms/epoch - 57ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 1.0020 - accuracy: 0.6197 - val_loss: 0.9377 - val_accuracy: 0.5455 - 287ms/epoch - 57ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 0.9839 - accuracy: 0.6033 - val_loss: 0.9390 - val_accuracy: 0.5584 - 286ms/epoch - 57ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 0.9720 - accuracy: 0.5869 - val_loss: 0.9218 - val_accuracy: 0.5455 - 292ms/epoch - 58ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9999 - accuracy: 0.6000 - val_loss: 0.9142 - val_accuracy: 0.5455 - 313ms/epoch - 63ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.9636 - accuracy: 0.6164 - val_loss: 0.9092 - val_accuracy: 0.5584 - 300ms/epoch - 60ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.9826 - accuracy: 0.6197 - val_loss: 0.9102 - val_accuracy: 0.5584 - 318ms/epoch - 64ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.9532 - accuracy: 0.6328 - val_loss: 0.9054 - val_accuracy: 0.5714 - 307ms/epoch - 61ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.9829 - accuracy: 0.6328 - val_loss: 0.9044 - val_accuracy: 0.5455 - 292ms/epoch - 58ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 0.9499 - accuracy: 0.6098 - val_loss: 0.9140 - val_accuracy: 0.5584 - 282ms/epoch - 56ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9744 - accuracy: 0.6197 - val_loss: 0.8898 - val_accuracy: 0.5714 - 284ms/epoch - 57ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9728 - accuracy: 0.6131 - val_loss: 0.8875 - val_accuracy: 0.5584 - 281ms/epoch - 56ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9577 - accuracy: 0.6098 - val_loss: 0.9063 - val_accuracy: 0.5584 - 279ms/epoch - 56ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.9152 - accuracy: 0.6230 - val_loss: 0.9053 - val_accuracy: 0.5455 - 274ms/epoch - 55ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.9602 - accuracy: 0.6098 - val_loss: 0.8975 - val_accuracy: 0.5714 - 279ms/epoch - 56ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.9478 - accuracy: 0.5967 - val_loss: 0.9084 - val_accuracy: 0.5455 - 286ms/epoch - 57ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.9150 - accuracy: 0.6328 - val_loss: 0.8782 - val_accuracy: 0.6623 - 271ms/epoch - 54ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.9069 - accuracy: 0.6361 - val_loss: 0.8726 - val_accuracy: 0.6364 - 276ms/epoch - 55ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.9179 - accuracy: 0.6459 - val_loss: 0.8658 - val_accuracy: 0.6364 - 284ms/epoch - 57ms/step\n",
      "Epoch 64/10000\n",
      "5/5 - 0s - loss: 0.9316 - accuracy: 0.6197 - val_loss: 0.8659 - val_accuracy: 0.6234 - 272ms/epoch - 54ms/step\n",
      "Epoch 65/10000\n",
      "5/5 - 0s - loss: 0.9484 - accuracy: 0.6164 - val_loss: 0.8935 - val_accuracy: 0.5455 - 290ms/epoch - 58ms/step\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 0.9298 - accuracy: 0.6459 - val_loss: 0.8800 - val_accuracy: 0.6364 - 275ms/epoch - 55ms/step\n",
      "Epoch 67/10000\n",
      "5/5 - 0s - loss: 0.9298 - accuracy: 0.6426 - val_loss: 0.8729 - val_accuracy: 0.6494 - 284ms/epoch - 57ms/step\n",
      "Epoch 68/10000\n",
      "5/5 - 0s - loss: 0.8841 - accuracy: 0.6623 - val_loss: 0.8633 - val_accuracy: 0.6494 - 282ms/epoch - 56ms/step\n",
      "Epoch 69/10000\n",
      "5/5 - 0s - loss: 0.8898 - accuracy: 0.6492 - val_loss: 0.8541 - val_accuracy: 0.6494 - 281ms/epoch - 56ms/step\n",
      "Epoch 70/10000\n",
      "5/5 - 0s - loss: 0.9011 - accuracy: 0.6426 - val_loss: 0.8617 - val_accuracy: 0.6364 - 293ms/epoch - 59ms/step\n",
      "Epoch 71/10000\n",
      "5/5 - 0s - loss: 0.9252 - accuracy: 0.6328 - val_loss: 0.8600 - val_accuracy: 0.6364 - 280ms/epoch - 56ms/step\n",
      "Epoch 72/10000\n",
      "5/5 - 0s - loss: 0.9363 - accuracy: 0.6525 - val_loss: 0.8733 - val_accuracy: 0.6104 - 286ms/epoch - 57ms/step\n",
      "Epoch 73/10000\n",
      "5/5 - 0s - loss: 0.9592 - accuracy: 0.6230 - val_loss: 0.8881 - val_accuracy: 0.5584 - 290ms/epoch - 58ms/step\n",
      "Epoch 74/10000\n",
      "5/5 - 0s - loss: 0.9348 - accuracy: 0.6426 - val_loss: 0.8709 - val_accuracy: 0.6234 - 287ms/epoch - 57ms/step\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8990 - accuracy: 0.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 10:59:34,619] Trial 94 finished with value: 0.6470588445663452 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 143}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 - 4s - loss: 1.3861 - accuracy: 0.2918 - val_loss: 1.3850 - val_accuracy: 0.2987 - 4s/epoch - 861ms/step\n",
      "Epoch 2/10000\n",
      "5/5 - 0s - loss: 1.3855 - accuracy: 0.2885 - val_loss: 1.3836 - val_accuracy: 0.2857 - 319ms/epoch - 64ms/step\n",
      "Epoch 3/10000\n",
      "5/5 - 0s - loss: 1.3845 - accuracy: 0.2689 - val_loss: 1.3821 - val_accuracy: 0.3377 - 338ms/epoch - 68ms/step\n",
      "Epoch 4/10000\n",
      "5/5 - 0s - loss: 1.3836 - accuracy: 0.3115 - val_loss: 1.3803 - val_accuracy: 0.3377 - 338ms/epoch - 68ms/step\n",
      "Epoch 5/10000\n",
      "5/5 - 0s - loss: 1.3815 - accuracy: 0.3639 - val_loss: 1.3774 - val_accuracy: 0.4026 - 336ms/epoch - 67ms/step\n",
      "Epoch 6/10000\n",
      "5/5 - 0s - loss: 1.3796 - accuracy: 0.3279 - val_loss: 1.3734 - val_accuracy: 0.4026 - 332ms/epoch - 66ms/step\n",
      "Epoch 7/10000\n",
      "5/5 - 0s - loss: 1.3747 - accuracy: 0.3377 - val_loss: 1.3685 - val_accuracy: 0.3247 - 344ms/epoch - 69ms/step\n",
      "Epoch 8/10000\n",
      "5/5 - 0s - loss: 1.3676 - accuracy: 0.3836 - val_loss: 1.3600 - val_accuracy: 0.3766 - 341ms/epoch - 68ms/step\n",
      "Epoch 9/10000\n",
      "5/5 - 0s - loss: 1.3539 - accuracy: 0.4623 - val_loss: 1.3448 - val_accuracy: 0.4156 - 360ms/epoch - 72ms/step\n",
      "Epoch 10/10000\n",
      "5/5 - 0s - loss: 1.3345 - accuracy: 0.4426 - val_loss: 1.3230 - val_accuracy: 0.4545 - 361ms/epoch - 72ms/step\n",
      "Epoch 11/10000\n",
      "5/5 - 0s - loss: 1.3015 - accuracy: 0.5115 - val_loss: 1.2954 - val_accuracy: 0.4416 - 360ms/epoch - 72ms/step\n",
      "Epoch 12/10000\n",
      "5/5 - 0s - loss: 1.2617 - accuracy: 0.5213 - val_loss: 1.2584 - val_accuracy: 0.3896 - 374ms/epoch - 75ms/step\n",
      "Epoch 13/10000\n",
      "5/5 - 0s - loss: 1.2515 - accuracy: 0.4557 - val_loss: 1.2232 - val_accuracy: 0.3766 - 348ms/epoch - 70ms/step\n",
      "Epoch 14/10000\n",
      "5/5 - 0s - loss: 1.2248 - accuracy: 0.4918 - val_loss: 1.1953 - val_accuracy: 0.3766 - 337ms/epoch - 67ms/step\n",
      "Epoch 15/10000\n",
      "5/5 - 0s - loss: 1.1885 - accuracy: 0.4689 - val_loss: 1.1815 - val_accuracy: 0.3766 - 333ms/epoch - 67ms/step\n",
      "Epoch 16/10000\n",
      "5/5 - 0s - loss: 1.1879 - accuracy: 0.4951 - val_loss: 1.1729 - val_accuracy: 0.3896 - 339ms/epoch - 68ms/step\n",
      "Epoch 17/10000\n",
      "5/5 - 0s - loss: 1.1822 - accuracy: 0.4656 - val_loss: 1.1819 - val_accuracy: 0.3896 - 332ms/epoch - 66ms/step\n",
      "Epoch 18/10000\n",
      "5/5 - 0s - loss: 1.1701 - accuracy: 0.4852 - val_loss: 1.1683 - val_accuracy: 0.3766 - 342ms/epoch - 68ms/step\n",
      "Epoch 19/10000\n",
      "5/5 - 0s - loss: 1.1601 - accuracy: 0.4918 - val_loss: 1.1633 - val_accuracy: 0.3636 - 343ms/epoch - 69ms/step\n",
      "Epoch 20/10000\n",
      "5/5 - 0s - loss: 1.1603 - accuracy: 0.4885 - val_loss: 1.1619 - val_accuracy: 0.3766 - 338ms/epoch - 68ms/step\n",
      "Epoch 21/10000\n",
      "5/5 - 0s - loss: 1.1271 - accuracy: 0.5148 - val_loss: 1.1561 - val_accuracy: 0.3766 - 335ms/epoch - 67ms/step\n",
      "Epoch 22/10000\n",
      "5/5 - 0s - loss: 1.1372 - accuracy: 0.4918 - val_loss: 1.1419 - val_accuracy: 0.3766 - 330ms/epoch - 66ms/step\n",
      "Epoch 23/10000\n",
      "5/5 - 0s - loss: 1.1500 - accuracy: 0.4885 - val_loss: 1.1337 - val_accuracy: 0.3766 - 336ms/epoch - 67ms/step\n",
      "Epoch 24/10000\n",
      "5/5 - 0s - loss: 1.1596 - accuracy: 0.4787 - val_loss: 1.1281 - val_accuracy: 0.4026 - 347ms/epoch - 69ms/step\n",
      "Epoch 25/10000\n",
      "5/5 - 0s - loss: 1.1166 - accuracy: 0.4787 - val_loss: 1.1243 - val_accuracy: 0.3896 - 334ms/epoch - 67ms/step\n",
      "Epoch 26/10000\n",
      "5/5 - 0s - loss: 1.0990 - accuracy: 0.5344 - val_loss: 1.1158 - val_accuracy: 0.4026 - 341ms/epoch - 68ms/step\n",
      "Epoch 27/10000\n",
      "5/5 - 0s - loss: 1.1068 - accuracy: 0.5049 - val_loss: 1.1095 - val_accuracy: 0.4026 - 340ms/epoch - 68ms/step\n",
      "Epoch 28/10000\n",
      "5/5 - 0s - loss: 1.1245 - accuracy: 0.5279 - val_loss: 1.1025 - val_accuracy: 0.4156 - 347ms/epoch - 69ms/step\n",
      "Epoch 29/10000\n",
      "5/5 - 0s - loss: 1.1168 - accuracy: 0.5246 - val_loss: 1.0943 - val_accuracy: 0.4286 - 343ms/epoch - 69ms/step\n",
      "Epoch 30/10000\n",
      "5/5 - 0s - loss: 1.0866 - accuracy: 0.5410 - val_loss: 1.0897 - val_accuracy: 0.4545 - 343ms/epoch - 69ms/step\n",
      "Epoch 31/10000\n",
      "5/5 - 0s - loss: 1.1009 - accuracy: 0.5279 - val_loss: 1.0813 - val_accuracy: 0.4545 - 334ms/epoch - 67ms/step\n",
      "Epoch 32/10000\n",
      "5/5 - 0s - loss: 1.0837 - accuracy: 0.5115 - val_loss: 1.0763 - val_accuracy: 0.4416 - 340ms/epoch - 68ms/step\n",
      "Epoch 33/10000\n",
      "5/5 - 0s - loss: 1.0904 - accuracy: 0.5246 - val_loss: 1.0779 - val_accuracy: 0.4416 - 341ms/epoch - 68ms/step\n",
      "Epoch 34/10000\n",
      "5/5 - 0s - loss: 1.0827 - accuracy: 0.5574 - val_loss: 1.0749 - val_accuracy: 0.4675 - 345ms/epoch - 69ms/step\n",
      "Epoch 35/10000\n",
      "5/5 - 0s - loss: 1.0813 - accuracy: 0.5410 - val_loss: 1.0705 - val_accuracy: 0.4935 - 339ms/epoch - 68ms/step\n",
      "Epoch 36/10000\n",
      "5/5 - 0s - loss: 1.0760 - accuracy: 0.5443 - val_loss: 1.0612 - val_accuracy: 0.5065 - 358ms/epoch - 72ms/step\n",
      "Epoch 37/10000\n",
      "5/5 - 0s - loss: 1.0608 - accuracy: 0.5410 - val_loss: 1.0524 - val_accuracy: 0.4935 - 359ms/epoch - 72ms/step\n",
      "Epoch 38/10000\n",
      "5/5 - 0s - loss: 1.0568 - accuracy: 0.5344 - val_loss: 1.0473 - val_accuracy: 0.4935 - 345ms/epoch - 69ms/step\n",
      "Epoch 39/10000\n",
      "5/5 - 0s - loss: 1.0681 - accuracy: 0.5213 - val_loss: 1.0405 - val_accuracy: 0.4935 - 341ms/epoch - 68ms/step\n",
      "Epoch 40/10000\n",
      "5/5 - 0s - loss: 1.0451 - accuracy: 0.5738 - val_loss: 1.0255 - val_accuracy: 0.5195 - 341ms/epoch - 68ms/step\n",
      "Epoch 41/10000\n",
      "5/5 - 0s - loss: 1.0464 - accuracy: 0.5803 - val_loss: 1.0142 - val_accuracy: 0.5714 - 347ms/epoch - 69ms/step\n",
      "Epoch 42/10000\n",
      "5/5 - 0s - loss: 1.0346 - accuracy: 0.5738 - val_loss: 1.0138 - val_accuracy: 0.5065 - 365ms/epoch - 73ms/step\n",
      "Epoch 43/10000\n",
      "5/5 - 0s - loss: 1.0293 - accuracy: 0.5475 - val_loss: 0.9973 - val_accuracy: 0.5065 - 335ms/epoch - 67ms/step\n",
      "Epoch 44/10000\n",
      "5/5 - 0s - loss: 1.0432 - accuracy: 0.5607 - val_loss: 0.9792 - val_accuracy: 0.5325 - 333ms/epoch - 67ms/step\n",
      "Epoch 45/10000\n",
      "5/5 - 0s - loss: 1.0106 - accuracy: 0.5934 - val_loss: 0.9750 - val_accuracy: 0.5455 - 334ms/epoch - 67ms/step\n",
      "Epoch 46/10000\n",
      "5/5 - 0s - loss: 1.0247 - accuracy: 0.5836 - val_loss: 0.9717 - val_accuracy: 0.5195 - 352ms/epoch - 70ms/step\n",
      "Epoch 47/10000\n",
      "5/5 - 0s - loss: 1.0111 - accuracy: 0.5869 - val_loss: 0.9696 - val_accuracy: 0.5325 - 338ms/epoch - 68ms/step\n",
      "Epoch 48/10000\n",
      "5/5 - 0s - loss: 0.9892 - accuracy: 0.5705 - val_loss: 0.9578 - val_accuracy: 0.5325 - 349ms/epoch - 70ms/step\n",
      "Epoch 49/10000\n",
      "5/5 - 0s - loss: 0.9853 - accuracy: 0.5738 - val_loss: 0.9469 - val_accuracy: 0.5584 - 342ms/epoch - 68ms/step\n",
      "Epoch 50/10000\n",
      "5/5 - 0s - loss: 0.9875 - accuracy: 0.5934 - val_loss: 0.9361 - val_accuracy: 0.5584 - 334ms/epoch - 67ms/step\n",
      "Epoch 51/10000\n",
      "5/5 - 0s - loss: 0.9874 - accuracy: 0.6066 - val_loss: 0.9285 - val_accuracy: 0.5974 - 337ms/epoch - 67ms/step\n",
      "Epoch 52/10000\n",
      "5/5 - 0s - loss: 0.9689 - accuracy: 0.5902 - val_loss: 0.9187 - val_accuracy: 0.5455 - 344ms/epoch - 69ms/step\n",
      "Epoch 53/10000\n",
      "5/5 - 0s - loss: 0.9685 - accuracy: 0.6131 - val_loss: 0.9380 - val_accuracy: 0.5584 - 334ms/epoch - 67ms/step\n",
      "Epoch 54/10000\n",
      "5/5 - 0s - loss: 1.0183 - accuracy: 0.5705 - val_loss: 0.9247 - val_accuracy: 0.5714 - 339ms/epoch - 68ms/step\n",
      "Epoch 55/10000\n",
      "5/5 - 0s - loss: 0.9724 - accuracy: 0.6098 - val_loss: 0.9154 - val_accuracy: 0.5714 - 363ms/epoch - 73ms/step\n",
      "Epoch 56/10000\n",
      "5/5 - 0s - loss: 0.9866 - accuracy: 0.5836 - val_loss: 0.9119 - val_accuracy: 0.5714 - 361ms/epoch - 72ms/step\n",
      "Epoch 57/10000\n",
      "5/5 - 0s - loss: 0.9999 - accuracy: 0.5672 - val_loss: 0.9346 - val_accuracy: 0.5584 - 369ms/epoch - 74ms/step\n",
      "Epoch 58/10000\n",
      "5/5 - 0s - loss: 0.9781 - accuracy: 0.6262 - val_loss: 0.9232 - val_accuracy: 0.5584 - 374ms/epoch - 75ms/step\n",
      "Epoch 59/10000\n",
      "5/5 - 0s - loss: 0.9312 - accuracy: 0.6164 - val_loss: 0.9176 - val_accuracy: 0.5455 - 360ms/epoch - 72ms/step\n",
      "Epoch 60/10000\n",
      "5/5 - 0s - loss: 0.9850 - accuracy: 0.5934 - val_loss: 0.9319 - val_accuracy: 0.5714 - 349ms/epoch - 70ms/step\n",
      "Epoch 61/10000\n",
      "5/5 - 0s - loss: 0.9463 - accuracy: 0.6098 - val_loss: 0.9089 - val_accuracy: 0.5714 - 347ms/epoch - 69ms/step\n",
      "Epoch 62/10000\n",
      "5/5 - 0s - loss: 0.9411 - accuracy: 0.6131 - val_loss: 0.9012 - val_accuracy: 0.5974 - 339ms/epoch - 68ms/step\n",
      "Epoch 63/10000\n",
      "5/5 - 0s - loss: 0.9627 - accuracy: 0.6328 - val_loss: 0.9114 - val_accuracy: 0.5844 - 339ms/epoch - 68ms/step\n",
      "Epoch 64/10000\n",
      "5/5 - 0s - loss: 0.9588 - accuracy: 0.6000 - val_loss: 0.9058 - val_accuracy: 0.6234 - 345ms/epoch - 69ms/step\n",
      "Epoch 65/10000\n",
      "5/5 - 0s - loss: 0.9904 - accuracy: 0.6393 - val_loss: 0.9123 - val_accuracy: 0.5844 - 353ms/epoch - 71ms/step\n",
      "Epoch 66/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 0.9466 - accuracy: 0.6131 - val_loss: 0.9110 - val_accuracy: 0.5844 - 354ms/epoch - 71ms/step\n",
      "Epoch 67/10000\n",
      "5/5 - 0s - loss: 0.9451 - accuracy: 0.6525 - val_loss: 0.8951 - val_accuracy: 0.6234 - 335ms/epoch - 67ms/step\n",
      "Epoch 68/10000\n",
      "5/5 - 0s - loss: 0.9285 - accuracy: 0.6230 - val_loss: 0.8894 - val_accuracy: 0.5844 - 347ms/epoch - 69ms/step\n",
      "Epoch 69/10000\n",
      "5/5 - 0s - loss: 0.9104 - accuracy: 0.6262 - val_loss: 0.8801 - val_accuracy: 0.6234 - 338ms/epoch - 68ms/step\n",
      "Epoch 70/10000\n",
      "5/5 - 0s - loss: 0.9249 - accuracy: 0.6426 - val_loss: 0.8695 - val_accuracy: 0.6364 - 340ms/epoch - 68ms/step\n",
      "Epoch 71/10000\n",
      "5/5 - 0s - loss: 0.9233 - accuracy: 0.6525 - val_loss: 0.8658 - val_accuracy: 0.6364 - 333ms/epoch - 67ms/step\n",
      "Epoch 72/10000\n",
      "5/5 - 0s - loss: 0.9464 - accuracy: 0.6197 - val_loss: 0.8827 - val_accuracy: 0.5844 - 349ms/epoch - 70ms/step\n",
      "Epoch 73/10000\n",
      "5/5 - 0s - loss: 0.9039 - accuracy: 0.6393 - val_loss: 0.8863 - val_accuracy: 0.5844 - 343ms/epoch - 69ms/step\n",
      "Epoch 74/10000\n",
      "5/5 - 0s - loss: 0.8976 - accuracy: 0.6393 - val_loss: 0.8759 - val_accuracy: 0.6104 - 336ms/epoch - 67ms/step\n",
      "Epoch 75/10000\n",
      "5/5 - 0s - loss: 0.9147 - accuracy: 0.6459 - val_loss: 0.8730 - val_accuracy: 0.6494 - 339ms/epoch - 68ms/step\n",
      "Epoch 76/10000\n",
      "5/5 - 0s - loss: 0.9010 - accuracy: 0.6754 - val_loss: 0.8783 - val_accuracy: 0.6104 - 338ms/epoch - 68ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8722 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 11:00:06,398] Trial 95 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 64, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 157}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 4s - loss: 1.3830 - accuracy: 0.2623 - val_loss: 1.3776 - val_accuracy: 0.4026 - 4s/epoch - 596ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3690 - accuracy: 0.4197 - val_loss: 1.3630 - val_accuracy: 0.3636 - 312ms/epoch - 45ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3500 - accuracy: 0.4361 - val_loss: 1.3400 - val_accuracy: 0.3766 - 320ms/epoch - 46ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3031 - accuracy: 0.4590 - val_loss: 1.2997 - val_accuracy: 0.3766 - 322ms/epoch - 46ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.2661 - accuracy: 0.4557 - val_loss: 1.2652 - val_accuracy: 0.3506 - 327ms/epoch - 47ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.2174 - accuracy: 0.4754 - val_loss: 1.2163 - val_accuracy: 0.3896 - 323ms/epoch - 46ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.1647 - accuracy: 0.4721 - val_loss: 1.1859 - val_accuracy: 0.3506 - 321ms/epoch - 46ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.2065 - accuracy: 0.4951 - val_loss: 1.1860 - val_accuracy: 0.3896 - 329ms/epoch - 47ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.1770 - accuracy: 0.4721 - val_loss: 1.1724 - val_accuracy: 0.4026 - 321ms/epoch - 46ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.1785 - accuracy: 0.4885 - val_loss: 1.1537 - val_accuracy: 0.4156 - 332ms/epoch - 47ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.1372 - accuracy: 0.5213 - val_loss: 1.1599 - val_accuracy: 0.4156 - 348ms/epoch - 50ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.1338 - accuracy: 0.5148 - val_loss: 1.1688 - val_accuracy: 0.4286 - 345ms/epoch - 49ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.1352 - accuracy: 0.5082 - val_loss: 1.1495 - val_accuracy: 0.4286 - 342ms/epoch - 49ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.1300 - accuracy: 0.5016 - val_loss: 1.1369 - val_accuracy: 0.4156 - 346ms/epoch - 49ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.1322 - accuracy: 0.5115 - val_loss: 1.1340 - val_accuracy: 0.4416 - 342ms/epoch - 49ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.1379 - accuracy: 0.5246 - val_loss: 1.1353 - val_accuracy: 0.4675 - 331ms/epoch - 47ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.1249 - accuracy: 0.4984 - val_loss: 1.1263 - val_accuracy: 0.4805 - 336ms/epoch - 48ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1222 - accuracy: 0.5344 - val_loss: 1.1230 - val_accuracy: 0.4675 - 338ms/epoch - 48ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1134 - accuracy: 0.5508 - val_loss: 1.1026 - val_accuracy: 0.4286 - 320ms/epoch - 46ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1158 - accuracy: 0.5311 - val_loss: 1.0880 - val_accuracy: 0.4935 - 331ms/epoch - 47ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1029 - accuracy: 0.5311 - val_loss: 1.0655 - val_accuracy: 0.4935 - 332ms/epoch - 47ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.0830 - accuracy: 0.5574 - val_loss: 1.0756 - val_accuracy: 0.5065 - 324ms/epoch - 46ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.0954 - accuracy: 0.5541 - val_loss: 1.0652 - val_accuracy: 0.4675 - 324ms/epoch - 46ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.0682 - accuracy: 0.5377 - val_loss: 1.0679 - val_accuracy: 0.4545 - 328ms/epoch - 47ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.0889 - accuracy: 0.5574 - val_loss: 1.0600 - val_accuracy: 0.4675 - 330ms/epoch - 47ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.0695 - accuracy: 0.5475 - val_loss: 1.0514 - val_accuracy: 0.5455 - 332ms/epoch - 47ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.0771 - accuracy: 0.5279 - val_loss: 1.0634 - val_accuracy: 0.5325 - 330ms/epoch - 47ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.0609 - accuracy: 0.5738 - val_loss: 1.0354 - val_accuracy: 0.4675 - 325ms/epoch - 46ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.0580 - accuracy: 0.5508 - val_loss: 1.0312 - val_accuracy: 0.4935 - 338ms/epoch - 48ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.0787 - accuracy: 0.5475 - val_loss: 1.0475 - val_accuracy: 0.4675 - 322ms/epoch - 46ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.0425 - accuracy: 0.5639 - val_loss: 1.0264 - val_accuracy: 0.4805 - 323ms/epoch - 46ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.0304 - accuracy: 0.5443 - val_loss: 1.0376 - val_accuracy: 0.4805 - 332ms/epoch - 47ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0430 - accuracy: 0.5607 - val_loss: 1.0222 - val_accuracy: 0.4935 - 324ms/epoch - 46ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.0093 - accuracy: 0.5738 - val_loss: 0.9964 - val_accuracy: 0.5195 - 336ms/epoch - 48ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0038 - accuracy: 0.5803 - val_loss: 0.9765 - val_accuracy: 0.5584 - 334ms/epoch - 48ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.0313 - accuracy: 0.5803 - val_loss: 0.9577 - val_accuracy: 0.5974 - 327ms/epoch - 47ms/step\n",
      "Epoch 37/10000\n",
      "7/7 - 0s - loss: 0.9812 - accuracy: 0.6164 - val_loss: 0.9736 - val_accuracy: 0.6494 - 329ms/epoch - 47ms/step\n",
      "Epoch 38/10000\n",
      "7/7 - 0s - loss: 1.0048 - accuracy: 0.5836 - val_loss: 0.9740 - val_accuracy: 0.5455 - 326ms/epoch - 47ms/step\n",
      "Epoch 39/10000\n",
      "7/7 - 0s - loss: 1.0001 - accuracy: 0.6000 - val_loss: 0.9840 - val_accuracy: 0.5065 - 343ms/epoch - 49ms/step\n",
      "Epoch 40/10000\n",
      "7/7 - 0s - loss: 1.0028 - accuracy: 0.6164 - val_loss: 0.9464 - val_accuracy: 0.5325 - 341ms/epoch - 49ms/step\n",
      "Epoch 41/10000\n",
      "7/7 - 0s - loss: 0.9923 - accuracy: 0.5738 - val_loss: 0.9568 - val_accuracy: 0.6753 - 382ms/epoch - 55ms/step\n",
      "Epoch 42/10000\n",
      "7/7 - 0s - loss: 1.0123 - accuracy: 0.5902 - val_loss: 0.9127 - val_accuracy: 0.6364 - 367ms/epoch - 52ms/step\n",
      "Epoch 43/10000\n",
      "7/7 - 0s - loss: 0.9767 - accuracy: 0.5738 - val_loss: 0.9123 - val_accuracy: 0.5714 - 358ms/epoch - 51ms/step\n",
      "Epoch 44/10000\n",
      "7/7 - 0s - loss: 0.9950 - accuracy: 0.5803 - val_loss: 0.9094 - val_accuracy: 0.5974 - 344ms/epoch - 49ms/step\n",
      "Epoch 45/10000\n",
      "7/7 - 0s - loss: 0.9783 - accuracy: 0.6197 - val_loss: 0.9241 - val_accuracy: 0.5714 - 336ms/epoch - 48ms/step\n",
      "Epoch 46/10000\n",
      "7/7 - 0s - loss: 0.9605 - accuracy: 0.6164 - val_loss: 0.9554 - val_accuracy: 0.5325 - 347ms/epoch - 50ms/step\n",
      "Epoch 47/10000\n",
      "7/7 - 0s - loss: 0.9569 - accuracy: 0.6066 - val_loss: 0.9417 - val_accuracy: 0.5584 - 352ms/epoch - 50ms/step\n",
      "Epoch 48/10000\n",
      "7/7 - 0s - loss: 0.9433 - accuracy: 0.6164 - val_loss: 0.9237 - val_accuracy: 0.5974 - 346ms/epoch - 49ms/step\n",
      "Epoch 49/10000\n",
      "7/7 - 0s - loss: 0.9574 - accuracy: 0.6131 - val_loss: 0.8875 - val_accuracy: 0.6364 - 349ms/epoch - 50ms/step\n",
      "Epoch 50/10000\n",
      "7/7 - 0s - loss: 0.9255 - accuracy: 0.6262 - val_loss: 0.8760 - val_accuracy: 0.6364 - 354ms/epoch - 51ms/step\n",
      "Epoch 51/10000\n",
      "7/7 - 0s - loss: 0.9563 - accuracy: 0.6164 - val_loss: 0.8778 - val_accuracy: 0.6104 - 320ms/epoch - 46ms/step\n",
      "Epoch 52/10000\n",
      "7/7 - 0s - loss: 0.9751 - accuracy: 0.6131 - val_loss: 0.8812 - val_accuracy: 0.6104 - 368ms/epoch - 53ms/step\n",
      "Epoch 53/10000\n",
      "7/7 - 0s - loss: 0.9335 - accuracy: 0.6033 - val_loss: 0.9046 - val_accuracy: 0.5974 - 355ms/epoch - 51ms/step\n",
      "Epoch 54/10000\n",
      "7/7 - 0s - loss: 0.9264 - accuracy: 0.6393 - val_loss: 0.9082 - val_accuracy: 0.5974 - 330ms/epoch - 47ms/step\n",
      "Epoch 55/10000\n",
      "7/7 - 0s - loss: 0.9317 - accuracy: 0.6098 - val_loss: 0.9041 - val_accuracy: 0.5714 - 330ms/epoch - 47ms/step\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.8743 - accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 11:00:30,540] Trial 96 finished with value: 0.6764705777168274 and parameters: {'activation_func_1': 'relu', 'activation_func_2': 'linear', 'activation_func_3': 'selu', 'batch_size': 50, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 162}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 6s - loss: 1.3821 - accuracy: 0.2689 - val_loss: 1.3766 - val_accuracy: 0.3377 - 6s/epoch - 630ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3597 - accuracy: 0.4492 - val_loss: 1.3490 - val_accuracy: 0.4286 - 362ms/epoch - 36ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3099 - accuracy: 0.5082 - val_loss: 1.2852 - val_accuracy: 0.3896 - 371ms/epoch - 37ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2413 - accuracy: 0.4787 - val_loss: 1.2225 - val_accuracy: 0.3766 - 375ms/epoch - 37ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.1993 - accuracy: 0.4787 - val_loss: 1.1834 - val_accuracy: 0.4026 - 371ms/epoch - 37ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.1712 - accuracy: 0.5148 - val_loss: 1.1614 - val_accuracy: 0.3766 - 372ms/epoch - 37ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1593 - accuracy: 0.5082 - val_loss: 1.1474 - val_accuracy: 0.3896 - 368ms/epoch - 37ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1582 - accuracy: 0.5180 - val_loss: 1.1466 - val_accuracy: 0.4156 - 366ms/epoch - 37ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1437 - accuracy: 0.5180 - val_loss: 1.1295 - val_accuracy: 0.3896 - 370ms/epoch - 37ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1208 - accuracy: 0.5115 - val_loss: 1.1306 - val_accuracy: 0.4156 - 362ms/epoch - 36ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1325 - accuracy: 0.5246 - val_loss: 1.1360 - val_accuracy: 0.3766 - 396ms/epoch - 40ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1140 - accuracy: 0.5213 - val_loss: 1.1381 - val_accuracy: 0.4026 - 368ms/epoch - 37ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1108 - accuracy: 0.5410 - val_loss: 1.1298 - val_accuracy: 0.4026 - 368ms/epoch - 37ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.0969 - accuracy: 0.5574 - val_loss: 1.1036 - val_accuracy: 0.4286 - 368ms/epoch - 37ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1067 - accuracy: 0.5508 - val_loss: 1.0964 - val_accuracy: 0.4545 - 375ms/epoch - 38ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.0877 - accuracy: 0.5475 - val_loss: 1.0856 - val_accuracy: 0.4156 - 367ms/epoch - 37ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0807 - accuracy: 0.5475 - val_loss: 1.0896 - val_accuracy: 0.4675 - 368ms/epoch - 37ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0762 - accuracy: 0.5574 - val_loss: 1.0810 - val_accuracy: 0.4935 - 368ms/epoch - 37ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0725 - accuracy: 0.5705 - val_loss: 1.0863 - val_accuracy: 0.4805 - 367ms/epoch - 37ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0626 - accuracy: 0.5803 - val_loss: 1.0532 - val_accuracy: 0.5455 - 358ms/epoch - 36ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0426 - accuracy: 0.5738 - val_loss: 1.0408 - val_accuracy: 0.4675 - 370ms/epoch - 37ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0279 - accuracy: 0.5803 - val_loss: 1.0234 - val_accuracy: 0.4935 - 368ms/epoch - 37ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0245 - accuracy: 0.5967 - val_loss: 1.0251 - val_accuracy: 0.5195 - 375ms/epoch - 38ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0019 - accuracy: 0.5967 - val_loss: 0.9971 - val_accuracy: 0.5195 - 408ms/epoch - 41ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9947 - accuracy: 0.5869 - val_loss: 0.9816 - val_accuracy: 0.5325 - 398ms/epoch - 40ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9861 - accuracy: 0.6131 - val_loss: 0.9388 - val_accuracy: 0.6234 - 393ms/epoch - 39ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9600 - accuracy: 0.6361 - val_loss: 0.9383 - val_accuracy: 0.5195 - 397ms/epoch - 40ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9450 - accuracy: 0.6098 - val_loss: 0.9545 - val_accuracy: 0.5714 - 373ms/epoch - 37ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.9405 - accuracy: 0.6230 - val_loss: 0.9280 - val_accuracy: 0.5844 - 366ms/epoch - 37ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9305 - accuracy: 0.6459 - val_loss: 0.8838 - val_accuracy: 0.6364 - 376ms/epoch - 38ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9168 - accuracy: 0.6393 - val_loss: 0.9054 - val_accuracy: 0.5974 - 373ms/epoch - 37ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9033 - accuracy: 0.6328 - val_loss: 0.9001 - val_accuracy: 0.6104 - 365ms/epoch - 37ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.8957 - accuracy: 0.6131 - val_loss: 0.9160 - val_accuracy: 0.5844 - 390ms/epoch - 39ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9049 - accuracy: 0.6426 - val_loss: 0.9091 - val_accuracy: 0.6234 - 378ms/epoch - 38ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9029 - accuracy: 0.6393 - val_loss: 0.8914 - val_accuracy: 0.5974 - 359ms/epoch - 36ms/step\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9154 - accuracy: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 11:00:51,614] Trial 97 finished with value: 0.6323529481887817 and parameters: {'activation_func_1': 'tanh', 'activation_func_2': 'tanh', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.25, 'neurons': 149}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 4s - loss: 1.3854 - accuracy: 0.3311 - val_loss: 1.3839 - val_accuracy: 0.4026 - 4s/epoch - 410ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3810 - accuracy: 0.3770 - val_loss: 1.3784 - val_accuracy: 0.3247 - 370ms/epoch - 37ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3708 - accuracy: 0.4689 - val_loss: 1.3666 - val_accuracy: 0.4026 - 373ms/epoch - 37ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.3385 - accuracy: 0.5082 - val_loss: 1.3417 - val_accuracy: 0.4286 - 391ms/epoch - 39ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.3071 - accuracy: 0.4525 - val_loss: 1.2817 - val_accuracy: 0.3636 - 381ms/epoch - 38ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2959 - accuracy: 0.4656 - val_loss: 1.2477 - val_accuracy: 0.3506 - 408ms/epoch - 41ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.2445 - accuracy: 0.4820 - val_loss: 1.2204 - val_accuracy: 0.3636 - 379ms/epoch - 38ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.2184 - accuracy: 0.4885 - val_loss: 1.2059 - val_accuracy: 0.3636 - 388ms/epoch - 39ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.1927 - accuracy: 0.4689 - val_loss: 1.1912 - val_accuracy: 0.4156 - 388ms/epoch - 39ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1606 - accuracy: 0.4984 - val_loss: 1.1675 - val_accuracy: 0.3896 - 384ms/epoch - 38ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1858 - accuracy: 0.4951 - val_loss: 1.1738 - val_accuracy: 0.4026 - 391ms/epoch - 39ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1395 - accuracy: 0.5082 - val_loss: 1.1496 - val_accuracy: 0.4156 - 377ms/epoch - 38ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1530 - accuracy: 0.5311 - val_loss: 1.1356 - val_accuracy: 0.4156 - 381ms/epoch - 38ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1383 - accuracy: 0.5246 - val_loss: 1.1180 - val_accuracy: 0.4026 - 391ms/epoch - 39ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1517 - accuracy: 0.5377 - val_loss: 1.1230 - val_accuracy: 0.4286 - 385ms/epoch - 39ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1240 - accuracy: 0.5279 - val_loss: 1.1141 - val_accuracy: 0.4156 - 415ms/epoch - 42ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.1117 - accuracy: 0.5082 - val_loss: 1.0895 - val_accuracy: 0.4156 - 405ms/epoch - 40ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.1053 - accuracy: 0.5311 - val_loss: 1.0874 - val_accuracy: 0.4805 - 416ms/epoch - 42ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0940 - accuracy: 0.5410 - val_loss: 1.0981 - val_accuracy: 0.4675 - 405ms/epoch - 41ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0851 - accuracy: 0.5443 - val_loss: 1.0781 - val_accuracy: 0.5065 - 391ms/epoch - 39ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0980 - accuracy: 0.5705 - val_loss: 1.0812 - val_accuracy: 0.4805 - 386ms/epoch - 39ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0638 - accuracy: 0.5311 - val_loss: 1.0621 - val_accuracy: 0.4675 - 379ms/epoch - 38ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0683 - accuracy: 0.5443 - val_loss: 1.0581 - val_accuracy: 0.4805 - 391ms/epoch - 39ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0624 - accuracy: 0.5508 - val_loss: 1.0507 - val_accuracy: 0.4935 - 372ms/epoch - 37ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 1.0590 - accuracy: 0.5541 - val_loss: 1.0239 - val_accuracy: 0.5065 - 379ms/epoch - 38ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 1.0587 - accuracy: 0.5541 - val_loss: 0.9994 - val_accuracy: 0.5584 - 401ms/epoch - 40ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 1.0503 - accuracy: 0.5508 - val_loss: 1.0095 - val_accuracy: 0.5065 - 412ms/epoch - 41ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 1.0453 - accuracy: 0.5672 - val_loss: 1.0029 - val_accuracy: 0.5195 - 422ms/epoch - 42ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 1.0546 - accuracy: 0.6098 - val_loss: 0.9955 - val_accuracy: 0.5325 - 453ms/epoch - 45ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 1.0387 - accuracy: 0.5836 - val_loss: 0.9815 - val_accuracy: 0.5455 - 447ms/epoch - 45ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9726 - accuracy: 0.5869 - val_loss: 0.9638 - val_accuracy: 0.5325 - 436ms/epoch - 44ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9777 - accuracy: 0.5803 - val_loss: 0.9701 - val_accuracy: 0.5325 - 471ms/epoch - 47ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 1.0087 - accuracy: 0.5672 - val_loss: 0.9457 - val_accuracy: 0.5455 - 483ms/epoch - 48ms/step\n",
      "Epoch 34/10000\n",
      "10/10 - 0s - loss: 0.9857 - accuracy: 0.5869 - val_loss: 0.9222 - val_accuracy: 0.5844 - 440ms/epoch - 44ms/step\n",
      "Epoch 35/10000\n",
      "10/10 - 0s - loss: 0.9867 - accuracy: 0.6197 - val_loss: 0.9343 - val_accuracy: 0.5455 - 419ms/epoch - 42ms/step\n",
      "Epoch 36/10000\n",
      "10/10 - 0s - loss: 0.9839 - accuracy: 0.5967 - val_loss: 0.9224 - val_accuracy: 0.5974 - 451ms/epoch - 45ms/step\n",
      "Epoch 37/10000\n",
      "10/10 - 0s - loss: 0.9701 - accuracy: 0.6262 - val_loss: 0.9107 - val_accuracy: 0.5974 - 434ms/epoch - 43ms/step\n",
      "Epoch 38/10000\n",
      "10/10 - 0s - loss: 0.9652 - accuracy: 0.6197 - val_loss: 0.8993 - val_accuracy: 0.5584 - 428ms/epoch - 43ms/step\n",
      "Epoch 39/10000\n",
      "10/10 - 0s - loss: 0.9709 - accuracy: 0.6098 - val_loss: 0.8979 - val_accuracy: 0.5714 - 433ms/epoch - 43ms/step\n",
      "Epoch 40/10000\n",
      "10/10 - 0s - loss: 0.9594 - accuracy: 0.6131 - val_loss: 0.8982 - val_accuracy: 0.5974 - 432ms/epoch - 43ms/step\n",
      "Epoch 41/10000\n",
      "10/10 - 0s - loss: 0.9707 - accuracy: 0.6459 - val_loss: 0.8854 - val_accuracy: 0.6494 - 431ms/epoch - 43ms/step\n",
      "Epoch 42/10000\n",
      "10/10 - 0s - loss: 0.9624 - accuracy: 0.6164 - val_loss: 0.8775 - val_accuracy: 0.6364 - 407ms/epoch - 41ms/step\n",
      "Epoch 43/10000\n",
      "10/10 - 0s - loss: 0.9313 - accuracy: 0.6525 - val_loss: 0.8951 - val_accuracy: 0.5974 - 388ms/epoch - 39ms/step\n",
      "Epoch 44/10000\n",
      "10/10 - 0s - loss: 0.9282 - accuracy: 0.6262 - val_loss: 0.8803 - val_accuracy: 0.6364 - 376ms/epoch - 38ms/step\n",
      "Epoch 45/10000\n",
      "10/10 - 0s - loss: 0.9846 - accuracy: 0.6361 - val_loss: 0.8867 - val_accuracy: 0.6234 - 385ms/epoch - 38ms/step\n",
      "Epoch 46/10000\n",
      "10/10 - 0s - loss: 0.9454 - accuracy: 0.6459 - val_loss: 0.8741 - val_accuracy: 0.6234 - 393ms/epoch - 39ms/step\n",
      "Epoch 47/10000\n",
      "10/10 - 0s - loss: 0.9278 - accuracy: 0.6361 - val_loss: 0.8758 - val_accuracy: 0.6234 - 396ms/epoch - 40ms/step\n",
      "Epoch 48/10000\n",
      "10/10 - 0s - loss: 0.9619 - accuracy: 0.6623 - val_loss: 0.8939 - val_accuracy: 0.5844 - 382ms/epoch - 38ms/step\n",
      "Epoch 49/10000\n",
      "10/10 - 0s - loss: 0.9029 - accuracy: 0.6426 - val_loss: 0.8778 - val_accuracy: 0.6623 - 381ms/epoch - 38ms/step\n",
      "Epoch 50/10000\n",
      "10/10 - 0s - loss: 0.9397 - accuracy: 0.6098 - val_loss: 0.8826 - val_accuracy: 0.6364 - 399ms/epoch - 40ms/step\n",
      "Epoch 51/10000\n",
      "10/10 - 0s - loss: 0.9375 - accuracy: 0.6164 - val_loss: 0.8663 - val_accuracy: 0.6364 - 378ms/epoch - 38ms/step\n",
      "Epoch 52/10000\n",
      "10/10 - 0s - loss: 0.9432 - accuracy: 0.6393 - val_loss: 0.8687 - val_accuracy: 0.6234 - 382ms/epoch - 38ms/step\n",
      "Epoch 53/10000\n",
      "10/10 - 0s - loss: 0.9078 - accuracy: 0.6426 - val_loss: 0.8862 - val_accuracy: 0.6234 - 389ms/epoch - 39ms/step\n",
      "Epoch 54/10000\n",
      "10/10 - 0s - loss: 0.9243 - accuracy: 0.6492 - val_loss: 0.8615 - val_accuracy: 0.6234 - 374ms/epoch - 37ms/step\n",
      "Epoch 55/10000\n",
      "10/10 - 0s - loss: 0.9291 - accuracy: 0.6426 - val_loss: 0.8568 - val_accuracy: 0.6234 - 409ms/epoch - 41ms/step\n",
      "Epoch 56/10000\n",
      "10/10 - 0s - loss: 0.9347 - accuracy: 0.6557 - val_loss: 0.8740 - val_accuracy: 0.6104 - 406ms/epoch - 41ms/step\n",
      "Epoch 57/10000\n",
      "10/10 - 0s - loss: 0.9076 - accuracy: 0.6131 - val_loss: 0.8721 - val_accuracy: 0.6364 - 411ms/epoch - 41ms/step\n",
      "Epoch 58/10000\n",
      "10/10 - 0s - loss: 0.8762 - accuracy: 0.6525 - val_loss: 0.8696 - val_accuracy: 0.6364 - 405ms/epoch - 41ms/step\n",
      "Epoch 59/10000\n",
      "10/10 - 0s - loss: 0.8871 - accuracy: 0.6754 - val_loss: 0.8511 - val_accuracy: 0.6494 - 407ms/epoch - 41ms/step\n",
      "Epoch 60/10000\n",
      "10/10 - 0s - loss: 0.9261 - accuracy: 0.6295 - val_loss: 0.8781 - val_accuracy: 0.6234 - 379ms/epoch - 38ms/step\n",
      "Epoch 61/10000\n",
      "10/10 - 0s - loss: 0.9120 - accuracy: 0.6557 - val_loss: 0.8621 - val_accuracy: 0.6494 - 384ms/epoch - 38ms/step\n",
      "Epoch 62/10000\n",
      "10/10 - 0s - loss: 0.8623 - accuracy: 0.6525 - val_loss: 0.8915 - val_accuracy: 0.5714 - 388ms/epoch - 39ms/step\n",
      "Epoch 63/10000\n",
      "10/10 - 0s - loss: 0.9068 - accuracy: 0.6262 - val_loss: 0.8718 - val_accuracy: 0.6364 - 390ms/epoch - 39ms/step\n",
      "Epoch 64/10000\n",
      "10/10 - 0s - loss: 0.9288 - accuracy: 0.6459 - val_loss: 0.9050 - val_accuracy: 0.5844 - 383ms/epoch - 38ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 0.8534 - accuracy: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8870 - accuracy: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 11:01:22,891] Trial 98 finished with value: 0.6911764740943909 and parameters: {'activation_func_1': 'linear', 'activation_func_2': 'relu', 'activation_func_3': 'relu', 'batch_size': 32, 'dropout_1': 0.5, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 153}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "7/7 - 5s - loss: 1.3863 - accuracy: 0.2459 - val_loss: 1.3854 - val_accuracy: 0.2597 - 5s/epoch - 649ms/step\n",
      "Epoch 2/10000\n",
      "7/7 - 0s - loss: 1.3858 - accuracy: 0.2623 - val_loss: 1.3847 - val_accuracy: 0.2597 - 303ms/epoch - 43ms/step\n",
      "Epoch 3/10000\n",
      "7/7 - 0s - loss: 1.3855 - accuracy: 0.2656 - val_loss: 1.3839 - val_accuracy: 0.2597 - 310ms/epoch - 44ms/step\n",
      "Epoch 4/10000\n",
      "7/7 - 0s - loss: 1.3848 - accuracy: 0.2656 - val_loss: 1.3826 - val_accuracy: 0.2597 - 301ms/epoch - 43ms/step\n",
      "Epoch 5/10000\n",
      "7/7 - 0s - loss: 1.3840 - accuracy: 0.2656 - val_loss: 1.3818 - val_accuracy: 0.2597 - 303ms/epoch - 43ms/step\n",
      "Epoch 6/10000\n",
      "7/7 - 0s - loss: 1.3829 - accuracy: 0.2951 - val_loss: 1.3810 - val_accuracy: 0.3117 - 321ms/epoch - 46ms/step\n",
      "Epoch 7/10000\n",
      "7/7 - 0s - loss: 1.3821 - accuracy: 0.3279 - val_loss: 1.3799 - val_accuracy: 0.3506 - 325ms/epoch - 46ms/step\n",
      "Epoch 8/10000\n",
      "7/7 - 0s - loss: 1.3789 - accuracy: 0.3574 - val_loss: 1.3770 - val_accuracy: 0.3117 - 319ms/epoch - 46ms/step\n",
      "Epoch 9/10000\n",
      "7/7 - 0s - loss: 1.3732 - accuracy: 0.3836 - val_loss: 1.3708 - val_accuracy: 0.3117 - 313ms/epoch - 45ms/step\n",
      "Epoch 10/10000\n",
      "7/7 - 0s - loss: 1.3665 - accuracy: 0.4131 - val_loss: 1.3630 - val_accuracy: 0.3766 - 311ms/epoch - 44ms/step\n",
      "Epoch 11/10000\n",
      "7/7 - 0s - loss: 1.3480 - accuracy: 0.4689 - val_loss: 1.3469 - val_accuracy: 0.4026 - 337ms/epoch - 48ms/step\n",
      "Epoch 12/10000\n",
      "7/7 - 0s - loss: 1.3185 - accuracy: 0.4918 - val_loss: 1.3240 - val_accuracy: 0.4156 - 315ms/epoch - 45ms/step\n",
      "Epoch 13/10000\n",
      "7/7 - 0s - loss: 1.2738 - accuracy: 0.5049 - val_loss: 1.2965 - val_accuracy: 0.3766 - 305ms/epoch - 44ms/step\n",
      "Epoch 14/10000\n",
      "7/7 - 0s - loss: 1.2533 - accuracy: 0.4787 - val_loss: 1.2527 - val_accuracy: 0.3636 - 311ms/epoch - 44ms/step\n",
      "Epoch 15/10000\n",
      "7/7 - 0s - loss: 1.2273 - accuracy: 0.4754 - val_loss: 1.2325 - val_accuracy: 0.3636 - 305ms/epoch - 44ms/step\n",
      "Epoch 16/10000\n",
      "7/7 - 0s - loss: 1.2187 - accuracy: 0.4590 - val_loss: 1.2154 - val_accuracy: 0.3636 - 317ms/epoch - 45ms/step\n",
      "Epoch 17/10000\n",
      "7/7 - 0s - loss: 1.2028 - accuracy: 0.4623 - val_loss: 1.2051 - val_accuracy: 0.3766 - 304ms/epoch - 43ms/step\n",
      "Epoch 18/10000\n",
      "7/7 - 0s - loss: 1.1949 - accuracy: 0.4820 - val_loss: 1.2021 - val_accuracy: 0.3766 - 307ms/epoch - 44ms/step\n",
      "Epoch 19/10000\n",
      "7/7 - 0s - loss: 1.1787 - accuracy: 0.4984 - val_loss: 1.1847 - val_accuracy: 0.3636 - 309ms/epoch - 44ms/step\n",
      "Epoch 20/10000\n",
      "7/7 - 0s - loss: 1.1555 - accuracy: 0.5180 - val_loss: 1.1712 - val_accuracy: 0.4026 - 324ms/epoch - 46ms/step\n",
      "Epoch 21/10000\n",
      "7/7 - 0s - loss: 1.1756 - accuracy: 0.4852 - val_loss: 1.1600 - val_accuracy: 0.4026 - 330ms/epoch - 47ms/step\n",
      "Epoch 22/10000\n",
      "7/7 - 0s - loss: 1.1474 - accuracy: 0.5049 - val_loss: 1.1525 - val_accuracy: 0.3766 - 332ms/epoch - 47ms/step\n",
      "Epoch 23/10000\n",
      "7/7 - 0s - loss: 1.1532 - accuracy: 0.4885 - val_loss: 1.1607 - val_accuracy: 0.3896 - 319ms/epoch - 46ms/step\n",
      "Epoch 24/10000\n",
      "7/7 - 0s - loss: 1.1308 - accuracy: 0.5049 - val_loss: 1.1421 - val_accuracy: 0.4026 - 318ms/epoch - 45ms/step\n",
      "Epoch 25/10000\n",
      "7/7 - 0s - loss: 1.1381 - accuracy: 0.5115 - val_loss: 1.1351 - val_accuracy: 0.4156 - 325ms/epoch - 46ms/step\n",
      "Epoch 26/10000\n",
      "7/7 - 0s - loss: 1.1428 - accuracy: 0.4951 - val_loss: 1.1307 - val_accuracy: 0.4026 - 312ms/epoch - 45ms/step\n",
      "Epoch 27/10000\n",
      "7/7 - 0s - loss: 1.1350 - accuracy: 0.5049 - val_loss: 1.1251 - val_accuracy: 0.3896 - 298ms/epoch - 43ms/step\n",
      "Epoch 28/10000\n",
      "7/7 - 0s - loss: 1.1255 - accuracy: 0.4951 - val_loss: 1.1165 - val_accuracy: 0.4026 - 321ms/epoch - 46ms/step\n",
      "Epoch 29/10000\n",
      "7/7 - 0s - loss: 1.1059 - accuracy: 0.5115 - val_loss: 1.1144 - val_accuracy: 0.4416 - 319ms/epoch - 46ms/step\n",
      "Epoch 30/10000\n",
      "7/7 - 0s - loss: 1.1469 - accuracy: 0.4852 - val_loss: 1.1235 - val_accuracy: 0.4026 - 308ms/epoch - 44ms/step\n",
      "Epoch 31/10000\n",
      "7/7 - 0s - loss: 1.1017 - accuracy: 0.5049 - val_loss: 1.1105 - val_accuracy: 0.4026 - 302ms/epoch - 43ms/step\n",
      "Epoch 32/10000\n",
      "7/7 - 0s - loss: 1.1415 - accuracy: 0.5279 - val_loss: 1.1146 - val_accuracy: 0.4026 - 311ms/epoch - 44ms/step\n",
      "Epoch 33/10000\n",
      "7/7 - 0s - loss: 1.0955 - accuracy: 0.5082 - val_loss: 1.1154 - val_accuracy: 0.4286 - 308ms/epoch - 44ms/step\n",
      "Epoch 34/10000\n",
      "7/7 - 0s - loss: 1.1078 - accuracy: 0.4918 - val_loss: 1.1269 - val_accuracy: 0.4156 - 320ms/epoch - 46ms/step\n",
      "Epoch 35/10000\n",
      "7/7 - 0s - loss: 1.0967 - accuracy: 0.5213 - val_loss: 1.1235 - val_accuracy: 0.3896 - 302ms/epoch - 43ms/step\n",
      "Epoch 36/10000\n",
      "7/7 - 0s - loss: 1.1123 - accuracy: 0.5148 - val_loss: 1.1140 - val_accuracy: 0.4935 - 303ms/epoch - 43ms/step\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0113 - accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-27 11:01:39,937] Trial 99 finished with value: 0.6617646813392639 and parameters: {'activation_func_1': 'swish', 'activation_func_2': 'swish', 'activation_func_3': 'relu', 'batch_size': 50, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 146}. Best is trial 14 with value: 0.7058823704719543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 2120.02 seconds\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(storage='sqlite:///db.sqlite3', \n",
    "                            study_name='LSTM_magnitude_change_7_day_lag_3_day_window',\n",
    "                            direction='maximize')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Elapsed Time: {elapsed_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12ec5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation_func_1': 'selu', 'activation_func_2': 'swish', 'activation_func_3': 'linear', 'batch_size': 32, 'dropout_1': 0.25, 'dropout_2': 0.5, 'dropout_3': 0.5, 'neurons': 160}\n",
      "Best Validation Accuracy: 0.7058823704719543\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_accuracy = study.best_value\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Validation Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1435a3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "10/10 - 5s - loss: 1.3846 - accuracy: 0.2820 - val_loss: 1.3810 - val_accuracy: 0.3896 - 5s/epoch - 515ms/step\n",
      "Epoch 2/10000\n",
      "10/10 - 0s - loss: 1.3753 - accuracy: 0.4623 - val_loss: 1.3630 - val_accuracy: 0.4286 - 352ms/epoch - 35ms/step\n",
      "Epoch 3/10000\n",
      "10/10 - 0s - loss: 1.3363 - accuracy: 0.4951 - val_loss: 1.2966 - val_accuracy: 0.4286 - 350ms/epoch - 35ms/step\n",
      "Epoch 4/10000\n",
      "10/10 - 0s - loss: 1.2770 - accuracy: 0.4852 - val_loss: 1.2589 - val_accuracy: 0.3896 - 353ms/epoch - 35ms/step\n",
      "Epoch 5/10000\n",
      "10/10 - 0s - loss: 1.2371 - accuracy: 0.4689 - val_loss: 1.2393 - val_accuracy: 0.4156 - 341ms/epoch - 34ms/step\n",
      "Epoch 6/10000\n",
      "10/10 - 0s - loss: 1.2120 - accuracy: 0.5016 - val_loss: 1.2267 - val_accuracy: 0.4026 - 347ms/epoch - 35ms/step\n",
      "Epoch 7/10000\n",
      "10/10 - 0s - loss: 1.1852 - accuracy: 0.4918 - val_loss: 1.2128 - val_accuracy: 0.4156 - 344ms/epoch - 34ms/step\n",
      "Epoch 8/10000\n",
      "10/10 - 0s - loss: 1.1984 - accuracy: 0.4820 - val_loss: 1.1982 - val_accuracy: 0.3896 - 349ms/epoch - 35ms/step\n",
      "Epoch 9/10000\n",
      "10/10 - 0s - loss: 1.2045 - accuracy: 0.5180 - val_loss: 1.2049 - val_accuracy: 0.3896 - 357ms/epoch - 36ms/step\n",
      "Epoch 10/10000\n",
      "10/10 - 0s - loss: 1.1875 - accuracy: 0.4951 - val_loss: 1.1568 - val_accuracy: 0.3896 - 356ms/epoch - 36ms/step\n",
      "Epoch 11/10000\n",
      "10/10 - 0s - loss: 1.1537 - accuracy: 0.5115 - val_loss: 1.1752 - val_accuracy: 0.4026 - 361ms/epoch - 36ms/step\n",
      "Epoch 12/10000\n",
      "10/10 - 0s - loss: 1.1441 - accuracy: 0.5049 - val_loss: 1.1640 - val_accuracy: 0.3766 - 346ms/epoch - 35ms/step\n",
      "Epoch 13/10000\n",
      "10/10 - 0s - loss: 1.1227 - accuracy: 0.5082 - val_loss: 1.1313 - val_accuracy: 0.4026 - 341ms/epoch - 34ms/step\n",
      "Epoch 14/10000\n",
      "10/10 - 0s - loss: 1.1077 - accuracy: 0.5279 - val_loss: 1.1092 - val_accuracy: 0.4286 - 343ms/epoch - 34ms/step\n",
      "Epoch 15/10000\n",
      "10/10 - 0s - loss: 1.1494 - accuracy: 0.5311 - val_loss: 1.1419 - val_accuracy: 0.4675 - 346ms/epoch - 35ms/step\n",
      "Epoch 16/10000\n",
      "10/10 - 0s - loss: 1.1427 - accuracy: 0.5541 - val_loss: 1.0958 - val_accuracy: 0.4156 - 363ms/epoch - 36ms/step\n",
      "Epoch 17/10000\n",
      "10/10 - 0s - loss: 1.0938 - accuracy: 0.5410 - val_loss: 1.0959 - val_accuracy: 0.4286 - 374ms/epoch - 37ms/step\n",
      "Epoch 18/10000\n",
      "10/10 - 0s - loss: 1.0675 - accuracy: 0.5475 - val_loss: 1.0721 - val_accuracy: 0.4805 - 372ms/epoch - 37ms/step\n",
      "Epoch 19/10000\n",
      "10/10 - 0s - loss: 1.0939 - accuracy: 0.5475 - val_loss: 1.0697 - val_accuracy: 0.4675 - 364ms/epoch - 36ms/step\n",
      "Epoch 20/10000\n",
      "10/10 - 0s - loss: 1.0459 - accuracy: 0.5607 - val_loss: 1.0544 - val_accuracy: 0.5195 - 363ms/epoch - 36ms/step\n",
      "Epoch 21/10000\n",
      "10/10 - 0s - loss: 1.0368 - accuracy: 0.5869 - val_loss: 1.0500 - val_accuracy: 0.4805 - 353ms/epoch - 35ms/step\n",
      "Epoch 22/10000\n",
      "10/10 - 0s - loss: 1.0369 - accuracy: 0.5934 - val_loss: 1.0063 - val_accuracy: 0.4935 - 366ms/epoch - 37ms/step\n",
      "Epoch 23/10000\n",
      "10/10 - 0s - loss: 1.0137 - accuracy: 0.5934 - val_loss: 0.9957 - val_accuracy: 0.5065 - 306ms/epoch - 31ms/step\n",
      "Epoch 24/10000\n",
      "10/10 - 0s - loss: 1.0000 - accuracy: 0.5967 - val_loss: 0.9762 - val_accuracy: 0.5325 - 308ms/epoch - 31ms/step\n",
      "Epoch 25/10000\n",
      "10/10 - 0s - loss: 0.9634 - accuracy: 0.6230 - val_loss: 0.9612 - val_accuracy: 0.5844 - 320ms/epoch - 32ms/step\n",
      "Epoch 26/10000\n",
      "10/10 - 0s - loss: 0.9778 - accuracy: 0.5967 - val_loss: 0.8933 - val_accuracy: 0.6494 - 317ms/epoch - 32ms/step\n",
      "Epoch 27/10000\n",
      "10/10 - 0s - loss: 0.9315 - accuracy: 0.6197 - val_loss: 0.9399 - val_accuracy: 0.5325 - 331ms/epoch - 33ms/step\n",
      "Epoch 28/10000\n",
      "10/10 - 0s - loss: 0.9048 - accuracy: 0.6459 - val_loss: 0.8647 - val_accuracy: 0.6234 - 313ms/epoch - 31ms/step\n",
      "Epoch 29/10000\n",
      "10/10 - 0s - loss: 0.8824 - accuracy: 0.6492 - val_loss: 0.8981 - val_accuracy: 0.5714 - 317ms/epoch - 32ms/step\n",
      "Epoch 30/10000\n",
      "10/10 - 0s - loss: 0.9258 - accuracy: 0.6066 - val_loss: 0.8928 - val_accuracy: 0.6494 - 311ms/epoch - 31ms/step\n",
      "Epoch 31/10000\n",
      "10/10 - 0s - loss: 0.9124 - accuracy: 0.6426 - val_loss: 0.8993 - val_accuracy: 0.6364 - 318ms/epoch - 32ms/step\n",
      "Epoch 32/10000\n",
      "10/10 - 0s - loss: 0.9215 - accuracy: 0.6262 - val_loss: 0.9314 - val_accuracy: 0.6234 - 318ms/epoch - 32ms/step\n",
      "Epoch 33/10000\n",
      "10/10 - 0s - loss: 0.9676 - accuracy: 0.5770 - val_loss: 0.9391 - val_accuracy: 0.5455 - 317ms/epoch - 32ms/step\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9075 - accuracy: 0.6471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9074902534484863, 0.6470588445663452]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a model using best hyperparameters\n",
    "neurons = best_params['neurons']\n",
    "dropout_1 = best_params['dropout_1']\n",
    "dropout_2 = best_params['dropout_2']\n",
    "dropout_3 = best_params['dropout_3']\n",
    "activation_func_1 = best_params['activation_func_1']\n",
    "activation_func_2 = best_params['activation_func_2']\n",
    "activation_func_3 = best_params['activation_func_3']\n",
    "batch_size = best_params['batch_size']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(neurons, \n",
    "                return_sequences=True, \n",
    "                input_shape=(X_train.shape[1], \n",
    "                                X_train.shape[2]), \n",
    "                activation=activation_func_1))\n",
    "model.add(Dropout(dropout_1))\n",
    "model.add(LSTM(neurons, \n",
    "                return_sequences=True, \n",
    "                activation=activation_func_2))\n",
    "model.add(Dropout(dropout_2))\n",
    "model.add(LSTM(neurons, \n",
    "                return_sequences=False,  \n",
    "                activation=activation_func_3))\n",
    "model.add(Dropout(dropout_3))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs=EPOCHS,\n",
    "          batch_size=batch_size, \n",
    "          verbose=2, \n",
    "          shuffle=True,\n",
    "          validation_split=0.2, \n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Test the model\n",
    "model.evaluate(X_test, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d07e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_magnitude_7_day_lag_3_day_window\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_magnitude_7_day_lag_3_day_window\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm_magnitude_7_day_lag_3_day_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4184b98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss graph\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d365433d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy graph\n",
    "accuracy_train = history.history['accuracy']\n",
    "accuracy_val = history.history['val_accuracy']\n",
    "epochs = range(1,len(accuracy_val) + 1)\n",
    "plt.plot(epochs, accuracy_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, accuracy_val, 'b', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8821eae4",
   "metadata": {},
   "source": [
    "### Model's metrics on 20 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f1cdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "310502ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = lagged_data.sample(frac=1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0197ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = 20\n",
    "datasets = np.array_split(shuffled_df, num_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45a40f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "xscaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d399916",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_model('lstm_magnitude_7_day_lag_3_day_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adad6e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_300 (LSTM)             (None, 3, 160)            106240    \n",
      "                                                                 \n",
      " dropout_300 (Dropout)       (None, 3, 160)            0         \n",
      "                                                                 \n",
      " lstm_301 (LSTM)             (None, 3, 160)            205440    \n",
      "                                                                 \n",
      " dropout_301 (Dropout)       (None, 3, 160)            0         \n",
      "                                                                 \n",
      " lstm_302 (LSTM)             (None, 160)               205440    \n",
      "                                                                 \n",
      " dropout_302 (Dropout)       (None, 160)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 4)                 644       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 517,764\n",
      "Trainable params: 517,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e00a2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_precision_list = []\n",
    "micro_recall_list = []\n",
    "micro_f1_list = []\n",
    "\n",
    "macro_precision_list = []\n",
    "macro_recall_list = []\n",
    "macro_f1_list = []\n",
    "\n",
    "weighted_precision_list = []\n",
    "weighted_recall_list = []\n",
    "weighted_f1_list = []\n",
    "\n",
    "samples_precision_list = []\n",
    "samples_recall_list = []\n",
    "samples_f1_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "721ce375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 590ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    X = dataset.iloc[:, :total_features].values\n",
    "    y = dataset['feature1(t)'].values\n",
    "    X = xscaler.fit_transform(X)\n",
    "    X = X.reshape((X.shape[0], n_lag, n_features))\n",
    "    \n",
    "    y_pred = saved_model.predict(X)\n",
    "    y_true = keras.utils.to_categorical(y, 4)\n",
    "    \n",
    "    max_indices = np.argmax(y_pred, axis=1)\n",
    "    one_hot_encoded = np.zeros_like(y_pred)\n",
    "    one_hot_encoded[np.arange(len(y_pred)), max_indices] = 1\n",
    "    \n",
    "    report = classification_report(y_true, one_hot_encoded, output_dict=True, zero_division=0)\n",
    "    \n",
    "    micro_precision_list.append(report['micro avg']['precision'])\n",
    "    micro_recall_list.append(report['micro avg']['recall'])\n",
    "    micro_f1_list.append(report['micro avg']['f1-score'])\n",
    "    \n",
    "    macro_precision_list.append(report['macro avg']['precision'])\n",
    "    macro_recall_list.append(report['macro avg']['recall'])\n",
    "    macro_f1_list.append(report['macro avg']['f1-score'])\n",
    "    \n",
    "    weighted_precision_list.append(report['weighted avg']['precision'])\n",
    "    weighted_recall_list.append(report['weighted avg']['recall'])\n",
    "    weighted_f1_list.append(report['weighted avg']['f1-score'])\n",
    "    \n",
    "    samples_precision_list.append(report['samples avg']['precision'])\n",
    "    samples_recall_list.append(report['samples avg']['recall'])\n",
    "    samples_f1_list.append(report['samples avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10575273",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_micro_precision = np.mean(micro_precision_list)\n",
    "avg_micro_recall = np.mean(micro_recall_list)\n",
    "avg_micro_f1 = np.mean(micro_f1_list)\n",
    "\n",
    "avg_macro_precision = np.mean(macro_precision_list)\n",
    "avg_macro_recall = np.mean(macro_recall_list)\n",
    "avg_macro_f1 = np.mean(macro_f1_list)\n",
    "\n",
    "avg_weighted_precision = np.mean(weighted_precision_list)\n",
    "avg_weighted_recall = np.mean(weighted_recall_list)\n",
    "avg_weighted_f1 = np.mean(weighted_f1_list)\n",
    "\n",
    "avg_samples_precision = np.mean(samples_precision_list)\n",
    "avg_samples_recall = np.mean(samples_recall_list)\n",
    "avg_samples_f1 = np.mean(samples_f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b75e8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro\n",
      "Average Micro Precision: 0.5968379446640316\n",
      "Average Micro Recall: 0.5968379446640316\n",
      "Average Micro F1-score: 0.5968379446640315\n",
      "\n",
      "\n",
      "Macro\n",
      "Average Macro Precision: 0.6041904623154624\n",
      "Average Macro Recall: 0.6170535714285714\n",
      "Average Macro F1-score: 0.5680086514437537\n",
      "\n",
      "\n",
      "Weighted\n",
      "Average Weighted Precision: 0.6255794293541329\n",
      "Average Weighted Recall: 0.5968379446640316\n",
      "Average Weighted F1-score: 0.5683296336980516\n",
      "\n",
      "\n",
      "Samples\n",
      "Average Samples Precision: 0.5968379446640316\n",
      "Average Samples Recall: 0.5968379446640316\n",
      "Average Samples F1-score: 0.5968379446640316\n"
     ]
    }
   ],
   "source": [
    "print('Micro')\n",
    "print(f'Average Micro Precision: {avg_micro_precision}')\n",
    "print(f'Average Micro Recall: {avg_micro_recall}')\n",
    "print(f'Average Micro F1-score: {avg_micro_f1}')\n",
    "\n",
    "print('\\n\\nMacro')\n",
    "print(f'Average Macro Precision: {avg_macro_precision}')\n",
    "print(f'Average Macro Recall: {avg_macro_recall}')\n",
    "print(f'Average Macro F1-score: {avg_macro_f1}')\n",
    "\n",
    "print('\\n\\nWeighted')\n",
    "print(f'Average Weighted Precision: {avg_weighted_precision}')\n",
    "print(f'Average Weighted Recall: {avg_weighted_recall}')\n",
    "print(f'Average Weighted F1-score: {avg_weighted_f1}')\n",
    "\n",
    "print('\\n\\nSamples')\n",
    "print(f'Average Samples Precision: {avg_samples_precision}')\n",
    "print(f'Average Samples Recall: {avg_samples_recall}')\n",
    "print(f'Average Samples F1-score: {avg_samples_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c26c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'micro_precision': micro_precision_list,\n",
    "    'micro_recall': micro_recall_list,\n",
    "    'micro_f1': micro_f1_list,\n",
    "    'macro_precision': macro_precision_list,\n",
    "    'macro_recall': macro_recall_list,\n",
    "    'macro_f1': macro_f1_list,\n",
    "    'weighted_precision': weighted_precision_list,\n",
    "    'weighted_recall': weighted_recall_list,\n",
    "    'weighted_f1': weighted_f1_list,\n",
    "    'samples_precision': samples_precision_list,\n",
    "    'samples_recall': samples_recall_list,\n",
    "    'samples_f1': samples_f1_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3218158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3df4de16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>samples_precision</th>\n",
       "      <th>samples_recall</th>\n",
       "      <th>samples_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.597436</td>\n",
       "      <td>0.606211</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.679167</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.605429</td>\n",
       "      <td>0.682609</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.586078</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.664916</td>\n",
       "      <td>0.721187</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.654914</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.631410</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.500414</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.562625</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.563194</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.612132</td>\n",
       "      <td>0.653140</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.688619</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.843434</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.681349</td>\n",
       "      <td>0.832235</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.700690</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.622619</td>\n",
       "      <td>0.622024</td>\n",
       "      <td>0.689441</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.637164</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.404167</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.436232</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.400778</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.718452</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.711310</td>\n",
       "      <td>0.751346</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.732402</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.525794</td>\n",
       "      <td>0.532738</td>\n",
       "      <td>0.519986</td>\n",
       "      <td>0.543823</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.544924</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.622619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.620915</td>\n",
       "      <td>0.694156</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.644088</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.400298</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.387762</td>\n",
       "      <td>0.419102</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.377305</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.501488</td>\n",
       "      <td>0.586905</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.549242</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.587367</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>0.551190</td>\n",
       "      <td>0.532814</td>\n",
       "      <td>0.640909</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.538850</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.574242</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.564426</td>\n",
       "      <td>0.575207</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466106</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.620238</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.617542</td>\n",
       "      <td>0.615152</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.592781</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.540179</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.425253</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538690</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.704861</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.763258</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.582576</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    micro_precision  micro_recall  micro_f1  macro_precision  macro_recall  \\\n",
       "0          0.695652      0.695652  0.695652         0.564286      0.637500   \n",
       "1          0.608696      0.608696  0.608696         0.679167      0.642857   \n",
       "2          0.652174      0.652174  0.652174         0.746032      0.656250   \n",
       "3          0.608696      0.608696  0.608696         0.631410      0.537500   \n",
       "4          0.739130      0.739130  0.739130         0.563194      0.687500   \n",
       "5          0.739130      0.739130  0.739130         0.843434      0.696429   \n",
       "6          0.652174      0.652174  0.652174         0.726190      0.622619   \n",
       "7          0.391304      0.391304  0.391304         0.404167      0.391667   \n",
       "8          0.739130      0.739130  0.739130         0.718452      0.729167   \n",
       "9          0.565217      0.565217  0.565217         0.525794      0.532738   \n",
       "10         0.636364      0.636364  0.636364         0.622619      0.666667   \n",
       "11         0.409091      0.409091  0.409091         0.400298      0.447917   \n",
       "12         0.636364      0.636364  0.636364         0.501488      0.586905   \n",
       "13         0.545455      0.545455  0.545455         0.617857      0.551190   \n",
       "14         0.636364      0.636364  0.636364         0.645833      0.677083   \n",
       "15         0.500000      0.500000  0.500000         0.574242      0.687500   \n",
       "16         0.636364      0.636364  0.636364         0.620238      0.684524   \n",
       "17         0.409091      0.409091  0.409091         0.455556      0.540179   \n",
       "18         0.500000      0.500000  0.500000         0.538690      0.662500   \n",
       "19         0.636364      0.636364  0.636364         0.704861      0.702381   \n",
       "\n",
       "    macro_f1  weighted_precision  weighted_recall  weighted_f1  \\\n",
       "0   0.597436            0.606211         0.695652     0.646600   \n",
       "1   0.605429            0.682609         0.608696     0.586078   \n",
       "2   0.664916            0.721187         0.652174     0.654914   \n",
       "3   0.500414            0.692308         0.608696     0.562625   \n",
       "4   0.612132            0.653140         0.739130     0.688619   \n",
       "5   0.681349            0.832235         0.739130     0.700690   \n",
       "6   0.622024            0.689441         0.652174     0.637164   \n",
       "7   0.382756            0.436232         0.391304     0.400778   \n",
       "8   0.711310            0.751346         0.739130     0.732402   \n",
       "9   0.519986            0.543823         0.565217     0.544924   \n",
       "10  0.620915            0.694156         0.636364     0.644088   \n",
       "11  0.387762            0.419102         0.409091     0.377305   \n",
       "12  0.538961            0.549242         0.636364     0.587367   \n",
       "13  0.532814            0.640909         0.545455     0.538850   \n",
       "14  0.633333            0.681818         0.636364     0.627273   \n",
       "15  0.564426            0.575207         0.500000     0.466106   \n",
       "16  0.617542            0.615152         0.636364     0.592781   \n",
       "17  0.450000            0.425253         0.409091     0.363636   \n",
       "18  0.520833            0.538961         0.500000     0.431818   \n",
       "19  0.595833            0.763258         0.636364     0.582576   \n",
       "\n",
       "    samples_precision  samples_recall  samples_f1  \n",
       "0            0.695652        0.695652    0.695652  \n",
       "1            0.608696        0.608696    0.608696  \n",
       "2            0.652174        0.652174    0.652174  \n",
       "3            0.608696        0.608696    0.608696  \n",
       "4            0.739130        0.739130    0.739130  \n",
       "5            0.739130        0.739130    0.739130  \n",
       "6            0.652174        0.652174    0.652174  \n",
       "7            0.391304        0.391304    0.391304  \n",
       "8            0.739130        0.739130    0.739130  \n",
       "9            0.565217        0.565217    0.565217  \n",
       "10           0.636364        0.636364    0.636364  \n",
       "11           0.409091        0.409091    0.409091  \n",
       "12           0.636364        0.636364    0.636364  \n",
       "13           0.545455        0.545455    0.545455  \n",
       "14           0.636364        0.636364    0.636364  \n",
       "15           0.500000        0.500000    0.500000  \n",
       "16           0.636364        0.636364    0.636364  \n",
       "17           0.409091        0.409091    0.409091  \n",
       "18           0.500000        0.500000    0.500000  \n",
       "19           0.636364        0.636364    0.636364  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6cfc4d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Values:\n",
      "micro_precision       0.391304\n",
      "micro_recall          0.391304\n",
      "micro_f1              0.391304\n",
      "macro_precision       0.400298\n",
      "macro_recall          0.391667\n",
      "macro_f1              0.382756\n",
      "weighted_precision    0.419102\n",
      "weighted_recall       0.391304\n",
      "weighted_f1           0.363636\n",
      "samples_precision     0.391304\n",
      "samples_recall        0.391304\n",
      "samples_f1            0.391304\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Maximum Values:\n",
      "micro_precision       0.739130\n",
      "micro_recall          0.739130\n",
      "micro_f1              0.739130\n",
      "macro_precision       0.843434\n",
      "macro_recall          0.729167\n",
      "macro_f1              0.711310\n",
      "weighted_precision    0.832235\n",
      "weighted_recall       0.739130\n",
      "weighted_f1           0.732402\n",
      "samples_precision     0.739130\n",
      "samples_recall        0.739130\n",
      "samples_f1            0.739130\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the minimum value of each column\n",
    "min_values = metrics_df.min()\n",
    "\n",
    "# Get the maximum value of each column\n",
    "max_values = metrics_df.max()\n",
    "\n",
    "print('Minimum Values:')\n",
    "print(min_values)\n",
    "\n",
    "print('\\n\\nMaximum Values:')\n",
    "print(max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8d69993",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('metrics/LSTM magnitude 7 day lag 3 day window.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249f985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
